{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange; font-weight:bold\">Note: To answer questions based on text documents, we recommend the procedure in <a href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\">Question Answering using Embeddings</a>. Some of the code below may rely on <a href=\"https://github.com/openai/openai-cookbook/tree/main/transition_guides_for_deprecated_API_endpoints\">deprecated API endpoints</a>.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tiktoken.get_encoding() to load an encoding by name.\n",
    "\n",
    "The first time this runs, it will require an internet connection to download. Later runs won't need an internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tiktoken.encoding_for_model() to automatically load the correct encoding for a given model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai_token.txt\", 'r') as fp:\n",
    "    openai_token = fp.readline()\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = openai_token\n",
    "# Set the environment variable\n",
    "#os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(sentence):\n",
    "    return ''.join(char for char in sentence if ord(char) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt/prompt_system_etd_gpt3.txt', 'r') as fp:\n",
    "    etd_system = fp.readlines()\n",
    "    \n",
    "with open('prompt/prompt_system_ps.txt', 'r') as fp:\n",
    "    ps_system = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use the following step-by-step instructions to respond to user inputs.  \\n 1.Identify sentences describing the program\\'s anticipated behavior or the user\\'s expectation in detail, typically containing patterns such as \\'trying/try/tried to do\\', \\'want/wanted to do\\', \\'need to do\\', \\'would like to do\\', an interrogative sentence starting with any of the phrases \\'how do I\\', \\'how to\\', \\'can I\\', \\'is there a way to\\'. Sentences only describing the system error or undesired behavior should not be considered, such as \\'any idea why...\\' or \\'doesn\\'t work\\'. Sentences missing details of anticipated behavior should also not be considered, such as \\'please help me ...\\'. If such sentences are found, proceed to Step 2. Otherwise, return \\'No sentences found to indicate the user\\'s expectation. The answer is NO.\\' \\n 2.Summarize the sentences into one or more patterns like \\'trying to VB\\' using keywords and part-of-speech tags. Then explain why the found sentences contain patterns like \\'trying to do\\' to describe the program\\'s anticipated behavior or the user\\'s expectation. \\n 3.Use the following format to respond to user inputs: The sentence \"\"\"insert found sentence here\"\"\" uses <pattern>insert pattern here</pattern> to indicate ... The answer is YES.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(etd_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_user_etd_len = num_tokens_from_string(\" \".join(etd_system), \"cl100k_base\")\n",
    "total_user_etd_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(ps_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user_ps_len = num_tokens_from_string(\" \".join(ps_system), \"cl100k_base\")\n",
    "total_user_ps_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue = pd.read_csv(\"prompt/issue.csv\", encoding = \"ISO-8859-1\")\n",
    "# df_issue = pd.read_csv(\"prompt/issue_wrong.csv\")\n",
    "\n",
    "df_etd_example = pd.read_csv(\"experiment/OpenAI/random_issue/ETD/etd_prompt_gemini_revised.csv\")\n",
    "# df_ps_example = pd.read_csv(\"experiment/random_pattern/PS/ps_prompt_random_with_neg1.1.csv\")\n",
    "#df_etd_example = pd.read_csv(\"experiment/frequent/ETD/etd_prompt_frequent1.csv\")\n",
    "#df_ps_example = pd.read_csv(\"experiment/frequent/PS/ps_prompt_frequent1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, when I am trying to apply class dynamicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is it possible to get a RouteConfig matched ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have angular running from a .Net Core server...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello everyone, I want to do sub menu with sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm struggling with getting this logic [code]....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               issue\n",
       "0  Hi, when I am trying to apply class dynamicall...\n",
       "1  is it possible to get a RouteConfig matched ag...\n",
       "2  I have angular running from a .Net Core server...\n",
       "3  Hello everyone, I want to do sub menu with sea...\n",
       "4  I'm struggling with getting this logic [code]...."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_clean = [remove_non_ascii(issue) for issue in df_issue[\"issue\"]]\n",
    "df_issue[\"issue\"] = issue_clean\n",
    "df_issue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for all examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_issue = list(df_etd_example[\"issue\"].values)\n",
    "chat_issue = list(df_ps_example[\"issue\"].values)\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_output = list(df_etd_example[\"output\"].values)\n",
    "chat_output = list(df_ps_example[\"output\"].values)\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for random/frequent pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\"\" Hi, I\\'m trying to import my wallet. When i drag and drop my keystore file it flashes importing but nothing shows up in the mist wallet. Does it need my passcode or something else? I also sent Eth when my wallet wasnt synced. Will the transaction go throgh? \"\"\"']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etd_randexample = df_etd_example[df_etd_example[\"1_example\"]==1]\n",
    "\n",
    "chat_issue = list(df_etd_randexample[\"issue\"].values)\n",
    "# chat_issue = [\"Question: \" + q_str + \"\\nAnswer: \" for q_str in list(df_etd_randexample[\"issue\"].values)]\n",
    "# chat_issue.extend(list(df_etd_randexample[\"issue_n\"].values))\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sentence \"\"\" I\\'m trying to import my wallet \"\"\" uses <pattern>trying to VB</pattern> to indicate that the user expects to \"import my wallet\". The answer is YES.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_output = list(df_etd_randexample[\"output\"].values)\n",
    "# chat_output.extend(list(df_etd_randexample[\"output_n\"].values))\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps_randexample = df_ps_example[df_ps_example[\"2_examples\"]==1]\n",
    "\n",
    "chat_issue = list(df_ps_randexample[\"issue\"].values)\n",
    "# chat_issue.extend(list(df_ps_randexample[\"issue_n\"].values))\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_output = list(df_ps_randexample[\"output\"].values)\n",
    "# chat_output.extend(list(df_ps_randexample[\"output_n\"].values))\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_string,output_string in zip(chat_issue,chat_output):\n",
    "    total_user_etd_len += num_tokens_from_string(user_string,\"cl100k_base\")\n",
    "    total_user_etd_len += num_tokens_from_string(output_string,\"cl100k_base\")\n",
    "    \n",
    "print(\"ETD total input token:\",total_user_etd_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS total input token: 487\n"
     ]
    }
   ],
   "source": [
    "for user_string,output_string in zip(chat_issue,chat_output):\n",
    "    total_user_ps_len += num_tokens_from_string(user_string,\"cl100k_base\")\n",
    "    total_user_ps_len += num_tokens_from_string(output_string,\"cl100k_base\")\n",
    "    \n",
    "print(\"PS total input token:\",total_user_ps_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans1= []\n",
    "start_i = 635\n",
    "flag = True\n",
    "while flag:\n",
    "    try:\n",
    "        for i in range(start_i,len(df_issue),1):\n",
    "#         for i in range(start_i,start_i+7,1):\n",
    "            issue = df_issue.loc[i][\"issue\"]\n",
    "            input_str = \"\\\"\\\"\\\" {} \\\"\\\"\\\"\".format(issue)\n",
    "    \n",
    "            result = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "            {\"role\": \"system\", \"content\": \" \".join(etd_system)},\n",
    "#             {\"role\": \"system\", \"content\": \" \".join(ps_system)},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[0]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[0]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[1]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[1]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[2]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[2]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[3]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[3]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[4]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[4]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[5]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[5]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[6]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[6]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[7]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[7]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[8]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[8]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[9]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[9]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[10]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[10]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[11]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[11]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[12]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[12]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[13]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[13]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[14]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[14]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[15]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[15]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[16]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[16]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[17]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[17]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[18]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[18]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[19]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[19]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[20]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[20]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[21]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[21]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[22]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[22]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[23]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[23]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[24]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[24]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[25]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[25]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[26]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[26]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[27]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[27]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[28]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[28]},\n",
    "            {\"role\": \"user\", \"content\": input_str},\n",
    "                ],\n",
    "                max_tokens = 300,\n",
    "                temperature = 0.8,\n",
    "#                 seed = 30\n",
    "        )\n",
    "    \n",
    "            ans1.append(result['choices'][0]['message']['content'])\n",
    "        \n",
    "        flag = False\n",
    "    except openai.error.RateLimitError as e:\n",
    "        print(f\"RateLimitError: {e}\")\n",
    "        time.sleep(60)\n",
    "        start_i = len(ans1)+635\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break  # Exit the loop on other errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1= []\n",
    "\n",
    "for i in range(len(df_issue)):\n",
    "    issue = df_issue.loc[i][\"issue\"]\n",
    "    input_str = \"Question: \\\"\\\"\\\" {} \\\"\\\"\\\"\\n Answer: \".format(issue)\n",
    "    \n",
    "    result = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \" \".join(etd_system)},\n",
    "#             {\"role\": \"system\", \"content\": \" \".join(ps_system)},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[0]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[0]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[1]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[1]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[2]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[2]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[3]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[3]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[4]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[4]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[5]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[5]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[6]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[6]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[7]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[7]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[8]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[8]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[9]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[9]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[10]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[10]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[11]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[11]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[12]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[12]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[13]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[13]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[14]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[14]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[15]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[15]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[16]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[16]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[17]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[17]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[18]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[18]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[19]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[19]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[20]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[20]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[21]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[21]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[22]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[22]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[23]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[23]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[24]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[24]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[25]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[25]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[26]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[26]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[27]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[27]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[28]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[28]},\n",
    "            {\"role\": \"user\", \"content\": input_str},\n",
    "            ],\n",
    "        max_tokens = 100,\n",
    "        temperature = 0\n",
    "    )\n",
    "    \n",
    "    ans1.append(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "print(len(ans1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The sentence \"now when trying to build 0.6.1-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>No sentences found to indicate the user's expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer1\n",
       "0  No sentences found to indicate the user's expe...\n",
       "1  No sentences found to indicate the user's expe...\n",
       "2  No sentences found to indicate the user's expe...\n",
       "3  No sentences found to indicate the user's expe...\n",
       "4  No sentences found to indicate the user's expe...\n",
       "5  No sentences found to indicate the user's expe...\n",
       "6  No sentences found to indicate the user's expe...\n",
       "7  The sentence \"now when trying to build 0.6.1-S...\n",
       "8  No sentences found to indicate the user's expe...\n",
       "9  No sentences found to indicate the user's expe..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"answer1\"] = ans1\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"experiment/OpenAI/random_issue/answer_rand.csv\",index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.531 recall: 0.953 F1: 0.682\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../Data/chat_pattern/chat_test_missing_1000.csv\")\n",
    "predictions_etd = df_test[\"y''_ETD\"]\n",
    "y_test = df_test[\"y_ETD\"]\n",
    "precison_etd = mt.precision_score(y_test, predictions_etd)\n",
    "recall_etd = mt.recall_score(y_test, predictions_etd)\n",
    "score_etd = mt.f1_score(y_test, predictions_etd)\n",
    "\n",
    "print(\"precision:\",round(precison_etd,3),\"recall:\",round(recall_etd,3),\"F1:\",round(score_etd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.827 recall: 0.728 F1: 0.775\n"
     ]
    }
   ],
   "source": [
    "predictions = df_test[\"y'_PS\"]\n",
    "y_test = df_test[\"y_PS\"]\n",
    "precison_ps = mt.precision_score(y_test, predictions)\n",
    "recall_ps = mt.recall_score(y_test, predictions)\n",
    "score_ps = mt.f1_score(y_test, predictions)\n",
    "\n",
    "print(\"precision:\",round(precison_ps,3),\"recall:\",round(recall_ps,3),\"F1:\",round(score_ps,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.77 recall: 0.485 F1: 0.595\n"
     ]
    }
   ],
   "source": [
    "# ETD results\n",
    "\n",
    "df_test_random = pd.read_csv(\"experiment/random_pattern/ETD/result_missing/etd_random_withneg12_result(t=0.8).csv\")\n",
    "predictions_etd = df_test_random[\"y''_ETD\"]\n",
    "y_test = df_test_random[\"y_ETD\"]\n",
    "precison_etd = mt.precision_score(y_test, predictions_etd)\n",
    "recall_etd = mt.recall_score(y_test, predictions_etd)\n",
    "score_etd = mt.f1_score(y_test, predictions_etd)\n",
    "\n",
    "print(\"precision:\",round(precison_etd,3),\"recall:\",round(recall_etd,3),\"F1:\",round(score_etd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.351 recall: 0.978 F1: 0.517\n"
     ]
    }
   ],
   "source": [
    "# ETD results\n",
    "\n",
    "df_test_random = pd.read_csv(\"experiment/OpenAI/random_issue/ETD/etd_random_0example_gpt3.5_result(t=0).csv\")\n",
    "predictions_etd = df_test_random[\"y''_ETD\"]\n",
    "y_test = df_test_random[\"y_ETD\"]\n",
    "precison_etd = mt.precision_score(y_test, predictions_etd)\n",
    "recall_etd = mt.recall_score(y_test, predictions_etd)\n",
    "score_etd = mt.f1_score(y_test, predictions_etd)\n",
    "\n",
    "print(\"precision:\",round(precison_etd,3),\"recall:\",round(recall_etd,3),\"F1:\",round(score_etd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.876 recall: 0.679 F1: 0.765\n"
     ]
    }
   ],
   "source": [
    "# PS results \n",
    "\n",
    "df_test_random = pd.read_csv(\"experiment/OpenAI/random_pattern/PS/result_missing/ps_random_withneg12_result(t=0.8).csv\")\n",
    "predictions_ps = df_test_random[\"y''_PS\"]\n",
    "y_test = df_test_random[\"y_PS\"]\n",
    "precison_ps = mt.precision_score(y_test, predictions_ps)\n",
    "recall_ps = mt.recall_score(y_test, predictions_ps)\n",
    "score_ps = mt.f1_score(y_test, predictions_ps)\n",
    "\n",
    "print(\"precision:\",round(precison_ps,3),\"recall:\",round(recall_ps,3),\"F1:\",round(score_ps,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9817b186a29e4e9713184d901f26c1ee05ad25243d878baff7f31bb1fef480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
