{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange; font-weight:bold\">Note: To answer questions based on text documents, we recommend the procedure in <a href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\">Question Answering using Embeddings</a>. Some of the code below may rely on <a href=\"https://github.com/openai/openai-cookbook/tree/main/transition_guides_for_deprecated_API_endpoints\">deprecated API endpoints</a>.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tiktoken.get_encoding() to load an encoding by name.\n",
    "\n",
    "The first time this runs, it will require an internet connection to download. Later runs won't need an internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tiktoken.encoding_for_model() to automatically load the correct encoding for a given model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai_token.txt\", 'r') as fp:\n",
    "    openai_token = fp.readline()\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = openai_token\n",
    "# Set the environment variable\n",
    "#os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(sentence):\n",
    "    return ''.join(char for char in sentence if ord(char) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt/prompt_system_etd.txt', 'r') as fp:\n",
    "    etd_system = fp.readlines()\n",
    "    \n",
    "with open('prompt/prompt_system_ps.txt', 'r') as fp:\n",
    "    ps_system = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use the following step-by-step instructions to respond to user inputs.\\n \\n Step 1 - The user will provide you with text in triple quotes (Question: \"\"\"insert text here\"\"\"). Find one sentence from the given text which can indicate the answer to \"What is the user expecting to do or achieve?\". The sentence only describing the system error or undesired behavior should not be considered. Use triple quotes to cite the found sentence. If the given text does not contain such sentence, write \"No sentences found to indicate the user\\'s expectation. The answer is NO.\" and skip Step 2 and Step 3.\\n \\n Step 2 - If found one sentence from Step 1, \\n summarize the sentence into one or more patterns delimited by <pattern>..</pattern> according to the syntax and semantic of the sentence. The pattern could be expressed by some keywords and part-of-speech tags from the found sentence, which can explain why this sentence provides the answer to \"What is the user expecting to do or achieve?\".\\n \\n Step 3 - Use the following format to respond to user inputs: \\n (The sentence \"\"\"insert found sentence here\"\"\" uses <pattern>insert pattern here</pattern> to describe the user\\'s expectation. The answer is YES.)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(etd_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_user_etd_len = num_tokens_from_string(\" \".join(etd_system), \"cl100k_base\")\n",
    "total_user_etd_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use the following step-by-step instructions to respond to user inputs.\\n \\n Step 1 - The user will provide you with text in triple quotes (Question: \"\"\"insert text here\"\"\"). Find one sentence from the given text which can indicate the answer to \"What is the error or undesired behavior of the system or code provided by the user?\". The sentence only describing the user\\'s expectation should not be considered. Use triple quotes to cite the found sentence. If the given text does not contain such sentence, write \"No sentences found to indicate the error or undesired behavior. The answer is NO.\" and skip Step 2 and Step 3.\\n \\n Step 2 - If found one sentence from Step 1, \\n summarize the sentence into one or more patterns delimited by <pattern>..</pattern> according to the syntax and semantic of the sentence. The pattern could be expressed by some keywords and part-of-speech tags from the found sentence, which can explain why this sentence provides the answer to \"What is the error or undesired behavior of the system or code provided by the user?\".\\n \\n Step 3 - Use the following format to respond to user inputs: \\n (The sentence \"\"\"insert found sentence here\"\"\" uses <pattern>insert discourse pattern here</pattern> .. to . The answer is YES.)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(ps_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_user_ps_len = num_tokens_from_string(\" \".join(ps_system), \"cl100k_base\")\n",
    "total_user_ps_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue = pd.read_csv(\"prompt/issue.csv\", encoding = \"ISO-8859-1\")\n",
    "# df_issue = pd.read_csv(\"prompt/issue_wrong.csv\")\n",
    "\n",
    "# df_etd_example = pd.read_csv(\"experiment/random_pattern/ETD/etd_prompt_random_with_neg1.1.csv\")\n",
    "df_ps_example = pd.read_csv(\"experiment/random_pattern/PS/ps_prompt_random_with_neg1.1.csv\")\n",
    "#df_etd_example = pd.read_csv(\"experiment/frequent/ETD/etd_prompt_frequent1.csv\")\n",
    "#df_ps_example = pd.read_csv(\"experiment/frequent/PS/ps_prompt_frequent1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, when I am trying to apply class dynamicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is it possible to get a RouteConfig matched ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have angular running from a .Net Core server...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello everyone, I want to do sub menu with sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm struggling with getting this logic [code]....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               issue\n",
       "0  Hi, when I am trying to apply class dynamicall...\n",
       "1  is it possible to get a RouteConfig matched ag...\n",
       "2  I have angular running from a .Net Core server...\n",
       "3  Hello everyone, I want to do sub menu with sea...\n",
       "4  I'm struggling with getting this logic [code]...."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_clean = [remove_non_ascii(issue) for issue in df_issue[\"issue\"]]\n",
    "df_issue[\"issue\"] = issue_clean\n",
    "df_issue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for all examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_issue = list(df_etd_example[\"issue\"].values)\n",
    "chat_issue = list(df_ps_example[\"issue\"].values)\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_output = list(df_etd_example[\"output\"].values)\n",
    "chat_output = list(df_ps_example[\"output\"].values)\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for random/frequent pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etd_randexample = df_etd_example[df_etd_example[\"6_examples\"]==1]\n",
    "\n",
    "chat_issue = list(df_etd_randexample[\"issue\"].values)\n",
    "# chat_issue.extend(list(df_etd_randexample[\"issue_n\"].values))\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_output = list(df_etd_randexample[\"output\"].values)\n",
    "# chat_output.extend(list(df_etd_randexample[\"output_n\"].values))\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question: \"\"\" any ideas on how i may be able to find the circular dependency? i tried adding the `--verbose` flag to the ng build command but that didn\\'t really help tried using this tool [link], but it reports no circular dependencies. i\\'ve also looked through the code and nothing really stands out \"\"\"\\nAnswer: ',\n",
       " 'Question: \"\"\" Hi, is there any way to detect no router change? I mean situation when user click the same routerLink he is allready in i would like to implement some monkeyPatch for forcing angular 4 router to reinitialize route \"\"\"\\nAnswer: ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_randexample = df_ps_example[df_ps_example[\"2_examples\"]==1]\n",
    "\n",
    "chat_issue = list(df_ps_randexample[\"issue\"].values)\n",
    "# chat_issue.extend(list(df_ps_randexample[\"issue_n\"].values))\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sentence \"\"\"  but it reports no circular dependencies. \"\"\" uses <pattern>reports no JJ NNS</pattern> indicate that \"reports no circular dependencies\" is an undesired behavior. The answer is YES.',\n",
       " 'The sentence \"\"\"  is there any way to detect no router change? \"\"\" uses <pattern>detect no router change</pattern> but \"no router change\" is a noun phrase here to indicate the user\\'s expectation instead of describing the error or undesired behavior, so the answer is NO.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_output = list(df_ps_randexample[\"output\"].values)\n",
    "# chat_output.extend(list(df_ps_randexample[\"output_n\"].values))\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETD total input token: 976\n"
     ]
    }
   ],
   "source": [
    "for user_string,output_string in zip(chat_issue,chat_output):\n",
    "    total_user_etd_len += num_tokens_from_string(user_string,\"cl100k_base\")\n",
    "    total_user_etd_len += num_tokens_from_string(output_string,\"cl100k_base\")\n",
    "    \n",
    "print(\"ETD total input token:\",total_user_etd_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS total input token: 487\n"
     ]
    }
   ],
   "source": [
    "for user_string,output_string in zip(chat_issue,chat_output):\n",
    "    total_user_ps_len += num_tokens_from_string(user_string,\"cl100k_base\")\n",
    "    total_user_ps_len += num_tokens_from_string(output_string,\"cl100k_base\")\n",
    "    \n",
    "print(\"PS total input token:\",total_user_ps_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1= []\n",
    "start_i = 0\n",
    "flag = True\n",
    "while flag:\n",
    "    try:\n",
    "        for i in range(start_i,len(df_issue),1):\n",
    "#         for i in range(start_i,start_i+7,1):\n",
    "            issue = df_issue.loc[i][\"issue\"]\n",
    "            input_str = \"Question: \\\"\\\"\\\" {} \\\"\\\"\\\"\\n Answer: \".format(issue)\n",
    "    \n",
    "            result = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "#             {\"role\": \"system\", \"content\": \" \".join(etd_system)},\n",
    "            {\"role\": \"system\", \"content\": \" \".join(ps_system)},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[0]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[0]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[1]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[1]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[2]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[2]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[3]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[3]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[4]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[4]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[5]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[5]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[6]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[6]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[7]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[7]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[8]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[8]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[9]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[9]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[10]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[10]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[11]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[11]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[12]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[12]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[13]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[13]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[14]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[14]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[15]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[15]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[16]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[16]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[17]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[17]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[18]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[18]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[19]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[19]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[20]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[20]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[21]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[21]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[22]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[22]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[23]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[23]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[24]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[24]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[25]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[25]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[26]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[26]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[27]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[27]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[28]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[28]},\n",
    "            {\"role\": \"user\", \"content\": input_str},\n",
    "                ],\n",
    "                max_tokens = 200,\n",
    "                temperature = 0.8,\n",
    "#                 seed = 30\n",
    "        )\n",
    "    \n",
    "            ans1.append(result['choices'][0]['message']['content'])\n",
    "        \n",
    "        flag = False\n",
    "    except openai.error.RateLimitError as e:\n",
    "        print(f\"RateLimitError: {e}\")\n",
    "        time.sleep(60)\n",
    "        start_i = len(ans1)+0\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break  # Exit the loop on other errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1= []\n",
    "\n",
    "for i in range(len(df_issue)):\n",
    "    issue = df_issue.loc[i][\"issue\"]\n",
    "    input_str = \"Question: \\\"\\\"\\\" {} \\\"\\\"\\\"\\n Answer: \".format(issue)\n",
    "    \n",
    "    result = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \" \".join(etd_system)},\n",
    "#             {\"role\": \"system\", \"content\": \" \".join(ps_system)},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[0]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[0]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[1]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[1]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[2]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[2]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[3]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[3]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[4]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[4]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[5]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[5]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[6]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[6]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[7]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[7]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[8]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[8]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[9]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[9]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[10]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[10]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[11]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[11]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[12]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[12]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[13]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[13]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[14]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[14]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[15]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[15]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[16]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[16]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[17]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[17]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[18]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[18]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[19]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[19]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[20]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[20]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[21]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[21]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[22]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[22]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[23]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[23]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[24]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[24]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[25]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[25]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[26]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[26]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[27]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[27]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[28]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[28]},\n",
    "            {\"role\": \"user\", \"content\": input_str},\n",
    "            ],\n",
    "        max_tokens = 100,\n",
    "        temperature = 0\n",
    "    )\n",
    "    \n",
    "    ans1.append(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(ans1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sentence \"\"\" it is messing up my material ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No sentences found to indicate the error or un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No sentences found to indicate the error or un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No sentences found to indicate the error or un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The sentence \"\"\"  if API returns no data \"\"\" u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No sentences found to indicate the error or un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sentence \"\"\" means that elements for both ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The sentence \"\"\" `Element implicitly has an 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No sentences found to indicate the error or un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The sentence \"\"\"The only problem is with proje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer1\n",
       "0  The sentence \"\"\" it is messing up my material ...\n",
       "1  No sentences found to indicate the error or un...\n",
       "2  No sentences found to indicate the error or un...\n",
       "3  No sentences found to indicate the error or un...\n",
       "4  The sentence \"\"\"  if API returns no data \"\"\" u...\n",
       "5  No sentences found to indicate the error or un...\n",
       "6  The sentence \"\"\" means that elements for both ...\n",
       "7  The sentence \"\"\" `Element implicitly has an 'a...\n",
       "8  No sentences found to indicate the error or un...\n",
       "9  The sentence \"\"\"The only problem is with proje..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"answer1\"] = ans1\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"experiment/random_pattern/answer_rand.csv\",index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.506 recall: 0.852 F1: 0.635\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../Data/chat_pattern/chat_test_missing_1000.csv\")\n",
    "predictions_etd = df_test[\"y'_ETD\"]\n",
    "y_test = df_test[\"y_ETD\"]\n",
    "precison_etd = mt.precision_score(y_test, predictions_etd)\n",
    "recall_etd = mt.recall_score(y_test, predictions_etd)\n",
    "score_etd = mt.f1_score(y_test, predictions_etd)\n",
    "\n",
    "print(\"precision:\",round(precison_etd,3),\"recall:\",round(recall_etd,3),\"F1:\",round(score_etd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.774 recall: 0.715 F1: 0.744\n"
     ]
    }
   ],
   "source": [
    "predictions = df_test[\"y'_PS\"]\n",
    "y_test = df_test[\"y_PS\"]\n",
    "precison_ps = mt.precision_score(y_test, predictions)\n",
    "recall_ps = mt.recall_score(y_test, predictions)\n",
    "score_ps = mt.f1_score(y_test, predictions)\n",
    "\n",
    "print(\"precision:\",round(precison_ps,3),\"recall:\",round(recall_ps,3),\"F1:\",round(score_ps,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.854 recall: 0.344 F1: 0.49\n"
     ]
    }
   ],
   "source": [
    "# ETD results\n",
    "\n",
    "df_test_random = pd.read_csv(\"experiment/random_pattern/ETD/etd_random_withneg2.2_result(t=0.8).csv\")\n",
    "predictions_etd = df_test_random[\"y''_ETD\"]\n",
    "y_test = df_test_random[\"y_ETD\"]\n",
    "precison_etd = mt.precision_score(y_test, predictions_etd)\n",
    "recall_etd = mt.recall_score(y_test, predictions_etd)\n",
    "score_etd = mt.f1_score(y_test, predictions_etd)\n",
    "\n",
    "print(\"precision:\",round(precison_etd,3),\"recall:\",round(recall_etd,3),\"F1:\",round(score_etd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.773 recall: 0.52 F1: 0.621\n"
     ]
    }
   ],
   "source": [
    "# ETD results\n",
    "\n",
    "df_test_random = pd.read_csv(\"experiment/random_pattern/ETD/result_missing/etd_rand1_5example_result2.csv\")\n",
    "predictions_etd = df_test_random[\"y''_ETD\"]\n",
    "y_test = df_test_random[\"y_ETD\"]\n",
    "precison_etd = mt.precision_score(y_test, predictions_etd)\n",
    "recall_etd = mt.recall_score(y_test, predictions_etd)\n",
    "score_etd = mt.f1_score(y_test, predictions_etd)\n",
    "\n",
    "print(\"precision:\",round(precison_etd,3),\"recall:\",round(recall_etd,3),\"F1:\",round(score_etd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.876 recall: 0.712 F1: 0.785\n"
     ]
    }
   ],
   "source": [
    "# PS results \n",
    "\n",
    "df_test_random = pd.read_csv(\"experiment/random_pattern/PS/ps_random_withneg12_result(t=0.8).csv\")\n",
    "predictions_ps = df_test_random[\"y''_PS\"]\n",
    "y_test = df_test_random[\"y_PS\"]\n",
    "precison_ps = mt.precision_score(y_test, predictions_ps)\n",
    "recall_ps = mt.recall_score(y_test, predictions_ps)\n",
    "score_ps = mt.f1_score(y_test, predictions_ps)\n",
    "\n",
    "print(\"precision:\",round(precison_ps,3),\"recall:\",round(recall_ps,3),\"F1:\",round(score_ps,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9817b186a29e4e9713184d901f26c1ee05ad25243d878baff7f31bb1fef480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
