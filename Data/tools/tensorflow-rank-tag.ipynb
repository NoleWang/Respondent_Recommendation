{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d4316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:13:34.056047: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 10:13:34.749182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simin/miniconda3/envs/tf-rank/lib/:/home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-04-13 10:13:34.749260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simin/miniconda3/envs/tf-rank/lib/:/home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-04-13 10:13:34.749266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd2228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:13:39.831992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:13:39.848197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:13:39.848583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a528bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = '../StackExchange/Stackoverflow/train1.tfrecords'\n",
    "_TEST_DATA_PATH = '../StackExchange/Stackoverflow/test1.tfrecords'\n",
    "\n",
    "# Store the vocabulary path for query and document tokens.\n",
    "_VOCAB_PATH = '../StackExchange/Stackoverflow/vocab1.txt'\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = 100\n",
    "\n",
    "# The document relevance label.\n",
    "_LABEL_FEATURE = \"relevance\"\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_HIDDEN_LAYER_DIMS = [\"64\", \"32\", \"16\"]\n",
    "_DROPOUT_RATE = 0.8\n",
    "_GROUP_SIZE = 1  # Pointwise scoring.\n",
    "\n",
    "# Location of model directory and number of training steps.\n",
    "_MODEL_DIR = \"/tmp/ranking_model_dir2\"\n",
    "_NUM_TRAIN_STEPS = 80 * 1000\n",
    "_EMBEDDING_DIMENSION = 20\n",
    "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\",\"c++\",\"c#\",\"f#\",\"node.js\",\"nodejs\",\".json\",\".js\",\".net\",\"objective-c\",\n",
    "                                  \"asp.net\",\"ruby-on-rails\",\"angular.js\",\"angular-js\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c2e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_feature_columns():\n",
    "    \"\"\"Returns context feature names to column definitions.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        key=\"query_tokens\",\n",
    "        vocabulary_file=_VOCAB_PATH)\n",
    "    query_embedding_column = tf.feature_column.embedding_column(\n",
    "        sparse_column, _EMBEDDING_DIMENSION)\n",
    "    return {\"query_tokens\": query_embedding_column}\n",
    "\n",
    "\n",
    "def example_feature_columns():\n",
    "    \"\"\"Returns the example feature columns.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        key=\"document_tokens\",\n",
    "        vocabulary_file=_VOCAB_PATH)\n",
    "    document_embedding_column = tf.feature_column.embedding_column(\n",
    "        sparse_column, _EMBEDDING_DIMENSION)\n",
    "    return {\"document_tokens\": document_embedding_column}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2991ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(path, num_epochs=None):\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values())\n",
    "    label_column = tf.feature_column.numeric_column(\n",
    "        _LABEL_FEATURE, dtype=tf.int64, default_value=_PADDING_LABEL)\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()) + [label_column])\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern=path,\n",
    "        data_format=tfr.data.ELWC,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        list_size=_LIST_SIZE,\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=False,\n",
    "        num_epochs=num_epochs)\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    label = tf.squeeze(features.pop(_LABEL_FEATURE), axis=2)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fb6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform_fn():\n",
    "    def _transform_fn(features, mode):\n",
    "        \"\"\"Defines transform_fn.\"\"\"\n",
    "        context_features, example_features = tfr.feature.encode_listwise_features(\n",
    "            features=features,\n",
    "            context_feature_columns=context_feature_columns(),\n",
    "            example_feature_columns=example_feature_columns(),\n",
    "            mode=mode,\n",
    "            scope=\"transform_layer\")\n",
    "\n",
    "        return context_features, example_features\n",
    "    return _transform_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf844aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        \"\"\"Defines the network to score a group of documents.\"\"\"\n",
    "        with tf.compat.v1.name_scope(\"input_layer\"):\n",
    "            context_input = [\n",
    "                tf.compat.v1.layers.flatten(context_features[name])\n",
    "                for name in sorted(context_feature_columns())\n",
    "            ]\n",
    "            group_input = [\n",
    "                tf.compat.v1.layers.flatten(group_features[name])\n",
    "                for name in sorted(example_feature_columns())\n",
    "            ]\n",
    "            input_layer = tf.concat(context_input + group_input, 1)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        cur_layer = input_layer\n",
    "        cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "            cur_layer,\n",
    "            training=is_training,\n",
    "            momentum=0.99)\n",
    "\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
    "            cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "                cur_layer,\n",
    "                training=is_training,\n",
    "                momentum=0.99)\n",
    "            cur_layer = tf.nn.relu(cur_layer)\n",
    "            cur_layer = tf.compat.v1.layers.dropout(\n",
    "                inputs=cur_layer, rate=_DROPOUT_RATE, training=is_training)\n",
    "        logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n",
    "        return logits\n",
    "\n",
    "    return _score_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fccce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_fns():\n",
    "    \"\"\"Returns a dict from name to metric functions.\n",
    "\n",
    "    This can be customized as follows. Care must be taken when handling padded\n",
    "    lists.\n",
    "\n",
    "    def _auc(labels, predictions, features):\n",
    "        is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
    "        clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
    "        clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
    "        return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
    "    metric_fns[\"auc\"] = _auc\n",
    "\n",
    "    Returns:\n",
    "        A dict mapping from metric name to a metric function with above signature.\n",
    "    \"\"\"\n",
    "    metric_fns = {}\n",
    "   \n",
    "    metric_fns.update({\n",
    "        f\"metric/ndcg@{topn}\": tfr.metrics.make_ranking_metric_fn(\n",
    "            tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "        for topn in [10,15,20,25,30]\n",
    "    })\n",
    "    \"\"\"\n",
    "    metric_fns.update({\n",
    "        f\"metric/map@{topn}\": tfr.metrics.make_ranking_metric_fn(\n",
    "            tfr.metrics.RankingMetricKey.MAP, topn=topn)\n",
    "        for topn in [15, 20]\n",
    "    })\n",
    "    \"\"\"\n",
    "    \n",
    "    return metric_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11998803",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072917a",
   "metadata": {},
   "source": [
    "### Create vocab.txt using bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75323b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import shutil\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ee42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../StackExchange/Stackoverflow/train/\"\n",
    "df_train = pd.read_csv(\"../StackExchange/Stackoverflow/cluster_4d.csv\")\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 16\n",
    "seed = 42\n",
    "class_list = sorted([str(folder) for folder in set(df_train[\"label\"])])\n",
    "num_class = len(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7602cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(sentence):\n",
    "    return ''.join(char for char in sentence if ord(char) < 128)\n",
    "\n",
    "'''\n",
    "def html_Filter(sentence):\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text\n",
    "    #print(\"after html_Filter\",sentence)\n",
    "    \n",
    "    return sentence\n",
    "'''\n",
    "\n",
    "def html_Filter(sentence):\n",
    "    soup = BeautifulSoup(sentence, \"html.parser\")\n",
    "    for data in soup(['style', 'script']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    "    \n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "\n",
    "\n",
    "def keywords_transform(sentence):\n",
    "    delimiter = [char for char in string.punctuation]\n",
    "    punc_reserved = ['#','+','-',\"'\"]\n",
    "    delimiter_filter = list(set(delimiter) - set(punc_reserved))\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    for char in delimiter_filter:\n",
    "        sentence = sentence.replace(char,' '+char+' ')\n",
    "\n",
    "    sentence = sentence.replace(\"node js\",\"node.js\")\n",
    "    sentence = sentence.replace(\"node . js\",\"node.js\")\n",
    "    sentence = sentence.replace(\" . js\",\".js\")\n",
    "    sentence = sentence.replace(\" . net\",\".net\")\n",
    "    sentence = sentence.replace(\"asp . net\",\"asp.net\")\n",
    "    sentence = sentence.replace(\" . json\",\".json\")\n",
    "    sentence = sentence.replace(\"objective c\",\"objective-c\")\n",
    "    sentence = sentence.replace(\"ruby on rails\",\"ruby-on-rails\")\n",
    "    sentence = sentence.replace(\"angular js\",\"angular-js\")\n",
    "    sentence = sentence.replace(\"angular . js\",\"angular.js\")\n",
    "    \n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd165d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vocab_file(filepath, vocab):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for token in vocab:\n",
    "            print(token, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1224fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform dataset if needed\n",
    "for name in class_list:\n",
    "    newpath = train_path+name+'/' \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "for i, sentence, tag, label in zip(df_train[\"Id\"],df_train[\"sentence\"],df_train[\"tag\"],df_train[\"label\"]):\n",
    "    tag_string = tag.replace(\"<\",\"\")\n",
    "    tag_string = tag_string.replace(\">\",\" \")\n",
    "    sentence += ' '+tag_string.strip()\n",
    "    sentence = html_Filter(sentence)\n",
    "    sentence = remove_non_ascii(sentence)\n",
    "    sentence = keywords_transform(sentence)\n",
    "    \n",
    "    #vlabel_list.append(label)\n",
    "    \n",
    "    with open(train_path+str(label)+'/'+str(i)+\".txt\",\"w\",encoding=\"UTF-8\") as f:\n",
    "        f.write(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6c3c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2194 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#fetech dataset\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels=None,\n",
    "    label_mode = None,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e02cd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_params=dict(lower_case=True)\n",
    "\n",
    "bert_vocab_args = dict(\n",
    "    # The target vocabulary size\n",
    "    vocab_size = 8000,\n",
    "    # Reserved tokens that must be included in the vocabulary\n",
    "    reserved_tokens=reserved_tokens,\n",
    "    # Arguments for `text.BertTokenizer`\n",
    "    bert_tokenizer_params=bert_tokenizer_params,\n",
    "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
    "    learn_params={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b5a631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = bert_vocab.bert_vocab_from_dataset(\n",
    "    train_ds.cache().prefetch(buffer_size=AUTOTUNE),\n",
    "    **bert_vocab_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "520ce477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5964\n"
     ]
    }
   ],
   "source": [
    "print(len(en_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00a076f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', '[UNK]', '[START]', '[END]', 'c++', 'c#', 'f#', 'node.js', 'nodejs', '.json', '.js', '.net', 'objective-c', 'asp.net', 'ruby-on-rails', 'angular.js', 'angular-js', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', 'the', 'to', 'is', 'in', 'java', 'this', 'and', 'of', 'it', 'at', '##s', 'if', 'for', 'string', 'new', 'that', 'error', 'class', 'public', 'function', 'my', 'int', 'not', 'but', 'with', 'have', 'from', 'return', 'android', 'code', 'id', 'na', 'on', 'name', 'as', 'get', 'value', 'an', 'file', 'data', 'void', 'can', 'how', 'when', 'am', 'php', 'be', 'com', 'using', 'what', 'org', 'do', 'null', 'import', 'main', '##1', 'so', '##2', 'out', 'add', 'use', 'or', 'private', 'here', 'type', 'object', 'var', 'array', 'app', 'list', '##ing', 'why', 'text', 'method', 'are', 'by', 'like', 'system', 'apache', 'line', '10', 'result', '##d', 'you', 'no', 'http', 'which', '##ed', 'does', 'all', 'user', 'true', 'self', 'me', 'set', 'view', 'there', 'any', 'include', 'run', 'javascript', 'print', 'log', 'trying', 'div', '##l', 'else', 'console', 'input', 'following', 'exception', '##3', 'char', 'std', 'one']\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fef85fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vocab_file(_VOCAB_PATH, en_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ad5fe",
   "metadata": {},
   "source": [
    "### Create elwc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "610c1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    \n",
    "    \n",
    "    tokens = value.split()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[token.encode() for token in tokens]))\n",
    "'''\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    \n",
    "    \n",
    "    value = html_Filter(value)\n",
    "    value = remove_non_ascii(value)\n",
    "    value = keywords_transform(value)\n",
    "    whitespace_tokenizer = tf_text.WhitespaceTokenizer()\n",
    "    words = whitespace_tokenizer.tokenize(value).numpy().tolist()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=words))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79af183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfexample(feature0, feature1):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "        'document_tokens': _bytes_feature(feature0),\n",
    "        'relevance': _int64_feature(feature1), \n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e8fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfquery(feature0):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "        'query_tokens': _bytes_feature(feature0),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07d73699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_elwc(elwc,num_example):\n",
    "    return tfr.data.parse_from_example_list(\n",
    "        [elwc],\n",
    "        list_size=num_example,\n",
    "        context_feature_spec={\"query_tokens\": tf.io.RaggedFeature(dtype=tf.string)},\n",
    "        example_feature_spec={\n",
    "            \"document_tokens\":\n",
    "                tf.io.RaggedFeature(dtype=tf.string),\n",
    "            \"relevance\":\n",
    "                tf.io.FixedLenFeature(shape=[], dtype=tf.int64, default_value=0)\n",
    "        },\n",
    "        size_feature_name=\"_list_size_\",\n",
    "        mask_feature_name=\"_mask_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1f20f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_serialized_elwc(tf_query, tf_examples):\n",
    "    ELWC = input_pb2.ExampleListWithContext()\n",
    "    ELWC.context.CopyFrom(tf_query)\n",
    "\n",
    "    for example in tf_examples:\n",
    "        example_features = ELWC.examples.add()\n",
    "        example_features.CopyFrom(example)\n",
    "    \n",
    "    return ELWC.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8b66e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset):\n",
    "    ELWC_list = []\n",
    "    \n",
    "    for data in dataset:\n",
    "        tag_string = data[\"tag\"].replace(\"<\",\"\")\n",
    "        tag_string = tag_string.replace(\">\",\" \")\n",
    "        query = data[\"query\"] + ' '+tag_string.strip()\n",
    "        tf_query = create_tfquery(query)\n",
    "        \n",
    "        EXAMPLES = []\n",
    "        for doc in data[\"documents\"]:\n",
    "            tag_string = doc[\"tag\"].replace(\"<\",\"\")\n",
    "            tag_string = tag_string.replace(\">\",\" \")\n",
    "            example = doc[\"doc\"] + ' '+tag_string.strip()\n",
    "            tf_example = create_tfexample(example,doc[\"relevance\"])\n",
    "            EXAMPLES.append(tf_example)\n",
    "        \n",
    "        ELWC_list.append(create_serialized_elwc(tf_query, EXAMPLES))\n",
    "    \n",
    "    return ELWC_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228dbf7",
   "metadata": {},
   "source": [
    "#### stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18b07e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5badc733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14191212</td>\n",
       "      <td>Alternative Function for EREGI in PHP &lt;p&gt;I was...</td>\n",
       "      <td>&lt;php&gt;&lt;regex&gt;&lt;preg-match&gt;&lt;eregi&gt;</td>\n",
       "      <td>2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14198874</td>\n",
       "      <td>JasperReports: Unsupported major.minor version...</td>\n",
       "      <td>&lt;java&gt;&lt;version&gt;&lt;unsupported-class-version&gt;</td>\n",
       "      <td>29595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1335851</td>\n",
       "      <td>What does \"use strict\" do in JavaScript, and w...</td>\n",
       "      <td>&lt;javascript&gt;&lt;syntax&gt;&lt;jslint&gt;&lt;use-strict&gt;</td>\n",
       "      <td>29590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1335886</td>\n",
       "      <td>mySQL Operand should contain 1 column error &lt;p...</td>\n",
       "      <td>&lt;mysql&gt;&lt;sql&gt;&lt;mysql-error-1241&gt;</td>\n",
       "      <td>123659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1352885</td>\n",
       "      <td>Remove elements as you traverse a list in Pyth...</td>\n",
       "      <td>&lt;python&gt;&lt;list&gt;&lt;loops&gt;&lt;iterator&gt;&lt;python-datamodel&gt;</td>\n",
       "      <td>15259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>14113884</td>\n",
       "      <td>Protect C++ program against decompiling &lt;block...</td>\n",
       "      <td>&lt;c++&gt;&lt;windows&gt;&lt;obfuscation&gt;&lt;decompiling&gt;&lt;sourc...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>14115904</td>\n",
       "      <td>$_POST not working. \"Notice: Undefined index: ...</td>\n",
       "      <td>&lt;php&gt;&lt;http-post&gt;&lt;undefined-index&gt;</td>\n",
       "      <td>8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>14121385</td>\n",
       "      <td>Select Distinct Rows from MySQL database throu...</td>\n",
       "      <td>&lt;php&gt;&lt;mysql&gt;&lt;pdo&gt;&lt;haversine&gt;</td>\n",
       "      <td>2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>14123290</td>\n",
       "      <td>Pull data from PHP object received from twitte...</td>\n",
       "      <td>&lt;php&gt;&lt;twitter&gt;&lt;twitter-streaming-api&gt;</td>\n",
       "      <td>219989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>14132789</td>\n",
       "      <td>Relative imports for the billionth time &lt;p&gt;I'v...</td>\n",
       "      <td>&lt;python&gt;&lt;import&gt;&lt;relative-path&gt;&lt;python-packagi...</td>\n",
       "      <td>147029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2194 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                           sentence  \\\n",
       "0     14191212  Alternative Function for EREGI in PHP <p>I was...   \n",
       "1     14198874  JasperReports: Unsupported major.minor version...   \n",
       "2      1335851  What does \"use strict\" do in JavaScript, and w...   \n",
       "3      1335886  mySQL Operand should contain 1 column error <p...   \n",
       "4      1352885  Remove elements as you traverse a list in Pyth...   \n",
       "...        ...                                                ...   \n",
       "2189  14113884  Protect C++ program against decompiling <block...   \n",
       "2190  14115904  $_POST not working. \"Notice: Undefined index: ...   \n",
       "2191  14121385  Select Distinct Rows from MySQL database throu...   \n",
       "2192  14123290  Pull data from PHP object received from twitte...   \n",
       "2193  14132789  Relative imports for the billionth time <p>I'v...   \n",
       "\n",
       "                                                    tag   label  \n",
       "0                       <php><regex><preg-match><eregi>    2867  \n",
       "1            <java><version><unsupported-class-version>   29595  \n",
       "2              <javascript><syntax><jslint><use-strict>   29590  \n",
       "3                        <mysql><sql><mysql-error-1241>  123659  \n",
       "4     <python><list><loops><iterator><python-datamodel>   15259  \n",
       "...                                                 ...     ...  \n",
       "2189  <c++><windows><obfuscation><decompiling><sourc...      29  \n",
       "2190                  <php><http-post><undefined-index>    8549  \n",
       "2191                       <php><mysql><pdo><haversine>    2802  \n",
       "2192              <php><twitter><twitter-streaming-api>  219989  \n",
       "2193  <python><import><relative-path><python-packagi...  147029  \n",
       "\n",
       "[2194 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../StackExchange/Stackoverflow/cluster_4d.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e08e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6fd714c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "234a8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for label in label_set:\n",
    "    df_relevant = df[df[\"label\"] == label]    \n",
    "    df_irrelevant = df[df[\"label\"] != label]\n",
    "    \n",
    "    for index in list(df_relevant.index.values):\n",
    "        data = {}\n",
    "        data[\"qid\"] = df_relevant.loc[index][\"Id\"]\n",
    "        data[\"query\"] = df_relevant.loc[index][\"sentence\"]\n",
    "        data[\"label\"] = df_relevant.loc[index][\"label\"]\n",
    "        data[\"tag\"] = df_relevant.loc[index][\"tag\"]\n",
    "        \n",
    "        \n",
    "        docs = []\n",
    "        df_doc = df_relevant[df_relevant[\"Id\"] != df_relevant.loc[index][\"Id\"]]\n",
    "        for index_d in list(df_doc.index.values):\n",
    "            doc = {}\n",
    "            doc[\"doc_id\"] = df_doc.loc[index_d][\"Id\"]\n",
    "            doc[\"doc\"] = df_doc.loc[index_d][\"sentence\"]\n",
    "            doc[\"tag\"] = df_doc.loc[index_d][\"tag\"]\n",
    "            doc[\"relevance\"] = 1\n",
    "            \n",
    "            docs.append(doc)\n",
    "        \n",
    "        \n",
    "        if len(docs) < _LIST_SIZE:\n",
    "            num_irrelevant = _LIST_SIZE - len(docs)\n",
    "            df_irdoc = df_irrelevant.sample(num_irrelevant)\n",
    "            for index_d in list(df_irdoc.index.values):\n",
    "                doc = {}\n",
    "                doc[\"doc_id\"] = df_irdoc.loc[index_d][\"Id\"]\n",
    "                doc[\"doc\"] = df_irdoc.loc[index_d][\"sentence\"]\n",
    "                doc[\"tag\"] = df_irdoc.loc[index_d][\"tag\"]\n",
    "                doc[\"relevance\"] = 0\n",
    "            \n",
    "                docs.append(doc)\n",
    "        \n",
    "        data[\"documents\"] = docs\n",
    "        \n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08f0345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "train = []\n",
    "test = []\n",
    "has_label = set()\n",
    "\n",
    "for data in dataset:\n",
    "    if data[\"label\"] in has_label:\n",
    "        train.append(data)\n",
    "    else:\n",
    "        test.append(data)\n",
    "        has_label.add(data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5376276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1971\n",
      "test: 223\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\",len(train))\n",
    "print(\"test:\",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43e28360",
   "metadata": {},
   "outputs": [],
   "source": [
    "elwc_train = create_dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eee79229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elwc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "edabfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(_TRAIN_DATA_PATH) as writer:\n",
    "    for objs in elwc_train:\n",
    "        writer.write(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abe113f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "elwc_test = create_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d08c78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(_TEST_DATA_PATH) as writer:\n",
    "    for objs in elwc_test:\n",
    "        writer.write(objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c39ac",
   "metadata": {},
   "source": [
    "## Losses, Metrics and Ranking Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9fc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function. To find a complete list of available\n",
    "# loss functions or to learn how to add your own custom function\n",
    "# please refer to the tensorflow_ranking.losses module.\n",
    "\n",
    "_LOSS = tfr.losses.RankingLossKey.APPROX_NDCG_LOSS\n",
    "loss_fn = tfr.losses.make_loss_fn(_LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba31dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "    learning_rate=_LEARNING_RATE)\n",
    "\n",
    "\n",
    "def _train_op_fn(loss):\n",
    "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "    minimize_op = optimizer.minimize(\n",
    "        loss=loss, global_step=tf.compat.v1.train.get_global_step())\n",
    "    train_op = tf.group([update_ops, minimize_op])\n",
    "    return train_op\n",
    "\n",
    "\n",
    "ranking_head = tfr.head.create_ranking_head(\n",
    "      loss_fn=loss_fn,\n",
    "      eval_metric_fns=eval_metric_fns(),\n",
    "      train_op_fn=_train_op_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab13156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building groupwise ranking model.\n"
     ]
    }
   ],
   "source": [
    "model_fn = tfr.model.make_groupwise_ranking_fn(\n",
    "          group_score_fn=make_score_fn(),\n",
    "          transform_fn=make_transform_fn(),\n",
    "          group_size=_GROUP_SIZE,\n",
    "          ranking_head=ranking_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803568ce",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d7a0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_fn():\n",
    "    \"\"\"Train and eval function used by `tf.estimator.train_and_evaluate`.\"\"\"\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        save_checkpoints_steps=5000)\n",
    "    ranker = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=_MODEL_DIR,\n",
    "        config=run_config)\n",
    "\n",
    "    train_input_fn = lambda: input_fn(_TRAIN_DATA_PATH)\n",
    "    eval_input_fn = lambda: input_fn(_TEST_DATA_PATH, num_epochs=1)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=train_input_fn, max_steps=_NUM_TRAIN_STEPS)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        name=\"eval\",\n",
    "        input_fn=eval_input_fn,\n",
    "        throttle_secs=15)\n",
    "    return (ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89935a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/ranking_model_dir2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x7faa6df17640>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "ranker, train_spec, eval_spec = train_and_eval_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f003e8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/simin/miniconda3/envs/tf-rank/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 5000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9557/2110212537.py:8: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(context_features[name])\n",
      "/tmp/ipykernel_9557/2110212537.py:12: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(group_features[name])\n",
      "/tmp/ipykernel_9557/2110212537.py:19: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_9557/2110212537.py:25: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
      "/tmp/ipykernel_9557/2110212537.py:26: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_9557/2110212537.py:31: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dropout(\n",
      "/tmp/ipykernel_9557/2110212537.py:33: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/training/adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:14:37.471545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 10:14:37.472891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:37.473276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:37.473639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.657288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.657699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.657711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:14:38.658093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.658139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
      "2023-04-13 10:14:38.696099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.696628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.697214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.698003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.698060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:14:38.698700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:14:38.698760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
      "2023-04-13 10:14:38.715218: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = -0.37449712, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:14:42.200933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 19.7855\n",
      "INFO:tensorflow:loss = -0.35700917, step = 100 (5.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9499\n",
      "INFO:tensorflow:loss = -0.71308994, step = 200 (4.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8998\n",
      "INFO:tensorflow:loss = -0.98231983, step = 300 (4.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7123\n",
      "INFO:tensorflow:loss = -0.65439934, step = 400 (4.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.61\n",
      "INFO:tensorflow:loss = -0.52747136, step = 500 (4.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4163\n",
      "INFO:tensorflow:loss = -0.80100596, step = 600 (4.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5618\n",
      "INFO:tensorflow:loss = -0.6971115, step = 700 (4.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3731\n",
      "INFO:tensorflow:loss = -0.5217722, step = 800 (4.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.406\n",
      "INFO:tensorflow:loss = -0.48806012, step = 900 (4.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8829\n",
      "INFO:tensorflow:loss = -0.84659386, step = 1000 (4.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.707\n",
      "INFO:tensorflow:loss = -0.7224319, step = 1100 (4.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0935\n",
      "INFO:tensorflow:loss = -0.47300613, step = 1200 (4.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8083\n",
      "INFO:tensorflow:loss = -0.4394709, step = 1300 (4.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2856\n",
      "INFO:tensorflow:loss = -0.5466901, step = 1400 (4.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9182\n",
      "INFO:tensorflow:loss = -0.8415448, step = 1500 (4.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6581\n",
      "INFO:tensorflow:loss = -0.50154483, step = 1600 (4.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4509\n",
      "INFO:tensorflow:loss = -0.42027324, step = 1700 (4.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2247\n",
      "INFO:tensorflow:loss = -0.7013118, step = 1800 (4.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6095\n",
      "INFO:tensorflow:loss = -0.3781454, step = 1900 (4.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8883\n",
      "INFO:tensorflow:loss = -0.43669564, step = 2000 (4.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6067\n",
      "INFO:tensorflow:loss = -0.40416306, step = 2100 (4.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4622\n",
      "INFO:tensorflow:loss = -0.40934074, step = 2200 (4.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5185\n",
      "INFO:tensorflow:loss = -0.66119945, step = 2300 (4.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6539\n",
      "INFO:tensorflow:loss = -0.38639522, step = 2400 (4.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2124\n",
      "INFO:tensorflow:loss = -0.7372515, step = 2500 (4.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6126\n",
      "INFO:tensorflow:loss = -0.37132215, step = 2600 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4559\n",
      "INFO:tensorflow:loss = -0.41927418, step = 2700 (4.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.727\n",
      "INFO:tensorflow:loss = -0.5957154, step = 2800 (4.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5871\n",
      "INFO:tensorflow:loss = -0.44609, step = 2900 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2034\n",
      "INFO:tensorflow:loss = -0.4868036, step = 3000 (4.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8903\n",
      "INFO:tensorflow:loss = -0.36626863, step = 3100 (4.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3911\n",
      "INFO:tensorflow:loss = -0.4390709, step = 3200 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.648\n",
      "INFO:tensorflow:loss = -0.91369486, step = 3300 (4.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7919\n",
      "INFO:tensorflow:loss = -0.44072, step = 3400 (4.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.411\n",
      "INFO:tensorflow:loss = -0.39530027, step = 3500 (4.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.55\n",
      "INFO:tensorflow:loss = -0.47829396, step = 3600 (4.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3581\n",
      "INFO:tensorflow:loss = -0.37686455, step = 3700 (4.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2929\n",
      "INFO:tensorflow:loss = -0.4516925, step = 3800 (4.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3689\n",
      "INFO:tensorflow:loss = -0.37146598, step = 3900 (4.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6529\n",
      "INFO:tensorflow:loss = -0.40682828, step = 4000 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1774\n",
      "INFO:tensorflow:loss = -0.903248, step = 4100 (4.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7524\n",
      "INFO:tensorflow:loss = -0.4829483, step = 4200 (4.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2005\n",
      "INFO:tensorflow:loss = -0.35972443, step = 4300 (4.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7943\n",
      "INFO:tensorflow:loss = -0.5273167, step = 4400 (4.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7884\n",
      "INFO:tensorflow:loss = -0.39716512, step = 4500 (4.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8471\n",
      "INFO:tensorflow:loss = -0.4616892, step = 4600 (4.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9067\n",
      "INFO:tensorflow:loss = -0.39608693, step = 4700 (4.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7999\n",
      "INFO:tensorflow:loss = -0.3996172, step = 4800 (5.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6113\n",
      "INFO:tensorflow:loss = -0.7846241, step = 4900 (4.235 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:18:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:18:24.668590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:18:24.669321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:18:24.669800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:18:24.670791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:18:24.670827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:18:24.671329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:18:24.671434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.26341s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:18:25\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, labels_mean = 0.08838565, logits_mean = 0.49075562, loss = -0.40103355, metric/ndcg@10 = 0.13704142, metric/ndcg@15 = 0.16023673, metric/ndcg@20 = 0.17916997, metric/ndcg@25 = 0.19806154, metric/ndcg@30 = 0.2171861\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/ranking_model_dir2/model.ckpt-5000\n",
      "INFO:tensorflow:global_step/sec: 13.9578\n",
      "INFO:tensorflow:loss = -0.38385648, step = 5000 (7.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0627\n",
      "INFO:tensorflow:loss = -0.43829346, step = 5100 (4.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2885\n",
      "INFO:tensorflow:loss = -0.52079403, step = 5200 (4.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7403\n",
      "INFO:tensorflow:loss = -0.4613398, step = 5300 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9457\n",
      "INFO:tensorflow:loss = -0.500227, step = 5400 (4.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7135\n",
      "INFO:tensorflow:loss = -0.3862232, step = 5500 (4.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4381\n",
      "INFO:tensorflow:loss = -0.3777572, step = 5600 (4.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.898\n",
      "INFO:tensorflow:loss = -0.62415, step = 5700 (4.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2738\n",
      "INFO:tensorflow:loss = -0.569749, step = 5800 (4.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2316\n",
      "INFO:tensorflow:loss = -0.52217567, step = 5900 (4.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5336\n",
      "INFO:tensorflow:loss = -0.4823079, step = 6000 (4.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3357\n",
      "INFO:tensorflow:loss = -0.43195552, step = 6100 (4.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.584\n",
      "INFO:tensorflow:loss = -0.43878996, step = 6200 (4.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.311\n",
      "INFO:tensorflow:loss = -0.48698893, step = 6300 (4.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5179\n",
      "INFO:tensorflow:loss = -0.67836434, step = 6400 (4.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4964\n",
      "INFO:tensorflow:loss = -0.45610756, step = 6500 (4.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6711\n",
      "INFO:tensorflow:loss = -0.508626, step = 6600 (4.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1206\n",
      "INFO:tensorflow:loss = -0.54852307, step = 6700 (4.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2334\n",
      "INFO:tensorflow:loss = -0.6706073, step = 6800 (4.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7637\n",
      "INFO:tensorflow:loss = -0.5041707, step = 6900 (4.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8249\n",
      "INFO:tensorflow:loss = -0.4578217, step = 7000 (4.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0639\n",
      "INFO:tensorflow:loss = -0.47864693, step = 7100 (4.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0312\n",
      "INFO:tensorflow:loss = -0.9778728, step = 7200 (4.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8426\n",
      "INFO:tensorflow:loss = -0.48872057, step = 7300 (4.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.532\n",
      "INFO:tensorflow:loss = -0.41878322, step = 7400 (4.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6442\n",
      "INFO:tensorflow:loss = -0.44084746, step = 7500 (4.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4133\n",
      "INFO:tensorflow:loss = -0.798681, step = 7600 (4.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6667\n",
      "INFO:tensorflow:loss = -0.35205227, step = 7700 (4.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7146\n",
      "INFO:tensorflow:loss = -0.42228, step = 7800 (4.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.944\n",
      "INFO:tensorflow:loss = -0.40943637, step = 7900 (4.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8334\n",
      "INFO:tensorflow:loss = -0.9806002, step = 8000 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0366\n",
      "INFO:tensorflow:loss = -0.66754204, step = 8100 (4.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9202\n",
      "INFO:tensorflow:loss = -0.4703706, step = 8200 (4.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1814\n",
      "INFO:tensorflow:loss = -0.673475, step = 8300 (4.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.56\n",
      "INFO:tensorflow:loss = -0.6058139, step = 8400 (4.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4831\n",
      "INFO:tensorflow:loss = -0.41229787, step = 8500 (4.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4745\n",
      "INFO:tensorflow:loss = -0.37908322, step = 8600 (4.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5791\n",
      "INFO:tensorflow:loss = -0.69595563, step = 8700 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8887\n",
      "INFO:tensorflow:loss = -0.9839419, step = 8800 (4.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9481\n",
      "INFO:tensorflow:loss = -0.6862863, step = 8900 (4.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5107\n",
      "INFO:tensorflow:loss = -0.5342171, step = 9000 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8819\n",
      "INFO:tensorflow:loss = -0.8167422, step = 9100 (4.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.68\n",
      "INFO:tensorflow:loss = -0.6944385, step = 9200 (4.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3305\n",
      "INFO:tensorflow:loss = -0.5250015, step = 9300 (4.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6071\n",
      "INFO:tensorflow:loss = -0.47833383, step = 9400 (4.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5162\n",
      "INFO:tensorflow:loss = -0.86430025, step = 9500 (4.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.037\n",
      "INFO:tensorflow:loss = -0.7539427, step = 9600 (4.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8361\n",
      "INFO:tensorflow:loss = -0.47805423, step = 9700 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4978\n",
      "INFO:tensorflow:loss = -0.42884183, step = 9800 (4.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7907\n",
      "INFO:tensorflow:loss = -0.59986657, step = 9900 (4.203 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:22:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:22:08.247546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:22:08.248101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:22:08.248640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:22:08.249447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:22:08.249486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:22:08.249978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:22:08.250035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.08835s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:22:09\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, labels_mean = 0.08838565, logits_mean = 0.5173469, loss = -0.4312785, metric/ndcg@10 = 0.15092117, metric/ndcg@15 = 0.17634909, metric/ndcg@20 = 0.20089683, metric/ndcg@25 = 0.22745244, metric/ndcg@30 = 0.2511349\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/ranking_model_dir2/model.ckpt-10000\n",
      "INFO:tensorflow:global_step/sec: 15.1972\n",
      "INFO:tensorflow:loss = -0.84632397, step = 10000 (6.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1227\n",
      "INFO:tensorflow:loss = -0.5382937, step = 10100 (4.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5901\n",
      "INFO:tensorflow:loss = -0.42758, step = 10200 (4.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2625\n",
      "INFO:tensorflow:loss = -0.74136794, step = 10300 (4.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1162\n",
      "INFO:tensorflow:loss = -0.33630353, step = 10400 (4.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3512\n",
      "INFO:tensorflow:loss = -0.4538023, step = 10500 (4.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0581\n",
      "INFO:tensorflow:loss = -0.40598172, step = 10600 (4.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4129\n",
      "INFO:tensorflow:loss = -0.4255295, step = 10700 (4.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4616\n",
      "INFO:tensorflow:loss = -0.7119919, step = 10800 (4.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1019\n",
      "INFO:tensorflow:loss = -0.42259973, step = 10900 (4.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6284\n",
      "INFO:tensorflow:loss = -0.71400726, step = 11000 (4.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5398\n",
      "INFO:tensorflow:loss = -0.42944425, step = 11100 (4.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9419\n",
      "INFO:tensorflow:loss = -0.41037172, step = 11200 (4.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7474\n",
      "INFO:tensorflow:loss = -0.58414435, step = 11300 (4.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5954\n",
      "INFO:tensorflow:loss = -0.44720203, step = 11400 (4.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9192\n",
      "INFO:tensorflow:loss = -0.4682368, step = 11500 (4.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8378\n",
      "INFO:tensorflow:loss = -0.3620704, step = 11600 (4.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8998\n",
      "INFO:tensorflow:loss = -0.43043298, step = 11700 (4.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1115\n",
      "INFO:tensorflow:loss = -0.9010185, step = 11800 (4.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6917\n",
      "INFO:tensorflow:loss = -0.47423267, step = 11900 (4.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9624\n",
      "INFO:tensorflow:loss = -0.4089467, step = 12000 (4.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0803\n",
      "INFO:tensorflow:loss = -0.49615327, step = 12100 (4.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5211\n",
      "INFO:tensorflow:loss = -0.40990394, step = 12200 (4.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2494\n",
      "INFO:tensorflow:loss = -0.41621977, step = 12300 (4.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6613\n",
      "INFO:tensorflow:loss = -0.37668705, step = 12400 (4.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2939\n",
      "INFO:tensorflow:loss = -0.43641898, step = 12500 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.292\n",
      "INFO:tensorflow:loss = -0.89847815, step = 12600 (4.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6334\n",
      "INFO:tensorflow:loss = -0.47772855, step = 12700 (4.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7497\n",
      "INFO:tensorflow:loss = -0.42453378, step = 12800 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7189\n",
      "INFO:tensorflow:loss = -0.51773465, step = 12900 (5.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0281\n",
      "INFO:tensorflow:loss = -0.39688918, step = 13000 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3486\n",
      "INFO:tensorflow:loss = -0.486319, step = 13100 (4.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2948\n",
      "INFO:tensorflow:loss = -0.44479412, step = 13200 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5453\n",
      "INFO:tensorflow:loss = -0.42272112, step = 13300 (4.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0184\n",
      "INFO:tensorflow:loss = -0.8126488, step = 13400 (4.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.388\n",
      "INFO:tensorflow:loss = -0.39191893, step = 13500 (5.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5898\n",
      "INFO:tensorflow:loss = -0.43486553, step = 13600 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1352\n",
      "INFO:tensorflow:loss = -0.5536872, step = 13700 (4.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7654\n",
      "INFO:tensorflow:loss = -0.46033612, step = 13800 (4.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1252\n",
      "INFO:tensorflow:loss = -0.514073, step = 13900 (4.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5829\n",
      "INFO:tensorflow:loss = -0.40059775, step = 14000 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3183\n",
      "INFO:tensorflow:loss = -0.36039102, step = 14100 (4.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5253\n",
      "INFO:tensorflow:loss = -0.6386344, step = 14200 (4.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2505\n",
      "INFO:tensorflow:loss = -0.5715591, step = 14300 (4.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3082\n",
      "INFO:tensorflow:loss = -0.48652127, step = 14400 (4.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5457\n",
      "INFO:tensorflow:loss = -0.5132541, step = 14500 (4.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4289\n",
      "INFO:tensorflow:loss = -0.4497632, step = 14600 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9964\n",
      "INFO:tensorflow:loss = -0.5153555, step = 14700 (4.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8524\n",
      "INFO:tensorflow:loss = -0.4848612, step = 14800 (4.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0724\n",
      "INFO:tensorflow:loss = -0.6282922, step = 14900 (4.746 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 15000...\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 15000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:25:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:25:54.085164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:25:54.085859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:25:54.086358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:25:54.087105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:25:54.087138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:25:54.087615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:25:54.087665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.11263s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:25:55\n",
      "INFO:tensorflow:Saving dict for global step 15000: global_step = 15000, labels_mean = 0.08838565, logits_mean = 0.61759, loss = -0.47030503, metric/ndcg@10 = 0.2013145, metric/ndcg@15 = 0.23328999, metric/ndcg@20 = 0.26187825, metric/ndcg@25 = 0.28507364, metric/ndcg@30 = 0.3088014\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /tmp/ranking_model_dir2/model.ckpt-15000\n",
      "INFO:tensorflow:global_step/sec: 15.3809\n",
      "INFO:tensorflow:loss = -0.46878025, step = 15000 (6.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0015\n",
      "INFO:tensorflow:loss = -0.56967854, step = 15100 (4.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1257\n",
      "INFO:tensorflow:loss = -0.5601562, step = 15200 (4.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5478\n",
      "INFO:tensorflow:loss = -0.65893817, step = 15300 (4.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0467\n",
      "INFO:tensorflow:loss = -0.51076066, step = 15400 (4.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3912\n",
      "INFO:tensorflow:loss = -0.43757603, step = 15500 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3227\n",
      "INFO:tensorflow:loss = -0.47478393, step = 15600 (4.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4527\n",
      "INFO:tensorflow:loss = -0.9807717, step = 15700 (4.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2954\n",
      "INFO:tensorflow:loss = -0.4793438, step = 15800 (4.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.846\n",
      "INFO:tensorflow:loss = -0.43359992, step = 15900 (4.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7183\n",
      "INFO:tensorflow:loss = -0.43705672, step = 16000 (4.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6043\n",
      "INFO:tensorflow:loss = -0.8054323, step = 16100 (4.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5781\n",
      "INFO:tensorflow:loss = -0.40577567, step = 16200 (4.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8659\n",
      "INFO:tensorflow:loss = -0.49577445, step = 16300 (4.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9218\n",
      "INFO:tensorflow:loss = -0.42675364, step = 16400 (4.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6753\n",
      "INFO:tensorflow:loss = -0.97974855, step = 16500 (4.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2529\n",
      "INFO:tensorflow:loss = -0.70281744, step = 16600 (4.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2302\n",
      "INFO:tensorflow:loss = -0.46878248, step = 16700 (4.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2617\n",
      "INFO:tensorflow:loss = -0.6742221, step = 16800 (4.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5979\n",
      "INFO:tensorflow:loss = -0.63733745, step = 16900 (4.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3677\n",
      "INFO:tensorflow:loss = -0.43104053, step = 17000 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5674\n",
      "INFO:tensorflow:loss = -0.38825548, step = 17100 (4.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5283\n",
      "INFO:tensorflow:loss = -0.6783829, step = 17200 (4.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9983\n",
      "INFO:tensorflow:loss = -0.984046, step = 17300 (4.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3897\n",
      "INFO:tensorflow:loss = -0.7301767, step = 17400 (4.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.368\n",
      "INFO:tensorflow:loss = -0.5538364, step = 17500 (4.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9092\n",
      "INFO:tensorflow:loss = -0.8109412, step = 17600 (4.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3927\n",
      "INFO:tensorflow:loss = -0.6789644, step = 17700 (4.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9845\n",
      "INFO:tensorflow:loss = -0.53222555, step = 17800 (4.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7683\n",
      "INFO:tensorflow:loss = -0.5147325, step = 17900 (4.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2939\n",
      "INFO:tensorflow:loss = -0.8500952, step = 18000 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8389\n",
      "INFO:tensorflow:loss = -0.81199497, step = 18100 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6905\n",
      "INFO:tensorflow:loss = -0.5064624, step = 18200 (4.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5194\n",
      "INFO:tensorflow:loss = -0.49452972, step = 18300 (4.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8799\n",
      "INFO:tensorflow:loss = -0.61938894, step = 18400 (4.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5169\n",
      "INFO:tensorflow:loss = -0.8481214, step = 18500 (5.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6037\n",
      "INFO:tensorflow:loss = -0.58203745, step = 18600 (4.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6089\n",
      "INFO:tensorflow:loss = -0.48339713, step = 18700 (4.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4306\n",
      "INFO:tensorflow:loss = -0.7690685, step = 18800 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2036\n",
      "INFO:tensorflow:loss = -0.35523105, step = 18900 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5971\n",
      "INFO:tensorflow:loss = -0.48010048, step = 19000 (4.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8854\n",
      "INFO:tensorflow:loss = -0.40569636, step = 19100 (4.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4611\n",
      "INFO:tensorflow:loss = -0.4311031, step = 19200 (4.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7187\n",
      "INFO:tensorflow:loss = -0.74650204, step = 19300 (4.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6719\n",
      "INFO:tensorflow:loss = -0.3980895, step = 19400 (4.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2342\n",
      "INFO:tensorflow:loss = -0.6857171, step = 19500 (4.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6436\n",
      "INFO:tensorflow:loss = -0.45319003, step = 19600 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2007\n",
      "INFO:tensorflow:loss = -0.4190004, step = 19700 (4.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4487\n",
      "INFO:tensorflow:loss = -0.5971861, step = 19800 (4.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1209\n",
      "INFO:tensorflow:loss = -0.4710883, step = 19900 (4.325 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20000...\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:29:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:29:38.827922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:29:38.828556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:29:38.829047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:29:38.829830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:29:38.829861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:29:38.830259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:29:38.830306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.06128s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:29:39\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, labels_mean = 0.08838565, logits_mean = 0.6269808, loss = -0.50342965, metric/ndcg@10 = 0.24471442, metric/ndcg@15 = 0.28099015, metric/ndcg@20 = 0.31526455, metric/ndcg@25 = 0.34038964, metric/ndcg@30 = 0.3628029\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/ranking_model_dir2/model.ckpt-20000\n",
      "INFO:tensorflow:global_step/sec: 15.1966\n",
      "INFO:tensorflow:loss = -0.47489673, step = 20000 (6.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.323\n",
      "INFO:tensorflow:loss = -0.40103382, step = 20100 (4.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6188\n",
      "INFO:tensorflow:loss = -0.48397246, step = 20200 (5.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7578\n",
      "INFO:tensorflow:loss = -0.9015269, step = 20300 (4.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7208\n",
      "INFO:tensorflow:loss = -0.46023816, step = 20400 (4.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9698\n",
      "INFO:tensorflow:loss = -0.4218418, step = 20500 (4.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2006\n",
      "INFO:tensorflow:loss = -0.5914887, step = 20600 (4.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2113\n",
      "INFO:tensorflow:loss = -0.42483848, step = 20700 (4.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2193\n",
      "INFO:tensorflow:loss = -0.46322268, step = 20800 (4.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5555\n",
      "INFO:tensorflow:loss = -0.3932237, step = 20900 (5.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5247\n",
      "INFO:tensorflow:loss = -0.4698517, step = 21000 (4.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.681\n",
      "INFO:tensorflow:loss = -0.9126687, step = 21100 (4.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0411\n",
      "INFO:tensorflow:loss = -0.49749792, step = 21200 (4.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5253\n",
      "INFO:tensorflow:loss = -0.40821537, step = 21300 (4.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7696\n",
      "INFO:tensorflow:loss = -0.5030595, step = 21400 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0478\n",
      "INFO:tensorflow:loss = -0.39957252, step = 21500 (4.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4618\n",
      "INFO:tensorflow:loss = -0.49607491, step = 21600 (4.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.366\n",
      "INFO:tensorflow:loss = -0.4380647, step = 21700 (4.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9766\n",
      "INFO:tensorflow:loss = -0.42126328, step = 21800 (4.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1859\n",
      "INFO:tensorflow:loss = -0.8396553, step = 21900 (4.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7029\n",
      "INFO:tensorflow:loss = -0.46212286, step = 22000 (4.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3897\n",
      "INFO:tensorflow:loss = -0.45961398, step = 22100 (4.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1896\n",
      "INFO:tensorflow:loss = -0.5798058, step = 22200 (4.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8993\n",
      "INFO:tensorflow:loss = -0.4950472, step = 22300 (4.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9031\n",
      "INFO:tensorflow:loss = -0.52908915, step = 22400 (4.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7354\n",
      "INFO:tensorflow:loss = -0.42872515, step = 22500 (4.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9378\n",
      "INFO:tensorflow:loss = -0.3725257, step = 22600 (4.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9445\n",
      "INFO:tensorflow:loss = -0.69239044, step = 22700 (4.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4743\n",
      "INFO:tensorflow:loss = -0.5718336, step = 22800 (4.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0313\n",
      "INFO:tensorflow:loss = -0.55720174, step = 22900 (4.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4623\n",
      "INFO:tensorflow:loss = -0.53435636, step = 23000 (4.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2961\n",
      "INFO:tensorflow:loss = -0.4724825, step = 23100 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9416\n",
      "INFO:tensorflow:loss = -0.53372806, step = 23200 (4.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4069\n",
      "INFO:tensorflow:loss = -0.5133797, step = 23300 (4.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3111\n",
      "INFO:tensorflow:loss = -0.61143667, step = 23400 (4.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8114\n",
      "INFO:tensorflow:loss = -0.5278928, step = 23500 (4.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6429\n",
      "INFO:tensorflow:loss = -0.58025575, step = 23600 (4.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9333\n",
      "INFO:tensorflow:loss = -0.55927837, step = 23700 (4.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7031\n",
      "INFO:tensorflow:loss = -0.65791637, step = 23800 (4.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0835\n",
      "INFO:tensorflow:loss = -0.55051535, step = 23900 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2101\n",
      "INFO:tensorflow:loss = -0.4677285, step = 24000 (4.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3454\n",
      "INFO:tensorflow:loss = -0.52249694, step = 24100 (4.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2057\n",
      "INFO:tensorflow:loss = -0.98261803, step = 24200 (4.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7447\n",
      "INFO:tensorflow:loss = -0.4898513, step = 24300 (4.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7537\n",
      "INFO:tensorflow:loss = -0.45994774, step = 24400 (4.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2009\n",
      "INFO:tensorflow:loss = -0.4738624, step = 24500 (4.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2816\n",
      "INFO:tensorflow:loss = -0.7894881, step = 24600 (4.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8393\n",
      "INFO:tensorflow:loss = -0.41297293, step = 24700 (4.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3662\n",
      "INFO:tensorflow:loss = -0.4955026, step = 24800 (4.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0908\n",
      "INFO:tensorflow:loss = -0.46274108, step = 24900 (4.526 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 25000...\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1064: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 25000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:33:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:33:27.722768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:33:27.723338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:33:27.723777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:33:27.724621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:33:27.724653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:33:27.725060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:33:27.725107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.10531s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:33:28\n",
      "INFO:tensorflow:Saving dict for global step 25000: global_step = 25000, labels_mean = 0.08838565, logits_mean = 0.82093966, loss = -0.5370207, metric/ndcg@10 = 0.28991267, metric/ndcg@15 = 0.33289826, metric/ndcg@20 = 0.37151784, metric/ndcg@25 = 0.3955859, metric/ndcg@30 = 0.41477826\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25000: /tmp/ranking_model_dir2/model.ckpt-25000\n",
      "INFO:tensorflow:global_step/sec: 15.0015\n",
      "INFO:tensorflow:loss = -0.9810732, step = 25000 (6.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7155\n",
      "INFO:tensorflow:loss = -0.7017694, step = 25100 (4.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9452\n",
      "INFO:tensorflow:loss = -0.474141, step = 25200 (4.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2372\n",
      "INFO:tensorflow:loss = -0.64797544, step = 25300 (4.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7206\n",
      "INFO:tensorflow:loss = -0.67290217, step = 25400 (4.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0464\n",
      "INFO:tensorflow:loss = -0.44944334, step = 25500 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8891\n",
      "INFO:tensorflow:loss = -0.41841692, step = 25600 (4.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4362\n",
      "INFO:tensorflow:loss = -0.6415833, step = 25700 (4.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5759\n",
      "INFO:tensorflow:loss = -0.98234516, step = 25800 (4.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6524\n",
      "INFO:tensorflow:loss = -0.7388705, step = 25900 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3253\n",
      "INFO:tensorflow:loss = -0.59089714, step = 26000 (4.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7859\n",
      "INFO:tensorflow:loss = -0.8116798, step = 26100 (4.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8694\n",
      "INFO:tensorflow:loss = -0.6543876, step = 26200 (4.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5691\n",
      "INFO:tensorflow:loss = -0.5170259, step = 26300 (4.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1983\n",
      "INFO:tensorflow:loss = -0.50013, step = 26400 (4.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9884\n",
      "INFO:tensorflow:loss = -0.863574, step = 26500 (4.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1183\n",
      "INFO:tensorflow:loss = -0.84472597, step = 26600 (4.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.466\n",
      "INFO:tensorflow:loss = -0.5403384, step = 26700 (4.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9208\n",
      "INFO:tensorflow:loss = -0.52744097, step = 26800 (4.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9155\n",
      "INFO:tensorflow:loss = -0.6611935, step = 26900 (4.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6398\n",
      "INFO:tensorflow:loss = -0.8405972, step = 27000 (4.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1129\n",
      "INFO:tensorflow:loss = -0.5988301, step = 27100 (4.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.077\n",
      "INFO:tensorflow:loss = -0.51591337, step = 27200 (4.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2368\n",
      "INFO:tensorflow:loss = -0.80092216, step = 27300 (4.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5335\n",
      "INFO:tensorflow:loss = -0.4082669, step = 27400 (4.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8244\n",
      "INFO:tensorflow:loss = -0.49320227, step = 27500 (4.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8514\n",
      "INFO:tensorflow:loss = -0.4521017, step = 27600 (4.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6245\n",
      "INFO:tensorflow:loss = -0.47434902, step = 27700 (4.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6154\n",
      "INFO:tensorflow:loss = -0.76683205, step = 27800 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8193\n",
      "INFO:tensorflow:loss = -0.46873367, step = 27900 (4.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9002\n",
      "INFO:tensorflow:loss = -0.66536474, step = 28000 (4.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8709\n",
      "INFO:tensorflow:loss = -0.5032017, step = 28100 (4.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0526\n",
      "INFO:tensorflow:loss = -0.4375726, step = 28200 (4.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8011\n",
      "INFO:tensorflow:loss = -0.6324484, step = 28300 (4.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4031\n",
      "INFO:tensorflow:loss = -0.50193614, step = 28400 (5.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.914\n",
      "INFO:tensorflow:loss = -0.5197793, step = 28500 (4.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2972\n",
      "INFO:tensorflow:loss = -0.412669, step = 28600 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7744\n",
      "INFO:tensorflow:loss = -0.5084276, step = 28700 (4.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2174\n",
      "INFO:tensorflow:loss = -0.90413773, step = 28800 (4.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6969\n",
      "INFO:tensorflow:loss = -0.4997264, step = 28900 (4.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3504\n",
      "INFO:tensorflow:loss = -0.45486477, step = 29000 (4.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9493\n",
      "INFO:tensorflow:loss = -0.5803069, step = 29100 (4.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4794\n",
      "INFO:tensorflow:loss = -0.48250315, step = 29200 (4.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8427\n",
      "INFO:tensorflow:loss = -0.4709099, step = 29300 (4.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.323\n",
      "INFO:tensorflow:loss = -0.4243142, step = 29400 (4.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7645\n",
      "INFO:tensorflow:loss = -0.51488173, step = 29500 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2353\n",
      "INFO:tensorflow:loss = -0.9161266, step = 29600 (4.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5742\n",
      "INFO:tensorflow:loss = -0.51690805, step = 29700 (4.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.654\n",
      "INFO:tensorflow:loss = -0.40396076, step = 29800 (4.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5106\n",
      "INFO:tensorflow:loss = -0.4894346, step = 29900 (4.442 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 30000...\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 30000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:37:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:37:15.490989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:37:15.491666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:37:15.492120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:37:15.492913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:37:15.492947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:37:15.493365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:37:15.493417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.13796s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:37:16\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, labels_mean = 0.08838565, logits_mean = 0.86671513, loss = -0.5541061, metric/ndcg@10 = 0.30896592, metric/ndcg@15 = 0.35772124, metric/ndcg@20 = 0.39513758, metric/ndcg@25 = 0.4214787, metric/ndcg@30 = 0.44408306\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: /tmp/ranking_model_dir2/model.ckpt-30000\n",
      "INFO:tensorflow:global_step/sec: 14.8261\n",
      "INFO:tensorflow:loss = -0.422363, step = 30000 (6.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3674\n",
      "INFO:tensorflow:loss = -0.52628696, step = 30100 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1003\n",
      "INFO:tensorflow:loss = -0.46677184, step = 30200 (4.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6309\n",
      "INFO:tensorflow:loss = -0.43091232, step = 30300 (5.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8629\n",
      "INFO:tensorflow:loss = -0.85958236, step = 30400 (4.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.825\n",
      "INFO:tensorflow:loss = -0.4599924, step = 30500 (4.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.608\n",
      "INFO:tensorflow:loss = -0.44581705, step = 30600 (4.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6411\n",
      "INFO:tensorflow:loss = -0.5866598, step = 30700 (4.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3259\n",
      "INFO:tensorflow:loss = -0.55140007, step = 30800 (4.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3583\n",
      "INFO:tensorflow:loss = -0.53519315, step = 30900 (4.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8554\n",
      "INFO:tensorflow:loss = -0.49623924, step = 31000 (5.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2392\n",
      "INFO:tensorflow:loss = -0.41244712, step = 31100 (4.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9548\n",
      "INFO:tensorflow:loss = -0.68978727, step = 31200 (4.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0352\n",
      "INFO:tensorflow:loss = -0.5816594, step = 31300 (4.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8355\n",
      "INFO:tensorflow:loss = -0.5621635, step = 31400 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3041\n",
      "INFO:tensorflow:loss = -0.53346586, step = 31500 (4.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.045\n",
      "INFO:tensorflow:loss = -0.48953184, step = 31600 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3661\n",
      "INFO:tensorflow:loss = -0.5865246, step = 31700 (4.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5293\n",
      "INFO:tensorflow:loss = -0.57818294, step = 31800 (4.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5832\n",
      "INFO:tensorflow:loss = -0.59113425, step = 31900 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4457\n",
      "INFO:tensorflow:loss = -0.597626, step = 32000 (4.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4032\n",
      "INFO:tensorflow:loss = -0.6708466, step = 32100 (4.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6282\n",
      "INFO:tensorflow:loss = -0.60601586, step = 32200 (4.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3261\n",
      "INFO:tensorflow:loss = -0.6465585, step = 32300 (4.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2413\n",
      "INFO:tensorflow:loss = -0.5886322, step = 32400 (4.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6991\n",
      "INFO:tensorflow:loss = -0.48414284, step = 32500 (4.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3574\n",
      "INFO:tensorflow:loss = -0.57338685, step = 32600 (4.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.37\n",
      "INFO:tensorflow:loss = -0.9768547, step = 32700 (4.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1045\n",
      "INFO:tensorflow:loss = -0.5124481, step = 32800 (4.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7731\n",
      "INFO:tensorflow:loss = -0.4345256, step = 32900 (4.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2781\n",
      "INFO:tensorflow:loss = -0.49889764, step = 33000 (4.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6176\n",
      "INFO:tensorflow:loss = -0.8025681, step = 33100 (4.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5674\n",
      "INFO:tensorflow:loss = -0.4282666, step = 33200 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0719\n",
      "INFO:tensorflow:loss = -0.5687508, step = 33300 (4.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5118\n",
      "INFO:tensorflow:loss = -0.47405195, step = 33400 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4259\n",
      "INFO:tensorflow:loss = -0.98446226, step = 33500 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9117\n",
      "INFO:tensorflow:loss = -0.69551754, step = 33600 (4.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9419\n",
      "INFO:tensorflow:loss = -0.48282138, step = 33700 (4.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0238\n",
      "INFO:tensorflow:loss = -0.6563731, step = 33800 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4625\n",
      "INFO:tensorflow:loss = -0.68341964, step = 33900 (4.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9554\n",
      "INFO:tensorflow:loss = -0.49688298, step = 34000 (4.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9166\n",
      "INFO:tensorflow:loss = -0.42369902, step = 34100 (4.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7951\n",
      "INFO:tensorflow:loss = -0.58257043, step = 34200 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1928\n",
      "INFO:tensorflow:loss = -0.98192286, step = 34300 (4.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8912\n",
      "INFO:tensorflow:loss = -0.75743985, step = 34400 (4.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0485\n",
      "INFO:tensorflow:loss = -0.60392547, step = 34500 (4.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2303\n",
      "INFO:tensorflow:loss = -0.8301009, step = 34600 (4.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3081\n",
      "INFO:tensorflow:loss = -0.6963859, step = 34700 (4.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8693\n",
      "INFO:tensorflow:loss = -0.5341718, step = 34800 (4.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8329\n",
      "INFO:tensorflow:loss = -0.51232135, step = 34900 (4.380 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 35000...\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 35000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:41:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-35000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:41:02.782333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:41:02.782800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:41:02.783151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:41:02.783794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:41:02.783827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:41:02.784144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:41:02.784193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.07001s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:41:03\n",
      "INFO:tensorflow:Saving dict for global step 35000: global_step = 35000, labels_mean = 0.08838565, logits_mean = 0.783205, loss = -0.56869453, metric/ndcg@10 = 0.3335593, metric/ndcg@15 = 0.38649333, metric/ndcg@20 = 0.42013362, metric/ndcg@25 = 0.4483855, metric/ndcg@30 = 0.47154897\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: /tmp/ranking_model_dir2/model.ckpt-35000\n",
      "INFO:tensorflow:global_step/sec: 15.0772\n",
      "INFO:tensorflow:loss = -0.8517353, step = 35000 (6.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.968\n",
      "INFO:tensorflow:loss = -0.9104295, step = 35100 (4.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5722\n",
      "INFO:tensorflow:loss = -0.5940645, step = 35200 (4.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0498\n",
      "INFO:tensorflow:loss = -0.55653554, step = 35300 (4.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9461\n",
      "INFO:tensorflow:loss = -0.6824397, step = 35400 (4.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3143\n",
      "INFO:tensorflow:loss = -0.8532048, step = 35500 (4.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0802\n",
      "INFO:tensorflow:loss = -0.6327095, step = 35600 (4.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3955\n",
      "INFO:tensorflow:loss = -0.5376123, step = 35700 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2713\n",
      "INFO:tensorflow:loss = -0.8275381, step = 35800 (4.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5492\n",
      "INFO:tensorflow:loss = -0.5093426, step = 35900 (4.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.817\n",
      "INFO:tensorflow:loss = -0.51452816, step = 36000 (4.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8652\n",
      "INFO:tensorflow:loss = -0.45266247, step = 36100 (4.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5219\n",
      "INFO:tensorflow:loss = -0.49122244, step = 36200 (4.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4737\n",
      "INFO:tensorflow:loss = -0.8067504, step = 36300 (4.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3538\n",
      "INFO:tensorflow:loss = -0.43345562, step = 36400 (4.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4113\n",
      "INFO:tensorflow:loss = -0.68731284, step = 36500 (4.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3117\n",
      "INFO:tensorflow:loss = -0.52463496, step = 36600 (4.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6999\n",
      "INFO:tensorflow:loss = -0.44736102, step = 36700 (4.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6339\n",
      "INFO:tensorflow:loss = -0.68863446, step = 36800 (4.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1877\n",
      "INFO:tensorflow:loss = -0.58557004, step = 36900 (4.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9542\n",
      "INFO:tensorflow:loss = -0.55810195, step = 37000 (4.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0798\n",
      "INFO:tensorflow:loss = -0.5151366, step = 37100 (4.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4635\n",
      "INFO:tensorflow:loss = -0.52715325, step = 37200 (4.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4793\n",
      "INFO:tensorflow:loss = -0.9109913, step = 37300 (4.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6606\n",
      "INFO:tensorflow:loss = -0.5110221, step = 37400 (4.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8513\n",
      "INFO:tensorflow:loss = -0.5129343, step = 37500 (4.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0196\n",
      "INFO:tensorflow:loss = -0.64328027, step = 37600 (4.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9468\n",
      "INFO:tensorflow:loss = -0.50370413, step = 37700 (5.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1545\n",
      "INFO:tensorflow:loss = -0.47953612, step = 37800 (4.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5477\n",
      "INFO:tensorflow:loss = -0.47385937, step = 37900 (4.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0831\n",
      "INFO:tensorflow:loss = -0.5274352, step = 38000 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.77\n",
      "INFO:tensorflow:loss = -0.9218708, step = 38100 (4.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0474\n",
      "INFO:tensorflow:loss = -0.5373798, step = 38200 (5.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9021\n",
      "INFO:tensorflow:loss = -0.47142488, step = 38300 (4.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3589\n",
      "INFO:tensorflow:loss = -0.50137997, step = 38400 (4.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1973\n",
      "INFO:tensorflow:loss = -0.4662363, step = 38500 (4.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8161\n",
      "INFO:tensorflow:loss = -0.56402516, step = 38600 (4.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2269\n",
      "INFO:tensorflow:loss = -0.46502513, step = 38700 (4.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4024\n",
      "INFO:tensorflow:loss = -0.48952708, step = 38800 (4.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.048\n",
      "INFO:tensorflow:loss = -0.87863106, step = 38900 (4.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1646\n",
      "INFO:tensorflow:loss = -0.49500704, step = 39000 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8786\n",
      "INFO:tensorflow:loss = -0.46970177, step = 39100 (4.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0369\n",
      "INFO:tensorflow:loss = -0.5887265, step = 39200 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3979\n",
      "INFO:tensorflow:loss = -0.54917717, step = 39300 (4.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2695\n",
      "INFO:tensorflow:loss = -0.55286455, step = 39400 (4.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6533\n",
      "INFO:tensorflow:loss = -0.46037203, step = 39500 (4.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1242\n",
      "INFO:tensorflow:loss = -0.40685242, step = 39600 (4.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5927\n",
      "INFO:tensorflow:loss = -0.72910047, step = 39700 (4.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2379\n",
      "INFO:tensorflow:loss = -0.5749472, step = 39800 (4.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7749\n",
      "INFO:tensorflow:loss = -0.56954265, step = 39900 (4.390 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 40000...\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 40000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:44:51\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:44:51.459597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:44:51.460220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:44:51.460677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:44:51.462649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:44:51.462741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:44:51.463259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:44:51.463314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.11019s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:44:52\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, labels_mean = 0.08838565, logits_mean = 0.6383553, loss = -0.5780001, metric/ndcg@10 = 0.35141844, metric/ndcg@15 = 0.39851242, metric/ndcg@20 = 0.43637654, metric/ndcg@25 = 0.46912032, metric/ndcg@30 = 0.48912692\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: /tmp/ranking_model_dir2/model.ckpt-40000\n",
      "INFO:tensorflow:global_step/sec: 14.3577\n",
      "INFO:tensorflow:loss = -0.5680507, step = 40000 (6.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6672\n",
      "INFO:tensorflow:loss = -0.5235133, step = 40100 (4.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6142\n",
      "INFO:tensorflow:loss = -0.64744323, step = 40200 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5527\n",
      "INFO:tensorflow:loss = -0.57504153, step = 40300 (4.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4139\n",
      "INFO:tensorflow:loss = -0.58217967, step = 40400 (4.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4205\n",
      "INFO:tensorflow:loss = -0.68849975, step = 40500 (4.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0489\n",
      "INFO:tensorflow:loss = -0.6724495, step = 40600 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8273\n",
      "INFO:tensorflow:loss = -0.6431873, step = 40700 (4.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1126\n",
      "INFO:tensorflow:loss = -0.6517372, step = 40800 (4.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6216\n",
      "INFO:tensorflow:loss = -0.5988841, step = 40900 (4.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8065\n",
      "INFO:tensorflow:loss = -0.5628387, step = 41000 (4.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7854\n",
      "INFO:tensorflow:loss = -0.59683627, step = 41100 (4.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9705\n",
      "INFO:tensorflow:loss = -0.9453065, step = 41200 (4.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2206\n",
      "INFO:tensorflow:loss = -0.56678706, step = 41300 (4.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3725\n",
      "INFO:tensorflow:loss = -0.4797379, step = 41400 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8244\n",
      "INFO:tensorflow:loss = -0.57013535, step = 41500 (4.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9985\n",
      "INFO:tensorflow:loss = -0.81254584, step = 41600 (4.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5637\n",
      "INFO:tensorflow:loss = -0.4351787, step = 41700 (4.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.768\n",
      "INFO:tensorflow:loss = -0.5757165, step = 41800 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3327\n",
      "INFO:tensorflow:loss = -0.50637984, step = 41900 (4.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8192\n",
      "INFO:tensorflow:loss = -0.9838159, step = 42000 (4.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6995\n",
      "INFO:tensorflow:loss = -0.6963017, step = 42100 (4.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9403\n",
      "INFO:tensorflow:loss = -0.5417866, step = 42200 (4.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0903\n",
      "INFO:tensorflow:loss = -0.64063346, step = 42300 (4.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0556\n",
      "INFO:tensorflow:loss = -0.7080213, step = 42400 (4.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6997\n",
      "INFO:tensorflow:loss = -0.48904458, step = 42500 (4.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7748\n",
      "INFO:tensorflow:loss = -0.48815328, step = 42600 (4.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0285\n",
      "INFO:tensorflow:loss = -0.5986843, step = 42700 (4.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4694\n",
      "INFO:tensorflow:loss = -0.9822327, step = 42800 (4.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6857\n",
      "INFO:tensorflow:loss = -0.76521635, step = 42900 (4.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4653\n",
      "INFO:tensorflow:loss = -0.6494556, step = 43000 (4.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6186\n",
      "INFO:tensorflow:loss = -0.8198118, step = 43100 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8449\n",
      "INFO:tensorflow:loss = -0.7047449, step = 43200 (4.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2152\n",
      "INFO:tensorflow:loss = -0.5294166, step = 43300 (4.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.812\n",
      "INFO:tensorflow:loss = -0.5271283, step = 43400 (4.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9534\n",
      "INFO:tensorflow:loss = -0.8649182, step = 43500 (4.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2215\n",
      "INFO:tensorflow:loss = -0.9341532, step = 43600 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7424\n",
      "INFO:tensorflow:loss = -0.64569986, step = 43700 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7571\n",
      "INFO:tensorflow:loss = -0.60117626, step = 43800 (4.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7635\n",
      "INFO:tensorflow:loss = -0.74828595, step = 43900 (4.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2873\n",
      "INFO:tensorflow:loss = -0.85408497, step = 44000 (4.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5056\n",
      "INFO:tensorflow:loss = -0.63894546, step = 44100 (4.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6366\n",
      "INFO:tensorflow:loss = -0.57104933, step = 44200 (4.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7592\n",
      "INFO:tensorflow:loss = -0.85165954, step = 44300 (4.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8968\n",
      "INFO:tensorflow:loss = -0.5162289, step = 44400 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9399\n",
      "INFO:tensorflow:loss = -0.5311485, step = 44500 (4.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.443\n",
      "INFO:tensorflow:loss = -0.51640445, step = 44600 (4.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1452\n",
      "INFO:tensorflow:loss = -0.52537245, step = 44700 (4.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0512\n",
      "INFO:tensorflow:loss = -0.8529533, step = 44800 (4.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0298\n",
      "INFO:tensorflow:loss = -0.46096227, step = 44900 (4.540 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 45000...\n",
      "INFO:tensorflow:Saving checkpoints for 45000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 45000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:48:37\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-45000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:48:37.681428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:48:37.682117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:48:37.682661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:48:37.683734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:48:37.683807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:48:37.684256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:48:37.684317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.03402s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:48:38\n",
      "INFO:tensorflow:Saving dict for global step 45000: global_step = 45000, labels_mean = 0.08838565, logits_mean = 0.3355157, loss = -0.59259075, metric/ndcg@10 = 0.36911505, metric/ndcg@15 = 0.42234063, metric/ndcg@20 = 0.46635416, metric/ndcg@25 = 0.49379042, metric/ndcg@30 = 0.51031\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 45000: /tmp/ranking_model_dir2/model.ckpt-45000\n",
      "INFO:tensorflow:global_step/sec: 15.1446\n",
      "INFO:tensorflow:loss = -0.68444455, step = 45000 (6.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8897\n",
      "INFO:tensorflow:loss = -0.6692792, step = 45100 (4.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9689\n",
      "INFO:tensorflow:loss = -0.5456697, step = 45200 (4.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9783\n",
      "INFO:tensorflow:loss = -0.7130718, step = 45300 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2285\n",
      "INFO:tensorflow:loss = -0.59182453, step = 45400 (4.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6136\n",
      "INFO:tensorflow:loss = -0.54414487, step = 45500 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5168\n",
      "INFO:tensorflow:loss = -0.5582992, step = 45600 (4.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2005\n",
      "INFO:tensorflow:loss = -0.56108, step = 45700 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2715\n",
      "INFO:tensorflow:loss = -0.9235884, step = 45800 (4.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0844\n",
      "INFO:tensorflow:loss = -0.51432186, step = 45900 (4.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8668\n",
      "INFO:tensorflow:loss = -0.5325632, step = 46000 (4.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.751\n",
      "INFO:tensorflow:loss = -0.66120607, step = 46100 (4.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9998\n",
      "INFO:tensorflow:loss = -0.5283607, step = 46200 (4.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0777\n",
      "INFO:tensorflow:loss = -0.5116036, step = 46300 (4.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4326\n",
      "INFO:tensorflow:loss = -0.4834923, step = 46400 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0013\n",
      "INFO:tensorflow:loss = -0.569876, step = 46500 (4.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0955\n",
      "INFO:tensorflow:loss = -0.9347664, step = 46600 (4.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9656\n",
      "INFO:tensorflow:loss = -0.6009002, step = 46700 (4.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7985\n",
      "INFO:tensorflow:loss = -0.51102436, step = 46800 (4.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.579\n",
      "INFO:tensorflow:loss = -0.5256818, step = 46900 (4.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2566\n",
      "INFO:tensorflow:loss = -0.49043912, step = 47000 (4.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1289\n",
      "INFO:tensorflow:loss = -0.5613338, step = 47100 (4.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1721\n",
      "INFO:tensorflow:loss = -0.4795599, step = 47200 (4.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0337\n",
      "INFO:tensorflow:loss = -0.4860772, step = 47300 (4.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9795\n",
      "INFO:tensorflow:loss = -0.8987533, step = 47400 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4946\n",
      "INFO:tensorflow:loss = -0.5206556, step = 47500 (4.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4512\n",
      "INFO:tensorflow:loss = -0.44125873, step = 47600 (4.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5035\n",
      "INFO:tensorflow:loss = -0.6265478, step = 47700 (4.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1029\n",
      "INFO:tensorflow:loss = -0.5784278, step = 47800 (4.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6633\n",
      "INFO:tensorflow:loss = -0.59043276, step = 47900 (4.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1106\n",
      "INFO:tensorflow:loss = -0.5130896, step = 48000 (4.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8714\n",
      "INFO:tensorflow:loss = -0.45407224, step = 48100 (4.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5518\n",
      "INFO:tensorflow:loss = -0.73429215, step = 48200 (4.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0275\n",
      "INFO:tensorflow:loss = -0.59834373, step = 48300 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8614\n",
      "INFO:tensorflow:loss = -0.5962943, step = 48400 (4.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.035\n",
      "INFO:tensorflow:loss = -0.5866307, step = 48500 (4.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3016\n",
      "INFO:tensorflow:loss = -0.5187763, step = 48600 (4.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.619\n",
      "INFO:tensorflow:loss = -0.6740514, step = 48700 (4.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4213\n",
      "INFO:tensorflow:loss = -0.5640336, step = 48800 (4.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0794\n",
      "INFO:tensorflow:loss = -0.5550468, step = 48900 (4.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1681\n",
      "INFO:tensorflow:loss = -0.71440923, step = 49000 (4.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8861\n",
      "INFO:tensorflow:loss = -0.76311517, step = 49100 (4.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1669\n",
      "INFO:tensorflow:loss = -0.66744035, step = 49200 (4.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7563\n",
      "INFO:tensorflow:loss = -0.6667375, step = 49300 (4.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.695\n",
      "INFO:tensorflow:loss = -0.61458606, step = 49400 (4.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8639\n",
      "INFO:tensorflow:loss = -0.4755335, step = 49500 (4.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2234\n",
      "INFO:tensorflow:loss = -0.6651476, step = 49600 (4.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9655\n",
      "INFO:tensorflow:loss = -0.9269538, step = 49700 (4.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5738\n",
      "INFO:tensorflow:loss = -0.52557, step = 49800 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8038\n",
      "INFO:tensorflow:loss = -0.4758782, step = 49900 (4.808 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 50000...\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 50000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:52:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-50000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:52:25.796609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:52:25.797408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:52:25.797920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:52:25.800691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:52:25.800730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:52:25.801188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:52:25.801243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.10411s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:52:26\n",
      "INFO:tensorflow:Saving dict for global step 50000: global_step = 50000, labels_mean = 0.08838565, logits_mean = 0.06887744, loss = -0.60165244, metric/ndcg@10 = 0.3835516, metric/ndcg@15 = 0.44048765, metric/ndcg@20 = 0.47789434, metric/ndcg@25 = 0.5067025, metric/ndcg@30 = 0.52831423\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50000: /tmp/ranking_model_dir2/model.ckpt-50000\n",
      "INFO:tensorflow:global_step/sec: 14.8353\n",
      "INFO:tensorflow:loss = -0.57925916, step = 50000 (6.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.698\n",
      "INFO:tensorflow:loss = -0.82090235, step = 50100 (4.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0968\n",
      "INFO:tensorflow:loss = -0.52429545, step = 50200 (4.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1655\n",
      "INFO:tensorflow:loss = -0.6218376, step = 50300 (4.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2152\n",
      "INFO:tensorflow:loss = -0.5602896, step = 50400 (4.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9651\n",
      "INFO:tensorflow:loss = -0.98315, step = 50500 (4.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7945\n",
      "INFO:tensorflow:loss = -0.70140433, step = 50600 (4.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9625\n",
      "INFO:tensorflow:loss = -0.5872438, step = 50700 (4.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7162\n",
      "INFO:tensorflow:loss = -0.6761962, step = 50800 (4.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5257\n",
      "INFO:tensorflow:loss = -0.73195755, step = 50900 (4.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2843\n",
      "INFO:tensorflow:loss = -0.5081963, step = 51000 (4.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4541\n",
      "INFO:tensorflow:loss = -0.5025971, step = 51100 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5493\n",
      "INFO:tensorflow:loss = -0.59863925, step = 51200 (4.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4245\n",
      "INFO:tensorflow:loss = -0.9848263, step = 51300 (4.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6316\n",
      "INFO:tensorflow:loss = -0.79332805, step = 51400 (4.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0677\n",
      "INFO:tensorflow:loss = -0.66718584, step = 51500 (4.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.479\n",
      "INFO:tensorflow:loss = -0.83574617, step = 51600 (4.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6884\n",
      "INFO:tensorflow:loss = -0.7016171, step = 51700 (4.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7465\n",
      "INFO:tensorflow:loss = -0.61124146, step = 51800 (4.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0011\n",
      "INFO:tensorflow:loss = -0.5475571, step = 51900 (4.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2187\n",
      "INFO:tensorflow:loss = -0.8763674, step = 52000 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9961\n",
      "INFO:tensorflow:loss = -0.96348083, step = 52100 (4.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3691\n",
      "INFO:tensorflow:loss = -0.6711358, step = 52200 (4.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1789\n",
      "INFO:tensorflow:loss = -0.59361213, step = 52300 (4.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0086\n",
      "INFO:tensorflow:loss = -0.7750422, step = 52400 (4.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7328\n",
      "INFO:tensorflow:loss = -0.8716413, step = 52500 (4.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9692\n",
      "INFO:tensorflow:loss = -0.6639848, step = 52600 (4.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7233\n",
      "INFO:tensorflow:loss = -0.5843774, step = 52700 (4.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4207\n",
      "INFO:tensorflow:loss = -0.85801995, step = 52800 (4.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2725\n",
      "INFO:tensorflow:loss = -0.5671778, step = 52900 (4.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4572\n",
      "INFO:tensorflow:loss = -0.5634773, step = 53000 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1567\n",
      "INFO:tensorflow:loss = -0.51184344, step = 53100 (4.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7828\n",
      "INFO:tensorflow:loss = -0.55004853, step = 53200 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1315\n",
      "INFO:tensorflow:loss = -0.8703815, step = 53300 (4.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.187\n",
      "INFO:tensorflow:loss = -0.5308233, step = 53400 (4.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8553\n",
      "INFO:tensorflow:loss = -0.66041255, step = 53500 (4.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5769\n",
      "INFO:tensorflow:loss = -0.645885, step = 53600 (4.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0118\n",
      "INFO:tensorflow:loss = -0.52836823, step = 53700 (4.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5275\n",
      "INFO:tensorflow:loss = -0.7119448, step = 53800 (4.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9369\n",
      "INFO:tensorflow:loss = -0.56123793, step = 53900 (4.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7873\n",
      "INFO:tensorflow:loss = -0.5822397, step = 54000 (4.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5457\n",
      "INFO:tensorflow:loss = -0.60971797, step = 54100 (4.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8177\n",
      "INFO:tensorflow:loss = -0.5577432, step = 54200 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.601\n",
      "INFO:tensorflow:loss = -0.93771374, step = 54300 (4.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4345\n",
      "INFO:tensorflow:loss = -0.5723419, step = 54400 (4.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7866\n",
      "INFO:tensorflow:loss = -0.55956876, step = 54500 (4.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8135\n",
      "INFO:tensorflow:loss = -0.66542614, step = 54600 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.617\n",
      "INFO:tensorflow:loss = -0.5651003, step = 54700 (4.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1322\n",
      "INFO:tensorflow:loss = -0.58017766, step = 54800 (4.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8318\n",
      "INFO:tensorflow:loss = -0.4977952, step = 54900 (4.580 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 55000...\n",
      "INFO:tensorflow:Saving checkpoints for 55000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 55000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T10:56:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-55000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:56:14.101298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:56:14.102002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:56:14.102497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:56:14.103890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:56:14.103924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 10:56:14.104374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 10:56:14.104426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.06912s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-10:56:15\n",
      "INFO:tensorflow:Saving dict for global step 55000: global_step = 55000, labels_mean = 0.08838565, logits_mean = -0.26027676, loss = -0.611324, metric/ndcg@10 = 0.40131778, metric/ndcg@15 = 0.453, metric/ndcg@20 = 0.49184448, metric/ndcg@25 = 0.51632243, metric/ndcg@30 = 0.5426219\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 55000: /tmp/ranking_model_dir2/model.ckpt-55000\n",
      "INFO:tensorflow:global_step/sec: 14.9888\n",
      "INFO:tensorflow:loss = -0.57565856, step = 55000 (6.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4117\n",
      "INFO:tensorflow:loss = -0.9243806, step = 55100 (4.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0903\n",
      "INFO:tensorflow:loss = -0.6063644, step = 55200 (4.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7452\n",
      "INFO:tensorflow:loss = -0.5287609, step = 55300 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7538\n",
      "INFO:tensorflow:loss = -0.5313171, step = 55400 (4.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8865\n",
      "INFO:tensorflow:loss = -0.53436947, step = 55500 (4.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0727\n",
      "INFO:tensorflow:loss = -0.5337728, step = 55600 (4.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7278\n",
      "INFO:tensorflow:loss = -0.5618101, step = 55700 (4.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3137\n",
      "INFO:tensorflow:loss = -0.4889074, step = 55800 (4.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3143\n",
      "INFO:tensorflow:loss = -0.914569, step = 55900 (4.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6897\n",
      "INFO:tensorflow:loss = -0.5382639, step = 56000 (4.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7812\n",
      "INFO:tensorflow:loss = -0.47583598, step = 56100 (4.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9994\n",
      "INFO:tensorflow:loss = -0.6506771, step = 56200 (4.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2438\n",
      "INFO:tensorflow:loss = -0.59950006, step = 56300 (4.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6594\n",
      "INFO:tensorflow:loss = -0.5674602, step = 56400 (4.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2257\n",
      "INFO:tensorflow:loss = -0.528216, step = 56500 (4.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8366\n",
      "INFO:tensorflow:loss = -0.50410175, step = 56600 (4.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6882\n",
      "INFO:tensorflow:loss = -0.7402525, step = 56700 (4.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8642\n",
      "INFO:tensorflow:loss = -0.5822246, step = 56800 (4.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0903\n",
      "INFO:tensorflow:loss = -0.6005337, step = 56900 (4.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0878\n",
      "INFO:tensorflow:loss = -0.6061448, step = 57000 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5638\n",
      "INFO:tensorflow:loss = -0.56841564, step = 57100 (4.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3937\n",
      "INFO:tensorflow:loss = -0.68905866, step = 57200 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0947\n",
      "INFO:tensorflow:loss = -0.52947795, step = 57300 (4.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.888\n",
      "INFO:tensorflow:loss = -0.56678987, step = 57400 (4.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6531\n",
      "INFO:tensorflow:loss = -0.75956106, step = 57500 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6406\n",
      "INFO:tensorflow:loss = -0.7340969, step = 57600 (4.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4187\n",
      "INFO:tensorflow:loss = -0.7161125, step = 57700 (4.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4661\n",
      "INFO:tensorflow:loss = -0.6944984, step = 57800 (4.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9568\n",
      "INFO:tensorflow:loss = -0.62167704, step = 57900 (4.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0593\n",
      "INFO:tensorflow:loss = -0.43655407, step = 58000 (4.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8762\n",
      "INFO:tensorflow:loss = -0.6312042, step = 58100 (4.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9214\n",
      "INFO:tensorflow:loss = -0.9097373, step = 58200 (4.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1371\n",
      "INFO:tensorflow:loss = -0.5539849, step = 58300 (4.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9845\n",
      "INFO:tensorflow:loss = -0.5632491, step = 58400 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4652\n",
      "INFO:tensorflow:loss = -0.6473963, step = 58500 (4.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.316\n",
      "INFO:tensorflow:loss = -0.8316224, step = 58600 (4.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3889\n",
      "INFO:tensorflow:loss = -0.53890705, step = 58700 (4.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.746\n",
      "INFO:tensorflow:loss = -0.6360374, step = 58800 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2696\n",
      "INFO:tensorflow:loss = -0.55783385, step = 58900 (4.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5822\n",
      "INFO:tensorflow:loss = -0.98490655, step = 59000 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7172\n",
      "INFO:tensorflow:loss = -0.70141894, step = 59100 (4.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1582\n",
      "INFO:tensorflow:loss = -0.6041198, step = 59200 (4.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.575\n",
      "INFO:tensorflow:loss = -0.6415993, step = 59300 (4.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8187\n",
      "INFO:tensorflow:loss = -0.7432675, step = 59400 (4.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9914\n",
      "INFO:tensorflow:loss = -0.5210451, step = 59500 (4.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8068\n",
      "INFO:tensorflow:loss = -0.5744449, step = 59600 (4.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2153\n",
      "INFO:tensorflow:loss = -0.61421627, step = 59700 (4.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4805\n",
      "INFO:tensorflow:loss = -0.97991467, step = 59800 (4.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1793\n",
      "INFO:tensorflow:loss = -0.77919686, step = 59900 (4.508 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 60000...\n",
      "INFO:tensorflow:Saving checkpoints for 60000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 60000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T11:00:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-60000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:00:04.403737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:00:04.404404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:00:04.404914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:00:04.405824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:00:04.405875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 11:00:04.406318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:00:04.406374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.11270s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-11:00:05\n",
      "INFO:tensorflow:Saving dict for global step 60000: global_step = 60000, labels_mean = 0.08838565, logits_mean = -0.605316, loss = -0.6168781, metric/ndcg@10 = 0.41240627, metric/ndcg@15 = 0.46353582, metric/ndcg@20 = 0.5019032, metric/ndcg@25 = 0.52842146, metric/ndcg@30 = 0.55016667\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 60000: /tmp/ranking_model_dir2/model.ckpt-60000\n",
      "INFO:tensorflow:global_step/sec: 13.8512\n",
      "INFO:tensorflow:loss = -0.6571351, step = 60000 (7.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9587\n",
      "INFO:tensorflow:loss = -0.8211029, step = 60100 (4.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6423\n",
      "INFO:tensorflow:loss = -0.7037802, step = 60200 (4.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4918\n",
      "INFO:tensorflow:loss = -0.61633897, step = 60300 (4.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.167\n",
      "INFO:tensorflow:loss = -0.5206185, step = 60400 (4.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6605\n",
      "INFO:tensorflow:loss = -0.8801404, step = 60500 (4.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4042\n",
      "INFO:tensorflow:loss = -0.9829625, step = 60600 (4.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1398\n",
      "INFO:tensorflow:loss = -0.7127913, step = 60700 (4.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.898\n",
      "INFO:tensorflow:loss = -0.66240394, step = 60800 (4.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4163\n",
      "INFO:tensorflow:loss = -0.7900708, step = 60900 (4.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1486\n",
      "INFO:tensorflow:loss = -0.86915267, step = 61000 (4.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2511\n",
      "INFO:tensorflow:loss = -0.68626356, step = 61100 (4.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8726\n",
      "INFO:tensorflow:loss = -0.603276, step = 61200 (4.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4336\n",
      "INFO:tensorflow:loss = -0.879534, step = 61300 (4.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2072\n",
      "INFO:tensorflow:loss = -0.62709385, step = 61400 (4.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6257\n",
      "INFO:tensorflow:loss = -0.6003525, step = 61500 (4.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6105\n",
      "INFO:tensorflow:loss = -0.59671885, step = 61600 (4.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.345\n",
      "INFO:tensorflow:loss = -0.6080288, step = 61700 (4.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7968\n",
      "INFO:tensorflow:loss = -0.8821888, step = 61800 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6882\n",
      "INFO:tensorflow:loss = -0.5882777, step = 61900 (4.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9854\n",
      "INFO:tensorflow:loss = -0.64735895, step = 62000 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7664\n",
      "INFO:tensorflow:loss = -0.69273704, step = 62100 (4.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7226\n",
      "INFO:tensorflow:loss = -0.5803127, step = 62200 (4.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.241\n",
      "INFO:tensorflow:loss = -0.6972798, step = 62300 (4.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5512\n",
      "INFO:tensorflow:loss = -0.5725336, step = 62400 (4.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0964\n",
      "INFO:tensorflow:loss = -0.59425926, step = 62500 (4.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9827\n",
      "INFO:tensorflow:loss = -0.66264266, step = 62600 (4.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4872\n",
      "INFO:tensorflow:loss = -0.6107347, step = 62700 (4.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2489\n",
      "INFO:tensorflow:loss = -0.90575916, step = 62800 (4.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7258\n",
      "INFO:tensorflow:loss = -0.5954293, step = 62900 (4.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0317\n",
      "INFO:tensorflow:loss = -0.63319486, step = 63000 (4.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4033\n",
      "INFO:tensorflow:loss = -0.67528534, step = 63100 (4.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3478\n",
      "INFO:tensorflow:loss = -0.64068615, step = 63200 (4.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7359\n",
      "INFO:tensorflow:loss = -0.6293643, step = 63300 (4.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8239\n",
      "INFO:tensorflow:loss = -0.51623166, step = 63400 (4.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6775\n",
      "INFO:tensorflow:loss = -0.640414, step = 63500 (4.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7941\n",
      "INFO:tensorflow:loss = -0.92242897, step = 63600 (4.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4946\n",
      "INFO:tensorflow:loss = -0.65142787, step = 63700 (4.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4475\n",
      "INFO:tensorflow:loss = -0.55517185, step = 63800 (4.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5357\n",
      "INFO:tensorflow:loss = -0.5594961, step = 63900 (4.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1329\n",
      "INFO:tensorflow:loss = -0.57483447, step = 64000 (4.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8884\n",
      "INFO:tensorflow:loss = -0.5388223, step = 64100 (4.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4604\n",
      "INFO:tensorflow:loss = -0.5401023, step = 64200 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9225\n",
      "INFO:tensorflow:loss = -0.50546646, step = 64300 (4.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1793\n",
      "INFO:tensorflow:loss = -0.915547, step = 64400 (4.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0691\n",
      "INFO:tensorflow:loss = -0.5787652, step = 64500 (4.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9193\n",
      "INFO:tensorflow:loss = -0.5017505, step = 64600 (4.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.354\n",
      "INFO:tensorflow:loss = -0.68785304, step = 64700 (4.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0169\n",
      "INFO:tensorflow:loss = -0.629951, step = 64800 (4.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2243\n",
      "INFO:tensorflow:loss = -0.60770094, step = 64900 (4.500 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 65000...\n",
      "INFO:tensorflow:Saving checkpoints for 65000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 65000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T11:03:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-65000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:03:53.453211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:03:53.453693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:03:53.454121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:03:53.455264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:03:53.455298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 11:03:53.455736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:03:53.455786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.05028s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-11:03:54\n",
      "INFO:tensorflow:Saving dict for global step 65000: global_step = 65000, labels_mean = 0.08838565, logits_mean = -0.91889757, loss = -0.62134665, metric/ndcg@10 = 0.41905275, metric/ndcg@15 = 0.46998936, metric/ndcg@20 = 0.50661194, metric/ndcg@25 = 0.53450835, metric/ndcg@30 = 0.5545381\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 65000: /tmp/ranking_model_dir2/model.ckpt-65000\n",
      "INFO:tensorflow:global_step/sec: 14.8702\n",
      "INFO:tensorflow:loss = -0.5720928, step = 65000 (6.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2312\n",
      "INFO:tensorflow:loss = -0.53699243, step = 65100 (4.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5203\n",
      "INFO:tensorflow:loss = -0.78269905, step = 65200 (4.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6851\n",
      "INFO:tensorflow:loss = -0.58718234, step = 65300 (4.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5876\n",
      "INFO:tensorflow:loss = -0.6139356, step = 65400 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3789\n",
      "INFO:tensorflow:loss = -0.64888203, step = 65500 (4.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5704\n",
      "INFO:tensorflow:loss = -0.5956071, step = 65600 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8686\n",
      "INFO:tensorflow:loss = -0.68987584, step = 65700 (4.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3847\n",
      "INFO:tensorflow:loss = -0.55788064, step = 65800 (4.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4462\n",
      "INFO:tensorflow:loss = -0.5775248, step = 65900 (4.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2226\n",
      "INFO:tensorflow:loss = -0.7626901, step = 66000 (4.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6381\n",
      "INFO:tensorflow:loss = -0.7244009, step = 66100 (4.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3163\n",
      "INFO:tensorflow:loss = -0.7180208, step = 66200 (4.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1464\n",
      "INFO:tensorflow:loss = -0.69266176, step = 66300 (4.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9266\n",
      "INFO:tensorflow:loss = -0.64306664, step = 66400 (4.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6331\n",
      "INFO:tensorflow:loss = -0.5392655, step = 66500 (4.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3496\n",
      "INFO:tensorflow:loss = -0.6506422, step = 66600 (4.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4548\n",
      "INFO:tensorflow:loss = -0.92135805, step = 66700 (4.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1676\n",
      "INFO:tensorflow:loss = -0.59202754, step = 66800 (4.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6335\n",
      "INFO:tensorflow:loss = -0.62757385, step = 66900 (4.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5119\n",
      "INFO:tensorflow:loss = -0.6786495, step = 67000 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.585\n",
      "INFO:tensorflow:loss = -0.8407097, step = 67100 (4.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1202\n",
      "INFO:tensorflow:loss = -0.6013211, step = 67200 (4.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8936\n",
      "INFO:tensorflow:loss = -0.6322456, step = 67300 (4.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1406\n",
      "INFO:tensorflow:loss = -0.5845658, step = 67400 (4.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3116\n",
      "INFO:tensorflow:loss = -0.98413146, step = 67500 (4.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6549\n",
      "INFO:tensorflow:loss = -0.6822026, step = 67600 (4.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4022\n",
      "INFO:tensorflow:loss = -0.63204277, step = 67700 (4.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2827\n",
      "INFO:tensorflow:loss = -0.6465012, step = 67800 (4.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7902\n",
      "INFO:tensorflow:loss = -0.7669936, step = 67900 (4.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1561\n",
      "INFO:tensorflow:loss = -0.5607852, step = 68000 (4.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9383\n",
      "INFO:tensorflow:loss = -0.6167612, step = 68100 (4.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.406\n",
      "INFO:tensorflow:loss = -0.6013862, step = 68200 (4.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1929\n",
      "INFO:tensorflow:loss = -0.9793788, step = 68300 (4.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0847\n",
      "INFO:tensorflow:loss = -0.79207355, step = 68400 (4.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4331\n",
      "INFO:tensorflow:loss = -0.6943072, step = 68500 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2085\n",
      "INFO:tensorflow:loss = -0.81825435, step = 68600 (4.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4782\n",
      "INFO:tensorflow:loss = -0.694698, step = 68700 (4.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7846\n",
      "INFO:tensorflow:loss = -0.60588706, step = 68800 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0266\n",
      "INFO:tensorflow:loss = -0.5231171, step = 68900 (4.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0243\n",
      "INFO:tensorflow:loss = -0.8572767, step = 69000 (4.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7029\n",
      "INFO:tensorflow:loss = -0.9830689, step = 69100 (4.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6916\n",
      "INFO:tensorflow:loss = -0.6993224, step = 69200 (4.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3944\n",
      "INFO:tensorflow:loss = -0.61710036, step = 69300 (4.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4254\n",
      "INFO:tensorflow:loss = -0.80875415, step = 69400 (4.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1548\n",
      "INFO:tensorflow:loss = -0.84647894, step = 69500 (4.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9992\n",
      "INFO:tensorflow:loss = -0.69292605, step = 69600 (4.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5964\n",
      "INFO:tensorflow:loss = -0.6246302, step = 69700 (4.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5003\n",
      "INFO:tensorflow:loss = -0.88165045, step = 69800 (4.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2943\n",
      "INFO:tensorflow:loss = -0.65624356, step = 69900 (4.486 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 70000...\n",
      "INFO:tensorflow:Saving checkpoints for 70000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 70000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T11:07:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-70000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:07:39.999308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:07:39.999907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:07:40.000355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:07:40.001526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:07:40.001556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 11:07:40.002100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:07:40.002144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.03207s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-11:07:40\n",
      "INFO:tensorflow:Saving dict for global step 70000: global_step = 70000, labels_mean = 0.08838565, logits_mean = -1.3594828, loss = -0.6275763, metric/ndcg@10 = 0.43024158, metric/ndcg@15 = 0.47617614, metric/ndcg@20 = 0.5097273, metric/ndcg@25 = 0.5396562, metric/ndcg@30 = 0.564373\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 70000: /tmp/ranking_model_dir2/model.ckpt-70000\n",
      "INFO:tensorflow:global_step/sec: 15.2554\n",
      "INFO:tensorflow:loss = -0.5647235, step = 70000 (6.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4333\n",
      "INFO:tensorflow:loss = -0.60222524, step = 70100 (4.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9941\n",
      "INFO:tensorflow:loss = -0.6396414, step = 70200 (4.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2487\n",
      "INFO:tensorflow:loss = -0.86946785, step = 70300 (4.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8963\n",
      "INFO:tensorflow:loss = -0.63902617, step = 70400 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6889\n",
      "INFO:tensorflow:loss = -0.64718425, step = 70500 (4.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8854\n",
      "INFO:tensorflow:loss = -0.73156595, step = 70600 (4.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6623\n",
      "INFO:tensorflow:loss = -0.5849468, step = 70700 (4.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9772\n",
      "INFO:tensorflow:loss = -0.67521703, step = 70800 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5171\n",
      "INFO:tensorflow:loss = -0.5819049, step = 70900 (4.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9741\n",
      "INFO:tensorflow:loss = -0.65219283, step = 71000 (4.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6644\n",
      "INFO:tensorflow:loss = -0.6863664, step = 71100 (4.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1033\n",
      "INFO:tensorflow:loss = -0.6408105, step = 71200 (4.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5855\n",
      "INFO:tensorflow:loss = -0.8807167, step = 71300 (4.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1037\n",
      "INFO:tensorflow:loss = -0.6082636, step = 71400 (4.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2392\n",
      "INFO:tensorflow:loss = -0.6491488, step = 71500 (4.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7757\n",
      "INFO:tensorflow:loss = -0.675874, step = 71600 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7956\n",
      "INFO:tensorflow:loss = -0.63397944, step = 71700 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4032\n",
      "INFO:tensorflow:loss = -0.61105573, step = 71800 (4.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4297\n",
      "INFO:tensorflow:loss = -0.56340617, step = 71900 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1206\n",
      "INFO:tensorflow:loss = -0.66156316, step = 72000 (4.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.733\n",
      "INFO:tensorflow:loss = -0.9182972, step = 72100 (4.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4144\n",
      "INFO:tensorflow:loss = -0.656989, step = 72200 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0759\n",
      "INFO:tensorflow:loss = -0.576612, step = 72300 (4.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1717\n",
      "INFO:tensorflow:loss = -0.6111901, step = 72400 (4.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3965\n",
      "INFO:tensorflow:loss = -0.5823033, step = 72500 (4.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5717\n",
      "INFO:tensorflow:loss = -0.56214297, step = 72600 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9928\n",
      "INFO:tensorflow:loss = -0.6057037, step = 72700 (4.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1716\n",
      "INFO:tensorflow:loss = -0.5355737, step = 72800 (4.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7217\n",
      "INFO:tensorflow:loss = -0.9307705, step = 72900 (4.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3627\n",
      "INFO:tensorflow:loss = -0.60427535, step = 73000 (4.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6118\n",
      "INFO:tensorflow:loss = -0.54730296, step = 73100 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7877\n",
      "INFO:tensorflow:loss = -0.7207207, step = 73200 (4.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0928\n",
      "INFO:tensorflow:loss = -0.61998427, step = 73300 (4.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9303\n",
      "INFO:tensorflow:loss = -0.59944475, step = 73400 (4.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3657\n",
      "INFO:tensorflow:loss = -0.5580314, step = 73500 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0525\n",
      "INFO:tensorflow:loss = -0.5458989, step = 73600 (4.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7545\n",
      "INFO:tensorflow:loss = -0.78321624, step = 73700 (4.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8377\n",
      "INFO:tensorflow:loss = -0.58820033, step = 73800 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0186\n",
      "INFO:tensorflow:loss = -0.6983074, step = 73900 (4.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0712\n",
      "INFO:tensorflow:loss = -0.62980443, step = 74000 (4.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2791\n",
      "INFO:tensorflow:loss = -0.6055437, step = 74100 (4.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1475\n",
      "INFO:tensorflow:loss = -0.6976297, step = 74200 (4.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8777\n",
      "INFO:tensorflow:loss = -0.55896664, step = 74300 (4.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0258\n",
      "INFO:tensorflow:loss = -0.5652157, step = 74400 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1346\n",
      "INFO:tensorflow:loss = -0.7648833, step = 74500 (4.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3196\n",
      "INFO:tensorflow:loss = -0.7220581, step = 74600 (4.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.784\n",
      "INFO:tensorflow:loss = -0.7112916, step = 74700 (4.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9992\n",
      "INFO:tensorflow:loss = -0.6875539, step = 74800 (4.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5679\n",
      "INFO:tensorflow:loss = -0.6630702, step = 74900 (4.431 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 75000...\n",
      "INFO:tensorflow:Saving checkpoints for 75000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 75000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T11:11:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-75000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:11:25.777821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:11:25.778502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:11:25.778977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:11:25.780617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:11:25.780656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 11:11:25.781105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:11:25.781161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.20510s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-11:11:26\n",
      "INFO:tensorflow:Saving dict for global step 75000: global_step = 75000, labels_mean = 0.08838565, logits_mean = -1.7312726, loss = -0.63247824, metric/ndcg@10 = 0.43860665, metric/ndcg@15 = 0.48314726, metric/ndcg@20 = 0.5184135, metric/ndcg@25 = 0.54259485, metric/ndcg@30 = 0.5634837\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 75000: /tmp/ranking_model_dir2/model.ckpt-75000\n",
      "INFO:tensorflow:global_step/sec: 14.5854\n",
      "INFO:tensorflow:loss = -0.5737903, step = 75000 (6.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0784\n",
      "INFO:tensorflow:loss = -0.686081, step = 75100 (4.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7362\n",
      "INFO:tensorflow:loss = -0.9199672, step = 75200 (4.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0976\n",
      "INFO:tensorflow:loss = -0.6107001, step = 75300 (4.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1103\n",
      "INFO:tensorflow:loss = -0.6733981, step = 75400 (4.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8703\n",
      "INFO:tensorflow:loss = -0.6748583, step = 75500 (4.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1182\n",
      "INFO:tensorflow:loss = -0.8222827, step = 75600 (4.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2181\n",
      "INFO:tensorflow:loss = -0.62893313, step = 75700 (4.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5596\n",
      "INFO:tensorflow:loss = -0.6593122, step = 75800 (4.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8149\n",
      "INFO:tensorflow:loss = -0.6518599, step = 75900 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3396\n",
      "INFO:tensorflow:loss = -0.9819752, step = 76000 (4.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7305\n",
      "INFO:tensorflow:loss = -0.6382345, step = 76100 (4.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8046\n",
      "INFO:tensorflow:loss = -0.64927423, step = 76200 (4.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5477\n",
      "INFO:tensorflow:loss = -0.61963654, step = 76300 (4.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8564\n",
      "INFO:tensorflow:loss = -0.81155765, step = 76400 (4.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1484\n",
      "INFO:tensorflow:loss = -0.5720981, step = 76500 (4.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7422\n",
      "INFO:tensorflow:loss = -0.59392154, step = 76600 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6572\n",
      "INFO:tensorflow:loss = -0.6156107, step = 76700 (4.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9203\n",
      "INFO:tensorflow:loss = -0.9802007, step = 76800 (4.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4418\n",
      "INFO:tensorflow:loss = -0.80086833, step = 76900 (4.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1598\n",
      "INFO:tensorflow:loss = -0.72152907, step = 77000 (4.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0044\n",
      "INFO:tensorflow:loss = -0.8063675, step = 77100 (4.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9608\n",
      "INFO:tensorflow:loss = -0.71648943, step = 77200 (4.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9591\n",
      "INFO:tensorflow:loss = -0.59283143, step = 77300 (4.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8874\n",
      "INFO:tensorflow:loss = -0.52415514, step = 77400 (4.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9831\n",
      "INFO:tensorflow:loss = -0.81999743, step = 77500 (4.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4116\n",
      "INFO:tensorflow:loss = -0.9799017, step = 77600 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4523\n",
      "INFO:tensorflow:loss = -0.7194072, step = 77700 (5.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6119\n",
      "INFO:tensorflow:loss = -0.6193129, step = 77800 (4.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2473\n",
      "INFO:tensorflow:loss = -0.81738627, step = 77900 (4.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3605\n",
      "INFO:tensorflow:loss = -0.87145007, step = 78000 (4.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4774\n",
      "INFO:tensorflow:loss = -0.6912668, step = 78100 (4.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8567\n",
      "INFO:tensorflow:loss = -0.61826366, step = 78200 (4.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5119\n",
      "INFO:tensorflow:loss = -0.88386357, step = 78300 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1102\n",
      "INFO:tensorflow:loss = -0.72113055, step = 78400 (4.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3788\n",
      "INFO:tensorflow:loss = -0.58102345, step = 78500 (4.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6389\n",
      "INFO:tensorflow:loss = -0.63595873, step = 78600 (4.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9285\n",
      "INFO:tensorflow:loss = -0.64807516, step = 78700 (4.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5362\n",
      "INFO:tensorflow:loss = -0.88894975, step = 78800 (4.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2156\n",
      "INFO:tensorflow:loss = -0.6861347, step = 78900 (4.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8724\n",
      "INFO:tensorflow:loss = -0.6022386, step = 79000 (4.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5365\n",
      "INFO:tensorflow:loss = -0.73384166, step = 79100 (4.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1188\n",
      "INFO:tensorflow:loss = -0.5927907, step = 79200 (4.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2322\n",
      "INFO:tensorflow:loss = -0.6533683, step = 79300 (4.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7232\n",
      "INFO:tensorflow:loss = -0.5743774, step = 79400 (4.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0475\n",
      "INFO:tensorflow:loss = -0.6635627, step = 79500 (4.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9537\n",
      "INFO:tensorflow:loss = -0.72991073, step = 79600 (4.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8923\n",
      "INFO:tensorflow:loss = -0.6592765, step = 79700 (4.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9018\n",
      "INFO:tensorflow:loss = -0.8971994, step = 79800 (4.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3779\n",
      "INFO:tensorflow:loss = -0.6803382, step = 79900 (4.468 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 80000...\n",
      "INFO:tensorflow:Saving checkpoints for 80000 into /tmp/ranking_model_dir2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 80000...\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T11:15:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:15:14.294440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:15:14.295083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:15:14.295588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:15:14.296349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:15:14.296383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 11:15:14.296848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 11:15:14.296901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.14025s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-11:15:15\n",
      "INFO:tensorflow:Saving dict for global step 80000: global_step = 80000, labels_mean = 0.08838565, logits_mean = -2.036921, loss = -0.6290036, metric/ndcg@10 = 0.4359496, metric/ndcg@15 = 0.4803662, metric/ndcg@20 = 0.5101482, metric/ndcg@25 = 0.53360116, metric/ndcg@30 = 0.55688655\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 80000: /tmp/ranking_model_dir2/model.ckpt-80000\n",
      "INFO:tensorflow:Loss for final step: -0.56614244.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'labels_mean': 0.08838565,\n",
       "  'logits_mean': -2.036921,\n",
       "  'loss': -0.6290036,\n",
       "  'metric/ndcg@10': 0.4359496,\n",
       "  'metric/ndcg@15': 0.4803662,\n",
       "  'metric/ndcg@20': 0.5101482,\n",
       "  'metric/ndcg@25': 0.53360116,\n",
       "  'metric/ndcg@30': 0.55688655,\n",
       "  'global_step': 80000},\n",
       " [])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! rm -rf \"/tmp/ranking_model_dir2\"  # Clean up the model directory.\n",
    "#ranker, train_spec, eval_spec = train_and_eval_fn()\n",
    "tf.estimator.train_and_evaluate(ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801f806",
   "metadata": {},
   "source": [
    "## Inference and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4004d70",
   "metadata": {},
   "source": [
    "We show how to generate predictions over the features of a dataset. We assume that the label is not present and needs to be inferred using the ranking model.\n",
    "\n",
    "Similar to the `input_fn` used for training and evaluation,  `predict_input_fn` reads in data in ELWC format and stored as TFRecords to generate features. We set number of epochs to be 1, so that the generator stops iterating when it reaches the end of the dataset. Also the datapoints are not shuffled while reading, so that the behavior of the `predict()` function is deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31819ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_fn(path):\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values())\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()))\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern=path,\n",
    "        data_format=tfr.data.ELWC,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        list_size=_LIST_SIZE,\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=False,\n",
    "        num_epochs=1)\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73ef17",
   "metadata": {},
   "source": [
    "We generate predictions on the test dataset, where we only consider context and example features and predict the labels. The `predict_input_fn` generates predictions on a batch of datapoints. Batching allows us to iterate over large datasets which cannot be loaded in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e90d1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ranker.predict(input_fn=lambda: predict_input_fn(_TEST_DATA_PATH), checkpoint_path = ranker.latest_checkpoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ecc424",
   "metadata": {},
   "source": [
    "`ranker.predict` returns a generator, which we can iterate over to create predictions, till the generator is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dd316b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5964 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab1.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9557/2110212537.py:8: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(context_features[name])\n",
      "/tmp/ipykernel_9557/2110212537.py:12: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(group_features[name])\n",
      "/tmp/ipykernel_9557/2110212537.py:19: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_9557/2110212537.py:25: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
      "/tmp/ipykernel_9557/2110212537.py:26: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_9557/2110212537.py:31: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dropout(\n",
      "/tmp/ipykernel_9557/2110212537.py:33: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir2/model.ckpt-80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 23:31:46.367228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 23:31:46.368162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 23:31:46.368629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 23:31:46.371856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 23:31:46.371898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-13 23:31:46.372382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-13 23:31:46.372644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "x = next(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee3b6f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11030643,  1.068628  , -1.193237  , -3.2113945 , -0.3502589 ,\n",
       "       -1.2521886 , -0.60464126, -1.3437957 , -1.7907504 ,  0.7912551 ,\n",
       "       -1.9312412 , -0.6163245 , -0.28500426, -2.2479465 ,  4.7539926 ,\n",
       "       -2.3935404 , -1.7506343 , -2.5653894 , -1.2723231 , -2.1217813 ,\n",
       "        0.41525897, 10.724654  ,  6.3025565 ,  2.6733677 , -1.2480651 ,\n",
       "       -0.89325863,  0.21330483, -0.7000864 ,  0.16781536,  0.49158466,\n",
       "       -4.091258  , -4.3734603 , -5.695457  ,  0.8357709 ,  0.7534142 ,\n",
       "       -1.3700782 ,  0.57691455,  4.40552   , -3.9967525 , -0.6031495 ,\n",
       "       -2.1061022 , -3.0913947 ,  5.2450986 ,  3.575774  , -7.1628213 ,\n",
       "       -2.1439857 ,  1.8048462 , -8.92773   , -5.502502  ,  3.0449636 ,\n",
       "       -3.171954  ,  7.69224   , -4.2807536 , -3.1045454 , -5.5898147 ,\n",
       "       -4.8819    , -1.0271748 ,  0.7564909 , -0.75493735,  2.7342317 ,\n",
       "       -0.06257825, -0.8753093 ,  4.357507  , -1.6211015 ,  0.87937874,\n",
       "       -0.66134495, -0.67206615,  0.6673526 ,  3.612667  , -2.1480105 ,\n",
       "       -3.6447515 , -4.3964133 , -2.154483  , -0.7578145 ,  0.8448825 ,\n",
       "       -0.49481356,  0.22342344, -0.5417295 , -3.3991911 , -1.763265  ,\n",
       "       -7.1120596 , -3.9266613 ,  0.50549173,  0.48549458, -3.8140333 ,\n",
       "        0.2790658 , -0.63939184,  0.48006636, -1.6283581 , -0.77017504,\n",
       "       -1.0819101 , -0.51401275, -0.24960943, -1.6096591 , -1.1527776 ,\n",
       "        4.0712523 , -6.6944547 , -1.9578035 ,  0.7498937 , -2.6209135 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a8b2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = next(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0416d438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20.973263  ,  17.09673   ,  13.169425  ,  16.274303  ,\n",
       "        17.291176  ,  13.715188  ,  -4.7571187 ,  -6.941793  ,\n",
       "        -6.175723  ,  -5.5665503 ,  -2.7041383 ,  -6.376344  ,\n",
       "        -2.2829974 ,  18.833288  ,  -5.716882  ,  -3.215854  ,\n",
       "        -3.1922626 ,  -9.3092985 ,  -4.170464  ,  -3.6266415 ,\n",
       "        -1.3036622 ,  -5.4949846 ,  -4.5339613 ,   2.0997164 ,\n",
       "        -3.5297594 ,  -0.9621393 ,  -4.033933  ,   0.5803681 ,\n",
       "        -3.3392985 ,  -1.3197008 ,  -1.5215089 ,  -1.937019  ,\n",
       "        -4.7749863 ,  -4.3586135 ,  -3.7780015 ,  -6.1432805 ,\n",
       "        23.08628   ,  -6.8669505 ,  -9.590476  ,  -1.8483611 ,\n",
       "        -4.9096484 ,  -4.911651  ,  -4.0619025 ,   0.49486762,\n",
       "        -2.7750752 ,  -3.5110867 , -10.211501  , -13.408258  ,\n",
       "        -4.6502423 ,  -7.7602897 ,  -0.11777582,  -7.939951  ,\n",
       "        -3.1290004 ,  15.996386  ,  -8.233302  ,  -3.7229564 ,\n",
       "        -3.1207817 ,  -2.9017193 ,  -3.506057  ,  -2.0014176 ,\n",
       "        -8.869835  ,  -0.76471597,  -2.8754084 ,  -2.9788487 ,\n",
       "        -4.486268  ,  -5.2527957 , -10.854545  ,  -4.3215156 ,\n",
       "        12.698099  ,  -5.2461705 ,  15.862755  ,   0.0234598 ,\n",
       "         8.166303  ,  -3.6132329 ,  -2.9207487 ,  18.555916  ,\n",
       "         6.2490635 ,  -2.918698  ,  -0.67339355,  -8.896405  ,\n",
       "        -9.235666  ,  -6.551475  ,  -6.7877545 ,  -4.185275  ,\n",
       "        -2.6921036 ,   3.5708153 ,  -3.6473367 ,  -1.2376517 ,\n",
       "         4.83835   ,  -3.0137851 ,  -4.9600067 ,  -1.8099147 ,\n",
       "        17.72547   ,  -0.7062692 ,  -1.4128019 ,  -2.854345  ,\n",
       "        -7.9885297 ,  16.51591   ,  19.433636  ,  -2.8179018 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47690d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-rank",
   "language": "python",
   "name": "tf-rank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
