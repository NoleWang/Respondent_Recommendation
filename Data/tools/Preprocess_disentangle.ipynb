{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert json into raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('C:/Users/wangs/Desktop/Test/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11771 entries, 0 to 11770\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  11771 non-null  object \n",
      " 1   text                11771 non-null  object \n",
      " 2   html                11771 non-null  object \n",
      " 3   sent                11771 non-null  object \n",
      " 4   unread              11771 non-null  bool   \n",
      " 5   readBy              11771 non-null  int64  \n",
      " 6   urls                11771 non-null  object \n",
      " 7   mentions            11771 non-null  object \n",
      " 8   issues              11771 non-null  object \n",
      " 9   meta                11771 non-null  object \n",
      " 10  v                   11771 non-null  int64  \n",
      " 11  fromUser            11771 non-null  object \n",
      " 12  editedAt            517 non-null    object \n",
      " 13  status              57 non-null     float64\n",
      " 14  threadMessageCount  35 non-null     float64\n",
      " 15  virtualUser         53 non-null     object \n",
      "dtypes: bool(1), float64(2), int64(2), object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>html</th>\n",
       "      <th>sent</th>\n",
       "      <th>unread</th>\n",
       "      <th>readBy</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>issues</th>\n",
       "      <th>meta</th>\n",
       "      <th>v</th>\n",
       "      <th>fromUser</th>\n",
       "      <th>editedAt</th>\n",
       "      <th>status</th>\n",
       "      <th>threadMessageCount</th>\n",
       "      <th>virtualUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541a532981dbba5a557f6514</td>\n",
       "      <td>Hi all!</td>\n",
       "      <td>Hi all!</td>\n",
       "      <td>2014-09-18T03:36:09.349Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>{'id': '541a528b163965c9bc2053de', 'username':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54495e163875ac4b09d05990</td>\n",
       "      <td>I don't know if this is the right place but I ...</td>\n",
       "      <td>I don&amp;#39;t know if this is the right place bu...</td>\n",
       "      <td>2014-10-23T19:59:18.153Z</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>{'id': '544906e2db8155e6700cdd16', 'username':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54495e41d907477d1f7d8530</td>\n",
       "      <td>any idea?</td>\n",
       "      <td>any idea?</td>\n",
       "      <td>2014-10-23T20:00:01.849Z</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>{'id': '544906e2db8155e6700cdd16', 'username':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54495ead3875ac4b09d059a9</td>\n",
       "      <td>My first approach was to convert each feature ...</td>\n",
       "      <td>My first approach was to convert each feature ...</td>\n",
       "      <td>2014-10-23T20:01:49.864Z</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>{'id': '544906e2db8155e6700cdd16', 'username':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54495f3e3875ac4b09d059c0</td>\n",
       "      <td>by the way, Oliver Grisel: Hi! :D</td>\n",
       "      <td>by the way, Oliver Grisel: Hi! :D</td>\n",
       "      <td>2014-10-23T20:04:14.788Z</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>{'id': '544906e2db8155e6700cdd16', 'username':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  541a532981dbba5a557f6514   \n",
       "1  54495e163875ac4b09d05990   \n",
       "2  54495e41d907477d1f7d8530   \n",
       "3  54495ead3875ac4b09d059a9   \n",
       "4  54495f3e3875ac4b09d059c0   \n",
       "\n",
       "                                                text  \\\n",
       "0                                            Hi all!   \n",
       "1  I don't know if this is the right place but I ...   \n",
       "2                                          any idea?   \n",
       "3  My first approach was to convert each feature ...   \n",
       "4                  by the way, Oliver Grisel: Hi! :D   \n",
       "\n",
       "                                                html  \\\n",
       "0                                            Hi all!   \n",
       "1  I don&#39;t know if this is the right place bu...   \n",
       "2                                          any idea?   \n",
       "3  My first approach was to convert each feature ...   \n",
       "4                  by the way, Oliver Grisel: Hi! :D   \n",
       "\n",
       "                       sent  unread  readBy urls mentions issues meta  v  \\\n",
       "0  2014-09-18T03:36:09.349Z   False       0   []       []     []   []  1   \n",
       "1  2014-10-23T19:59:18.153Z   False       4   []       []     []   []  1   \n",
       "2  2014-10-23T20:00:01.849Z   False       4   []       []     []   []  1   \n",
       "3  2014-10-23T20:01:49.864Z   False       4   []       []     []   []  1   \n",
       "4  2014-10-23T20:04:14.788Z   False       4   []       []     []   []  1   \n",
       "\n",
       "                                            fromUser editedAt  status  \\\n",
       "0  {'id': '541a528b163965c9bc2053de', 'username':...      NaN     NaN   \n",
       "1  {'id': '544906e2db8155e6700cdd16', 'username':...      NaN     NaN   \n",
       "2  {'id': '544906e2db8155e6700cdd16', 'username':...      NaN     NaN   \n",
       "3  {'id': '544906e2db8155e6700cdd16', 'username':...      NaN     NaN   \n",
       "4  {'id': '544906e2db8155e6700cdd16', 'username':...      NaN     NaN   \n",
       "\n",
       "   threadMessageCount virtualUser  \n",
       "0                 NaN         NaN  \n",
       "1                 NaN         NaN  \n",
       "2                 NaN         NaN  \n",
       "3                 NaN         NaN  \n",
       "4                 NaN         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init['MessageId'] = df['id']\n",
    "df_init['Message'] = df['text']\n",
    "df_init['sentDate'] = df['sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MessageId</th>\n",
       "      <th>Message</th>\n",
       "      <th>sentDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541a532981dbba5a557f6514</td>\n",
       "      <td>Hi all!</td>\n",
       "      <td>2014-09-18T03:36:09.349Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54495e163875ac4b09d05990</td>\n",
       "      <td>I don't know if this is the right place but I ...</td>\n",
       "      <td>2014-10-23T19:59:18.153Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54495e41d907477d1f7d8530</td>\n",
       "      <td>any idea?</td>\n",
       "      <td>2014-10-23T20:00:01.849Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54495ead3875ac4b09d059a9</td>\n",
       "      <td>My first approach was to convert each feature ...</td>\n",
       "      <td>2014-10-23T20:01:49.864Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54495f3e3875ac4b09d059c0</td>\n",
       "      <td>by the way, Oliver Grisel: Hi! :D</td>\n",
       "      <td>2014-10-23T20:04:14.788Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MessageId  \\\n",
       "0  541a532981dbba5a557f6514   \n",
       "1  54495e163875ac4b09d05990   \n",
       "2  54495e41d907477d1f7d8530   \n",
       "3  54495ead3875ac4b09d059a9   \n",
       "4  54495f3e3875ac4b09d059c0   \n",
       "\n",
       "                                             Message                  sentDate  \n",
       "0                                            Hi all!  2014-09-18T03:36:09.349Z  \n",
       "1  I don't know if this is the right place but I ...  2014-10-23T19:59:18.153Z  \n",
       "2                                          any idea?  2014-10-23T20:00:01.849Z  \n",
       "3  My first approach was to convert each feature ...  2014-10-23T20:01:49.864Z  \n",
       "4                  by the way, Oliver Grisel: Hi! :D  2014-10-23T20:04:14.788Z  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = [df['fromUser'].iloc[i]['id'] for i in range(len(df))]\n",
    "username = [df['fromUser'].iloc[i]['username'] for i in range(len(df))]\n",
    "displayName = [df['fromUser'].iloc[i]['displayName'] for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init['UserId'] = user_id\n",
    "df_init['UserName'] = username\n",
    "df_init['DisplayName'] = displayName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MessageId</th>\n",
       "      <th>Message</th>\n",
       "      <th>sentDate</th>\n",
       "      <th>UserId</th>\n",
       "      <th>UserName</th>\n",
       "      <th>DisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541a532981dbba5a557f6514</td>\n",
       "      <td>Hi all!</td>\n",
       "      <td>2014-09-18T03:36:09.349Z</td>\n",
       "      <td>541a528b163965c9bc2053de</td>\n",
       "      <td>ogrisel</td>\n",
       "      <td>Olivier Grisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54495e163875ac4b09d05990</td>\n",
       "      <td>I don't know if this is the right place but I ...</td>\n",
       "      <td>2014-10-23T19:59:18.153Z</td>\n",
       "      <td>544906e2db8155e6700cdd16</td>\n",
       "      <td>mac2bua</td>\n",
       "      <td>Cristian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54495e41d907477d1f7d8530</td>\n",
       "      <td>any idea?</td>\n",
       "      <td>2014-10-23T20:00:01.849Z</td>\n",
       "      <td>544906e2db8155e6700cdd16</td>\n",
       "      <td>mac2bua</td>\n",
       "      <td>Cristian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54495ead3875ac4b09d059a9</td>\n",
       "      <td>My first approach was to convert each feature ...</td>\n",
       "      <td>2014-10-23T20:01:49.864Z</td>\n",
       "      <td>544906e2db8155e6700cdd16</td>\n",
       "      <td>mac2bua</td>\n",
       "      <td>Cristian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54495f3e3875ac4b09d059c0</td>\n",
       "      <td>by the way, Oliver Grisel: Hi! :D</td>\n",
       "      <td>2014-10-23T20:04:14.788Z</td>\n",
       "      <td>544906e2db8155e6700cdd16</td>\n",
       "      <td>mac2bua</td>\n",
       "      <td>Cristian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MessageId  \\\n",
       "0  541a532981dbba5a557f6514   \n",
       "1  54495e163875ac4b09d05990   \n",
       "2  54495e41d907477d1f7d8530   \n",
       "3  54495ead3875ac4b09d059a9   \n",
       "4  54495f3e3875ac4b09d059c0   \n",
       "\n",
       "                                             Message  \\\n",
       "0                                            Hi all!   \n",
       "1  I don't know if this is the right place but I ...   \n",
       "2                                          any idea?   \n",
       "3  My first approach was to convert each feature ...   \n",
       "4                  by the way, Oliver Grisel: Hi! :D   \n",
       "\n",
       "                   sentDate                    UserId UserName     DisplayName  \n",
       "0  2014-09-18T03:36:09.349Z  541a528b163965c9bc2053de  ogrisel  Olivier Grisel  \n",
       "1  2014-10-23T19:59:18.153Z  544906e2db8155e6700cdd16  mac2bua        Cristian  \n",
       "2  2014-10-23T20:00:01.849Z  544906e2db8155e6700cdd16  mac2bua        Cristian  \n",
       "3  2014-10-23T20:01:49.864Z  544906e2db8155e6700cdd16  mac2bua        Cristian  \n",
       "4  2014-10-23T20:04:14.788Z  544906e2db8155e6700cdd16  mac2bua        Cristian  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utter = pd.DataFrame()\n",
    "df_utter['sentDate'] = df_init['sentDate']\n",
    "df_utter['UserId'] = df_init['UserId']\n",
    "df_utter['Message'] = df_init['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utter.head()\n",
    "df_utter.to_csv('C:/Users/wangs/Desktop/Test/Data_ScikitLearn.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/wangs/Desktop/Test/ScikitLearn.raw.txt', \"w\", encoding='utf8') as f:\n",
    "    for i in range(len(df_utter)):\n",
    "        s = \"\"\n",
    "        s += \"[\" + df_utter['sentDate'].iloc[i] + \"] \"\n",
    "        s += \"<\"+df_utter['UserId'].iloc[i] + \"> \"\n",
    "        s += df_utter['Message'].iloc[i].replace(\"\\n\", \" \") + \"\\n\"\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into separate files by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def strToDatetime(str):\n",
    "    strptime = datetime.datetime.strptime(str, \"%Y-%m-%d\")\n",
    "    return strptime\n",
    "\n",
    "path = \"C:/Users/wangs/Documents/GitFiles/Respondent_Recommendation/Data/Gitter_Channels/Angular/disentangle/message_by_day/\"\n",
    "fileName = \"2014-01-01\"\n",
    "file = open(path+fileName+\".txt\",\"w\",encoding=\"UTF-8\")\n",
    "for line in open(\"C:/Users/wangs/Documents/GitFiles/Respondent_Recommendation/Data/Gitter_Channels/Angular/disentangle/Angular.ascii.txt\",encoding=\"UTF-8\"):\n",
    "    if line[0] == '[' and len(line) >= 20 and line[5] == '-':\n",
    "        day = line[1:11]\n",
    "        date = strToDatetime(day)\n",
    "        fileDate = strToDatetime(fileName)\n",
    "        \n",
    "    if fileDate != date:\n",
    "        file = open(path+day+\".ascii_o.txt\",\"w\",encoding=\"UTF-8\")\n",
    "        fileName = day\n",
    "        file.write(line)\n",
    "    else:\n",
    "        file.write(line)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "filenames = glob.glob(\"C:/Users/wangs/Desktop/Test/Scikitlearn/*ascii*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename in filenames:\n",
    "    tmp = []\n",
    "    for line in open(filename,\"r\"):\n",
    "        output = line[0]+line[12:17]+line[25:]\n",
    "        tmp.append(output)\n",
    "    \n",
    "    with open(filename,\"w\") as f:\n",
    "        for line in tmp:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/wangs/Documents/GitFiles/Respondent_Recommendation/Data/Gitter_Channels/Angular/disentangle/message_by_day/\"\n",
    "for filename in os.listdir(path):\n",
    "    if \"ascii_o\" not in filename:\n",
    "        continue\n",
    "        \n",
    "    tmp = []\n",
    "    for line in open(path+filename,\"r\"):\n",
    "        output = line[0]+line[12:17]+line[20:]\n",
    "        tmp.append(output)\n",
    "    \n",
    "    with open(path+filename[:10]+\".ascii.txt\",\"w\") as f:\n",
    "        for line in tmp:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserved = {\n",
    "    'ubuntu', 'help', 'linux'\n",
    "\"topic\", \"signoff\", \"signon\", \"total\", \"#ubuntu\", \"window\", \"server:\",\n",
    "\"screen:\", \"geometry\", \"co,\", \"current\", \"query\", \"prompt:\", \"second\", \"split\",\n",
    "\"logging\", \"logfile\", \"notification\", \"hold\", \"window\", \"lastlog\", \"notify\",\n",
    "'netjoined:',\n",
    "\"artful\", \"aardvark\", \"bionic\", \"beaver\", \"breezy\", \"badger\", \"cosmic\",\n",
    "\"cuttlefish\", \"dapper\", \"drake\", \"disco\", \"dingo\", \"edgy\", \"eft\", \"feisty\",\n",
    "\"fawn\", \"gutsy\", \"gibbon\", \"hardy\", \"heron\", \"hoary\", \"hedgehog\", \"intrepid\",\n",
    "\"ibex\", \"jaunty\", \"jackalope\", \"karmic\", \"koala\", \"lucid\", \"lynx\", \"maverick\",\n",
    "\"meerkat\", \"natty\", \"narwhal\", \"oneiric\", \"ocelot\", \"precise\", \"pangolin\",\n",
    "\"quantal\", \"quetzal\", \"raring\", \"ringtail\", \"saucy\", \"salamander\", \"trusty\",\n",
    "\"tahr\", \"utopic\", \"unicorn\", \"vivid\", \"vervet\", \"warty\", \"warthog\", \"wily\",\n",
    "\"werewolf\", \"xenial\", \"xerus\", \"yakkety\", \"yak\", \"zesty\", \"zapus\",\n",
    "\"`\", \"^^\", \"^_^\", \"^\", \"||\", \"|\", \"_\", \"[\", \"[[\", \"]]\", \"{\", \"\\\\\", \"\\\\\\\\\", \"^5\", \"a\",\n",
    "\"aaah\", \"aaahhh\", \"aao\", \"aargh\", \"abandoned\", \"abit\", \"able\", \"abot\", \"about\",\n",
    "\"above\", \"absolute\", \"accent\", \"accept\", \"acceptance\", \"acces\", \"access\",\n",
    "\"accident\", \"account\", \"accused\", \"acpi\", \"acronym\", \"across\", \"act\", \"action\",\n",
    "\"active\", \"activex\", \"acts\", \"adapter\", \"adb\", \"add\", \"addict\", \"adding\",\n",
    "\"additional\", \"addon\", \"adds\", \"adduser\", \"adept\", \"administer\",\n",
    "\"administration\", \"administrators\", \"adn\", \"adobe\", \"adsl\", \"advanced\",\n",
    "\"adventure\", \"advertise\", \"advertising\", \"advise\", \"af\", \"afk\", \"african\",\n",
    "\"after\", \"again\", \"against\", \"aggravating\", \"aggressive\", \"ago\", \"agp\",\n",
    "\"agree\", \"ah\", \"aha\", \"ahead\", \"ahh\", \"ahhh\", \"ahhhh\", \"ahs\", \"ai\", \"air\",\n",
    "\"airflow\", \"airsnort\", \"ait\", \"aix\", \"album\", \"alert\", \"algorithm\", \"alguien\",\n",
    "\"algun\", \"alias\", \"aliases\", \"all\", \"alla\", \"allegro\", \"alli\", \"alliance\",\n",
    "\"allow\", \"allright\", \"almost\", \"alo\", \"alone\", \"along\", \"alors\", \"already\",\n",
    "\"alsa\", \"alsaconf\", \"alse\", \"also\", \"alt\", \"alter\", \"alternate\", \"alternative\",\n",
    "\"always\", \"am\", \"amarok\", \"amazed\", \"amazing\", \"amazon\", \"amd\", \"amd64\",\n",
    "\"among\", \"ampache\", \"an\", \"analog\", \"analysis\", \"analyzer\", \"and\", \"angles\",\n",
    "\"animals\", \"anime\", \"anjuta\", \"anotehr\", \"another\", \"ansible\", \"antenna\",\n",
    "\"anthy\", \"any\", \"anybody\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"aol\",\n",
    "\"apache\", \"apache2\", \"apci\", \"apis\", \"apm\", \"apology\", \"app\", \"appears\",\n",
    "\"apple\", \"applet\", \"application\", \"applied\", \"apply\", \"appreciated\",\n",
    "\"appropriate\", \"apps\", \"apr\", \"april\", \"aprox\", \"apt\", \"apt-get\", \"aptitude\",\n",
    "\"archaic\", \"architecture\", \"archive\", \"archiver\", \"archives\", \"archlinux\",\n",
    "\"are\", \"area\", \"arena\", \"arg\", \"argh\", \"arise\", \"arista\", \"ark\", \"arm\", \"arms\",\n",
    "\"array\", \"arrgh\", \"artist\", \"arts\", \"as\", \"asap\", \"ascii\", \"aside\", \"ask\",\n",
    "\"asking\", \"asla\", \"ass\", \"assertion\", \"assist\", \"assistance\", \"association\",\n",
    "\"at\", \"ath0\", \"athlonxp\", \"ati\", \"atm\", \"atsc\", \"attack\", \"attackers\",\n",
    "\"attempt\", \"attractive\", \"audacity\", \"audigy\", \"audio\", \"audition\", \"aug\",\n",
    "\"aus\", \"auth\", \"author\", \"authority\", \"authorized\", \"auto\", \"automated\",\n",
    "\"automatic\", \"automatix\", \"autostart\", \"aux\", \"av\", \"avail\", \"available\",\n",
    "\"avant\", \"avconv\", \"aw\", \"aware\", \"away\", \"awe\", \"awesome\", \"awry\", \"awww\",\n",
    "\"awwww\", \"aye\", \"ayone\", \"ayuda\", \"azalia\", \"b4\", \"back\", \"backdoor\",\n",
    "\"backintime\", \"backlight\", \"backport\", \"backspace\", \"backup\", \"bad\", \"bahasa\",\n",
    "\"bakc\", \"balloon\", \"ban\", \"band\", \"banned\", \"banning\", \"banshee\", \"bar\",\n",
    "\"barrel\", \"bars\", \"base\", \"basement\", \"bash\", \"bashing\", \"bashrc\", \"basic\",\n",
    "\"bastard\", \"battery\", \"bay\", \"bbl\", \"bcm4318\", \"bcm43xx\", \"bcm43xx-fwcutter\",\n",
    "\"bcz\", \"be\", \"beagle\", \"beautiful\", \"beauty\", \"becase\", \"because\", \"bed\",\n",
    "\"been\", \"beep\", \"beers\", \"beg\", \"begin\", \"begs\", \"being\", \"bell\", \"bells\",\n",
    "\"bench\", \"berly\", \"bery\", \"beryl\", \"best\", \"bet\", \"beta\", \"better\", \"beyond\",\n",
    "\"bg\", \"bi\", \"bias\", \"bible\", \"bie\", \"big\", \"biger\", \"bigger\", \"biggy\", \"bin\",\n",
    "\"binary\", \"bios\", \"bit\", \"bitch\", \"bitches\", \"bitchx\", \"bitlbee\", \"bitrate\",\n",
    "\"bitten\", \"bittorrent\", \"bizarre\", \"bizzare\", \"bla\", \"black\", \"blacklist\",\n",
    "\"bleeding\", \"blew\", \"blinking\", \"block\", \"blocks\", \"blow\", \"blue\", \"bluefish\",\n",
    "\"blueman\", \"bluetooth\", \"bluez\", \"blu-ray\", \"bmp\", \"bnc\", \"boat\", \"bochs\",\n",
    "\"body\", \"bonding\", \"bonsoir\", \"book\", \"books\", \"boost\", \"boot\", \"booted\",\n",
    "\"bootloader\", \"bootmgr\", \"boots\", \"boottime\", \"bootup\", \"border\", \"bose\",\n",
    "\"both\", \"botnet\", \"bots\", \"botsnack\", \"bound\", \"bout\", \"box\", \"boxes\", \"boys\",\n",
    "\"brackets\", \"brake\", \"branch\", \"branches\", \"brand\", \"brasero\", \"brave\",\n",
    "\"brazil\", \"brb\", \"break\", \"breaks\", \"breezy\", \"bricks\", \"bridge\", \"brightness\",\n",
    "\"brightside\", \"brilliant\", \"british\", \"broad\", \"broadband\", \"broke\", \"brother\",\n",
    "\"brown\", \"browser\", \"browsing\", \"bsd\", \"btnx\", \"btrfs\", \"btw\", \"budget\",\n",
    "\"buffer\", \"bug\", \"bugfixes\", \"bugger\", \"buggy\", \"bugs\", \"bugzilla\", \"build\",\n",
    "\"bulk\", \"burn\", \"burned\", \"burning\", \"busca\", \"busted\", \"busy\", \"busybox\",\n",
    "\"but\", \"button\", \"buttons\", \"buzz\", \"by\", \"bzip\", \"c\", \"c2\", \"ca\", \"cable\",\n",
    "\"cache\", \"cacher\", \"caldera\", \"calendar\", \"california\", \"call\", \"called\",\n",
    "\"caller\", \"came\", \"camera\", \"campus\", \"cams\", \"can\", \"canada\", \"cancel\",\n",
    "\"canonical\", \"cant\", \"capital\", \"capitals\", \"caps\", \"capslock\", \"car\", \"card\",\n",
    "\"cards\", \"care\", \"carry\", \"cases\", \"`cat\", \"cat5\", \"catalyst\", \"ccleaner\",\n",
    "\"cd\", \"cd1\", \"cd-r\", \"cds\", \"ce\", \"celeron\", \"cellphone\", \"center\", \"centos\",\n",
    "\"century\", \"certain\", \"certificate\", \"cfdisk\", \"challenged\", \"chance\",\n",
    "\"chanell\", \"change\", \"changing\", \"charge\", \"charged\", \"charm\", \"chars\",\n",
    "\"charset\", \"chat\", \"chatter\", \"cheat\", \"check\", \"checker\", \"checks\", \"cheers\",\n",
    "\"chess\", \"chicago\", \"child\", \"chime\", \"china\", \"chinese\", \"chips\", \"chipset\",\n",
    "\"chm\", \"chmod\", \"choice\", \"choices\", \"choppy\", \"chops\", \"chose\", \"chosen\",\n",
    "\"chown\", \"chowned\", \"christ\", \"christmas\", \"chrome\", \"chromium\", \"chunk\",\n",
    "\"chunks\", \"ci\", \"ciao\", \"cigarettes\", \"circuits\", \"claim\", \"class\", \"clean\",\n",
    "\"cleaner\", \"clear\", \"cli\", \"click\", \"client\", \"clients\", \"clock\", \"clocking\",\n",
    "\"clone\", \"clonezilla\", \"close\", \"closed\", \"closer\", \"clue\", \"clueless\",\n",
    "\"clutter\", \"cmd\", \"cms\", \"cnt\", \"cobol\", \"coc\", \"code\", \"coded\", \"coders\",\n",
    "\"coding\", \"color\", \"column\", \"com\", \"comand\", \"combine\", \"comcast\", \"come\",\n",
    "\"comfort\", \"comics\", \"coming\", \"command\", \"command-line\", \"commandline\",\n",
    "\"common\", \"community\", \"como\", \"comp\", \"compile\", \"compiler\", \"compiz\",\n",
    "\"complete\", \"compliant\", \"comply\", \"component\", \"composite\", \"compressed\",\n",
    "\"computer\", \"computers\", \"concentrate\", \"concepts\", \"concerned\", \"concrete\",\n",
    "\"conf\", \"confident\", \"config\", \"conflict\", \"confuse\", \"confusion\", \"conky\",\n",
    "\"connect\", \"connected\", \"connecting\", \"connection\", \"connections\", \"connector\",\n",
    "\"console\", \"construct\", \"contact\", \"contents\", \"contract\", \"control\",\n",
    "\"controller\", \"controls\", \"controversial\", \"convert\", \"converted\", \"converter\",\n",
    "\"convinced\", \"coo\", \"cookies\", \"copies\", \"copy\", \"core2\", \"core2duo\", \"corner\",\n",
    "\"correct\", \"corrupted\", \"cost\", \"couch\", \"coucou\", \"coul\", \"counter\",\n",
    "\"country\", \"couple\", \"cousin\", \"cousins\", \"cover\", \"cpanel\", \"cpp\", \"cpu\",\n",
    "\"cpufreqd\", \"crappy\", \"crash\", \"crashed\", \"crazy\", \"create\", \"creating\",\n",
    "\"creation\", \"creative\", \"creator\", \"crippled\", \"critical\", \"cron\", \"cronjob\",\n",
    "\"crontab\", \"cross\", \"crossover\", \"crt\", \"crud\", \"cry\", \"ctcp\", \"ctrl\",\n",
    "\"ctrl-alt-del\", \"cuda\", \"culprit\", \"cup\", \"cure\", \"curious\", \"current\",\n",
    "\"curses\", \"cursor\", \"curve\", \"cuss\", \"custom\", \"customize\", \"cuz\", \"cvs\", \"cz\",\n",
    "\"czech\", \"czy\", \"daemons\", \"daily\", \"damn\", \"damnit\", \"dances\", \"dancing\",\n",
    "\"dang\", \"danger\", \"dangerous\", \"danko\", \"dapper\", \"darn\", \"dashboard\", \"data\",\n",
    "\"dates\", \"day\", \"daytime\", \"db\", \"dban\", \"dbus\", \"dcc\", \"dd\", \"de\", \"dead\",\n",
    "\"deal\", \"deb\", \"debain\", \"debian\", \"debians\", \"debs\", \"debug\", \"dec\", \"decade\",\n",
    "\"decent\", \"decode\", \"decoded\", \"decrypt\", \"decryption\", \"dedicated\", \"deeper\",\n",
    "\"def\", \"defalt\", \"default\", \"defect\", \"defense\", \"deff\", \"define\", \"defined\",\n",
    "\"defult\", \"deg\", \"degree\", \"delay\", \"delet\", \"delete\", \"deleted\", \"deluge\",\n",
    "\"demonoid\", \"demuxer\", \"denied\", \"dependencies\", \"depth\", \"design\", \"designer\",\n",
    "\"desktop\", \"destination\", \"destroy\", \"detached\", \"detail\", \"detected\",\n",
    "\"detection\", \"determin\", \"deutsch\", \"deutsche\", \"dev\", \"devede\", \"develop\",\n",
    "\"device\", \"devote\", \"devs\", \"df\", \"dhcp\", \"diag\", \"diagnostic\", \"dial\",\n",
    "\"dial-up\", \"dictionary\", \"did\", \"died\", \"dif\", \"diff\", \"different\",\n",
    "\"difficult\", \"dig\", \"dilemma\", \"dillo\", \"dinner\", \"dir\", \"dire\", \"directory\",\n",
    "\"directx\", \"disabled\", \"disappear\", \"disappeared\", \"disc\", \"disconnect\",\n",
    "\"disconnected\", \"discrete\", \"diskette\", \"disks\", \"display\", \"diss\", \"dist\",\n",
    "\"distinct\", \"distorted\", \"distracted\", \"distribution\", \"distro\", \"distupgrade\",\n",
    "\"disturb\", \"dit\", \"ditch\", \"dl\", \"dlink\", \"dmesg\", \"dns\", \"do\", \"doable\",\n",
    "\"doc\", \"dock\", \"docker\", \"docky\", \"dod\", \"doe\", \"does\", \"doki\", \"domain\",\n",
    "\"domu\", \"done\", \"dongle\", \"donno\", \"dont\", \"dos\", \"dose\", \"dots\", \"double\",\n",
    "\"doubleclick\", \"doubt\", \"dove\", \"down\", \"downgrade\", \"downloader\",\n",
    "\"downloading\", \"downtime\", \"doze\", \"dozen\", \"dpi\", \"dram\", \"draw\", \"drawn\",\n",
    "\"dreamweaver\", \"dress\", \"dri\", \"drinks\", \"drive\", \"driver\", \"drm\", \"drop\",\n",
    "\"dropbox\", \"dropped\", \"drops\", \"drug\", \"drums\", \"dsp\", \"du\", \"dual\",\n",
    "\"dualboot\", \"dudes\", \"due\", \"duh\", \"dumb\", \"dummies\", \"dump\", \"dun\", \"dunno\",\n",
    "\"duo\", \"duplex\", \"duplicated\", \"duplicity\", \"duron\", \"dvb\", \"dvd\", \"dvd-rw\",\n",
    "\"dvdrw\", \"dvds\", \"dvr\", \"dynamic\", \"e\", \"e2fsck\", \"each\", \"ear\", \"early\",\n",
    "\"earth\", \"ease\", \"east\", \"easter\", \"easy\", \"eat\", \"ebay\", \"edit\", \"edited\",\n",
    "\"editor\", \"ee\", \"eed\", \"eeebuntu\", \"een\", \"effect\", \"effective\", \"effort\",\n",
    "\"efi\", \"eg\", \"eh\", \"ehat\", \"eheh\", \"eide\", \"electronic\", \"elegant\", \"elements\",\n",
    "\"elevate\", \"elevated\", \"elitist\", \"ello\", \"else\", \"emacs\", \"email\", \"embedded\",\n",
    "\"embeded\", \"emerald\", \"emergency\", \"emmm\", \"empathy\", \"empty\", \"emulator\",\n",
    "\"emulators\", \"en\", \"encode\", \"encoder\", \"encoding\", \"encrypted\", \"encryption\",\n",
    "\"end\", \"enemy\", \"engine\", \"engineering\", \"english\", \"enjoy\", \"enlightened\",\n",
    "\"enter\", \"entra\", \"entrance\", \"enuf\", \"enumerate\", \"enumeration\", \"env\",\n",
    "\"envy\", \"enyone\", \"eol\", \"epiphany\", \"equipment\", \"equipped\", \"er\", \"erase\",\n",
    "\"erh\", \"erlang\", \"erorr\", \"err\", \"errno\", \"erro\", \"erroneous\", \"error\", \"es\",\n",
    "\"esd\", \"est\", \"este\", \"estimate\", \"et\", \"eta\", \"etc\", \"etch\", \"eth\", \"eth0\",\n",
    "\"eth2\", \"ethernet\", \"etho\", \"european\", \"even\", \"evening\", \"ever\", \"everybody\",\n",
    "\"everyday\", \"evidence\", \"evolution\", \"evolved\", \"ew\", \"ex\", \"exact\", \"exceed\",\n",
    "\"excellent\", \"except\", \"excessive\", \"exe\", \"exec\", \"execute\", \"exfat\", \"exist\",\n",
    "\"existed\", \"existence\", \"exit\", \"expect\", \"expecting\", \"experiment\", \"expert\",\n",
    "\"explicit\", \"explicitly\", \"explode\", \"explorer\", \"export\", \"express\",\n",
    "\"expression\", \"ext\", \"ext3\", \"ext4\", \"extended\", \"extra\", \"eye\", \"eyecandy\",\n",
    "\"eyes\", \"f1\", \"f10\", \"f2\", \"f3\", \"f7\", \"facebook\", \"faced\", \"fact\", \"factoid\",\n",
    "\"fail\", \"fair\", \"fait\", \"fake\", \"fala\", \"fallow\", \"falls\", \"familiar\", \"fan\",\n",
    "\"fancy\", \"fantasy\", \"faptastic\", \"far\", \"fashion\", \"faster\", \"fastest\",\n",
    "\"fat32\", \"fatal\", \"fatrat\", \"fault\", \"faulty\", \"favor\", \"favorite\",\n",
    "\"favorites\", \"favourite\", \"fawn\", \"fb\", \"fd0\", \"fdd\", \"fdi\", \"feat\", \"feb\",\n",
    "\"fedora\", \"fee\", \"feed\", \"feel\", \"feeling\", \"feisty\", \"fellas\", \"fellow\",\n",
    "\"fetch\", \"few\", \"ff\", \"ff2\", \"fglrx\", \"fi\", \"fiddle\", \"field\", \"fighting\",\n",
    "\"file\", \"files\", \"fileserver\", \"filesystem\", \"fill\", \"filling\", \"filter\",\n",
    "\"filtered\", \"final\", \"finally\", \"find\", \"fine\", \"fing\", \"fingers\", \"fins\",\n",
    "\"firebug\", \"firefox\", \"firefox3\", \"firestarter\", \"firewall\", \"firewalls\",\n",
    "\"firewire\", \"firmware\", \"first\", \"firstly\", \"fishing\", \"fits\", \"fix\", \"fixed\",\n",
    "\"flag\", \"flaky\", \"flamed\", \"flash\", \"flashed\", \"flashget\", \"flashplugin\",\n",
    "\"flavor\", \"flavors\", \"flawed\", \"flickering\", \"flock\", \"flood\", \"floodbot\",\n",
    "\"flooding\", \"floola\", \"floor\", \"floppy\", \"floss\", \"fluff\", \"flux\", \"fluxbox\",\n",
    "\"fly\", \"fml\", \"fn\", \"focus\", \"folder\", \"folk\", \"folks\", \"follow\", \"font\",\n",
    "\"fonts\", \"foobar2000\", \"fools\", \"foomatic\", \"football\", \"footprint\", \"fopen\",\n",
    "\"for\", \"force\", \"forensic\", \"forget\", \"forgotten\", \"fork\", \"form\", \"format\",\n",
    "\"formatted\", \"forme\", \"former\", \"formula\", \"forth\", \"fortress\", \"fortune\",\n",
    "\"forum\", \"forward\", \"foss\", \"found\", \"founder\", \"fr\", \"francais\", \"free\",\n",
    "\"freebsd\", \"freely\", \"freenode\", \"freevo\", \"freeware\", \"freezes\", \"freezing\",\n",
    "\"french\", \"fresh\", \"freshly\", \"friend\", \"friendly\", \"friends\", \"friggin\",\n",
    "\"frist\", \"fro\", \"from\", \"froze\", \"fs\", \"fsck\", \"fsf\", \"fspot\", \"ftp\", \"ftw\",\n",
    "\"fucker\", \"fuhrer\", \"full\", \"fullscreen\", \"fully\", \"function\", \"funny\", \"fuss\",\n",
    "\"future\", \"fvwm\", \"g3\", \"g5\", \"gaah\", \"gadmin\", \"gah\", \"gals\", \"game\", \"games\",\n",
    "\"gaming\", \"garbage\", \"gates\", \"gateway\", \"gather\", \"gave\", \"gay\", \"gb\", \"gcc\",\n",
    "\"gconf\", \"gconftool\", \"gd\", \"gdisk\", \"gear\", \"geeks\", \"geese\", \"gem\",\n",
    "\"general\", \"generate\", \"gentoo\", \"get\", \"getty\", \"gf\", \"gftp\", \"gfx\", \"ghz\",\n",
    "\"gib\", \"gibbon\", \"gift\", \"gig\", \"gigabit\", \"gimp\", \"girlfriend\", \"gist\", \"git\",\n",
    "\"give\", \"gksudo\", \"glad\", \"glibc\", \"gmp\", \"gmt\", \"gnash\", \"gnewsense\", \"gnite\",\n",
    "\"gnome\", \"gnomes\", \"gnome-shell\", \"gnome-terminal\", \"gnone\", \"gns3\", \"gnu\",\n",
    "\"gnutella\", \"go\", \"goddamnit\", \"gods\", \"goes\", \"goin\", \"going\", \"golly\",\n",
    "\"gone\", \"gonna\", \"good\", \"goodbye\", \"goodness\", \"goodnight\", \"google\",\n",
    "\"googled\", \"google-fu\", \"googles\", \"googling\", \"goole\", \"goood\", \"goot\", \"got\",\n",
    "\"goto\", \"gotten\", \"government\", \"gpart\", \"gparted\", \"gpg\", \"gpt\", \"gpu\", \"gq\",\n",
    "\"grabbed\", \"gracias\", \"grade\", \"grain\", \"grammer\", \"grand\", \"grants\", \"graph\",\n",
    "\"graphic\", \"graphical\", \"graphics\", \"graphix\", \"grasp\", \"grats\", \"gratz\",\n",
    "\"grazie\", \"great\", \"grep\", \"greyed\", \"grid\", \"grief\", \"ground\", \"groundhog\",\n",
    "\"growisofs\", \"grr\", \"grub\", \"grub2\", \"grubs\", \"gsm\", \"gstreamer\", \"gta\", \"gtg\",\n",
    "\"gtk\", \"gues\", \"guess\", \"guessing\", \"gui\", \"guid\", \"guide\", \"guilty\", \"guis\",\n",
    "\"gusty\", \"guts\", \"gutsy\", \"guy\", \"guys\", \"guyz\", \"gvim\", \"gw\", \"gxmame\", \"gym\",\n",
    "\"gz\", \"ha\", \"haa\", \"hacked\", \"hackers\", \"hacking\", \"hacks\", \"had\", \"hadoop\",\n",
    "\"haha\", \"hahaha\", \"hahahah\", \"hahahaha\", \"hahahahah\", \"half\", \"halflife\",\n",
    "\"halfway\", \"halloween\", \"haloo\", \"hand\", \"handle\", \"hands\", \"handy\", \"hang\",\n",
    "\"hanks\", \"happier\", \"happily\", \"hard\", \"harddrive\", \"harder\", \"hardly\",\n",
    "\"hardware\", \"hardy\", \"has\", \"hate\", \"hav\", \"have\", \"haves\", \"hd\", \"hda\",\n",
    "\"hda1\", \"hdb\", \"hdd\", \"hdtv\", \"he\", \"head\", \"header\", \"headless\", \"headphone\",\n",
    "\"heads\", \"healthy\", \"hear\", \"heart\", \"heartbleed\", \"heat\", \"heavy\", \"heck\",\n",
    "\"hee\", \"hefty\", \"heh\", \"hehe\", \"heheh\", \"heil\", \"held\", \"hell\", \"hella\",\n",
    "\"helllo\", \"hello\", \"heloo\", \"help\", \"hence\", \"here\", \"heres\", \"heron\",\n",
    "\"herring\", \"het\", \"heu\", \"heve\", \"hex\", \"hey\", \"heya\", \"heyyy\", \"hi\", \"hidden\",\n",
    "\"hides\", \"hie\", \"hier\", \"high\", \"high-end\", \"hii\", \"hilfe\", \"him\", \"himself\",\n",
    "\"hint\", \"his\", \"history\", \"hit\", \"hits\", \"hl2\", \"hm\", \"hmm\", \"hmmm\", \"hmmmmm\",\n",
    "\"ho\", \"hoary\", \"hoe\", \"hokay\", \"holder\", \"homepage\", \"homeserver\", \"homework\",\n",
    "\"honest\", \"honesty\", \"hoops\", \"hooray\", \"hope\", \"horny\", \"horrid\", \"hosed\",\n",
    "\"host\", \"hosting\", \"hostname\", \"hotspot\", \"hours\", \"how\", \"howso\", \"howto\",\n",
    "\"howtos\", \"hr\", \"hrhr\", \"hrm\", \"hrs\", \"hsf\", \"hsync\", \"htop\", \"http\", \"huawei\",\n",
    "\"hug\", \"huge\", \"huh\", \"hum\", \"hung\", \"hw\", \"hwe\", \"hwy\", \"hy\", \"hypervisor\",\n",
    "\"_i_\", \"i\", \"i3\", \"i386\", \"i7\", \"ia64\", \"ibook\", \"ican\", \"iceweasel\", \"ici\",\n",
    "\"icon\", \"icons\", \"icq\", \"ics\", \"id\", \"id3\", \"ide\", \"idea\", \"ideas\", \"ident\",\n",
    "\"idiocy\", \"idk\", \"idle\", \"idling\", \"idont\", \"ie\", \"ieee\", \"if\", \"iface\",\n",
    "\"ifconfig\", \"iffy\", \"ifup\", \"ignorance\", \"ignorant\", \"ignore\", \"igp\", \"ihr\",\n",
    "\"iii\", \"iin\", \"ill\", \"illiterate\", \"illustrator\", \"i`m\", \"im\", \"image\",\n",
    "\"imagine\", \"img\", \"immediately\", \"immune\", \"imo\", \"impatient\",\n",
    "\"implementation\", \"import\", \"improve\", \"improved\", \"in\", \"inbox\", \"inch\",\n",
    "\"incident\", \"incomplete\", \"inconvenience\", \"indeed\", \"india\", \"indicates\",\n",
    "\"individual\", \"indonesia\", \"inet\", \"inet6\", \"inetd\", \"infection\", \"infer\",\n",
    "\"info\", \"inform\", \"infos\", \"ing\", \"in-game\", \"init\", \"initial\", \"initialize\",\n",
    "\"initram\", \"injection\", \"inline\", \"insecure\", \"insert\", \"inserts\", \"inside\",\n",
    "\"inspiron\", \"install\", \"installer\", \"installing\", \"instant\", \"instantly\",\n",
    "\"insurance\", \"integrated\", \"intel\", \"intent\", \"interactive\", \"interested\",\n",
    "\"interface\", \"interim\", \"internal\", \"internet\", \"internets\", \"interval\",\n",
    "\"intrepid\", \"intro\", \"introduce\", \"invalid\", \"invert\", \"ioctl\", \"ios\", \"iot\",\n",
    "\"ip\", \"ipad\", \"iphone\", \"ipod\", \"ips\", \"iptraf\", \"ir\", \"irc\", \"irs\", \"irssi\",\n",
    "\"is\", \"isdn\", \"isee\", \"island\", \"isnt\", \"iso\", \"isp\", \"issue\", \"ist\",\n",
    "\"istanbul\", \"it\", \"italiano\", \"itanium\", \"item\", \"ith\", \"itouch\", \"its\", \"itt\",\n",
    "\"itunes\", \"iu\", \"iv\", \"ive\", \"iw\", \"iwl3945\", \"jackalope\", \"jaunty\", \"java\",\n",
    "\"javascript\", \"jdk\", \"jeez\", \"jetzt\", \"jfs\", \"job\", \"jobs\", \"join\", \"joins\",\n",
    "\"joke\", \"joomla\", \"jou\", \"journal\", \"joystick\", \"jre\", \"jump\", \"jumps\", \"junk\",\n",
    "\"jus\", \"just\", \"justs\", \"k\", \"k6\", \"k7\", \"kaffeine\", \"kanji\", \"karmic\",\n",
    "\"kazam\", \"kb\", \"kde\", \"kde4\", \"kdm\", \"keep\", \"keine\", \"kernal\", \"kernel\",\n",
    "\"kewl\", \"key\", \"keyboard\", \"keygen\", \"keyring\", \"keys\", \"keystroke\", \"keyword\",\n",
    "\"khz\", \"kick\", \"kicks\", \"kil\", \"kile\", \"kill\", \"killed\", \"killing\", \"kinda\",\n",
    "\"kindly\", \"kino\", \"kiso\", \"kit\", \"kk\", \"kms\", \"knew\", \"knock\", \"know\", \"knows\",\n",
    "\"knw\", \"koala\", \"kodi\", \"konquerer\", \"kontact\", \"kopete\", \"krusader\", \"ksirc\",\n",
    "\"kthx\", \"kto\", \"kubuntu\", \"kvm\", \"l2\", \"la\", \"label\", \"lack\", \"lacking\",\n",
    "\"ladies\", \"lagged\", \"lame\", \"lamp\", \"lan\", \"landlord\", \"landscape\", \"laptop\",\n",
    "\"large\", \"laserjet\", \"last\", \"late\", \"latency\", \"later\", \"laugh\", \"laughing\",\n",
    "\"launch\", \"launched\", \"launchpad\", \"law\", \"lay\", \"layer\", \"ldd\", \"le\", \"lead\",\n",
    "\"leading\", \"leak\", \"lean\", \"lear\", \"learn\", \"learning\", \"leave\", \"leaves\",\n",
    "\"left\", \"leg\", \"legacy\", \"legal\", \"lesbian\", \"less\", \"let\", \"letter\", \"level\",\n",
    "\"lfe\", \"lib\", \"libc\", \"libet\", \"library\", \"libre\", \"license\", \"lid\", \"lie\",\n",
    "\"life\", \"light\", \"lightning\", \"lights\", \"like\", \"liked\", \"likes\", \"limb\",\n",
    "\"limewire\", \"limited\", \"line\", \"linear\", \"lines\", \"link\", \"linked\", \"links\",\n",
    "\"links2\", \"linksys\", \"linux-\", \"linux\", \"linux-firmware\", \"linuxmce\", \"list\",\n",
    "\"listen\", \"listening\", \"little\", \"live\", \"liveboot\", \"live-cd\", \"livecd\",\n",
    "\"liveusb\", \"living\", \"lo\", \"load\", \"loaded\", \"loader\", \"loading\", \"lobby\",\n",
    "\"local\", \"locales\", \"localhost\", \"locate\", \"locked\", \"lockup\", \"log\",\n",
    "\"logging\", \"logical\", \"logically\", \"logins\", \"logo\", \"lol\", \"long\", \"longer\",\n",
    "\"longterm\", \"look\", \"looking\", \"looks\", \"lookup\", \"loop\", \"loop0\", \"loopback\",\n",
    "\"looping\", \"loose\", \"los\", \"lose\", \"losing\", \"loss\", \"lossless\", \"lossy\",\n",
    "\"lost\", \"lot\", \"love\", \"lovely\", \"loving\", \"low\", \"lowest\", \"lpr\", \"ls\",\n",
    "\"lsblk\", \"lsof\", \"lspci\", \"lts\", \"ltsp\", \"lubuntu\", \"lucid\", \"luck\", \"lug\",\n",
    "\"luks\", \"lvm\", \"lxde\", \"lyx\", \"m\", \"m68k\", \"maas\", \"mabe\", \"mac\", \"macbookpro\",\n",
    "\"machine\", \"machines\", \"macintosh\", \"macos\", \"macosx\", \"made\", \"mageia\",\n",
    "\"mail\", \"mailserver\", \"main\", \"major\", \"majority\", \"make\", \"makefile\", \"makin\",\n",
    "\"male\", \"malicious\", \"malone\", \"mam\", \"man\", \"manager\", \"mandatory\",\n",
    "\"mandriva\", \"manger\", \"mangled\", \"manipulate\", \"many\", \"mapping\", \"marked\",\n",
    "\"marketing\", \"massive\", \"mastering\", \"matchbox\", \"mate\", \"matter\", \"mature\",\n",
    "\"maximum\", \"may\", \"maybe\", \"mb\", \"mbox\", \"mbr\", \"mce\", \"md5\", \"md5sum\",\n",
    "\"mdadm\", \"me\", \"mean\", \"means\", \"mechanical\", \"media\", \"medicine\", \"medium\",\n",
    "\"member\", \"men\", \"mention\", \"mentor\", \"menu\", \"mepis\", \"merci\", \"merge\",\n",
    "\"merry\", \"mess\", \"metacity\", \"method\", \"me-tv\", \"mf1\", \"mga\", \"mhm\", \"mi\",\n",
    "\"mic\", \"mice\", \"microsd\", \"microsoft\", \"midi\", \"might\", \"mikrotik\", \"mileage\",\n",
    "\"min\", \"mind\", \"mine\", \"minecraft\", \"mines\", \"minimal\", \"minor\", \"mins\",\n",
    "\"minute\", \"mirc\", \"mirror\", \"mirrored\", \"mirrors\", \"miserable\", \"misplaced\",\n",
    "\"miss\", \"missed\", \"missing\", \"mistake\", \"mix\", \"mixer\", \"mixing\", \"mkay\",\n",
    "\"mkdir\", \"mkv\", \"mldonkey\", \"mlr\", \"mmap\", \"mmh\", \"mmkay\", \"mobility\",\n",
    "\"moblin\", \"mobo\", \"modding\", \"mode\", \"model\", \"modem\", \"modern\", \"modify\",\n",
    "\"modinfo\", \"modprobe\", \"modular\", \"mol\", \"moment\", \"monde\", \"monitor\",\n",
    "\"monitoring\", \"month\", \"moral\", \"more\", \"morning\", \"most\", \"mostly\", \"mother\",\n",
    "\"motu\", \"mount\", \"mousepad\", \"mout\", \"move\", \"mozilla\", \"mp2\", \"mp3\", \"mpeg\",\n",
    "\"mprime\", \"mpv\", \"mroe\", \"msdos\", \"msg\", \"msn\", \"mtp\", \"muck\", \"muh\", \"multi\",\n",
    "\"multimedia\", \"munin\", \"music\", \"must\", \"muted\", \"mutt\", \"mv\", \"my\", \"mybe\",\n",
    "\"mysql\", \"myuser\", \"\\\\n\", \"n\", \"na\", \"nah\", \"nahh\", \"name\", \"namely\", \"nar\",\n",
    "\"narwhal\", \"nasty\", \"nat\", \"native\", \"natty\", \"navigator\", \"nay\", \"nbr\", \"nc\",\n",
    "\"ncq\", \"ndiswrapper\", \"near\", \"nearby\", \"neat\", \"need\", \"neighbor\", \"neither\",\n",
    "\"nerdy\", \"nervous\", \"nessus\", \"net\", \"netbios\", \"netbook\", \"netcat\", \"nethack\",\n",
    "\"netmask\", \"netstat\", \"network\", \"networked\", \"networking\", \"networks\",\n",
    "\"never\", \"new\", \"newbs\", \"newer\", \"newline\", \"news\", \"nexenta\", \"next\",\n",
    "\"nexuiz\", \"nfs\", \"nfsv4\", \"nginx\", \"ni\", \"nice\", \"nicely\", \"nick\", \"nicks\",\n",
    "\"nickspam\", \"nicotine\", \"nid\", \"nie\", \"nipple\", \"nmap\", \"no\", \"noapic\",\n",
    "\"nobody\", \"nome\", \"non\", \"none\", \"nonsense\", \"noobs\", \"no-one\", \"nop\", \"nope\",\n",
    "\"nor\", \"norm\", \"normal\", \"normally\", \"not\", \"note\", \"notes\", \"nothing\",\n",
    "\"nouveau\", \"novell\", \"now\", \"np\", \"ns\", \"ntfs\", \"ntfs-3g\", \"ntp\", \"nuisance\",\n",
    "\"number\", \"numbers\", \"nun\", \"nup\", \"nvidia\", \"nvm\", \"nx\", \"o\", \"obex\",\n",
    "\"observing\", \"obv\", \"oct\", \"od\", \"odd\", \"odds\", \"oes\", \"of\", \"ofc\", \"ofcourse\",\n",
    "\"off\", \"offense\", \"offensive\", \"offer\", \"offsets\", \"offtopic\", \"often\", \"ogl\",\n",
    "\"ogle\", \"oh\", \"oi\", \"oic\", \"ok\", \"okay\", \"oki\", \"okies\", \"okk\", \"okkk\", \"oky\",\n",
    "\"okz\", \"ola\", \"old\", \"omg\", \"on\", \"onboard\", \"once\", \"one\", \"ones\", \"online\",\n",
    "\"only\", \"onto\", \"oof\", \"ook\", \"ooo\", \"oops\", \"op\", \"open\", \"openarena\",\n",
    "\"openbox\", \"opend\", \"opened\", \"openerp\", \"opengl\", \"openoffice\", \"open-source\",\n",
    "\"opensource\", \"opensuse\", \"openttd\", \"openvpn\", \"opinion\", \"ops\", \"option\",\n",
    "\"or\", \"orange\", \"oranges\", \"order\", \"original\", \"originals\", \"oss\", \"osx\",\n",
    "\"ot\", \"other\", \"others\", \"ouch\", \"oui\", \"out\", \"output\", \"outside\", \"ovaries\",\n",
    "\"over\", \"overkill\", \"overloaded\", \"overlook\", \"override\", \"owa\", \"own\",\n",
    "\"owned\", \"p2p\", \"p3\", \"p4\", \"pack\", \"package\", \"packets\", \"padding\", \"pae\",\n",
    "\"pain\", \"painful\", \"paint\", \"pakage\", \"palm\", \"paman\", \"panasonic\", \"panic\",\n",
    "\"para\", \"paragraph\", \"parallel\", \"parent\", \"parents\", \"park\", \"part\",\n",
    "\"partition\", \"partitioner\", \"partner\", \"party\", \"pas\", \"pass\", \"passed\",\n",
    "\"passwd\", \"password\", \"past\", \"paste\", \"pata\", \"patch\", \"patches\", \"patient\",\n",
    "\"pattern\", \"patterns\", \"pavilion\", \"pay\", \"pc\", \"pcbsd\", \"pci\", \"pcm\", \"pcs\",\n",
    "\"pctv\", \"pdf\", \"pearl\", \"peek\", \"peer\", \"pending\", \"pentium\", \"people\",\n",
    "\"peoples\", \"per\", \"perfect\", \"performances\", \"perl\", \"permanent\",\n",
    "\"persistence\", \"personal\", \"pesky\", \"peu\", \"pff\", \"pgp\", \"phd\", \"phew\",\n",
    "\"philosophy\", \"phone\", \"phones\", \"photo\", \"photos\", \"php\", \"phpmyadmin\",\n",
    "\"physical\", \"phyton\", \"pianobar\", \"pic\", \"picard\", \"pick\", \"pico\", \"pics\",\n",
    "\"picture\", \"pictures\", \"pid\", \"pidgin\", \"pidof\", \"piece\", \"ping\", \"pingus\",\n",
    "\"pink\", \"pint\", \"pipe\", \"pipes\", \"pity\", \"places\", \"plagued\", \"plain\",\n",
    "\"plaintext\", \"plan\", \"play\", \"playback\", \"player\", \"playing\", \"please\",\n",
    "\"plenty\", \"plex\", \"pls\", \"plug\", \"plugin\", \"plugins\", \"plugs\", \"plymouth\",\n",
    "\"plz\", \"pm\", \"pocket\", \"pocketpc\", \"poff\", \"point\", \"pointer\", \"pointless\",\n",
    "\"poke\", \"poking\", \"police\", \"polite\", \"poll\", \"pooched\", \"pool\", \"poor\", \"pop\",\n",
    "\"pop3\", \"popup\", \"por\", \"porno\", \"port\", \"portable\", \"portage\", \"ports\",\n",
    "\"portugues\", \"positive\", \"possible\", \"post\", \"postgres\", \"postgresql\", \"pour\",\n",
    "\"pov\", \"power\", \"powered\", \"powerpc\", \"ppc\", \"ppl\", \"ppp0\", \"pppoe\", \"pptp\",\n",
    "\"pra\", \"practical\", \"practice\", \"pre\", \"preferred\", \"prefixed\", \"preload\",\n",
    "\"premiere\", \"preseed\", \"press\", \"pretty\", \"prety\", \"price\", \"primary\", \"print\",\n",
    "\"printer\", \"prints\", \"prior\", \"priv\", \"privacy\", \"private\", \"privileged\",\n",
    "\"prize\", \"prob\", \"probably\", \"probe\", \"problem\", \"problems\", \"proc\", \"proceed\",\n",
    "\"process\", \"processor\", \"procs\", \"programer\", \"programming\", \"progress\",\n",
    "\"progs\", \"prohibit\", \"project\", \"projects\", \"prolog\", \"prompt\", \"proper\",\n",
    "\"props\", \"protect\", \"protection\", \"protocols\", \"prove\", \"proven\", \"provider\",\n",
    "\"proxy\", \"prt\", \"pry\", \"ps\", \"ps2\", \"ps3\", \"psd\", \"psk\", \"psu\", \"ptp\",\n",
    "\"public\", \"puel\", \"pulse\", \"pulseaudio\", \"pun\", \"purge\", \"purpose\", \"puta\",\n",
    "\"putty\", \"puzzled\", \"pv\", \"pvt\", \"pwd\", \"pxe\", \"pxeboot\", \"q3\", \"qdisc\",\n",
    "\"qemu\", \"qn\", \"qt\", \"quad\", \"quadro\", \"quake2\", \"quakenet\", \"qualcuno\",\n",
    "\"quality\", \"quanta\", \"quantal\", \"que\", \"quel\", \"query\", \"question\",\n",
    "\"questionable\", \"questioning\", \"questions\", \"questo\", \"quick\", \"quickly\",\n",
    "\"quicksilver\", \"quit\", \"quotes\", \"r1\", \"r40\", \"r9\", \"raep\", \"ragazzi\", \"raid\",\n",
    "\"raid0\", \"rails\", \"ramdisk\", \"ran\", \"random\", \"randomly\", \"rape\", \"rar\",\n",
    "\"rare\", \"ratio\", \"rc\", \"re\", \"reach\", \"read\", \"reader\", \"reading\", \"readme\",\n",
    "\"ready\", \"real\", \"realistic\", \"reality\", \"realize\", \"really\", \"realm\",\n",
    "\"realplayer\", \"realtek\", \"realtime\", \"rear\", \"reason\", \"reasonable\", \"reasons\",\n",
    "\"reboot\", \"reburn\", \"recall\", \"received\", \"recent\", \"reconnect\", \"record\",\n",
    "\"recover\", \"recovery\", \"recreate\", \"recycle\", \"redhat\", \"redo\", \"reduce\",\n",
    "\"refresh\", \"refund\", \"regard\", \"regenerate\", \"regenerating\", \"regexp\",\n",
    "\"register\", \"regression\", \"regular\", \"reinstall\", \"reiserfs\", \"relate\",\n",
    "\"relation\", \"relax\", \"relay\", \"release\", \"relevant\", \"reload\", \"reloaded\",\n",
    "\"reloading\", \"rely\", \"remaster\", \"remastersys\", \"remember\", \"remembers\",\n",
    "\"remix\", \"remote\", \"removed\", \"rename\", \"repair\", \"replaced\", \"replay\", \"repo\",\n",
    "\"repro\", \"reproducing\", \"request\", \"required\", \"rerun\", \"rescue\", \"research\",\n",
    "\"reservation\", \"reserved\", \"reset\", \"resolution\", \"resolve\", \"respectful\",\n",
    "\"responce\", \"respond\", \"rest\", \"restart\", \"restricted\", \"results\", \"retards\",\n",
    "\"return\", \"returning\", \"reverse\", \"revision\", \"rf\", \"rfc\", \"ribbon\", \"rid\",\n",
    "\"ridiculous\", \"right\", \"ringtail\", \"ripoff\", \"ripping\", \"risk\", \"rite\", \"rl\",\n",
    "\"rm\", \"rmdir\", \"road\", \"roaming\", \"rocks\", \"rolling\", \"roms\", \"room\", \"root\",\n",
    "\"roulette\", \"routed\", \"router\", \"routing\", \"row\", \"rows\", \"rpi\", \"rpm\",\n",
    "\"rsync\", \"rtf\", \"rtt\", \"ru\", \"rude\", \"ruin\", \"rule\", \"run\", \"runaway\",\n",
    "\"runescape\", \"runlevel\", \"runs\", \"rushed\", \"rv8\", \"rvm\", \"rwx\", \"s3\", \"safe\",\n",
    "\"safety\", \"said\", \"salut\", \"samba\", \"same\", \"samples\", \"sand\", \"sandbox\",\n",
    "\"sandisk\", \"sans\", \"sansa\", \"sarcasm\", \"sasl\", \"sat\", \"sata\", \"saturday\",\n",
    "\"saucy\", \"save\", \"saveas\", \"savvy\", \"saw\", \"sawfish\", \"say\", \"scaled\", \"scan\",\n",
    "\"scandisk\", \"scheduler\", \"science\", \"scite\", \"scp\", \"scrambled\", \"scratch\",\n",
    "\"screen\", \"screencast\", \"screening\", \"screensaver\", \"screenshot\", \"screw\",\n",
    "\"screwed\", \"screwing\", \"script\", \"scripts\", \"scroll\", \"scrollbar\", \"scrolls\",\n",
    "\"scsi\", \"sda3\", \"sda9\", \"sdc\", \"sdcard\", \"se\", \"seagate\", \"seahorse\",\n",
    "\"seamonkey\", \"search\", \"searched\", \"searching\", \"seattle\", \"sec\", \"second\",\n",
    "\"secondary\", \"secondlife\", \"security\", \"sed\", \"see\", \"seed\", \"seeking\",\n",
    "\"segfaults\", \"select\", \"selection\", \"selective\", \"selinux\", \"selling\", \"sem\",\n",
    "\"semicolon\", \"send\", \"sense\", \"sensible\", \"sent\", \"sentence\", \"senza\",\n",
    "\"separate\", \"serial\", \"series\", \"serious\", \"seriously\", \"serpentine\", \"serve\",\n",
    "\"server\", \"servers\", \"servlet\", \"session\", \"set\", \"seti\", \"setting\", \"setup\",\n",
    "\"sever\", \"sex\", \"sfs\", \"sftp\", \"sh\", \"sha1\", \"shame\", \"sharing\", \"she\",\n",
    "\"shell\", \"shells\", \"shellshock\", \"shift\", \"shipit\", \"shite\", \"sho\", \"shoes\",\n",
    "\"shoot\", \"shoots\", \"shop\", \"short\", \"shortcut\", \"shortcuts\", \"shorter\",\n",
    "\"shoutcast\", \"shouting\", \"shown\", \"shred\", \"shrink\", \"shrugs\", \"shuffle\",\n",
    "\"shure\", \"shut\", \"shutdown\", \"shuttleworth\", \"si\", \"sick\", \"side\", \"sidebar\",\n",
    "\"siema\", \"siemens\", \"sigh\", \"sign\", \"signal\", \"silence\", \"silently\", \"silly\",\n",
    "\"sim\", \"similar\", \"simple\", \"simplicity\", \"simply\", \"simulate\", \"sing\",\n",
    "\"single\", \"sips\", \"sir\", \"sis\", \"sistem\", \"sit0\", \"site\", \"situation\",\n",
    "\"skills\", \"skin\", \"skype\", \"slang\", \"slaps\", \"slave\", \"sleep\", \"sleeping\",\n",
    "\"sleeve\", \"slightly\", \"slow\", \"slower\", \"slowest\", \"slowing\", \"slowness\",\n",
    "\"sm56\", \"small\", \"smarter\", \"smb\", \"sme\", \"smooth\", \"smp\", \"smth\", \"smtp\",\n",
    "\"snaps\", \"snapshot\", \"snes\", \"snippets\", \"snmp\", \"so\", \"sobre\", \"socat\",\n",
    "\"social\", \"socks\", \"soem\", \"soft\", \"software\", \"solar\", \"solution\", \"solving\",\n",
    "\"som\", \"some\", \"some1\", \"somebody\", \"somehow\", \"someon\", \"someone\",\n",
    "\"someplace\", \"somethin\", \"something\", \"somewhat\", \"somewhere\", \"somone\",\n",
    "\"song\", \"songbird\", \"soo\", \"soon\", \"sooner\", \"soooo\", \"sorry\", \"sort\", \"sorta\",\n",
    "\"sory\", \"soulseek\", \"sound\", \"soundblaster\", \"soundtrack\", \"source\",\n",
    "\"sourcecode\", \"sourced\", \"sow\", \"sp2\", \"sp3\", \"space\", \"spam\", \"spanish\",\n",
    "\"spe\", \"speak\", \"speaker\", \"speakers\", \"specs\", \"speed\", \"speeding\",\n",
    "\"speedtouch\", \"spelling\", \"spin\", \"spinning\", \"spit\", \"splash\", \"split\",\n",
    "\"splitter\", \"spoke\", \"spoofing\", \"spot\", \"spread\", \"sprint\", \"spurious\",\n",
    "\"spyware\", \"sql\", \"squares\", \"squeeze\", \"srt\", \"ssb\", \"ssd\", \"ssh\", \"sshd\",\n",
    "\"ssh-server\", \"ssl\", \"sta\", \"stack\", \"stacks\", \"stand\", \"standalone\",\n",
    "\"standard\", \"standby\", \"starcraft\", \"start\", \"startkeylogger\", \"startx\",\n",
    "\"stat\", \"state\", \"stated\", \"states\", \"static\", \"status\", \"stay\", \"stderr\",\n",
    "\"stdout\", \"steady\", \"steam\", \"steep\", \"step\", \"steps\", \"stfu\", \"sthg\",\n",
    "\"stickers\", \"sticks\", \"still\", \"stopped\", \"storage\", \"store\", \"strace\",\n",
    "\"strain\", \"stream\", \"streamer\", \"street\", \"strength\", \"stress\", \"string\",\n",
    "\"stripped\", \"stroke\", \"strong\", \"stronger\", \"stty\", \"stubborn\", \"stuck\",\n",
    "\"study\", \"studying\", \"stuff\", \"stuffs\", \"stupid\", \"stupidity\", \"su\", \"subject\",\n",
    "\"subnet\", \"subset\", \"substance\", \"subversion\", \"succeed\", \"sucker\", \"sucks\",\n",
    "\"sucky\", \"suddenly\", \"sudo\", \"sudoers\", \"suffer\", \"suffering\", \"suffice\",\n",
    "\"sugar\", \"sum\", \"sunday\", \"sup\", \"super-user\", \"supply\", \"suppor\", \"support\",\n",
    "\"supybot\", \"sure\", \"surely\", \"surfing\", \"surprise\", \"survives\", \"suse\",\n",
    "\"suspend\", \"sux\", \"svn\", \"swap\", \"swapon\", \"swedish\", \"sweeet\", \"sweet\", \"swf\",\n",
    "\"swiftweasel\", \"switch\", \"switched\", \"switcher\", \"switches\", \"sym\", \"symbolic\",\n",
    "\"symlinks\", \"synaptic\", \"synatic\", \"sync\", \"synoptic\", \"sys\", \"syscall\",\n",
    "\"sysctl\", \"syslogd\", \"system\", \"system76\", \"systemd\", \"systems\", \"systray\",\n",
    "\"sysv\", \"t\", \"t400\", \"t42\", \"t61\", \"ta\", \"tab\", \"tab-complete\", \"tablet\",\n",
    "\"taboo\", \"tabs\", \"tails\", \"take\", \"taken\", \"taking\", \"talk\", \"talkin\", \"tanks\",\n",
    "\"tap\", \"tape\", \"target\", \"tasks\", \"tcp\", \"tea\", \"teach\", \"teachers\", \"team\",\n",
    "\"teams\", \"teamspeak\", \"technical\", \"techs\", \"tedious\", \"tee\", \"teh\", \"tel\",\n",
    "\"television\", \"tell\", \"telling\", \"telnet\", \"temperature\", \"temporary\", \"tend\",\n",
    "\"terminal\", \"terminate\", \"terminology\", \"terror\", \"terse\", \"tes\", \"tested\",\n",
    "\"testing\", \"text\", \"tf2\", \"th\", \"tha\", \"thank\", \"thanks\", \"thankyou\", \"that\",\n",
    "\"thats\", \"the\", \"theater\", \"them\", \"theme\", \"then\", \"theora\", \"there\",\n",
    "\"therefore\", \"these\", \"they\", \"thier\", \"thik\", \"thing\", \"things\", \"think\",\n",
    "\"thinking\", \"third\", \"this\", \"thng\", \"tho\", \"thos\", \"thought\", \"thoughts\",\n",
    "\"thousands\", \"threads\", \"three\", \"threw\", \"throttled\", \"ths\", \"tht\",\n",
    "\"thumbdrive\", \"thumbs\", \"thunar\", \"thunderbird\", \"thunk\", \"thus\", \"thx\", \"ti\",\n",
    "\"tia\", \"ticking\", \"tie\", \"tiff\", \"tightvnc\", \"till\", \"time\", \"timeout\",\n",
    "\"timers\", \"timestamp\", \"tip\", \"tips\", \"tired\", \"tis\", \"tit\", \"tivo\", \"tks\",\n",
    "\"tlp\", \"tls\", \"tnx\", \"to\", \"toasted\", \"today\", \"together\", \"toilet\",\n",
    "\"tomorrow\", \"tonight\", \"too\", \"took\", \"tool\", \"tools\", \"top\", \"topic\", \"tor\",\n",
    "\"torrent\", \"toss\", \"total\", \"totem\", \"touch\", \"touched\", \"touchpad\", \"tough\",\n",
    "\"tous\", \"tp\", \"tracert\", \"track\", \"tracker\", \"trackpoint\", \"tracks\", \"trafic\",\n",
    "\"training\", \"transgaming\", \"transient\", \"transition\", \"translated\",\n",
    "\"transparent\", \"trap\", \"trash\", \"travelmate\", \"tray\", \"trayer\", \"treat\",\n",
    "\"tremulous\", \"trial\", \"trick\", \"tricky\", \"tried\", \"trigger\", \"triple\",\n",
    "\"trivial\", \"trolling\", \"trolls\", \"trouble\", \"troubleshooter\", \"tru\", \"true\",\n",
    "\"truly\", \"truncate\", \"trunk\", \"trusted\", \"trusty\", \"try\", \"trying\", \"tsc\",\n",
    "\"ttf\", \"ttfn\", \"tthe\", \"tty\", \"tty1\", \"tue\", \"tune\", \"tuner\", \"tunes\",\n",
    "\"tunnel\", \"turds\", \"tut\", \"tuto\", \"tutorial\", \"tutorials\", \"tutti\", \"tuxracer\",\n",
    "\"tv\", \"tweaks\", \"twenty\", \"twin\", \"twitter\", \"twm\", \"two\", \"txt\", \"tym\",\n",
    "\"type\", \"u\", \"uac\", \"uae\", \"ubnutu\", \"ubunto\", \"ubuntu-cn\", \"ubuntu-dev\",\n",
    "\"ubuntu-es\", \"ubuntu-fr\", \"ubuntuguide\", \"ubuntu-server\", \"ubunutu\", \"ubutto\",\n",
    "\"ues\", \"ufw\", \"ug\", \"ugh\", \"ughh\", \"ugly\", \"uh\", \"uhh\", \"uh-oh\", \"uhu\", \"uid\",\n",
    "\"uk\", \"ulimit\", \"um\", \"uma\", \"umm\", \"ummm\", \"una\", \"unable\", \"unallocated\",\n",
    "\"uname\", \"unbanned\", \"unbelievable\", \"unbound\", \"unbuntu\", \"unclean\", \"und\",\n",
    "\"undefined\", \"under\", \"undo\", \"undone\", \"une\", \"unetbootin\", \"unfriendly\",\n",
    "\"unhappy\", \"uni\", \"unicorn\", \"unified\", \"unit\", \"univ\", \"universe\", \"unix\",\n",
    "\"unix-like\", \"unless\", \"unlike\", \"unlimited\", \"unlock\", \"unmanaged\", \"unplug\",\n",
    "\"unplugged\", \"unregged\", \"unto\", \"untouched\", \"untrusted\", \"unused\", \"up\",\n",
    "\"update\", \"updated\", \"updater\", \"updates\", \"upgrade\", \"upgrading\", \"uploaded\",\n",
    "\"upon\", \"upside\", \"upstairs\", \"upstart\", \"uptime\", \"ur\", \"urban\", \"urgh\",\n",
    "\"url\", \"urs\", \"us\", \"usa\", \"usb\", \"use\", \"user\", \"userb\", \"userid\", \"userland\",\n",
    "\"users\", \"using\", \"usre\", \"ut\", \"ut2004\", \"utf-8\", \"util\", \"utils\", \"utopic\",\n",
    "\"utorrent\", \"uxa\", \"v4l\", \"v8\", \"v9\", \"vagina\", \"vagrant\", \"vai\", \"vain\",\n",
    "\"value\", \"values\", \"valve\", \"various\", \"vary\", \"vault\", \"vbox\", \"venezuela\",\n",
    "\"vent\", \"ventrilo\", \"verbosity\", \"versatile\", \"version\", \"vertical\", \"very\",\n",
    "\"vga\", \"vi\", \"via\", \"victory\", \"vid\", \"viet\", \"view\", \"vim\", \"virgin\",\n",
    "\"virtual\", \"virtualbox\", \"virtualized\", \"virtualmachine\", \"visit\", \"vista\",\n",
    "\"visual\", \"visually\", \"vlc\", \"vmlinuz\", \"vms\", \"vmstat\", \"vmware\", \"vnc\",\n",
    "\"voip\", \"volume\", \"volunteer\", \"vorbis\", \"vpc\", \"vpn\", \"vps\", \"vram\", \"vs\",\n",
    "\"vsftpd\", \"vt\", \"vulnerable\", \"w7\", \"w8\", \"wa\", \"wack\", \"wah\", \"waht\", \"wait\",\n",
    "\"waiting\", \"walking\", \"wall\", \"wan\", \"wana\", \"wanna\", \"wanted\", \"warcraft\",\n",
    "\"warning\", \"wary\", \"was\", \"washed\", \"wast\", \"waste\", \"watch\", \"watchdog\",\n",
    "\"wav\", \"way\", \"wayland\", \"ways\", \"wbar\", \"we\", \"wear\", \"weather\", \"web\",\n",
    "\"webadmin\", \"webhosting\", \"webmin\", \"webserver\", \"website\", \"wed\", \"weechat\",\n",
    "\"weird\", \"welcom\", \"welcome\", \"well\", \"welll\", \"wep\", \"wer\", \"were\", \"werk\",\n",
    "\"wget\", \"whacky\", \"what\", \"whatever\", \"whatis\", \"whee\", \"when\", \"where\",\n",
    "\"wherever\", \"which\", \"while\", \"whim\", \"whit\", \"white\", \"whitespace\", \"who\",\n",
    "\"whoa\", \"whole\", \"whomever\", \"whoops\", \"whore\", \"whose\", \"wht\", \"why\", \"wid\",\n",
    "\"widescreen\", \"width\", \"wie\", \"wife\", \"wi-fi\", \"wifi\", \"wiki\", \"wikipedia\",\n",
    "\"wildcards\", \"will\", \"willl\", \"win\", \"win2k\", \"win7\", \"winblows\", \"winbox\",\n",
    "\"window\", \"windows\", \"windows7\", \"windoze\", \"wine\", \"winehq\", \"wink\", \"wins\",\n",
    "\"winxp\", \"wipe\", \"wire\", \"wired\", \"wireless\", \"wiser\", \"wish\", \"wit\", \"witch\",\n",
    "\"with\", \"without\", \"wl\", \"wlan\", \"wlan0\", \"wm\", \"wmware\", \"wo\", \"wobbly\",\n",
    "\"wol\", \"woman\", \"wonder\", \"wondered\", \"wonderful\", \"wondering\", \"wont\", \"woof\",\n",
    "\"woohoo\", \"woohooo\", \"woooo\", \"woops\", \"word\", \"work\", \"workbench\", \"worker\",\n",
    "\"workgroup\", \"working\", \"works\", \"world\", \"worried\", \"worry\", \"wors\", \"worth\",\n",
    "\"worx\", \"wow\", \"wrapper\", \"wrecked\", \"write\", \"writer\", \"writing\", \"written\",\n",
    "\"wrong\", \"wtc\", \"wtf\", \"wubi\", \"wusb54g\", \"wxp\", \"x\", \"x11\", \"x64\", \"x86\",\n",
    "\"x86_64\", \"xampp\", \"xandros\", \"xargs\", \"x-chat\", \"xchat\", \"xconfig\", \"xd\",\n",
    "\"xdmcp\", \"xe1\", \"xenial\", \"xeyes\", \"xf86\", \"xfburn\", \"xfce\", \"xfire\", \"xfs\",\n",
    "\"xfx\", \"xgl\", \"xine\", \"xls\", \"xmacro\", \"xml\", \"xmms\", \"xmonad\", \"xmpp\", \"xorg\",\n",
    "\"xp\", \"xps\", \"xsane\", \"xscreen\", \"xt\", \"xterm\", \"xubuntu\", \"xv\", \"xvf\", \"ya\",\n",
    "\"yakuake\", \"yawn\", \"yay\", \"yea\", \"yeah\", \"yeap\", \"yeh\", \"yell\", \"yelp\", \"yep\",\n",
    "\"yer\", \"yes\", \"yess\", \"yessir\", \"yesterday\", \"yet\", \"yields\", \"yikes\", \"you\",\n",
    "\"your\", \"yours\", \"yourself\", \"yourusername\", \"youtube\", \"youve\", \"yoy\", \"yp\",\n",
    "\"yrs\", \"yummy\", \"yup\", \"yus\", \"yw\", \"zeros\", \"zesty\", \"zips\", \"znc\", \"zomg\",\n",
    "\"zone\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unk(word):\n",
    "    has_digit = any(c in string.digits for c in word)\n",
    "    has_letter = any(c in string.ascii_letters for c in word)\n",
    "    marks = set()\n",
    "    for c in word:\n",
    "        if c in string.punctuation:\n",
    "            marks.add(c)\n",
    "    marks = list(marks)\n",
    "    marks.sort()\n",
    "    marks = ''.join(marks)\n",
    "\n",
    "    ans = \"<unk\"\n",
    "    if has_digit:\n",
    "        ans += \"#\"\n",
    "    if has_letter:\n",
    "        ans += \"a\"\n",
    "    ans += marks\n",
    "    ans += \">\"\n",
    "    return ans\n",
    "\n",
    "def apply_re(expression, done, todo, current, label=''):\n",
    "    if len(current) == 0:\n",
    "        return current\n",
    "    else:\n",
    "        # Split\n",
    "        parts = []\n",
    "        for v in re.split(expression, current):\n",
    "            if v is not None and len(v) > 0:\n",
    "                parts.append(label + v)\n",
    "\n",
    "        # Push all but the start back on todo\n",
    "        if len(parts) > 1:\n",
    "            for part in parts[:0:-1]:\n",
    "                if len(part) > 0:\n",
    "                    todo.insert(0, part)\n",
    "\n",
    "        return parts[0]\n",
    "\n",
    "# Names two letters or less that occur more than 500 times in the data\n",
    "common_short_names = {\"ng\", \"_2\", \"x_\", \"rq\", \"\\\\9\", \"ww\", \"nn\", \"bc\", \"te\",\n",
    "\"io\", \"v7\", \"dm\", \"m0\", \"d1\", \"mr\", \"x3\", \"nm\", \"nu\", \"jc\", \"wy\", \"pa\", \"mn\",\n",
    "\"a_\", \"xz\", \"qr\", \"s1\", \"jo\", \"sw\", \"em\", \"jn\", \"cj\", \"j_\"}\n",
    "\n",
    "def tokenise(line, vocab, users, line_no):\n",
    "    tokens = []\n",
    "\n",
    "    parts = line.strip().split()\n",
    "    # Handle timestamp and username\n",
    "    if re.match(\".*\\[[0-9][0-9][:][0-9][0-9]\\]$\", parts[0]) is None:\n",
    "        timestamp = parts.pop(0)\n",
    "    else:\n",
    "        timestamp = parts.pop(0)\n",
    "        user = parts.pop(0)\n",
    "        while user[-1] != '>' and len(parts) > 0:\n",
    "            user +=\" \"+ parts.pop(0)\n",
    "\n",
    "    # Handle message\n",
    "    while len(parts) > 0:\n",
    "        current = parts.pop(0)\n",
    "        current = current.lower()\n",
    "\n",
    "        # Handle username mentions\n",
    "        user = None\n",
    "        if current in users and len(current) > 2:\n",
    "            user = current\n",
    "        else:\n",
    "            core = [char for char in current]\n",
    "            while len(core) > 0 and core[-1] in string.punctuation:\n",
    "                core.pop()\n",
    "                nword = ''.join(core)\n",
    "                if nword in users and (len(core) > 2 or nword in common_short_names):\n",
    "                    user = nword\n",
    "                    break\n",
    "            if user is None:\n",
    "                while len(core) > 0 and core[0] in string.punctuation:\n",
    "                    core.pop(0)\n",
    "                    nword = ''.join(core)\n",
    "                    if nword in users and (len(core) > 2 or nword in common_short_names):\n",
    "                        user = nword\n",
    "                        break\n",
    "        if user is not None:\n",
    "            cmin, cmax = users[user]\n",
    "            if cmin - 1000 <= line_no <= cmax + 1000:\n",
    "                subparts = current.split(user)\n",
    "                if len(subparts[0]) > 0:\n",
    "                    tokens.append(subparts[0])\n",
    "                tokens.append(\"<user>\")\n",
    "                if len(subparts[-1]) > 0:\n",
    "                    tokens.append(subparts[-1])\n",
    "                current = ''\n",
    "                continue\n",
    "\n",
    "        #  - email (...@...) or prompt (...@...:...) make word shape (...@...) and split on ':'\n",
    "        if \"@\" in current and (not current.startswith(\"@\")) and (not current.endswith('@')):\n",
    "            if len(current.split(\"@\")) == 2:\n",
    "                tokens.append(\"ADDRESS_\" + current.split(\"@\")[0])\n",
    "                tokens.append(\"ADDRESS_@\" + current.split(\"@\")[1])\n",
    "                current = ''\n",
    "                continue\n",
    "\n",
    "        #  - Permissions (only rwxd-), split into groups of three characters\n",
    "        if len(current) == 10 and re.fullmatch(\"[-rwxd]+\", current) is not None:\n",
    "            tokens.append('PERMISSIONS_'+ current[:1])\n",
    "            tokens.append('PERMISSIONS_'+ current[1:4])\n",
    "            tokens.append('PERMISSIONS_'+ current[4:7])\n",
    "            tokens.append('PERMISSIONS_'+ current[7:])\n",
    "            current = ''\n",
    "            continue\n",
    "\n",
    "        #  - URLs (start with http, sftp, telnet) split on '/' and add it (http://) (...) (/.../) (/.../) ...\n",
    "        if re.match(\"^((http)|(sftp)|(telnet)).*\\/\", current) is not None:\n",
    "            chunks = [c for c in current.split(\"/\") if len(c) != 0]\n",
    "            tokens.append(\"URL/\"+ chunks[0] +\"/\")\n",
    "            if len(chunks) > 1:\n",
    "                tokens.append(\"URL/\"+ chunks[1] +\"/\")\n",
    "                if len(chunks) > 2:\n",
    "                    tokens.append(\"URL/\"+ '/'.join(chunks[2:]) +\"/\")\n",
    "            current = ''\n",
    "            continue\n",
    "        if current.startswith(\"www.\"):\n",
    "            current = \"URL/\"+ current\n",
    "\n",
    "        #  - ...[:;*,.?!)] and group repeats (... or ... or !?!!??!?!)\n",
    "        current = apply_re(\"\"\"([\":;?!.,)}\\]]+$)\"\"\", tokens, parts, current)\n",
    "\n",
    "        #  - Directories (start with / or ~) split into pieces (/.../) (/.../)\n",
    "        if re.match(\"^[~/]\", current) is not None:\n",
    "            chunks = current.split(\"/\")\n",
    "            for chunk in chunks:\n",
    "                if len(chunk) > 0:\n",
    "                    tokens.append(\"DIR/\"+ chunk +\"/\")\n",
    "            current = ''\n",
    "            continue\n",
    "\n",
    "        #  - [!({[]...\n",
    "        current = apply_re(\"\"\"(^[\"!({[]+)\"\"\", tokens, parts, current)\n",
    "\n",
    "        #  - ...'s  ...n't  ...'ll  ...'m ...'ve (and in all cases allow ' or \")\n",
    "        current = apply_re(\"\"\"(['\"]s)$\"\"\", tokens, parts, current)\n",
    "        current = apply_re(\"\"\"(n['\"]t)$\"\"\", tokens, parts, current)\n",
    "        current = apply_re(\"\"\"(['\"]ll)$\"\"\", tokens, parts, current)\n",
    "        current = apply_re(\"\"\"(['\"]m)$\"\"\", tokens, parts, current)\n",
    "        current = apply_re(\"\"\"(['\"]ve)$\"\"\", tokens, parts, current)\n",
    "\n",
    "        #  - mid-word ellipses (e.g. know...But)\n",
    "        current = apply_re(\"\"\"([.][.]+)\"\"\", tokens, parts, current)\n",
    "\n",
    "        #  - Instructions like \"System->Admin->Shared\" split on \"[-]?>\"\n",
    "        current = apply_re(\"\"\"([-]?[>])\"\"\", tokens, parts, current)\n",
    "\n",
    "        #  - \"s/.../...\" to \"substitution / ... / ... /\"\n",
    "        if re.match(\"s/.*/\", current) is not None:\n",
    "            for chunk in current.split(\"/\"):\n",
    "                if len(chunk) > 0:\n",
    "                    tokens.append(\"SUB/\"+ chunk +\"/\")\n",
    "            current = ''\n",
    "            continue\n",
    "\n",
    "        #  - Numbers (do not convert all numbers to 0, as 32 != 64)\n",
    "        # versions, etc, so not worth collapsing\n",
    "\n",
    "        if len(current) > 0:\n",
    "            tokens.append(current)\n",
    "\n",
    "    # Add unks\n",
    "    if len(vocab) > 0:\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token.lower() not in users and token not in vocab:\n",
    "                tokens[i] = make_unk(token)\n",
    "\n",
    "    tokens.insert(0, \"<s>\")\n",
    "    tokens.append(\"</s>\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def update_user(users, user, line_no):\n",
    "    if user in reserved:\n",
    "        return\n",
    "    all_digit = True\n",
    "    for char in user:\n",
    "        if char not in string.digits:\n",
    "            all_digit = False\n",
    "    if all_digit:\n",
    "        return\n",
    "\n",
    "    if user not in users:\n",
    "        users[user] = (line_no, line_no)\n",
    "    else:\n",
    "        cmin, cmax = users[user]\n",
    "        users[user] = (min(cmin, line_no), max(cmax, line_no))\n",
    "\n",
    "def update_users(line, users, line_no):\n",
    "    if len(line.split()) < 2:\n",
    "        return\n",
    "    user = line.split()[1]\n",
    "    if user in [\"Topic\", \"Signoff\", \"Signon\", \"Total\", \"#ubuntu\",\n",
    "            \"Window\", \"Server:\", \"Screen:\", \"Geometry\", \"CO,\",\n",
    "            \"Current\", \"Query\", \"Prompt:\", \"Second\", \"Split\",\n",
    "            \"Logging\", \"Logfile\", \"Notification\", \"Hold\", \"Window\",\n",
    "            \"Lastlog\", \"Notify\", 'netjoined:']:\n",
    "        # Ignore as these are channel commands\n",
    "        pass\n",
    "    else:\n",
    "        if line.split()[0].endswith(\"===\"):\n",
    "            parts = line.split(\"is now known as\")\n",
    "            if len(parts) == 2 and line.split()[-1] == parts[-1].strip():\n",
    "                user = line.split()[-1]\n",
    "        elif line.split()[0][-1] == ']':\n",
    "            if user[0] == '<':\n",
    "                user = user[1:]\n",
    "            if user[-1] == '>':\n",
    "                user = user[:-1]\n",
    "\n",
    "        user = user.lower()\n",
    "        update_user(users, user, line_no)\n",
    "        # This is for cases like a user named |blah| who is\n",
    "        # refered to as simply blah\n",
    "        core = [char for char in user]\n",
    "        while len(core) > 0 and core[0] in string.punctuation:\n",
    "            core.pop(0)\n",
    "        while len(core) > 0 and core[-1] in string.punctuation:\n",
    "            core.pop()\n",
    "        core = ''.join(core)\n",
    "        update_user(users, core, line_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01.ascii_o.txt\n",
      "2016-01-02.ascii_o.txt\n",
      "2016-01-03.ascii_o.txt\n",
      "2016-01-04.ascii_o.txt\n",
      "2016-01-05.ascii_o.txt\n",
      "2016-01-06.ascii_o.txt\n",
      "2016-01-07.ascii_o.txt\n",
      "2016-01-08.ascii_o.txt\n",
      "2016-01-09.ascii_o.txt\n",
      "2016-01-10.ascii_o.txt\n",
      "2016-01-11.ascii_o.txt\n",
      "2016-01-12.ascii_o.txt\n",
      "2016-01-13.ascii_o.txt\n",
      "2016-01-14.ascii_o.txt\n",
      "2016-01-15.ascii_o.txt\n",
      "2016-01-16.ascii_o.txt\n",
      "2016-01-17.ascii_o.txt\n",
      "2016-01-18.ascii_o.txt\n",
      "2016-01-19.ascii_o.txt\n",
      "2016-01-20.ascii_o.txt\n",
      "2016-01-21.ascii_o.txt\n",
      "2016-01-22.ascii_o.txt\n",
      "2016-01-23.ascii_o.txt\n",
      "2016-01-24.ascii_o.txt\n",
      "2016-01-25.ascii_o.txt\n",
      "2016-01-26.ascii_o.txt\n",
      "2016-01-27.ascii_o.txt\n",
      "2016-01-28.ascii_o.txt\n",
      "2016-01-29.ascii_o.txt\n",
      "2016-01-30.ascii_o.txt\n",
      "2016-01-31.ascii_o.txt\n",
      "2016-02-01.ascii_o.txt\n",
      "2016-02-02.ascii_o.txt\n",
      "2016-02-03.ascii_o.txt\n",
      "2016-02-04.ascii_o.txt\n",
      "2016-02-05.ascii_o.txt\n",
      "2016-02-06.ascii_o.txt\n",
      "2016-02-07.ascii_o.txt\n",
      "2016-02-08.ascii_o.txt\n",
      "2016-02-09.ascii_o.txt\n",
      "2016-02-10.ascii_o.txt\n",
      "2016-02-11.ascii_o.txt\n",
      "2016-02-12.ascii_o.txt\n",
      "2016-02-13.ascii_o.txt\n",
      "2016-02-14.ascii_o.txt\n",
      "2016-02-15.ascii_o.txt\n",
      "2016-02-16.ascii_o.txt\n",
      "2016-02-17.ascii_o.txt\n",
      "2016-02-18.ascii_o.txt\n",
      "2016-02-19.ascii_o.txt\n",
      "2016-02-20.ascii_o.txt\n",
      "2016-02-21.ascii_o.txt\n",
      "2016-02-22.ascii_o.txt\n",
      "2016-02-23.ascii_o.txt\n",
      "2016-02-24.ascii_o.txt\n",
      "2016-02-25.ascii_o.txt\n",
      "2016-02-26.ascii_o.txt\n",
      "2016-02-27.ascii_o.txt\n",
      "2016-02-28.ascii_o.txt\n",
      "2016-02-29.ascii_o.txt\n",
      "2016-03-01.ascii_o.txt\n",
      "2016-03-02.ascii_o.txt\n",
      "2016-03-03.ascii_o.txt\n",
      "2016-03-04.ascii_o.txt\n",
      "2016-03-05.ascii_o.txt\n",
      "2016-03-06.ascii_o.txt\n",
      "2016-03-07.ascii_o.txt\n",
      "2016-03-08.ascii_o.txt\n",
      "2016-03-09.ascii_o.txt\n",
      "2016-03-10.ascii_o.txt\n",
      "2016-03-11.ascii_o.txt\n",
      "2016-03-12.ascii_o.txt\n",
      "2016-03-13.ascii_o.txt\n",
      "2016-03-14.ascii_o.txt\n",
      "2016-03-15.ascii_o.txt\n",
      "2016-03-16.ascii_o.txt\n",
      "2016-03-17.ascii_o.txt\n",
      "2016-03-18.ascii_o.txt\n",
      "2016-03-19.ascii_o.txt\n",
      "2016-03-20.ascii_o.txt\n",
      "2016-03-21.ascii_o.txt\n",
      "2016-03-22.ascii_o.txt\n",
      "2016-03-23.ascii_o.txt\n",
      "2016-03-25.ascii_o.txt\n",
      "2016-03-26.ascii_o.txt\n",
      "2016-03-27.ascii_o.txt\n",
      "2016-03-28.ascii_o.txt\n",
      "2016-03-29.ascii_o.txt\n",
      "2016-03-30.ascii_o.txt\n",
      "2016-03-31.ascii_o.txt\n",
      "2016-04-01.ascii_o.txt\n",
      "2016-04-02.ascii_o.txt\n",
      "2016-04-03.ascii_o.txt\n",
      "2016-04-04.ascii_o.txt\n",
      "2016-04-05.ascii_o.txt\n",
      "2016-04-08.ascii_o.txt\n",
      "2016-04-09.ascii_o.txt\n",
      "2016-04-10.ascii_o.txt\n",
      "2016-04-11.ascii_o.txt\n",
      "2016-04-12.ascii_o.txt\n",
      "2016-04-13.ascii_o.txt\n",
      "2016-04-14.ascii_o.txt\n",
      "2016-04-15.ascii_o.txt\n",
      "2016-04-16.ascii_o.txt\n",
      "2016-04-17.ascii_o.txt\n",
      "2016-04-18.ascii_o.txt\n",
      "2016-04-19.ascii_o.txt\n",
      "2016-04-20.ascii_o.txt\n",
      "2016-04-21.ascii_o.txt\n",
      "2016-04-22.ascii_o.txt\n",
      "2016-04-23.ascii_o.txt\n",
      "2016-04-24.ascii_o.txt\n",
      "2016-04-25.ascii_o.txt\n",
      "2016-04-26.ascii_o.txt\n",
      "2016-04-27.ascii_o.txt\n",
      "2016-04-28.ascii_o.txt\n",
      "2016-04-29.ascii_o.txt\n",
      "2016-04-30.ascii_o.txt\n",
      "2016-05-01.ascii_o.txt\n",
      "2016-05-02.ascii_o.txt\n",
      "2016-05-03.ascii_o.txt\n",
      "2016-05-04.ascii_o.txt\n",
      "2016-05-05.ascii_o.txt\n",
      "2016-05-07.ascii_o.txt\n",
      "2016-05-08.ascii_o.txt\n",
      "2016-05-09.ascii_o.txt\n",
      "2016-05-10.ascii_o.txt\n",
      "2016-05-11.ascii_o.txt\n",
      "2016-05-12.ascii_o.txt\n",
      "2016-05-13.ascii_o.txt\n",
      "2016-05-14.ascii_o.txt\n",
      "2016-05-15.ascii_o.txt\n",
      "2016-05-16.ascii_o.txt\n",
      "2016-05-17.ascii_o.txt\n",
      "2016-05-18.ascii_o.txt\n",
      "2016-05-19.ascii_o.txt\n",
      "2016-05-21.ascii_o.txt\n",
      "2016-05-22.ascii_o.txt\n",
      "2016-05-23.ascii_o.txt\n",
      "2016-05-24.ascii_o.txt\n",
      "2016-05-25.ascii_o.txt\n",
      "2016-05-26.ascii_o.txt\n",
      "2016-05-27.ascii_o.txt\n",
      "2016-05-28.ascii_o.txt\n",
      "2016-05-29.ascii_o.txt\n",
      "2016-05-30.ascii_o.txt\n",
      "2016-05-31.ascii_o.txt\n",
      "2016-06-01.ascii_o.txt\n",
      "2016-06-02.ascii_o.txt\n",
      "2016-06-03.ascii_o.txt\n",
      "2016-06-04.ascii_o.txt\n",
      "2016-06-05.ascii_o.txt\n",
      "2016-06-06.ascii_o.txt\n",
      "2016-06-07.ascii_o.txt\n",
      "2016-06-08.ascii_o.txt\n",
      "2016-06-09.ascii_o.txt\n",
      "2016-06-10.ascii_o.txt\n",
      "2016-06-11.ascii_o.txt\n",
      "2016-06-12.ascii_o.txt\n",
      "2016-06-15.ascii_o.txt\n",
      "2016-06-16.ascii_o.txt\n",
      "2016-06-17.ascii_o.txt\n",
      "2016-06-18.ascii_o.txt\n",
      "2016-06-19.ascii_o.txt\n",
      "2016-06-20.ascii_o.txt\n",
      "2016-06-21.ascii_o.txt\n",
      "2016-06-22.ascii_o.txt\n",
      "2016-06-23.ascii_o.txt\n",
      "2016-06-24.ascii_o.txt\n",
      "2016-06-25.ascii_o.txt\n",
      "2016-06-26.ascii_o.txt\n",
      "2016-06-27.ascii_o.txt\n",
      "2016-06-28.ascii_o.txt\n",
      "2016-06-29.ascii_o.txt\n",
      "2016-06-30.ascii_o.txt\n",
      "2016-07-01.ascii_o.txt\n",
      "2016-07-02.ascii_o.txt\n",
      "2016-07-03.ascii_o.txt\n",
      "2016-07-04.ascii_o.txt\n",
      "2016-07-05.ascii_o.txt\n",
      "2016-07-06.ascii_o.txt\n",
      "2016-07-07.ascii_o.txt\n",
      "2016-07-08.ascii_o.txt\n",
      "2016-07-09.ascii_o.txt\n",
      "2016-07-10.ascii_o.txt\n",
      "2016-07-11.ascii_o.txt\n",
      "2016-07-12.ascii_o.txt\n",
      "2016-07-13.ascii_o.txt\n",
      "2016-07-14.ascii_o.txt\n",
      "2016-07-15.ascii_o.txt\n",
      "2016-07-16.ascii_o.txt\n",
      "2016-07-17.ascii_o.txt\n",
      "2016-07-18.ascii_o.txt\n",
      "2016-07-19.ascii_o.txt\n",
      "2016-07-20.ascii_o.txt\n",
      "2016-07-21.ascii_o.txt\n",
      "2016-07-22.ascii_o.txt\n",
      "2016-07-23.ascii_o.txt\n",
      "2016-07-24.ascii_o.txt\n",
      "2016-07-25.ascii_o.txt\n",
      "2016-07-26.ascii_o.txt\n",
      "2016-07-27.ascii_o.txt\n",
      "2016-07-28.ascii_o.txt\n",
      "2016-07-29.ascii_o.txt\n",
      "2016-07-30.ascii_o.txt\n",
      "2016-07-31.ascii_o.txt\n",
      "2016-08-01.ascii_o.txt\n",
      "2016-08-02.ascii_o.txt\n",
      "2016-08-03.ascii_o.txt\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/wangs/Documents/GitFiles/Respondent_Recommendation/Data/Gitter_Channels/Angular/disentangle/message_by_day/\"\n",
    "vocab = set()\n",
    "for line in open(\"C:/Users/wangs/Documents/GitFiles/Respondent_Recommendation/ISPY/disentanglement/tools/preprocessing/vocab.txt\"):\n",
    "    vocab.add(line.strip().split()[-1])\n",
    "for input_filename in os.listdir(path):\n",
    "    out = open(path+input_filename[:10] + \".tok.txt\", 'w', encoding='utf8')\n",
    "\n",
    "    users = {}\n",
    "    line_no = 0\n",
    "    print(input_filename)\n",
    "    for line in open(path+input_filename,encoding=\"ISO-8859-1\"):\n",
    "        line_no += 1\n",
    "        update_users(line.strip(), users, line_no)\n",
    "\n",
    "    line_no = 0\n",
    "    for line in open(path+input_filename,encoding=\"ISO-8859-1\"):\n",
    "        line_no += 1\n",
    "        line = line.strip()\n",
    "        if line==\"\":\n",
    "            continue\n",
    "        tokens = tokenise(line, vocab, users, line_no)\n",
    "        print(' '.join(tokens), file=out)\n",
    "\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-09-18.ascii.txt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"C:/Users/wangs/Desktop/Test/Scikitlearn/\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
