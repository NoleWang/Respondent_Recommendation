[08:05] <567f5d7716b6c7089cc043a8> @razou could you please paste a fully reproducible piece of code?
--------------------------------------------------------------------------------------------------
[08:07] <567f5d7716b6c7089cc043a8> @NoahWoehler_twitter we get quite a bit of these requests these days (which is a good thing, shows people are looking into issues). But it would help people decide if they want to spend time on it, if you give a tiny bit of intro on what it is. Also, feel free to send an email to the mailing list with that information if you want to reach more people.
--------------------------------------------------------------------------------------------------
[08:13] <613b2abc6da0373984853e44> Sure, I wasn't sure whether this falls under advertising. We are looking for open source contributors who are willing to talk to us about how security and trust are handled within their projects' communities. This is the landing page with more info: https://research.teamusec.de/2021-interviews-oss/
[08:15] <567f5d7716b6c7089cc043a8> ah interesting. I don't think we do much of that in this project, but others may think differently.
--------------------------------------------------------------------------------------------------
[08:17] <5cdeaebed73408ce4fc08df3> > @razou could you please paste a fully reproducible piece of code?  ``` from sklearn.calibration import CalibratedClassifierCV from sklearn.multioutput import ClassifierChain from lightgbm import LGBMClassifier  base_estimator = LGBMClassifier() calibrator = CalibratedClassifierCV(base_estimator=base_estimator) clf = ClassifierChain(base_estimator=calibrator, order='random', random_state=20) clf.fit(X=train_x, Y=train_y)  y_pred_proba = clf.predict_proba(validation_x) ```
[08:21] <5cdeaebed73408ce4fc08df3> The aim was to perform multi-label classifier and retourn probability scores for each (label, profile) pair. NB: y was encoded wit h MultiLabelBinarizer
--------------------------------------------------------------------------------------------------
[08:27] <541a528b163965c9bc2053de> @razou please provide a minimal reproducible piece of code, that is a piece a piece of code that we can just copy and paste in a python shell or python script and run to trigger the problem. Here the code you provide does not include the definition of `train_x` and `train_y` which is probably the core of the problem. Using minimal random data from np.random.normal(size=(n_samples, n_features) or np.random.randint(low=0, high=10, size=n_samples)
[08:29] <541a528b163965c9bc2053de> and also add the necessary code to preprocess train_y and the code that computes the cross validation with the score you want.
[08:30] <541a528b163965c9bc2053de> Minimal stands for removing anything that is not necessary. For instance are CalibratedClassifierCV ClassifierChain necessary to reproduce the problem? Or can you just reproduce the problem by cross validating the base estatimtor directly? If so simplify the code snippet.
[08:31] <541a528b163965c9bc2053de> https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports
--------------------------------------------------------------------------------------------------
[09:04] <5cdeaebed73408ce4fc08df3> Thanks you guys for your answers  1. libraries ``` pip install lightgbm==3.2.1 pip install scikit-learn==0.22.2.post1 ```  2. Code snipet  ``` from sklearn.datasets import make_multilabel_classification from sklearn.model_selection import train_test_split from sklearn.preprocessing import MultiLabelBinarizer from sklearn.calibration import CalibratedClassifierCV from sklearn.multioutput import ClassifierChain  from lightgbm import LGBMClassifier  X, y = make_multilabel_classification(n_samples=2000, n_classes=10, n_labels=2, allow_unlabeled=True) train_x, validation_x, train_y, validation_y = train_test_split(X, y, test_size=0.25)  mlb = MultiLabelBinarizer() train_y_encoded = mlb.fit_transform(train_y) validation_y_encoded = mlb.transform(validation_y)  base_estimator = LGBMClassifier() calibrator = CalibratedClassifierCV(base_estimator=base_estimator) clf = ClassifierChain(base_estimator=calibrator, order='random', random_state=20) clf.fit(X=train_x, Y=train_y_encoded)  y_pred_proba = clf.predict_proba(validation_x) print(y_pred_proba[:3]) ```
--------------------------------------------------------------------------------------------------
[14:09] <541a528b163965c9bc2053de> I don't understand why you are using `MultiLabelBinarizer` here because `y` is already a binary representation of the target variable since in this snippet you used `make_multilabel_classification`. Please provide a snippet that causes the same error message as the problem you observe with cross-validation cohen kappa score.  Anyways by reading the scikit-learn documentation https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa I don't see how this would work for binary encoded multilabeled data.
[14:10] <541a528b163965c9bc2053de> The scikit-learn error message is actually quite explicit:  ```python >>> from sklearn.metrics import cohen_kappa_score >>> cohen_kappa_score([[0, 1], [1, 1]], [[0, 0], [1, 0]]) Traceback (most recent call last):   File "<ipython-input-19-2a87559cbf88>", line 1, in <module>     cohen_kappa_score([[0, 1], [1, 1]], [[0, 0], [1, 0]])   File "/Users/ogrisel/code/scikit-learn/sklearn/metrics/_classification.py", line 639, in cohen_kappa_score     confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)   File "/Users/ogrisel/code/scikit-learn/sklearn/metrics/_classification.py", line 304, in confusion_matrix     raise ValueError("%s is not supported" % y_type) ValueError: multilabel-indicator is not supported ```
--------------------------------------------------------------------------------------------------
