[04:47] <59b56a87d73408ce4f751f7b> hi i am new here can anyone guide me..!
--------------------------------------------------------------------------------------------------
[15:23] <58db7784d73408ce4f5484eb> Hi, i am quite new to machine learning and am thinking about a good approach for my ML analysis. I have several tables with data in a DB. Some of this data are name, adresses and email and so on and some are 'other' data, mostly numbers and configuration data. Both kind of data can be in the same table. What I want to analyse now is, has a column address like data or number/config data. As I undersatand it with most ML examples you have a number of test data in tables and each table row is a data point. When I want to predict something, I take data that has the data structure of one table row and see that I predict the wanted data based on the test data training. In my case I have the table + column metadata (column name, length, etc) plus the actual content of the table column. My first idea is now to create a new table with (table name, colunm name, length, ctable column content as a string ,lets say) and then copy the column content column by column into this structture. This would give me individual rows to analyse. It just feels a bit clonky as the meta data (table/comuln name, ..) would be naturally the same for a whole column and only the column content differs and so there is not much variation in this table. Is there a more clever way of prepading the data ?
--------------------------------------------------------------------------------------------------
