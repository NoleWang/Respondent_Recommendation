[06:23] <5910079ed73408ce4f5dc467> I have a doubt  in my code ``` from sklearn.tree import DecisionTreeClassifier from sklearn.datasets import load_breast_cancer from sklearn.cross_validation import train_test_split cancer = load_breast_cancer() X_train, X_test, y_train, y_test = train_test_split( cancer.data, cancer.target, stratify=cancer.target, random_state=42) tree = DecisionTreeClassifier(random_state=0) tree.fit(X_train, y_train) print(tree.score(X_train, y_train)) print(tree.score(X_test, y_test)) ``` The first random_state is in test_train_split is used for  getting the same result next time when we are gonna run the code. But I don't get why is there a random_state in DecisionTreeClassifier line ? And how does that work ? @amueller  ..
--------------------------------------------------------------------------------------------------
[08:24] <55d21ee30fc9f982beadabb8> @ashiskriz There is some randomness in the decision tree. For instance a subset of feature can be taken at each note with a randomization. Having this in mind the random_state allows to have this part deterministic as well
--------------------------------------------------------------------------------------------------
[11:57] <5910079ed73408ce4f5dc467> @glemaitre  - Thank you very much . Thats helpful  And I  want to add that the book I was following  written by @amueller  had a sentence saying "We fix the random_state in the tree, which is used for tiebreaking internally"  . I was wondering about the mechanism of tie breaking thing . How is the tie breaking thing happens internally?
--------------------------------------------------------------------------------------------------
[13:39] <56ed9a8885d51f252ab9b33f>
--------------------------------------------------------------------------------------------------
[14:21] <58e46e92d73408ce4f562b3b> @punitaojha you have posted the exact same message in https://gitter.im/Machine-Learning-Group/chat too. That's I believe a spammy behavior...
--------------------------------------------------------------------------------------------------
[14:41] <590c8ffdd73408ce4f5d352d> Hey Guys, I am planning to build a ML and probabilistic modelling libray in Python. Would like to know if anybody is interested to start the project with me?
--------------------------------------------------------------------------------------------------
[22:00] <55d21ee30fc9f982beadabb8> @ashiskriz at each node, a random set of feature will be used to find a best split. If there two features leading to a split with the same impurity improvement, you get a tie. Therefore, the first feature which was randomly picked up will be selected.
[22:01] <55d21ee30fc9f982beadabb8> If you try multiple times, you will select one feature or the other which will lead to different trees architectures. Therefore, random_state allows you to pick up always the same feature in case of a tie.
--------------------------------------------------------------------------------------------------
[23:35] <55901c1b15522ed4b3e2f949> @anisnouri how will it be different from current existing libraries?
--------------------------------------------------------------------------------------------------
[23:41] <590c8ffdd73408ce4f5d352d> @jmschrei  would be much focused on quantifying uncertainty.
--------------------------------------------------------------------------------------------------
[23:42] <55901c1b15522ed4b3e2f949> Have you looked into PyMC3 and PyStan, and the libraries built on top of those?
[23:44] <590c8ffdd73408ce4f5d352d> @jmschrei  yeah. I find them a bit compound and complex to use. Would be nice to have something with the same APIs design as sklearn
--------------------------------------------------------------------------------------------------
[23:55] <55901c1b15522ed4b3e2f949> You should probably reach out in those communities then, if you'll be building on top of it. I think that learning Bayesian models like that is much more niche than classical machine learning.
--------------------------------------------------------------------------------------------------
