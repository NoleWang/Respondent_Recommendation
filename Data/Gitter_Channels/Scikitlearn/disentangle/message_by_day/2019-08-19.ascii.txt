[14:52] <5810cd4cd73408ce4f3101ce> omg omg omg, For L2 loss, if i replace `import numpy as np` with `import cupy as np`, i get another 10x Speed up for 1 split, but i would lost the edge when i have too many depth.. i need to refactor my code... 
[14:54] <567f5d7716b6c7089cc043a8> +1
[14:54] <5810cd4cd73408ce4f3101ce> but i really like the fact that, switching to GPU is so trivial ... 
[20:37] <5924c519d73408ce4f61c9c7> Have a question maybe someone can answer. Trying to use a simple model on a set of data. About a couple thousand rows and only a dozen features, most are binary. I'm training on Logistic Regression, and found my model overfits. So when I try to tune my hyperparameters, my accuracy remains entirely unchanged. Has anyone seen this before or know why this is happening?
