[12:27] <5decf929d73408ce4fd36f72> I made some machine learning models using Python scikitlearn library and I found some strange situation for me regarding real importance of some variables (features) to ML model. I found that variable which has smaller Pearson coefficient has higher importance on ML model (when exclude variable from model using backward elimination principle) than variables which has higher Pearson.  Below I send the real results of three models where first model includes all three variables and another two models excludes some variables (- means variable is excludes). Iuse Random Forest method.  Model Name     MAE  ModelV1V2V3 0.92 ModelV1V2- 3.86 ModelV1-V3 2.96  PearsonV1=0.99, PearsonV1=0.82, PearsonV3=0.02  When I exclude variables which has no importance based on Pearson (0.02) I got model with better performance comparing to model which includes another variable (V2) whic has far higher Pearson (0.82). Please, help me to explain this situation.  Please, answer me as soon as possible.  Thank You in advance.  Dusko Tovilovic
