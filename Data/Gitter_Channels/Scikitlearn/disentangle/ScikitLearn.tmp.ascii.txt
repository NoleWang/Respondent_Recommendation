[2014-09-18T03:36:09.349Z] <541a528b163965c9bc2053de> Hi all!
[2014-10-23T19:59:18.153Z] <544906e2db8155e6700cdd16> I don't know if this is the right place but I need some advice on how to train a classifier using a data set with multiple feature types: text, integers, floats, dates
[2014-10-23T20:00:01.849Z] <544906e2db8155e6700cdd16> any idea?
[2014-10-23T20:01:49.864Z] <544906e2db8155e6700cdd16> My first approach was to convert each feature to binary, example: feature 1 -> "the word w_i is in column j?" , feature 2 -> "the value in column j is greater than 10?", feature 3 -> "the month in the date of column j was abril?", etc.
[2014-10-23T20:04:14.788Z] <544906e2db8155e6700cdd16> by the way, Oliver Grisel: Hi! :D
[2015-01-23T15:38:51.846Z] <53a5cf04a9176b500d1ced1a> This message is without content. I wonder if anyone hangs out here.
[2015-01-23T16:49:57.683Z] <541a528b163965c9bc2053de> @mac2bua, I just saw your message. It's probably better to ask specific question with running code snippets on toy example data on stackoverflow. You might be interested in having a look at sklearn_pandas for feature extraction from heterogeneously typed columns. FeaturesUnion might also be helpful.
[2015-01-23T17:48:29.169Z] <544906e2db8155e6700cdd16> @ogrisel Thanks a lot for the advice! Fortunately I found this very useful blog: http://bit.ly/1mPEEhH and I decided to start using feature union and pipelines. The result was very good! :smile:  I know that you are a member of the core team of scikit learn so I'd like to thank you, sklearn is so awesome!.  Just one more question: Is there any easy way to get the name of the features?  So often I needed to print out the names in order to understand the relationship between them and the different classes. I wrote some code that gather the information of the different vocabularies in the case of the textual or categorical features and the name of the column in the case of the numerical ones.  Sorry for my bad english! 
[2015-01-23T17:56:27.138Z] <541a528b163965c9bc2053de> No, not in general unfortunately: most of the time the data will get internally converted to numpy arrays for efficiency and code simplicity reasons  and even if the column were named in the original representation (e.g. a DataFrame) that information is lost along the way.
[2015-02-06T11:13:32.546Z] <54d4a1d6db8155e6700f853b> hey
[2015-02-06T11:13:54.003Z] <541a528b163965c9bc2053de> hi @amueller 
[2015-02-06T11:14:02.400Z] <54d4a1d6db8155e6700f853b> Thanks for starting on the reviews :)
[2015-02-06T11:14:20.813Z] <54a99c64db8155e6700e5ac4> Hi
[2015-02-06T11:14:24.318Z] <541a528b163965c9bc2053de> I want to do the `check_array` empty data first
[2015-02-06T11:14:30.335Z] <54d4a1d6db8155e6700f853b> I'm with family this week and so not super active, but I hope we can work towards the release next week :)
[2015-02-06T11:14:39.978Z] <54d4a1d6db8155e6700f853b> sure. There is another check_array pr that might be conflicting
[2015-02-06T11:14:49.844Z] <54d4a1d6db8155e6700f853b> and that I think is very important
[2015-02-06T11:14:52.681Z] <54d4a1d6db8155e6700f853b> the dtype=object one
[2015-02-06T11:15:08.779Z] <541a528b163965c9bc2053de> yeah, I got side-tracked to work on clusterlib the past 2 weeks, I hope I will rebalance effort to sklearn next week as well
[2015-02-06T11:15:45.470Z] <541a528b163965c9bc2053de> what is the issue number of dtype=object?
[2015-02-06T11:15:57.606Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4057
[2015-02-06T11:16:03.367Z] <541a528b163965c9bc2053de> tks
[2015-02-06T11:18:04.123Z] <54d4a1d6db8155e6700f853b> Most of the bug-fixes are isolated to one estimator. So I think they are important for the release, but shouldn't interact with other issues so much. The ones that are more API-ish are the dtype=object one (https://github.com/scikit-learn/scikit-learn/pull/4057), the clustering / pipeline one https://github.com/scikit-learn/scikit-learn/pull/4064 and the input validation one https://github.com/scikit-learn/scikit-learn/pull/4136
[2015-02-06T11:18:34.008Z] <541a528b163965c9bc2053de> ok
[2015-02-06T11:18:53.963Z] <54d4a1d6db8155e6700f853b> the last two interact somewhat. not sure how clear that is from the PR but the main thing in the input validation is that it extends common tests to estimators that don't inherit from clustering, classification, regression or transformation mixins
[2015-02-06T11:20:22.657Z] <54d4a1d6db8155e6700f853b> I'll try but I'm not sure I'll finish writing the pipeline integration tests today
[2015-02-06T11:20:55.722Z] <54d4a1d6db8155e6700f853b> oh and going toward the release, we need to fix the bugs and regressions in isotonic regression :-/ I don't think a fix exists yet
[2015-02-06T11:21:38.729Z] <541a528b163965c9bc2053de> yeah
[2015-02-06T11:21:58.783Z] <541a528b163965c9bc2053de> the slinear side effects?
[2015-02-06T11:22:10.981Z] <541a528b163965c9bc2053de> I saw it broke the calibration PR
[2015-02-06T11:22:55.449Z] <541a528b163965c9bc2053de> too many open tabs, my firefox is so slow at times...
[2015-02-06T11:23:40.941Z] <54d4a1d6db8155e6700f853b> it did? I didn't see that. haha I know the open tabs issue. Well the ``slinear`` broke some cases of ``fit`` and ``fit_transform`` not doing the same thing. Maybe it broke other things, too.
[2015-02-06T11:24:32.759Z] <54d4a1d6db8155e6700f853b> Bugs that are not regressions are that fit and fit_transform were not consistent before in the case of ties, and that having sample_weight=0 in multiple places can lead to infinite loops in the isotonic regression code
[2015-02-06T11:25:22.479Z] <541a528b163965c9bc2053de> that's bad
[2015-02-06T11:26:17.304Z] <54d4a1d6db8155e6700f853b> I agree. I proposed a fix in one of the issues. Maybe just remove the implementation of ``fit_transform``, that is use the naive fit.transform, and mask out sample_weight=0. That should get rid of the worst bugs.
[2015-02-06T11:26:27.116Z] <54d4a1d6db8155e6700f853b> but doesn't solve all issues with tie-breaking, I think.
[2015-02-06T11:27:36.117Z] <54d4a1d6db8155e6700f853b> some discussion here: https://github.com/scikit-learn/scikit-learn/issues/2507 and in the issues linked at the bottom
[2015-02-06T11:29:19.006Z] <54d4a1d6db8155e6700f853b> So that was a list of the "hard" issues / PRs. If you want I can also give you a list of the simple bug fixes lol
[2015-02-06T11:30:08.441Z] <54d4a1d6db8155e6700f853b> what are you working on with clusterlib btw?
[2015-02-06T11:35:19.913Z] <541a528b163965c9bc2053de> I want to implement the `concurrent.futures` API. That includes porting cloudpickle.py to Python 3 or implemeting something similar with dill.
[2015-02-06T11:36:41.289Z] <541a528b163965c9bc2053de> The goal is to be able to use SGE / SLURM clusters easily, without having to write bash or boilerplate python scripts.
[2015-02-06T11:36:54.739Z] <541a528b163965c9bc2053de> There is also cloudpi.pe to watch in the same space.
[2015-02-06T11:37:52.937Z] <541a528b163965c9bc2053de> going grab some lunch, see you later
[2015-02-06T12:05:50.579Z] <54d4a1d6db8155e6700f853b> Args. I am slightly confused by the current API requirements in pipeline. If ``fit_transform`` accepts ``y=None`` we don't require ``transform`` to accept a ``y=None``. That is somewhat inconsistent and weird, I think...
[2015-02-06T12:07:51.061Z] <54d4a1d6db8155e6700f853b> Huh ok transform is never passed ``y`` at all... never mind...
[2015-02-06T13:32:16.059Z] <541a528b163965c9bc2053de> @amueller I am reviewing #4057
[2015-02-06T13:32:53.569Z] <541a528b163965c9bc2053de> In another PR I suggested in a comment to add support for the `dtype=[np.float64, np.float32]` idiom.
[2015-02-06T13:33:12.510Z] <541a528b163965c9bc2053de> but I don't remember which PR ;)
[2015-02-06T13:34:30.582Z] <541a528b163965c9bc2053de> I think the dtype='numeric' is a fine, loose default but I would like to check with the other PR if we also need the `dtype=<list of accepted dtypes idiom>` for specific cases as well.
[2015-02-06T13:34:41.281Z] <541a528b163965c9bc2053de> do you remember which PR it was?
[2015-02-06T13:41:15.890Z] <541a528b163965c9bc2053de> Ok found it: it was collapsed in: https://github.com/scikit-learn/scikit-learn/pull/4136#discussion_r24176562
[2015-02-06T14:04:48.825Z] <54d4a1d6db8155e6700f853b> sorry didn't watch the chat
[2015-02-06T14:05:14.548Z] <54d4a1d6db8155e6700f853b> yeah so a dtype list for check_array would be nice, and then we could get rid of ``as_float_array``
[2015-02-06T14:06:54.273Z] <541a528b163965c9bc2053de> I agree
[2015-02-06T14:08:46.822Z] <541a528b163965c9bc2053de> "unfriend all multi-output estimators on facebook."
[2015-02-06T14:08:47.280Z] <541a528b163965c9bc2053de> :)
[2015-02-06T14:10:50.446Z] <54d4a1d6db8155e6700f853b> There was only slight frustration on my part. I'm not sure if the ``y_numeric`` is a good workaround, because it somehow stipulates that by default "y" are arbitrary objects aka classification labels
[2015-02-06T14:13:09.230Z] <54d4a1d6db8155e6700f853b> btw, there are not really that many tests on ``y``.  Many estimators just used ``np.asarray(y)``...
[2015-02-06T14:13:25.910Z] <541a528b163965c9bc2053de> ...
[2015-02-06T14:13:26.045Z] <54d4a1d6db8155e6700f853b> we should probably test for finite targets for regression
[2015-02-06T14:13:50.829Z] <541a528b163965c9bc2053de> I don't understand what you mean by finite targets
[2015-02-06T14:14:57.485Z] <541a528b163965c9bc2053de> integers & categorical labels?
[2015-02-07T07:24:47.871Z] <54d4a1d6db8155e6700f853b> I meant for regression, where the target is a float
[2015-02-08T10:15:08.281Z] <5474d9eadb8155e6700d8178> Hey all! :) @ogrisel You might want to set up gitter to get live activity feeds on the right! Choose github and travis under integrations ( under settings )
[2015-02-08T20:57:01.568Z] <541a528b163965c9bc2053de> @ragv done! thanks for the tip
[2015-02-08T22:33:16.656Z] <541a528b163965c9bc2053de> It seems that I broke travis but I cannot reach the report page. Running the tests locally.
[2015-02-08T22:50:25.005Z] <541a528b163965c9bc2053de> Ok fixing the broken tests ATM
[2015-02-09T18:01:03.131Z] <5474d9eadb8155e6700d8178> Scikit learn has crossed 5000 stars on github :beer:
[2015-02-11T18:21:36.596Z] <54d4a1d6db8155e6700f853b> hey hey
[2015-02-11T18:21:52.736Z] <54d4a1d6db8155e6700f853b> ogrisel, are you around?
[2015-02-12T09:45:11.939Z] <541a528b163965c9bc2053de> Hi @amueller sorry I was offline for the past couple of days as I had to attend local events. Today I will be working on clusterlib with a colleague. tomorrow I will be available to review PRs on sklearn
[2015-02-12T13:36:36.101Z] <54d4a1d6db8155e6700f853b> Alright. Next week I'll be at strata, though, and won't have much time. We should settle on a timeline for release.
[2015-02-12T13:50:48.672Z] <541a528b163965c9bc2053de> What about setting the objective of cutting the first beta on Friday Feb 27.
[2015-02-12T13:51:09.144Z] <541a528b163965c9bc2053de> Then one beta every two weeks.
[2015-02-12T13:51:28.860Z] <541a528b163965c9bc2053de> And release end of March?
[2015-02-12T15:09:17.630Z] <54d4a1d6db8155e6700f853b> Sounds good :)
[2015-02-15T08:40:18.950Z] <5474d9eadb8155e6700d8178> @ogrisel Would you be interested in setting up http://landscape.io and landscape bot? #3888 
[2015-02-15T08:46:05.223Z] <5474d9eadb8155e6700d8178> Refer [this](https://landscape.io/github/ragv/scikit-learn) for live preview of our repo and [this](https://github.com/hugovk/word-tools/pull/7#issuecomment-67533284) for an example comment by the bot.
[2015-02-15T09:25:50.955Z] <5474d9eadb8155e6700d8178> A general suggestion... I feel it would be more helpful to debug test results if we replaced docstrings for tests by comment...  Output when a docstring is present for a test ``` Tests all estimators which support partial_fit ... ok Tests all estimators which support partial_fit ... ok Tests all estimators which support partial_fit ... ok ``` Output when no docstring is present for a test ``` test_common.test_partial_fit('Perceptron', <class 'sklearn.linear_model.perceptron.Perceptron'>) ... ok test_common.test_partial_fit('Perceptron', <class 'sklearn.linear_model.perceptron.Perceptron'>) ... ok test_common.test_partial_fit('Perceptron', <class 'sklearn.linear_model.perceptron.Perceptron'>) ... ok test_common.test_partial_fit('SGDClassifier', <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>) ... ok ```
[2015-02-15T11:47:27.124Z] <5474d9eadb8155e6700d8178> Trying out gitter from irc
[2015-02-15T12:02:23.260Z] <54e07def15522ed4b3dc0864> @ragv thanks for the invite
[2015-02-15T15:56:48.903Z] <541a528b163965c9bc2053de> I agree about the test docstring issue.
[2015-02-15T16:32:19.447Z] <5474d9eadb8155e6700d8178> @ogrisel would it be worth to have a pr for that? Or should I just create an issue and refer that when any related code is changed?
[2015-02-15T16:33:21.124Z] <541a528b163965c9bc2053de> Explaining the pbm in an issue is a good idea. Then a bunch of small PRs related to that issue if people have no objection.
[2015-02-15T16:33:39.526Z] <5474d9eadb8155e6700d8178> Ok! thanks!
[2015-02-15T16:35:02.672Z] <541a528b163965c9bc2053de> Alternatively we could use this on travis: https://pypi.python.org/pypi/nose-ignore-docstring
[2015-02-15T16:36:15.527Z] <5474d9eadb8155e6700d8178> Ah! thanks ;) that was helpful! Sorry should have googled a bit before asking...
[2015-02-15T17:04:59.423Z] <54d4a1d6db8155e6700f853b> and in the makefile, I'd say
[2015-02-15T17:05:07.381Z] <54d4a1d6db8155e6700f853b> don't we even have a nose config file in the repo?
[2015-02-15T17:05:25.742Z] <5474d9eadb8155e6700d8178> Im about to send a PR for that ;)
[2015-02-15T17:05:34.622Z] <5474d9eadb8155e6700d8178> and yea `setup.cfg`
[2015-02-15T17:05:37.836Z] <54d4a1d6db8155e6700f853b> :) oh we do need to install a package, I thought it was a build-in option
[2015-02-15T17:06:07.099Z] <5474d9eadb8155e6700d8178> yea It will go in `continuous-integration/install.sh` after `pip install nose`
[2015-02-15T18:15:05.648Z] <5474d9eadb8155e6700d8178> @amueller How do you feel about https://github.com/finnp/gitter-irc-bot ?
[2015-02-15T18:15:23.149Z] <5474d9eadb8155e6700d8178> It look really very simple and could cleanly sync irc and gitter...
[2015-02-15T18:20:47.736Z] <5474d9eadb8155e6700d8178> I'll take care of the setup...
[2015-02-18T00:53:13.109Z] <54d4a1d6db8155e6700f853b> sounds ok but I don't have too many cycles to look into it. you can do it and see if anyone complains about noise (which is unlikely)
[2015-02-18T14:28:09.716Z] <5474d9eadb8155e6700d8178> okay! thanks! :)
[2015-02-20T14:43:58.834Z] <541a528b163965c9bc2053de> +1
[2015-02-23T00:00:50.956Z] <54d4a1d6db8155e6700f853b> hey hey. I'm kinda back, though somehow in Dallas.
[2015-02-23T00:01:24.657Z] <54d4a1d6db8155e6700f853b> And I only have ~400 unread github notifications
[2015-02-23T08:05:30.583Z] <541a528b163965c9bc2053de> ...
[2015-02-23T08:05:50.413Z] <541a528b163965c9bc2053de> @amueller how did you enjoy strata?
[2015-02-23T15:43:23.098Z] <54d4a1d6db8155e6700f853b> It was pretty awesome :) met a lot of interesting people. Are you bug-crunching this week? I have to do some organisational stuff for GSOC but the rest of the week should be free for release things.
[2015-02-23T18:02:48.505Z] <541a528b163965c9bc2053de> I was having a look at the FDR PR and trying to understand why the actual FDR is always lower than alpha. I am working on something else tonight. Will resume tomorrow. I think I have an idea.
[2015-02-23T20:40:55.057Z] <5474d9eadb8155e6700d8178> > And I only have ~400 unread github notifications  haha :p  
[2015-02-24T13:23:14.368Z] <5474d9eadb8155e6700d8178> How do I make sure the cython sources are compiled when I rebuild for testing? ( related to #4288 ) ?
[2015-02-24T14:06:38.259Z] <541a528b163965c9bc2053de> cython path/to/file.pyx
[2015-02-24T14:07:34.901Z] <5474d9eadb8155e6700d8178> Thanks! :)
[2015-02-24T22:25:01.391Z] <541a528b163965c9bc2053de> @amueller here I mean
[2015-02-24T22:28:55.955Z] <54d4a1d6db8155e6700f853b> so much sense
[2015-02-24T22:29:05.659Z] <54d4a1d6db8155e6700f853b> sorry about that
[2015-02-24T22:29:18.063Z] <54d4a1d6db8155e6700f853b> btw what time is it in Paris? Are you in Paris?
[2015-02-24T22:30:48.436Z] <541a528b163965c9bc2053de> yes I am in paris
[2015-02-24T22:30:55.698Z] <541a528b163965c9bc2053de> it's almost midnight
[2015-02-24T22:31:36.118Z] <541a528b163965c9bc2053de> I am rebasing #3945 then going to bed
[2015-02-24T22:34:21.200Z] <54d4a1d6db8155e6700f853b> sweet, thanks. tomorrow I will be in the office earlier. Thanks for working late :)
[2015-02-24T22:35:06.784Z] <54d4a1d6db8155e6700f853b> For some reason I tagged the old SVC.sparse_decision_function PR with 0.16, but not my new one. That doesn't make sense. Do you think I should tag my PR or untag the old?
[2015-02-24T22:41:04.088Z] <541a528b163965c9bc2053de> Actually I was primarily working on dl-machine this evening :)
[2015-02-24T22:41:35.158Z] <541a528b163965c9bc2053de> > For some reason I tagged the old SVC.sparse_decision_function PR with 0.16, but not my new one. That doesn't make sense. Do you think I should tag my PR or untag the old?  I am not sure which is which
[2015-02-24T22:42:18.685Z] <54d4a1d6db8155e6700f853b> dl-machine?
[2015-02-24T22:42:47.578Z] <54d4a1d6db8155e6700f853b> rephrasing my question: should the sparse decision function be tagged for 0.16 or not (i.e. is it a priority to go into the release)
[2015-02-24T22:44:31.351Z] <54d4a1d6db8155e6700f853b> ah, I see. Are you working with torch or theano primarily?
[2015-02-24T22:45:27.626Z] <541a528b163965c9bc2053de> https://github.com/deeplearningparis/dl-machine
[2015-02-24T22:46:18.534Z] <541a528b163965c9bc2053de> setting up tutorial material for a workshop on theano, but adding support for torch was easy so I added it.
[2015-02-24T22:46:45.930Z] <541a528b163965c9bc2053de> +1 for including the sparse decision function fix
[2015-02-24T22:46:48.370Z] <54d4a1d6db8155e6700f853b> cool
[2015-02-24T22:46:49.241Z] <54d4a1d6db8155e6700f853b> ok
[2015-02-24T22:47:13.816Z] <54d4a1d6db8155e6700f853b> that means 23 PRs left for the release lol
[2015-02-24T22:47:23.752Z] <541a528b163965c9bc2053de> :)
[2015-02-24T22:48:14.698Z] <54d4a1d6db8155e6700f853b> have a good night. Hope we make some more progress on the PRs this week
[2015-02-24T22:48:25.018Z] <541a528b163965c9bc2053de> Even if we don't fix them all prior to friday (the first beta) it's fine. As long as we only include fixes in the 0.16.X branch once the beta is cut.
[2015-02-24T22:48:32.548Z] <541a528b163965c9bc2053de> thanks
[2015-02-24T22:50:55.202Z] <541a528b163965c9bc2053de> good night, see you tomorrow!
[2015-02-24T23:00:24.528Z] <54d4a1d6db8155e6700f853b> good night :)
[2015-02-25T18:40:24.939Z] <54d4a1d6db8155e6700f853b> anything in particular that you would like me to review?
[2015-02-25T18:44:04.326Z] <54d4a1d6db8155e6700f853b> Did you have a look at this one yet: https://github.com/scikit-learn/scikit-learn/pull/4192 I haven't really followed what is happening with the pos_label etc in the metrics
[2015-02-25T18:46:43.214Z] <5474d9eadb8155e6700d8178> Hey :) sorry to interrupt you... do you feel we could do the data indep. cv part first and later do the renaming?
[2015-02-25T18:51:09.705Z] <54d4a1d6db8155e6700f853b> There are two roads we could go down: either doing both together, but using the fact to have a deprecation path for it. That would mean copying a lot of code for a while. OR doing them separately. If we do them separately, I would do the CV objects first. Also, I wouldn't do either for the 0.16 release, I think.
[2015-02-25T18:52:58.948Z] <54d4a1d6db8155e6700f853b> Actually, I think the code duplication thing is not necessary, so we should just focus on the cv objects
[2015-02-25T18:54:06.462Z] <54d4a1d6db8155e6700f853b> @ogrisel green button on https://github.com/scikit-learn/scikit-learn/pull/4249 (sign flip) ?
[2015-02-25T18:59:09.020Z] <5474d9eadb8155e6700d8178> Okay! so I'll salvage #4294 to do the CV related fixes alone?
[2015-02-25T18:59:35.719Z] <54d4a1d6db8155e6700f853b> yeah that sounds like a good idea
[2015-02-25T19:02:58.227Z] <5474d9eadb8155e6700d8178> thanks! :)
[2015-02-25T19:04:36.054Z] <5474d9eadb8155e6700d8178> Just one more minor thing... what is the expected range of scores ( w.r.t #4295 ) ( could it by any chance be >= 40? )
[2015-02-25T19:07:31.829Z] <54d4a1d6db8155e6700f853b> the sigmoid should be between 0 and 1 as you plotted, and the votes shouldn't be larger than the number of classes, right?
[2015-02-25T19:09:30.102Z] <5474d9eadb8155e6700d8178> if the values for `sum_of_confidences` ( previously `scores` ) exceed 34 we get 1 which is not desirable... i.e `expit(34)` is 1... with 0.5 it extends upto 73...
[2015-02-25T19:09:46.751Z] <5474d9eadb8155e6700d8178> or am I too paranoid? perhaps `scores` do not extend  upto 34?
[2015-02-25T19:11:53.829Z] <54d4a1d6db8155e6700f853b> sorry, I don't follow. scores can be arbitrary high. You say that it actually reaches 1? that seems a bit odd
[2015-02-25T19:13:16.593Z] <54d4a1d6db8155e6700f853b> I see... maybe then we need to do 0.9 * expit(scores) ? which would be just another magic value....
[2015-02-25T19:13:54.877Z] <5474d9eadb8155e6700d8178> sorry its at 37.... and yea in my system `expit(37) == 0`... would you mind confirming the same pl?
[2015-02-25T19:14:40.427Z] <54d4a1d6db8155e6700f853b> you mean == 1
[2015-02-25T19:14:49.702Z] <54d4a1d6db8155e6700f853b> In [9]: expit(37) Out[9]: array(0.9999999999999999)  In [10]: expit(38) Out[10]: array(1.0) 
[2015-02-25T19:15:01.143Z] <54d4a1d6db8155e6700f853b> I commented on the issue and pinged @mblondel 
[2015-02-25T19:15:07.598Z] <5474d9eadb8155e6700d8178> yes :P sorry again...
[2015-02-25T19:15:38.936Z] <54d4a1d6db8155e6700f853b> np. you are right, that is an issue
[2015-02-25T19:17:01.286Z] <5474d9eadb8155e6700d8178> Perhaps we could scale to `[0, 1]` before mapping it using sigmoid? ( it would be a tad slower )
[2015-02-25T19:19:26.148Z] <54d4a1d6db8155e6700f853b> that is also weird ;)
[2015-02-25T19:25:58.226Z] <5474d9eadb8155e6700d8178> haha yea ;)
[2015-02-25T19:53:40.541Z] <54d4a1d6db8155e6700f853b> took me only 3 days to catch up with 7 days of sklearn notifications....
[2015-02-25T19:53:49.511Z] <54d4a1d6db8155e6700f853b> now for some actual work
[2015-02-25T20:02:06.026Z] <5474d9eadb8155e6700d8178> That was fast ;)  What issue are you currently working on? :)
[2015-02-25T20:06:57.567Z] <54d4a1d6db8155e6700f853b> I have to do some pystruct stuff now because I commited to some research projects. Other than that, I'm working on getting as many PRs as possible that are tagged with 0.16 in, and writing as many bug-fixes for 0.16 tagged issues as possible
[2015-02-25T20:07:01.938Z] <54d4a1d6db8155e6700f853b> mostly reviewing currently
[2015-02-25T20:30:52.679Z] <54d4a1d6db8155e6700f853b> @ogrisel this one should also be simple: https://github.com/scikit-learn/scikit-learn/pull/4082
[2015-02-26T15:12:37.998Z] <54d4a1d6db8155e6700f853b> morning
[2015-02-26T15:13:19.061Z] <541a528b163965c9bc2053de> morning :)
[2015-02-26T15:13:27.954Z] <54d4a1d6db8155e6700f853b> or afternoon ;)_
[2015-02-26T15:18:51.038Z] <54d4a1d6db8155e6700f853b> are you working on the isotonic stuff right now? Anything I should review?
[2015-02-26T15:19:42.518Z] <54d4a1d6db8155e6700f853b> ah, you are doing https://github.com/scikit-learn/scikit-learn/pull/4082, cool :)
[2015-02-26T15:26:52.015Z] <541a528b163965c9bc2053de> yes #4082, I am resolving conflicts (both syntactic and logic), almost done. running the full test suite
[2015-02-26T15:27:22.527Z] <54d4a1d6db8155e6700f853b> cool
[2015-02-26T15:27:27.569Z] <541a528b163965c9bc2053de> previously I was trying to understand what's wrong with the isotonic transform (interp1d with kind='slinear')
[2015-02-26T15:27:53.803Z] <541a528b163965c9bc2053de> the bug you found (the infinite loop with zero sample weight) is something entirely different
[2015-02-26T15:27:59.131Z] <54d4a1d6db8155e6700f853b> yeah maybe that was a bad idea. but it was already broken before
[2015-02-26T15:28:19.862Z] <541a528b163965c9bc2053de> both are important bugs we should make a priority to fix IMHO.
[2015-02-26T15:28:39.770Z] <54d4a1d6db8155e6700f853b> I know the bugs are unrelated, but I thought the fix might be. I was thinking about removing the implementation of partial fit, which would make it easier to fix both bugs, I think
[2015-02-26T15:28:54.577Z] <541a528b163965c9bc2053de> I don't understand the details of any of the 2 bugs at the moment, feel free to investigate on your side
[2015-02-26T15:29:40.008Z] <541a528b163965c9bc2053de> Are you sure this is related to partial_fit?
[2015-02-26T15:30:00.394Z] <54d4a1d6db8155e6700f853b> args I meant fit_transform
[2015-02-26T15:30:11.494Z] <54d4a1d6db8155e6700f853b> err fit_predict?
[2015-02-26T15:31:24.692Z] <54d4a1d6db8155e6700f853b> I kind of understand the infinite loop. there is a while x != y and if both are NAN then it never finishes. The easiest way to solve the problem is to remove data points with zero sample weight. But if you do that, you can not implement fit_predict the way it currently is.
[2015-02-26T15:31:42.796Z] <54d4a1d6db8155e6700f853b> The other way would be to take care of zero sample weight in the Cython code, but I don't understand that part 100%
[2015-02-26T15:32:41.173Z] <54d4a1d6db8155e6700f853b> fixed https://github.com/scikit-learn/scikit-learn/pull/4189
[2015-02-26T15:35:06.621Z] <541a528b163965c9bc2053de> ok, but this seem completely independent from the bug found in transform by mjbommard in #4185
[2015-02-26T15:36:53.520Z] <54d4a1d6db8155e6700f853b> when I last checked, I had the impression that some of the inconsistencies come from the way that fit_transform is implemented. If it is indeed only an error in transform, then they are unrelated.
[2015-02-26T15:37:28.216Z] <54d4a1d6db8155e6700f853b> I'll double check.
[2015-02-26T15:39:11.505Z] <54d4a1d6db8155e6700f853b> it does look like fit_transform works correctly, never mind then
[2015-02-26T15:40:05.691Z] <54d4a1d6db8155e6700f853b> it seems different versions of scipy give different results
[2015-02-26T15:40:42.026Z] <541a528b163965c9bc2053de> which version of scipy are you running and how the test fail in your case ?
[2015-02-26T15:41:16.978Z] <541a528b163965c9bc2053de> I need to run catch my shuttle. not sure I will be able to work on that further today but will catch up tomorrow
[2015-02-26T15:41:47.001Z] <54d4a1d6db8155e6700f853b> ok. I'll try to look into it more today. Now my tests are failing the same way yours are doing. But I had different results on my different laptop
[2015-02-26T15:42:05.820Z] <54d4a1d6db8155e6700f853b> this one is on 0.13.3
[2015-02-26T15:42:17.806Z] <541a528b163965c9bc2053de> bye
[2015-02-26T15:42:19.654Z] <54d4a1d6db8155e6700f853b> bye
[2015-02-26T15:45:07.270Z] <54d4a1d6db8155e6700f853b> what is the difference between "predict" and "transform" in isotonic regression?
[2015-02-26T15:45:26.997Z] <54d4a1d6db8155e6700f853b> ah, there is none. Isn't that slightly confusing?
[2015-02-26T19:47:18.995Z] <541a528b163965c9bc2053de> It is, mayve we could deprecate transform in favor of predict.
[2015-02-26T19:47:58.102Z] <54d4a1d6db8155e6700f853b> fyi https://github.com/scikit-learn/scikit-learn/pull/4285 should be good
[2015-02-26T19:48:21.599Z] <54d4a1d6db8155e6700f853b> I had some weird behavior with the interp1d but I need to do some NYU stuff before I can investigate further
[2015-02-26T19:53:27.578Z] <5474d9eadb8155e6700d8178> @amueller can I take up the newly tagged easy issues, assuming this will help u release the 0.16 beta cut or should I leave those for a new contributor instead? 
[2015-02-26T19:54:09.384Z] <54d4a1d6db8155e6700f853b> which ones in particular? For the release only the tagged issues are important imho
[2015-02-26T20:02:38.570Z] <5474d9eadb8155e6700d8178> I had meant #4298, #4296, #4292... but I just realized I had one unfinished 0.16 tagged PR - #4225... I'll work on it instead :)
[2015-02-26T20:04:19.904Z] <54d4a1d6db8155e6700f853b> you can leave the three issues for new people, or you can go for them. But they are really low priority. Finishing up the other PRs you already have open might be better for us at the moment.
[2015-02-26T20:09:06.648Z] <5474d9eadb8155e6700d8178> yea :) thanks!
[2015-02-27T18:12:00.315Z] <54d4a1d6db8155e6700f853b> @ogrisel how are things?
[2015-02-27T18:15:12.847Z] <541a528b163965c9bc2053de> hi @amueller , I got side tracked on other stuff. I merged the BernoulliNB fix though. Still need to understand the isotonic transform stuff
[2015-02-27T18:15:20.283Z] <541a528b163965c9bc2053de> and you ?
[2015-02-27T18:15:43.229Z] <54d4a1d6db8155e6700f853b> I looked into it. I can work on it the rest of the day. It seems we need to do it ourselves. I can't make sense of the scipy results. I posted a notebook in the issue.
[2015-02-27T18:16:01.331Z] <54d4a1d6db8155e6700f853b> I'll upgrade scipy to see if the results look the same, but I think we need to implement our own way to deal with duplicates
[2015-02-27T18:16:08.661Z] <54d4a1d6db8155e6700f853b> anything else you'd consider blocking?
[2015-02-27T18:16:13.028Z] <541a528b163965c9bc2053de> ok
[2015-02-27T18:16:28.828Z] <541a528b163965c9bc2053de> let me scan throught the remaining issues
[2015-02-27T18:17:29.375Z] <54d4a1d6db8155e6700f853b> I am not happy about this: https://github.com/scikit-learn/scikit-learn/issues/4262
[2015-02-27T18:18:21.319Z] <54d4a1d6db8155e6700f853b> I think this would be good to get in: https://github.com/scikit-learn/scikit-learn/pull/4121
[2015-02-27T18:20:49.593Z] <54d4a1d6db8155e6700f853b> This is an easy fix for pretty bad bug: https://github.com/scikit-learn/scikit-learn/pull/4182 (DPGMM.sample() giving attribute error)
[2015-02-27T18:26:05.641Z] <541a528b163965c9bc2053de> Would be good to get your sparse decision function as well as it seems ready to me.
[2015-02-27T18:28:38.355Z] <541a528b163965c9bc2053de> Will do #4274 now.
[2015-02-27T18:29:08.790Z] <541a528b163965c9bc2053de> There is also the setup.py fix to leverage wheelhouse uploader to automate wheel upload
[2015-02-27T18:32:11.843Z] <54d4a1d6db8155e6700f853b> Yeah I think I +1'd that one
[2015-02-27T18:32:34.899Z] <54d4a1d6db8155e6700f853b> I think the decision function is ready, too, but it needs another review.
[2015-02-27T18:51:10.840Z] <541a528b163965c9bc2053de> I will have a look at #4121 now
[2015-02-27T19:27:14.839Z] <541a528b163965c9bc2053de> argl #4121 highlight an API bug that went trough the initia LSHForest reviews: the shape of the values returned by radius_neighbors is not consistent with the exact methods
[2015-02-27T19:27:25.978Z] <541a528b163965c9bc2053de> I will open a new issue for this specific point
[2015-02-27T19:34:24.472Z] <54d4a1d6db8155e6700f853b> meh...
[2015-02-27T19:35:02.361Z] <54d4a1d6db8155e6700f853b> I have a naive fix for https://github.com/scikit-learn/scikit-learn/pull/4302 but there are backward compatibility issues.
[2015-02-27T19:54:41.282Z] <541a528b163965c9bc2053de> argl there is also the dtype=object compat issue
[2015-02-27T19:54:50.306Z] <541a528b163965c9bc2053de> in brute force
[2015-02-27T19:54:56.878Z] <541a528b163965c9bc2053de> this is annoying as well.
[2015-02-27T19:56:52.592Z] <541a528b163965c9bc2053de> I am hungry and tired. I think I will stop here for tonight and resume work on neighbors stuff tomorrow. I would like to fix all the neighbors API issue and isotonic stuff (I need to read the paper on the tie breaking stuff) before cutting the beta. That make me thing that we can move the target to Monday for the beta.
[2015-02-27T19:57:04.484Z] <541a528b163965c9bc2053de> @amueller WDYT?
[2015-02-27T19:58:16.941Z] <54d4a1d6db8155e6700f853b> Sounds good. I have time on the weekend. The tie-breaking stuff is not hard, but we have to make a choice (See my PR). If we agree that that PR is the way to go, it needs cython code, I think.
[2015-02-27T19:58:44.056Z] <54d4a1d6db8155e6700f853b> dtype=object in the output or the input?
[2015-02-27T19:59:08.828Z] <54d4a1d6db8155e6700f853b> For the inputs is should be fine everywhere now, methinks
[2015-02-27T20:13:20.257Z] <541a528b163965c9bc2053de> output of radius_neighbors
[2015-02-27T20:13:23.141Z] <541a528b163965c9bc2053de> which is fine
[2015-02-27T20:13:45.011Z] <541a528b163965c9bc2053de> but brute does not follow the behavior of  balltree and kdtree
[2015-02-27T20:14:13.617Z] <54d4a1d6db8155e6700f853b> I thought that was fixed. all should output dtype=object now
[2015-02-27T20:16:39.891Z] <54d4a1d6db8155e6700f853b> should have been fixed here: https://github.com/scikit-learn/scikit-learn/pull/4046/files
[2015-02-27T20:17:42.002Z] <54d4a1d6db8155e6700f853b> or are you talking about this: https://github.com/scikit-learn/scikit-learn/issues/1400
[2015-02-27T20:29:14.638Z] <541a528b163965c9bc2053de> ok maybe it's missing a rebase
[2015-02-27T20:29:23.784Z] <541a528b163965c9bc2053de> I will have look tomorrow
[2015-02-27T20:57:50.973Z] <54d4a1d6db8155e6700f853b> ok, have a good night :)
[2015-02-27T20:57:56.402Z] <54d4a1d6db8155e6700f853b> / fun
[2015-02-27T21:29:17.043Z] <541a528b163965c9bc2053de> thanks good night as well ;)
[2015-02-27T21:42:28.750Z] <54d4a1d6db8155e6700f853b> I fixed the isotonic part and wrote the necessary cython
[2015-02-27T21:49:00.251Z] <541a528b163965c9bc2053de> \o/
[2015-02-27T21:49:31.970Z] <54d4a1d6db8155e6700f853b> :)
[2015-02-27T21:49:52.563Z] <541a528b163965c9bc2053de> going to be this time :)
[2015-02-27T21:50:01.524Z] <541a528b163965c9bc2053de> bye
[2015-02-27T21:50:05.295Z] <54d4a1d6db8155e6700f853b> bye
[2015-03-02T14:19:02.753Z] <54d4a1d6db8155e6700f853b> @ogrisel what is your plan for the day? I didn't have much time on the weekend unfortunately :-/
[2015-03-02T14:44:13.313Z] <541a528b163965c9bc2053de> no pbm. I just pushed #4317 to tackle the remaining docstring and test issues w.r.t. radius_neighbors. Please feel free to have a look.
[2015-03-02T14:45:28.877Z] <541a528b163965c9bc2053de> I will now catch up on your work on isotonic regression. I think it looks good from a first look at it. Will test it a bit more. That might make it possible to remove the random tie breaking in the calibration code.
[2015-03-02T14:46:21.162Z] <54d4a1d6db8155e6700f853b> The behavior is different from what it was before, but I think this is the only way to make fit().transform() and fit_transform() be the same.
[2015-03-02T14:46:37.717Z] <54d4a1d6db8155e6700f853b> I'll head t othe office now and look at #4317 once I'm ther
[2015-03-02T14:52:34.058Z] <541a528b163965c9bc2053de> Alright. I will be offline for 1h (commute back home from saclay) but should get back online afterwards.
[2015-03-02T14:53:43.927Z] <54d4a1d6db8155e6700f853b> damn time difference ;)
[2015-03-02T14:56:10.016Z] <541a528b163965c9bc2053de> It's also because I have to commute early in the morning and in the afternoon to take a shuttle bus that avoids most of the Paris rush hour traffic :) I would not wake up at 6:30am naturally otherwise...
[2015-03-02T14:56:43.731Z] <541a528b163965c9bc2053de> I a good paper to read on hyperparam search on the way back home :)
[2015-03-02T14:59:05.927Z] <54d4a1d6db8155e6700f853b> the one kyle sent around? Jasper Snoek will give a talk at NYU on Friday :)
[2015-03-02T14:59:32.681Z] <541a528b163965c9bc2053de> yes
[2015-03-02T15:00:33.251Z] <541a528b163965c9bc2053de> it seems only useful when you can use a big compute cluster for a week though. Still it looks interesting.
[2015-03-02T15:01:09.224Z] <541a528b163965c9bc2053de> It means that we might be able to use the future MLP model for hyperparam search instead of trying to fix the GP to make them efficient ;)
[2015-03-02T15:04:32.583Z] <54d4a1d6db8155e6700f853b> well spearmint uses the sklearn random forests for hyperparameter search l)
[2015-03-02T15:04:39.620Z] <54d4a1d6db8155e6700f853b> so we could also use that ;)
[2015-03-02T15:10:08.652Z] <541a528b163965c9bc2053de> yes but apparently it does not reach the quality of the solution of bayes optimization with GPs or NNs.
[2015-03-02T15:10:30.600Z] <541a528b163965c9bc2053de> Nor does TPEs, at least in the benchmarks run in this paper.
[2015-03-02T15:10:53.453Z] <541a528b163965c9bc2053de> anyway let's focus back on the release :)
[2015-03-02T15:41:41.730Z] <54d4a1d6db8155e6700f853b> btw, for https://github.com/scikit-learn/scikit-learn/issues/2274 currently the random projections are pretty loud
[2015-03-02T16:26:52.821Z] <54d4a1d6db8155e6700f853b> #4318
[2015-03-02T17:34:26.558Z] <54d4a1d6db8155e6700f853b> wait, which is the paper you read on the train? not this one, right? http://arxiv.org/pdf/1502.03492v2.pdf
[2015-03-02T17:35:08.245Z] <54d4a1d6db8155e6700f853b> I guess this one: http://arxiv.org/pdf/1502.05700.pdf
[2015-03-02T18:27:34.341Z] <54d4a1d6db8155e6700f853b> do we have a link to the pdf docs on the website? I think we don't :-/ where should it go?
[2015-03-02T19:06:11.821Z] <541a528b163965c9bc2053de> I read the one by Snoek, but also read the other 2 weeks ago I think.
[2015-03-02T19:07:08.855Z] <541a528b163965c9bc2053de> > do we have a link to the pdf docs on the website? I think we don't :pensive: where should it go? no we don't, we don't build it on a regular basis but we could. It should be possible to upload it as part of the build process.
[2015-03-02T19:21:36.754Z] <54d4a1d6db8155e6700f853b> after this the latex build should be relatively clean: https://github.com/scikit-learn/scikit-learn/pull/4320
[2015-03-02T19:22:26.138Z] <54d4a1d6db8155e6700f853b> anything you want me to review / work on?
[2015-03-02T20:36:00.073Z] <5474d9eadb8155e6700d8178> Is there a way to make `GridSearchCV` act without the CV part ( do parameters `cv=None` or `refit` help in this context )?
[2015-03-02T20:38:30.893Z] <541a528b163965c9bc2053de> You can precompute a single test train split: train_idx, validation_idx = train_test_split(n_samples, test_size=0.2, random_state=0) cv = [(train_idx, validation_idx)] GridSearchCV(model, cv=cv).fit(X, y)
[2015-03-02T20:39:10.537Z] <5474d9eadb8155e6700d8178> Ahh thanks! :)
[2015-03-02T20:43:44.539Z] <5474d9eadb8155e6700d8178> I am using your code in a comment at #4301...
[2015-03-02T20:45:12.573Z] <541a528b163965c9bc2053de> I made a mistake:
[2015-03-02T20:45:23.657Z] <541a528b163965c9bc2053de> train_idx, validation_idx = train_test_split(np.arange(n_samples), test_size=0.2, random_state=0)
[2015-03-02T20:45:29.309Z] <541a528b163965c9bc2053de> missing the np.arange
[2015-03-02T21:05:50.870Z] <54d4a1d6db8155e6700f853b> it might be interesting to have the ability to not split into training and test data for unsupervised algorithms.
[2015-03-02T21:09:18.844Z] <5474d9eadb8155e6700d8178> what does setting cv to None do currently?
[2015-03-02T21:10:44.763Z] <5474d9eadb8155e6700d8178> Perhaps we could set cv to -1 for that behaviour?
[2015-03-02T21:20:00.921Z] <541a528b163965c9bc2053de> @amueller unsupervised scores can still overfit
[2015-03-02T21:21:19.854Z] <54d4a1d6db8155e6700f853b> it depends on the context. For clustering, where you can not even evaluate on non-training data, it totally makes sense.
[2015-03-02T21:22:14.605Z] <54d4a1d6db8155e6700f853b> I'm looking into the sphinx thing but I'm not entirely clear on how to achieve this. I don't know where to hook it in. Did you have time to look at the isotonic stuff?
[2015-03-02T21:22:40.323Z] <541a528b163965c9bc2053de> indeed
[2015-03-02T21:23:30.639Z] <541a528b163965c9bc2053de> I thought about k-means where predict is possible but this is not always the case, for instance when clustering is done on a precompute distance or similarity matrix
[2015-03-02T21:23:50.805Z] <541a528b163965c9bc2053de> I am testing it now
[2015-03-02T21:23:55.382Z] <541a528b163965c9bc2053de> the isotonic
[2015-03-02T21:46:26.926Z] <54d4a1d6db8155e6700f853b> sweet thanks :)
[2015-03-02T21:53:18.186Z] <5474d9eadb8155e6700d8178> @amueller for #4301, do you think the metrics might be useful?
[2015-03-02T21:54:28.068Z] <54d4a1d6db8155e6700f853b> possibly. I didn't have much time to look at them yet
[2015-03-02T21:54:39.260Z] <54d4a1d6db8155e6700f853b> this is not really a priority as I want to get stuff clean and fixed for the release first
[2015-03-02T21:55:52.586Z] <5474d9eadb8155e6700d8178> Okay... I'll just leave a comment there... take a look if you happen to find time after the release related work :)
[2015-03-02T22:06:42.937Z] <541a528b163965c9bc2053de> +1 for not working on not introducing any new feature that has not already received a significant amount of reviews.
[2015-03-02T22:07:43.925Z] <541a528b163965c9bc2053de> Rephrasing: I meant not working on PR introducing new features unless it has already been reviewed extensively.
[2015-03-02T22:08:10.846Z] <5474d9eadb8155e6700d8178> Sure :) 
[2015-03-02T22:19:17.752Z] <54d4a1d6db8155e6700f853b> :)
[2015-03-02T22:36:06.267Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4313
[2015-03-02T22:36:35.125Z] <54d4a1d6db8155e6700f853b> is part of the kneighbors_graph fix where you can press the green button. I agree that this should be in the beta
[2015-03-02T22:39:52.241Z] <541a528b163965c9bc2053de> haha I merged it before reading your message here ;)
[2015-03-02T22:40:05.975Z] <54d4a1d6db8155e6700f853b> haha I just saw it and thought you read my message ;)
[2015-03-02T22:40:24.357Z] <54d4a1d6db8155e6700f853b> anything I should look at now? btw, does beta mean uploading docs?
[2015-03-02T22:40:33.931Z] <54d4a1d6db8155e6700f853b> probably not I guess?
[2015-03-02T22:43:42.330Z] <541a528b163965c9bc2053de> no, no site change for the beta. But it's good to fix it anyway :)
[2015-03-02T22:45:21.339Z] <54d4a1d6db8155e6700f853b> so the plan is uploading a non-default pipy package and writing a mail? and wheels?
[2015-03-02T22:45:33.579Z] <54d4a1d6db8155e6700f853b> Maybe then I should focus on the very verbose tests ^^
[2015-03-02T22:45:51.797Z] <54d4a1d6db8155e6700f853b> As I said above, if you have anything on your wishlist, let me know
[2015-03-02T22:48:09.003Z] <541a528b163965c9bc2053de> yes
[2015-03-02T22:48:27.250Z] <541a528b163965c9bc2053de> verbose tests and maybe decide on #4309 because it has a slight API impact.
[2015-03-02T22:48:54.318Z] <541a528b163965c9bc2053de> and off-course the isotonic  and radius PRs that should be ready to merge very soon now.
[2015-03-02T22:56:09.884Z] <541a528b163965c9bc2053de> it's midnight here, I think I will call it a day on my side
[2015-03-02T22:56:52.362Z] <541a528b163965c9bc2053de> see you tomorrow. Tomorrow morning I will work to prepare a team meeting on probability calibration and meeting in the afternoon. Should be online after that.
[2015-03-02T22:58:48.438Z] <54d4a1d6db8155e6700f853b> well but for those we need another reviewer, right?
[2015-03-02T22:59:17.985Z] <54d4a1d6db8155e6700f853b> have a good night and see you tomorrow
[2015-03-02T23:00:18.969Z] <541a528b163965c9bc2053de> yes we need other reviewers for those.
[2015-03-02T23:00:26.216Z] <541a528b163965c9bc2053de> good night
[2015-03-03T15:05:44.810Z] <54d4a1d6db8155e6700f853b> looks like you got a lot of reviewing done already, sweet :)
[2015-03-03T15:05:58.786Z] <54d4a1d6db8155e6700f853b> care to weight in on the class_weight discussion?
[2015-03-03T16:07:55.589Z] <54d4a1d6db8155e6700f853b> we really need someone else for reviews :-/
[2015-03-03T19:13:18.909Z] <541a528b163965c9bc2053de> @agramfort are you around?
[2015-03-03T19:48:16.723Z] <54d4a1d6db8155e6700f853b> there is another bugfix here @ogrisel  https://github.com/scikit-learn/scikit-learn/pull/4326
[2015-03-03T19:48:28.938Z] <54d4a1d6db8155e6700f853b> I merged the RBM fix and docs after Kyle +1'ed
[2015-03-03T21:21:17.613Z] <541a528b163965c9bc2053de> Done.
[2015-03-03T21:21:24.827Z] <541a528b163965c9bc2053de> 15 left.
[2015-03-03T21:21:31.286Z] <541a528b163965c9bc2053de> 15 PRs left.
[2015-03-03T22:12:01.641Z] <54d4a1d6db8155e6700f853b> thanks
[2015-03-03T22:12:07.367Z] <54d4a1d6db8155e6700f853b> woah getting late again on your side ;)
[2015-03-03T22:12:37.057Z] <54d4a1d6db8155e6700f853b> 10PRs left I think
[2015-03-03T22:13:01.002Z] <54d4a1d6db8155e6700f853b> oh, wrong filter. 14PRs
[2015-03-03T22:14:35.196Z] <54d4a1d6db8155e6700f853b> the agglomerative clustering one I am not sure about. I don't know what the canonical meaning of alpha is. https://github.com/scikit-learn/scikit-learn/pull/3758
[2015-03-04T00:47:03.847Z] <5474d9eadb8155e6700d8178> @amueller for the partial_fit tests PR do you think there is still a lot of testing code that could be reduced/removed?
[2015-03-04T15:11:20.423Z] <54d4a1d6db8155e6700f853b> I'm not really sure
[2015-03-04T17:12:02.468Z] <54d4a1d6db8155e6700f853b> @ogrisel are you there and do you have time to talk about an outline for the webcast?
[2015-03-05T08:21:02.228Z] <541a528b163965c9bc2053de> @amueller  Sorry I was feeling sick yesterday night and I did not go online.
[2015-03-05T08:26:32.033Z] <541a528b163965c9bc2053de> I started thinking about it, we can do: - general intro to ML in Python with scikit-learn - couple of words on the project organization and the team of contributors - highlight of some new stuff in 0.16: improvement on speed or scalability of some methods such as:    - IncrementalPCA    - clustering (I am preparing a notebook comparing DBSCAN, MiniBatchKMeans, KMeans and Birch on 100k blobish 2D points to simulate someone working to extract Point of Interests from raw geo location data (e.g. GSM phone records) - new Approximate Nearest Neighbors search with LSHForest Then for the future we could talk about TSNE and algorithmic improvements under review in the pipeline
[2015-03-05T08:27:15.875Z] <541a528b163965c9bc2053de> I forgot, I also wanted to say a couple of words about probability calibration
[2015-03-05T14:47:59.412Z] <54d4a1d6db8155e6700f853b> Right, calibration is not on my list.  Is it in whatsnew?
[2015-03-05T14:51:54.429Z] <54d4a1d6db8155e6700f853b> Oh, and a title
[2015-03-05T14:52:04.444Z] <54d4a1d6db8155e6700f853b> Hope you are feeling better today
[2015-03-05T14:53:52.687Z] <54d4a1d6db8155e6700f853b> News from scikit-learn 0.16 and soon-to-be gems for the next release. ??
[2015-03-05T14:58:29.118Z] <541a528b163965c9bc2053de> sounds good to me
[2015-03-05T14:58:39.960Z] <541a528b163965c9bc2053de> I am half feeling better, really weird
[2015-03-05T14:58:58.081Z] <541a528b163965c9bc2053de> some hours I feel sick and then completely fine for a while
[2015-03-05T14:59:03.663Z] <541a528b163965c9bc2053de> that's weird
[2015-03-05T15:00:23.052Z] <541a528b163965c9bc2053de> I played a bit with clustering on 1e5 points in 2D
[2015-03-05T15:00:24.278Z] <541a528b163965c9bc2053de> http://nbviewer.ipython.org/github/ogrisel/notebooks/blob/master/sklearn_demos/Large%20Scale%202D%20Clustering.ipynb
[2015-03-05T15:00:41.523Z] <541a528b163965c9bc2053de> DBSCAN is 3x faster than 0.15.2
[2015-03-05T15:01:54.198Z] <541a528b163965c9bc2053de> MB KMeans is still the fastest although it does not deal with outliers as DBSCAN does
[2015-03-05T15:02:06.578Z] <54d4a1d6db8155e6700f853b> cool :) and there are still faster DBSCAN variants in the PRs
[2015-03-05T15:02:16.641Z] <54d4a1d6db8155e6700f853b> there is a pretty new PR on that I think
[2015-03-05T15:02:27.166Z] <541a528b163965c9bc2053de> Birch core set extraction seems to works great but the final affinity clustering pass is not as scalable as the core set extraction
[2015-03-05T15:43:12.898Z] <54d4a1d6db8155e6700f853b> what's on todays agenda for the release?
[2015-03-05T15:43:28.201Z] <54d4a1d6db8155e6700f853b> or what was for you ;)
[2015-03-05T15:44:27.787Z] <54d4a1d6db8155e6700f853b> no progress on isotonic I see
[2015-03-05T15:44:47.438Z] <54d4a1d6db8155e6700f853b> would you mind having a look at https://github.com/scikit-learn/scikit-learn/issues/4324
[2015-03-05T16:04:31.402Z] <54d4a1d6db8155e6700f853b> I guess I start reviewing the non-release PRs now. Or is there anything to review left?
[2015-03-05T16:07:25.288Z] <54d4a1d6db8155e6700f853b> Delaying the beta even more seems a bit silly to me, but the only other option is to merge the remaining urgent fixes with fewer reviews
[2015-03-05T20:39:58.293Z] <541a528b163965c9bc2053de> I am having a look at the DBSCAN. Let's release the beta tomorrow. Whatever the review state of the remaining PRs. we will do backports for the fixes afterwards for the second beta.
[2015-03-05T20:40:47.639Z] <54d4a1d6db8155e6700f853b> you want a second beta? Alright....
[2015-03-05T20:41:24.815Z] <541a528b163965c9bc2053de> maybe not
[2015-03-05T20:41:39.263Z] <541a528b163965c9bc2053de> it depends how stable we find the beta
[2015-03-05T20:41:56.808Z] <541a528b163965c9bc2053de> I would like to merge this https://github.com/scikit-learn/scikit-learn/pull/4028 before cutting the beta branch
[2015-03-05T20:42:30.743Z] <54d4a1d6db8155e6700f853b> go for it. It shouldn't interfere with anything.
[2015-03-05T20:42:50.484Z] <541a528b163965c9bc2053de> ok
[2015-03-05T20:43:16.489Z] <54d4a1d6db8155e6700f853b> Do you think we should get this one in soon: https://github.com/scikit-learn/scikit-learn/pull/4228
[2015-03-05T20:44:27.350Z] <541a528b163965c9bc2053de> If it's ready soon, +1 for a backport to the 0.16.X branch.
[2015-03-05T20:44:32.755Z] <54d4a1d6db8155e6700f853b> ok
[2015-03-05T20:45:52.852Z] <541a528b163965c9bc2053de> maybe we can do: beta tomorrow, continue backports of fixes and target 0.16 in 2 or 3 weeks. And if we fix additional important bugs, 0.16.1 in a month and half
[2015-03-05T20:46:27.482Z] <54d4a1d6db8155e6700f853b> yeah, sounds good.
[2015-03-05T20:46:34.179Z] <54d4a1d6db8155e6700f853b>  we should really release more regularly.
[2015-03-05T20:46:43.641Z] <541a528b163965c9bc2053de> I will be in PyCon at that point but you can do the 0.16.1 with the help of others if I am not responsive enough at that point.
[2015-03-05T20:46:56.903Z] <54d4a1d6db8155e6700f853b> Alright. I don't think I'll make it this year.
[2015-03-05T20:47:07.573Z] <54d4a1d6db8155e6700f853b> you are not coming to scipy are you?
[2015-03-05T20:52:50.090Z] <541a528b163965c9bc2053de> nope
[2015-03-05T20:53:23.768Z] <541a528b163965c9bc2053de> I was planning to attend ICML as a free-styler because is just 1h by train
[2015-03-05T20:54:25.815Z] <54d4a1d6db8155e6700f853b> :) sweet
[2015-03-05T21:07:25.197Z] <5474d9eadb8155e6700d8178> Hey :) could you help me with #4228 ? I don't understand a few things... When testing you said I could use multilabel data right? but which classifier do I test against? (or if you might have time could you take over?)
[2015-03-05T21:08:05.551Z] <54d4a1d6db8155e6700f853b> Try a tree? Or use OneVsRestClassifer(LogisticRegression).
[2015-03-05T21:08:09.850Z] <54d4a1d6db8155e6700f853b> I'll have a look soon.
[2015-03-05T21:08:47.821Z] <5474d9eadb8155e6700d8178> will grid search propagate the parameters from `OneVsRestClassifier` to `LogisticRegression`?
[2015-03-05T21:08:53.364Z] <5474d9eadb8155e6700d8178> and thanks :)
[2015-03-05T21:10:54.546Z] <54d4a1d6db8155e6700f853b> probably with ``estimator__``. But I'd rather go with a tree, which should work
[2015-03-05T21:11:52.707Z] <5474d9eadb8155e6700d8178> okay I'll push in sometime... pl see if I am in the right direction or kindly take over... sorry for having kept you waiting over that :)
[2015-03-05T21:17:06.076Z] <5474d9eadb8155e6700d8178> A small doubt do you use multiple monitors? ;)
[2015-03-05T21:24:42.658Z] <541a528b163965c9bc2053de> no why?
[2015-03-05T21:27:04.771Z] <5474d9eadb8155e6700d8178> Just curious how @amueller could be online and commenting at the same time :O I am online sometimes while I work since I use vim in a transparent guake terminal over the gitter chat window... :)
[2015-03-05T21:27:48.510Z] <54d4a1d6db8155e6700f853b> no transparency here. I technically have a laptop monitor and a large one, but in the office I currently only use the large one. Still context-switching too much.
[2015-03-05T21:28:01.593Z] <54d4a1d6db8155e6700f853b> I have the gitter tab just always open
[2015-03-05T21:28:45.019Z] <5474d9eadb8155e6700d8178> Ah :D :)
[2015-03-05T22:03:30.970Z] <54d4a1d6db8155e6700f853b> are you working on https://github.com/scikit-learn/scikit-learn/pull/4228 now or should I go for it? I only have like 2 hours of work left today, though ;)
[2015-03-05T22:13:23.231Z] <5474d9eadb8155e6700d8178> Please go for it :) :P Most ests don't seem to support sparse y... :)
[2015-03-05T22:15:52.328Z] <5474d9eadb8155e6700d8178> ``` ====================================================================== ERROR: sklearn.tree.tests.test_tree.test_sparse_input('DecisionTreeClassifier', 'sparse-mix', None) ---------------------------------------------------------------------- Traceback (most recent call last):   File "/usr/local/lib/python2.7/dist-packages/nose/case.py", line 197, in runTest     self.test(*self.arg)   File ".../scikit-learn/sklearn/tree/tests/test_tree.py", line 1051, in check_sparse_input     y_sparse)   File ".../scikit-learn/sklearn/tree/tree.py", line 221, in fit     "number of samples=%d" % (len(y), n_samples)) ValueError: Number of labels=1 does not match number of samples=20 -------------------- >> begin captured stdout << --------------------- ``` Perhaps the `len(y)` needs to be changed to `_num_samples(y)` here...
[2015-03-05T22:17:06.856Z] <54d4a1d6db8155e6700f853b> maybe... but with dense y it works?
[2015-03-05T22:22:36.331Z] <5474d9eadb8155e6700d8178> Even after changing to `_num_samples(y)` the error seems to persist :|
[2015-03-05T22:25:19.744Z] <54d4a1d6db8155e6700f853b> ok let me look at it tomorrow
[2015-03-05T22:25:29.813Z] <5474d9eadb8155e6700d8178> thanks!! :)
[2015-03-05T22:29:39.463Z] <541a528b163965c9bc2053de> I am working on the polishing of the no-shuffle DBSCAN
[2015-03-05T22:29:52.213Z] <541a528b163965c9bc2053de> running the tests and should merge soon.
[2015-03-05T22:34:47.550Z] <54d4a1d6db8155e6700f853b> yeah I saw. cool :)
[2015-03-05T22:34:56.803Z] <54d4a1d6db8155e6700f853b> I'm thinking about the class_weight heuristic
[2015-03-05T22:35:26.585Z] <541a528b163965c9bc2053de> I have not read the reference. Do you?
[2015-03-05T22:35:57.133Z] <541a528b163965c9bc2053de> I meant "have you?" not "do you?"
[2015-03-05T22:39:18.196Z] <54d4a1d6db8155e6700f853b> skimmed. But it makes more sense. I'll post a regression test in a second.
[2015-03-05T22:39:30.308Z] <541a528b163965c9bc2053de> Great!
[2015-03-05T22:44:16.470Z] <541a528b163965c9bc2053de> Alright, I will call it a day. See you tomorrow!
[2015-03-05T22:46:37.738Z] <54d4a1d6db8155e6700f853b> alright. you work soo much later than I do.... Have a good night and see you tomorrow
[2015-03-05T22:47:57.505Z] <541a528b163965c9bc2053de> ++
[2015-03-05T23:10:01.914Z] <54c084dbdb8155e6700eed4c> @amueller , just so you're aware, when I was messing with how to structure the forests' class_weight implementations, I noticed float-point numerical differences in some little toy test datasets between a couple of different implementations that differed only in where or how i was multiplying, say sample weight and bootstrap weights. 
[2015-03-05T23:10:53.397Z] <54c084dbdb8155e6700eed4c> I'd expect that the change in #4347 will definitely change the way small floating point differences are evaluated. This obviously has a big effect in trees as magnitude doesn't matter, just gini improvement... So the outputs using class_weight between implementations will likely be different for forests, probably trees. Not that this really matters as they are both entering @ 0.16
[2015-03-05T23:12:29.469Z] <54c084dbdb8155e6700eed4c> Long story short, I think SVMs and Linear Models could potentially change a little bit with #4347, though not as bad as trees I'm guessing. I'm not sure what "promise" is made to users about reproducibility between scikit-learn versions... 
[2015-03-06T09:36:38.003Z] <541a528b163965c9bc2053de> Unfortunately we cannot promise much for those cases. It would be interesting to check the actual impact of the correct heuristic on some datasets though. 
[2015-03-06T10:58:32.750Z] <5474d9eadb8155e6700d8178> @amueller @ogrisel could we use `0.5 - np.finfo(float).resolution` for #4295 (With the assumption that, it wouldn't be considered a magic no. since 0.5 is a standard symmetric scaling factor?) to scale it to `(-0.5, 0.5)`?
[2015-03-06T15:23:59.083Z] <54c084dbdb8155e6700eed4c> @ogrisel fair enough. I'll try to find some time this weekend to run some experiments. I agree that the new implementation is more intuitive, just throwing it out there.
[2015-03-06T15:25:44.776Z] <541a528b163965c9bc2053de> Thanks
[2015-03-06T16:02:48.119Z] <541a528b163965c9bc2053de> @amueller shall we try to cut the 0.16.X branch?
[2015-03-06T16:25:13.677Z] <54d4a1d6db8155e6700f853b> @ogrisel feel free. do we want to backport the isotonic stuff then? Or take @mjbommar's +1?
[2015-03-06T16:25:43.658Z] <541a528b163965c9bc2053de> Let's do the isotonic merge now
[2015-03-06T16:26:26.662Z] <541a528b163965c9bc2053de> I think it's tested enought both by the isotonic tests and the probability calibration tests to be correct.
[2015-03-06T16:26:50.804Z] <54d4a1d6db8155e6700f853b> I feel the same way
[2015-03-06T16:27:16.336Z] <54d4a1d6db8155e6700f853b> do you want to press the green button or should I do the rebase dance?
[2015-03-06T16:28:00.068Z] <54d4a1d6db8155e6700f853b> @mjbommar's fix is not in a PR...
[2015-03-06T16:30:14.049Z] <541a528b163965c9bc2053de> I pressed the green button.
[2015-03-06T16:31:02.428Z] <54d4a1d6db8155e6700f853b> ok. and merge the other fix on top? It has my +1 and yours
[2015-03-06T16:31:04.577Z] <541a528b163965c9bc2053de> Let's create the PR ourselves from his branch :)
[2015-03-06T16:31:16.180Z] <54d4a1d6db8155e6700f853b> Should I create PR or just merge?
[2015-03-06T16:31:22.615Z] <54d4a1d6db8155e6700f853b> I guess we want to run travis once
[2015-03-06T16:31:48.648Z] <541a528b163965c9bc2053de> Yes better create the PR from his branch to get travis to run it.
[2015-03-06T16:33:33.743Z] <54d4a1d6db8155e6700f853b> I'm on it
[2015-03-06T16:33:41.071Z] <541a528b163965c9bc2053de> actually it's not possible to create the PR directly from his branch as we need to get rid of the past commits:
[2015-03-06T16:33:41.910Z] <541a528b163965c9bc2053de> https://github.com/scikit-learn/scikit-learn/compare/master...mjbommar:issue-4297-infinite-isotonic
[2015-03-06T16:33:50.599Z] <541a528b163965c9bc2053de> that are redundant with your own PR
[2015-03-06T16:34:01.445Z] <541a528b163965c9bc2053de> I let you do the cherry-pick
[2015-03-06T16:40:59.676Z] <54d4a1d6db8155e6700f853b> I did a rebase thing
[2015-03-06T16:41:30.737Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4352
[2015-03-06T16:46:27.259Z] <54d4a1d6db8155e6700f853b> should we wait for feedback on https://github.com/scikit-learn/scikit-learn/pull/4322 and then backport it?
[2015-03-06T16:46:33.712Z] <54d4a1d6db8155e6700f853b> warnings in the beta seem not that bad
[2015-03-06T16:47:37.553Z] <541a528b163965c9bc2053de> yes +1 for waiting for this one
[2015-03-06T17:40:06.745Z] <541a528b163965c9bc2053de> @amueller unfortunately I won't have time to cut the branch tonight. I have to go now. Feel free to do it, push a commit with the 0.16b1 version number (that follows PEP-440) and push a tag with pointing to it. That should get the CI workers to build the wheels. If everything goes well we should be able to push the release to PyPI (after testing on https://testpypi.python.org/pypi first) using wheelhouse-uploader.
[2015-03-06T17:40:56.945Z] <541a528b163965c9bc2053de> I will be busy tomorrow (we organize a deep learning workshop in Paris) and on sunday I should be mostly offline.
[2015-03-06T17:41:30.290Z] <541a528b163965c9bc2053de> I can push the release on PyPI on Monday if appveyor works well.
[2015-03-06T17:41:56.642Z] <54d4a1d6db8155e6700f853b> Ok, then I'll do it this afternoon. Mail to mailing list after pypi push? Or wait for appveyor?
[2015-03-06T17:41:58.339Z] <541a528b163965c9bc2053de> travis is slow today...
[2015-03-06T17:42:25.800Z] <54d4a1d6db8155e6700f853b> Are there instructions on the wheel builts in the docs?
[2015-03-06T17:42:37.848Z] <541a528b163965c9bc2053de> I would like to wait for appveyor and MacPython : https://github.com/MacPython/wiki/wiki/Spinning-wheels
[2015-03-06T17:42:58.159Z] <541a528b163965c9bc2053de> wrong copy and paste
[2015-03-06T17:43:01.500Z] <541a528b163965c9bc2053de> I meant: https://github.com/MacPython/scikit-learn-wheels
[2015-03-06T17:43:29.224Z] <54d4a1d6db8155e6700f853b> what version number do you leave on master after doing the beta? Still 0.16-dev?
[2015-03-06T17:44:30.722Z] <541a528b163965c9bc2053de> I changed the master to follow PEP-440, so it's 0.16.dev0 at the moment
[2015-03-06T17:44:55.002Z] <541a528b163965c9bc2053de> It should move to 0.17.dev0 once the 0.16.X branch has been cut.
[2015-03-06T17:45:31.323Z] <541a528b163965c9bc2053de> I granted you push rights to https://github.com/MacPython/scikit-learn-wheels
[2015-03-06T17:45:32.188Z] <54d4a1d6db8155e6700f853b> Ok, wasn't sure if we do that after the beta or the release, but makes sense if we branch.
[2015-03-06T17:45:41.218Z] <54d4a1d6db8155e6700f853b> thanks
[2015-03-06T17:46:43.088Z] <541a528b163965c9bc2053de> once the scikit-learn 0.16b1 tag has been pushed to our github repo, we have to update the git submodules of https://github.com/MacPython/scikit-learn-wheels to point to it to get the travis bots of that repo to build all the Mac OSX wheels for that release.
[2015-03-06T17:48:17.512Z] <54d4a1d6db8155e6700f853b> ok
[2015-03-06T17:52:15.838Z] <54d4a1d6db8155e6700f853b> merge this on green then branching? https://github.com/scikit-learn/scikit-learn/pull/4352
[2015-03-06T17:52:50.056Z] <541a528b163965c9bc2053de> yes
[2015-03-06T17:53:06.081Z] <541a528b163965c9bc2053de> I have to go now, sorry for leaving you alone.
[2015-03-06T18:17:49.788Z] <5474d9eadb8155e6700d8178> Andy could you quickly take a look at #4228 to see if the test to be satisfied is correct. I'm using that as an objective for that PR! (I'll iterate different fixes till that test is satisfied...)
[2015-03-06T18:26:47.387Z] <5474d9eadb8155e6700d8178> I've reopened #4228 as #4354 since #4228 won't reopen (more precisely, github won't track branches against which closed PRs were raised... So #4228 remains at 0+0- even after pushing the new commit to that branch and hence won't reopen as it brings about no change) Sorry for wasting an issue no.! :/
[2015-03-06T18:42:16.219Z] <54d4a1d6db8155e6700f853b> Sorry, as I'll have to take care of the beta now, so I won't have time to look into the issue
[2015-03-06T18:43:18.737Z] <5474d9eadb8155e6700d8178> okay no problem :)
[2015-03-06T22:49:52.806Z] <54d4a1d6db8155e6700f853b> @ogrisel so if we don't build /upload the docs on beta, what should the links in the navigation of the "documentation" page be? I guess we have to fix them later....
[2015-03-06T22:50:21.699Z] <54d4a1d6db8155e6700f853b> because now there will not be any 0.16 documentation online
[2015-03-06T23:06:02.950Z] <54d4a1d6db8155e6700f853b> pushed the tag, updated the MacPython wheels.
[2015-03-07T09:32:54.728Z] <541a528b163965c9bc2053de> No there won't be any 0.16 website, before the 0.16 final release but I think this is fine. dev points to 0.17.dev0 and stable points to 0.15.2
[2015-03-07T09:36:05.751Z] <541a528b163965c9bc2053de> next time we upload the website we should remove the version for the link to the development documentation number from the documentation menu.
[2015-03-07T12:11:20.438Z] <5474d9eadb8155e6700d8178> Is there a nice cython guide that I could use? (Related to #4354 for `_tree.pyx` to make it support sparse y)
[2015-03-07T12:40:11.328Z] <541a528b163965c9bc2053de> @amueller I tried to install the macwheels in a new venv and it works:
[2015-03-07T12:40:13.846Z] <541a528b163965c9bc2053de> ``` (sklearn-0.16b1)0 [~]$ pip install -f http://wheels.scipy.org/ --pre numpy scipy scikit-learn Downloading/unpacking numpy   http://wheels.scipy.org/ uses an insecure transport scheme (http). Consider using https if wheels.scipy.org has it available   Downloading numpy-1.9.2-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (3.7MB): 3.7MB downloaded   Storing download in cache at ./.pip/cache/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fcp34%2Fn%2Fnumpy%2Fnumpy-1.9.2-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl Downloading/unpacking scipy   http://wheels.scipy.org/ uses an insecure transport scheme (http). Consider using https if wheels.scipy.org has it available   Downloading scipy-0.15.1-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (19.0MB): 19.0MB downloaded   Storing download in cache at ./.pip/cache/https%3A%2F%2Fpypi.python.org%2Fpackages%2F3.4%2Fs%2Fscipy%2Fscipy-0.15.1-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl Downloading/unpacking scikit-learn   http://wheels.scipy.org/ uses an insecure transport scheme (http). Consider using https if wheels.scipy.org has it available   Downloading scikit_learn-0.16_git-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (4.8MB): 4.8MB downloaded   Storing download in cache at ./.pip/cache/http%3A%2F%2Fwheels.scipy.org%2Fscikit_learn-0.16_git-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl Installing collected packages: numpy, scipy, scikit-learn Successfully installed numpy scipy scikit-learn Cleaning up... (sklearn-0.16b1)0 [~]$ python -c "import sklearn; print(sklearn.__version__)" 0.16-git ```
[2015-03-07T12:40:30.894Z] <541a528b163965c9bc2053de> However the version number is not good
[2015-03-07T12:42:08.832Z] <541a528b163965c9bc2053de> Actually it's my bad, it picked up the wrong wheel (because of the old version  number 0.16-git that is considered more recent than 0.16.b1)
[2015-03-07T12:42:58.770Z] <541a528b163965c9bc2053de> We won't have the problem when we upload on pypi as we won't upload that 0.16-git wheel
[2015-03-07T12:44:11.781Z] <541a528b163965c9bc2053de> If I fix the version of scikit-learn, it works: ``` (sklearn-0.16b1)0 [~]$ python -c "import sklearn; print(sklearn.__version__)" 0.16-git (sklearn-0.16b1)0 [~]$ pip uninstall -y scikit-learn Uninstalling scikit-learn:   Successfully uninstalled scikit-learn (sklearn-0.16b1)0 [~]$ pip install -f http://wheels.scipy.org scikit-learn==0.16b1 Downloading/unpacking scikit-learn==0.16b1   http://wheels.scipy.org uses an insecure transport scheme (http). Consider using https if wheels.scipy.org has it available   Downloading scikit_learn-0.16b1-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (5.0MB): 5.0MB downloaded   Storing download in cache at ./.pip/cache/http%3A%2F%2Fwheels.scipy.org%2Fscikit_learn-0.16b1-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl Installing collected packages: scikit-learn Successfully installed scikit-learn Cleaning up... (sklearn-0.16b1)0 [~]$ python -c "import sklearn; print(sklearn.__version__)" 0.16b1 ```
[2015-03-07T12:44:33.102Z] <541a528b163965c9bc2053de> I am launching the tests now
[2015-03-07T12:48:37.808Z] <541a528b163965c9bc2053de> All tests pass with the 0.16b1 wheel on my OSX laptop
[2015-03-07T12:49:28.269Z] <541a528b163965c9bc2053de> On windows on the other hand, the wheels were not uploaded because the tests are broken: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/history
[2015-03-07T12:50:01.680Z] <541a528b163965c9bc2053de> They have been broken for a while and I had not noticed
[2015-03-07T12:51:44.706Z] <541a528b163965c9bc2053de> Here is the error message: ``` [00:15:09] ====================================================================== [00:15:09] FAIL: Test that scorers support sample_weight or raise sensible errors [00:15:09] ---------------------------------------------------------------------- [00:15:09] Traceback (most recent call last): [00:15:09]   File "C:\Python34-x64\lib\site-packages\nose\case.py", line 198, in runTest [00:15:09]     self.test(*self.arg) [00:15:09]   File "C:\Python34-x64\lib\site-packages\sklearn\utils\testing.py", line 300, in wrapper [00:15:09]     return fn(*args, **kwargs) [00:15:09]   File "C:\Python34-x64\lib\site-packages\sklearn\metrics\tests\test_score_objects.py", line 343, in test_scorer_sample_weight [00:15:09]     "{2}".format(name, weighted, unweighted)) [00:15:09] AssertionError: 0.29999999999999999 == 0.29999999999999999 : scorer recall_samples behaves identically when called with sample weights: 0.3 vs 0.3 [00:15:09]  [00:15:09] ---------------------------------------------------------------------- ```
[2015-03-07T12:55:41.774Z] <541a528b163965c9bc2053de> I created this to track it: #4358
[2015-03-07T13:01:01.210Z] <541a528b163965c9bc2053de> I pushed a fix for master (hopefully)
[2015-03-07T13:02:54.338Z] <541a528b163965c9bc2053de> Apparently you did not push the 0.16.X branch to the repo. I cannot cherry-pick the fix (c23d4f31a3fcd7b24e46d46df6f2d274a839b201) to get it into the 0.16.X branch.
[2015-03-07T17:21:10.794Z] <54d4a1d6db8155e6700f853b> huh, pretty sure I pushed the 0.16.X branch. 
[2015-03-07T17:21:33.535Z] <54d4a1d6db8155e6700f853b> the tag is in the branch
[2015-03-07T17:22:37.610Z] <54d4a1d6db8155e6700f853b> hum ok guess I didn't push it. I pushed with --tags, apparently that only pushes the taggs
[2015-03-07T17:24:30.468Z] <54d4a1d6db8155e6700f853b> so which branch is this commit in? 09dc09a1e9d9088c2cb783c818980f5509d77a11
[2015-03-07T17:36:16.930Z] <54d4a1d6db8155e6700f853b> fixed it, I think
[2015-03-07T17:37:45.690Z] <541a528b163965c9bc2053de> @amueller I fixed #4358
[2015-03-07T17:38:11.259Z] <541a528b163965c9bc2053de> it was a missing `random_state`, do you want me to do the backport?
[2015-03-07T17:38:25.675Z] <54d4a1d6db8155e6700f853b> yeah, go ahead. the branch should be there now.
[2015-03-07T17:48:34.737Z] <541a528b163965c9bc2053de> yes I see it thanks!
[2015-03-07T17:50:20.407Z] <541a528b163965c9bc2053de> pushed
[2015-03-07T17:50:31.184Z] <541a528b163965c9bc2053de> let's wait for appveyor to build the wheels
[2015-03-07T17:51:16.904Z] <54d4a1d6db8155e6700f853b> btw, where is the continuous integration on appveyor? I'm sure there is a badge for that so we can see when it breaks
[2015-03-07T17:51:38.152Z] <541a528b163965c9bc2053de> https://ci.appveyor.com/project/sklearn-ci/scikit-learn/
[2015-03-07T17:53:31.972Z] <541a528b163965c9bc2053de> I have to go offline now. I might get back online tomorrow evening Paris time. If we are both online at that point we can push the release to PyPI together. Otherwise on monday. If the windows wheels are all generated correctly and you feel confident to use the upload-all command of the wheelhouse-uploader tool, feel free to do it before that.
[2015-03-07T17:55:35.822Z] <54d4a1d6db8155e6700f853b> Ok, I'll check back tomorrow, not gonna do anything today I think
[2015-03-07T17:56:06.219Z] <541a528b163965c9bc2053de> ok have a nice WE then :)
[2015-03-07T17:56:24.459Z] <54d4a1d6db8155e6700f853b> you too!
[2015-03-07T18:14:36.116Z] <54d4a1d6db8155e6700f853b> I think I would need to login to get the badge url
[2015-03-07T18:20:37.109Z] <54d4a1d6db8155e6700f853b> well we can use shields: https://img.shields.io/appveyor/ci/sklearn-ci/scikit-learn/master.svg
[2015-03-08T13:34:27.146Z] <5474d9eadb8155e6700d8178> spectral embedding doesn't accept lists... Should that be considered an issue?
[2015-03-08T21:21:13.322Z] <54d4a1d6db8155e6700f853b> the function or the class?
[2015-03-08T21:38:54.528Z] <5474d9eadb8155e6700d8178> the `fit` method I had meant
[2015-03-08T21:40:24.105Z] <54d4a1d6db8155e6700f853b> are you sure? That should be a common test. It might be that the common test doesn't cover clustering yet. Then this should be fixed.
[2015-03-08T21:43:25.802Z] <5474d9eadb8155e6700d8178> Yes `SpectralEmbedding().fit([[1, 2]])` doesn't work... Ok I'll fix it and add tests for that...
[2015-03-09T08:18:12.230Z] <541a528b163965c9bc2053de> SpectralEmbedding is neither a clustering nor or a classifier nor a transformer, just and estimator. This is probably the reason it's not caught by any of the common tests.
[2015-03-09T12:03:57.453Z] <541a528b163965c9bc2053de> Ok all 0.16b1 wheels have been properly generated by the CI workers. To fetch them all: ``` pip install wheelhouse-uploader cd scikit-learn git checkout 0.16.X python setup.py fetch_artifacts ```
[2015-03-09T12:04:28.870Z] <541a528b163965c9bc2053de> I am now launching a windows VM to test the windows wheels manually with the latest versions of numpy and scipy
[2015-03-09T12:15:54.429Z] <54d4a1d6db8155e6700f853b> But the the test for lists should be in ``test_non_meta_estimators`` which tests everything
[2015-03-09T12:21:50.410Z] <541a528b163965c9bc2053de> But the checks that check for list data are:     check_clustering,     check_regressors_train,     check_transformer, ...
[2015-03-09T12:32:48.858Z] <54d4a1d6db8155e6700f853b> yeah that is bad
[2015-03-09T12:33:14.422Z] <54d4a1d6db8155e6700f853b> pretty sure it can be done in a general way
[2015-03-09T12:35:59.437Z] <541a528b163965c9bc2053de> the problem is that to call fit on a list we need to know the structure of y and values that yield fast yet non-crashing fit calls.
[2015-03-09T12:36:10.859Z] <541a528b163965c9bc2053de> but it's probably doable as you said
[2015-03-09T12:43:42.692Z] <54d4a1d6db8155e6700f853b> what are the VMs doing? Btw, is appveyor only building for tags? or is it also doing continuous integration?
[2015-03-09T12:47:35.393Z] <541a528b163965c9bc2053de> appveyor builds everything pushed to the main repo (master, branches and tags)
[2015-03-09T12:48:59.034Z] <541a528b163965c9bc2053de> I have updated the wiki to add the commands to fetch and upload the wheels.
[2015-03-09T12:49:56.515Z] <541a528b163965c9bc2053de> I still need to run the tests manually on windows, both with manually installed numpy and scipy and once with christoph gohlke's packages for numpy and scipy.
[2015-03-09T12:50:16.750Z] <541a528b163965c9bc2053de> once this is done we should be able to push 0.16b1 to PyPI
[2015-03-09T12:51:13.505Z] <54d4a1d6db8155e6700f853b> cool :)
[2015-03-09T12:51:45.116Z] <54d4a1d6db8155e6700f853b> we should also add the appveyor shields to the readme, then. Or is there any notification if it breaks?
[2015-03-09T12:52:29.817Z] <541a528b163965c9bc2053de> I don't really understand the notification configuration but I do receive emails. I don't know who else receive them when it breaks.
[2015-03-09T12:52:52.330Z] <541a528b163965c9bc2053de> you did not receive any appveyor notification in the past?
[2015-03-09T12:53:10.459Z] <54d4a1d6db8155e6700f853b> no
[2015-03-09T12:53:30.821Z] <541a528b163965c9bc2053de> maybe we could create a new SF mailing list and find a way to authorize the appveyor bot to send email to it.
[2015-03-09T12:53:55.380Z] <541a528b163965c9bc2053de> but let me finish the windows testing first.
[2015-03-09T12:54:36.168Z] <541a528b163965c9bc2053de> @amueller can you please try to fetch the artifacts on your workstation with the previous commands I posted to check that it works?
[2015-03-09T13:07:40.161Z] <54d4a1d6db8155e6700f853b> the wheels shure
[2015-03-09T13:07:41.837Z] <54d4a1d6db8155e6700f853b> sure
[2015-03-09T13:09:39.454Z] <54d4a1d6db8155e6700f853b> running fetch_artifacts ValueError: unknown url type:  
[2015-03-09T13:09:52.749Z] <54d4a1d6db8155e6700f853b> I gotta run to the office now, I'll be there in 30 minutes
[2015-03-09T13:11:35.595Z] <541a528b163965c9bc2053de> ok
[2015-03-09T13:42:44.775Z] <54d4a1d6db8155e6700f853b> there :) 
[2015-03-09T13:44:34.235Z] <541a528b163965c9bc2053de> alright, can you try again and paste the full traceback you get?
[2015-03-09T13:45:05.186Z] <541a528b163965c9bc2053de> FYI, I run the tests on windows + Python 3.4 64bit + cgohlke's numpy and scipy and all tests pass
[2015-03-09T13:45:28.953Z] <541a528b163965c9bc2053de> Now trying with windows + Python 2.7.9 32 bit + official numpy and scipy from sourceforge
[2015-03-09T13:45:40.094Z] <541a528b163965c9bc2053de> looks good so far
[2015-03-09T13:46:08.220Z] <54d4a1d6db8155e6700f853b> http://pastebin.com/uX1Ccr39
[2015-03-09T13:46:17.385Z] <54d4a1d6db8155e6700f853b> ok.
[2015-03-09T13:47:04.782Z] <541a528b163965c9bc2053de> have you the latest version of wheelhouse-uploader ?
[2015-03-09T13:47:09.688Z] <54d4a1d6db8155e6700f853b> just pip-installed
[2015-03-09T13:47:42.215Z] <541a528b163965c9bc2053de> all tests pass for windows + Python 2.7.9 32 bit + official numpy and scipy from sourceforge
[2015-03-09T13:47:53.165Z] <541a528b163965c9bc2053de> let me try with Python 2.7
[2015-03-09T13:49:03.324Z] <54d4a1d6db8155e6700f853b> looks like there is a non-deterministic failure in lle on windows: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.547/job/r4p8ftc1v8f4x7kk
[2015-03-09T13:49:21.442Z] <54d4a1d6db8155e6700f853b> https://ci.appveyor.com/project/sklearn-ci/scikit-learn/history
[2015-03-09T13:51:11.681Z] <54d4a1d6db8155e6700f853b> so somewhere in the wheelhouse-uploader there is a url "#"
[2015-03-09T13:51:12.170Z] <54d4a1d6db8155e6700f853b> http://pastebin.com/SY0L6hQE
[2015-03-09T13:55:35.869Z] <541a528b163965c9bc2053de> I can reproduce the wheelhouse-uploader crash on Python 2.7
[2015-03-09T13:55:40.832Z] <541a528b163965c9bc2053de> will have a look
[2015-03-09T13:58:54.603Z] <54d4a1d6db8155e6700f853b> MacPython is for releases only, no CI, right?
[2015-03-09T14:00:11.959Z] <541a528b163965c9bc2053de> yes
[2015-03-09T14:00:44.507Z] <541a528b163965c9bc2053de> we could setup a full OSX CI bot but that's more work to do.
[2015-03-09T14:00:52.667Z] <54d4a1d6db8155e6700f853b> ok
[2015-03-09T14:01:13.989Z] <541a528b163965c9bc2053de> I think it's possible to configure travis to have both linux and OSX in the same .travis.yml configuration.
[2015-03-09T14:02:14.700Z] <541a528b163965c9bc2053de> We would probably need to change the adapt the scripts though. and honestly when all the tests pass on various python / numpy / scipy versions, they almost always pass under OSX as well
[2015-03-09T14:02:22.074Z] <541a528b163965c9bc2053de> this is not the case for windows ;)
[2015-03-09T14:02:59.415Z] <541a528b163965c9bc2053de> the remaining windows heisenfailures will be tedious to hunt down
[2015-03-09T14:03:10.812Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4364
[2015-03-09T14:31:25.560Z] <54d4a1d6db8155e6700f853b> are you uploading to pipy? Or are you debugging the wheels? I don't really have much experience with that
[2015-03-09T15:09:51.836Z] <541a528b163965c9bc2053de> sorry I was discussing a fix for a joblib with a colleague
[2015-03-09T15:10:20.231Z] <541a528b163965c9bc2053de> joblib bug, the one with read_zfile / write_zfile that is broken when switching from py2 to py3
[2015-03-09T15:10:26.458Z] <541a528b163965c9bc2053de> we now understand the pbm :)
[2015-03-09T15:10:34.156Z] <541a528b163965c9bc2053de> ok so back to the release
[2015-03-09T15:10:57.002Z] <541a528b163965c9bc2053de> I can upload the wheels and fix wheelhouse uploader for python 2.7 afterwards if you want
[2015-03-09T15:11:41.586Z] <541a528b163965c9bc2053de> Let me generate and test the .tar.gz first 
[2015-03-09T15:28:38.638Z] <54d4a1d6db8155e6700f853b> I don't think the wheelhouse uploader is really important. I think we should go ahead and upload to pipy
[2015-03-09T15:30:06.237Z] <541a528b163965c9bc2053de> I am running the tests on a freshly installed .tar.gz generated with sdist (after a make clean in the doc folder) on linux
[2015-03-09T15:30:22.074Z] <541a528b163965c9bc2053de> if everything is well I will launch the upload
[2015-03-09T15:30:42.913Z] <541a528b163965c9bc2053de> ``` Ran 4045 tests in 126.704s  OK (SKIP=20) ```
[2015-03-09T15:31:08.800Z] <54d4a1d6db8155e6700f853b> cool. just doing the same on my box ;)
[2015-03-09T15:31:19.985Z] <54d4a1d6db8155e6700f853b> (running the clean sdist, not uploading, that is)
[2015-03-09T15:32:41.720Z] <541a528b163965c9bc2053de> upload under progress...
[2015-03-09T15:33:35.519Z] <541a528b163965c9bc2053de> https://pypi.python.org/pypi/scikit-learn/0.16b1
[2015-03-09T15:36:33.652Z] <541a528b163965c9bc2053de> sending an announcement email on the mailing list
[2015-03-09T15:46:17.795Z] <54d4a1d6db8155e6700f853b> cool, thanks :)
[2015-03-09T15:47:05.926Z] <54d4a1d6db8155e6700f853b> I should have added a new 0.17 section in the whatsnew on master... well..
[2015-03-09T15:47:58.498Z] <54d4a1d6db8155e6700f853b> should we remove the 0.17 deprecated things (like the HMM) now or wait until the release?
[2015-03-09T15:58:36.455Z] <541a528b163965c9bc2053de> As you wish for hmm.
[2015-03-09T15:59:07.803Z] <541a528b163965c9bc2053de> +1 to add the 0.17 section on master.
[2015-03-09T15:59:58.491Z] <541a528b163965c9bc2053de> I am in the shuttle now. Will go offline otherwise I get sick.
[2015-03-09T16:00:23.149Z] <541a528b163965c9bc2053de> Do want to tweet?
[2015-03-09T16:28:08.444Z] <54d4a1d6db8155e6700f853b> I tweeted :)
[2015-03-09T16:52:43.022Z] <5474d9eadb8155e6700d8178> Cheers for the 0.16b :beers:  
[2015-03-09T17:33:06.068Z] <541a528b163965c9bc2053de> :beers:
[2015-03-09T18:20:57.167Z] <5474d9eadb8155e6700d8178> In [this cython code](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/neighbors/binary_tree.pxi#L1054) the `BinaryTree` seems to expose the metric as an attribute `dist_metric`. But `dist_metric` attribute seems to be absent from the `BallTree` instance... ``` In [7]: b. b.data                   b.get_tree_stats         b.node_bounds            b.query_radius           b.valid_metrics           b.get_arrays             b.idx_array              b.node_data              b.reset_n_calls           b.get_n_calls            b.kernel_density         b.query                  b.two_point_correlation   ``` Not sure where exactly I misunderstood :/
[2015-03-09T18:26:51.281Z] <54d4a1d6db8155e6700f853b> sorry, I'm not so familiar with that module, and I know Jake did some weird inheritance tricks there
[2015-03-09T18:34:52.390Z] <5474d9eadb8155e6700d8178> Okay! thanks.. I think its got something to do with cdef classes ... will look into it! :)
[2015-03-09T20:30:39.817Z] <5474d9eadb8155e6700d8178> Hmm... That requires a `public` keyword to make those attributes accessible to the python namespace!
[2015-03-10T18:10:08.760Z] <5474d9eadb8155e6700d8178> Now that we have appveyor tests, there is an appveyor integration for gitter that we could configure!
[2015-03-10T18:10:45.046Z] <54d4a1d6db8155e6700f853b> we've had appveyor tests for a long time ;)
[2015-03-10T18:10:48.900Z] <54d4a1d6db8155e6700f853b> we just didn't look at them
[2015-03-10T18:14:13.090Z] <5474d9eadb8155e6700d8178> Oh! I didn't know that :)
[2015-03-10T18:37:58.225Z] <54d4a1d6db8155e6700f853b> what needs to be done for integration?
[2015-03-10T19:00:26.600Z] <5474d9eadb8155e6700d8178> Try Settings --> Integrations --> appveyor. Use this webhook https://webhooks.gitter.im/e/0dc8e57cd38105aeb1b4 :)
[2015-03-10T19:01:04.028Z] <5474d9eadb8155e6700d8178> @ragv wonders who added the webhook :O
[2015-03-10T19:01:23.784Z] <5474d9eadb8155e6700d8178> `/me` messages look too large in gitter :/
[2015-03-10T19:02:41.001Z] <5474d9eadb8155e6700d8178> @ogrisel Seems to have added that from the git blame... I think he would have integrated it already (why aren't we getting notifications then?) Hmm... 
[2015-03-10T19:15:50.602Z] <5474d9eadb8155e6700d8178> BTW there seems to be a chrome app for gitter for linux users - https://chrome.google.com/webstore/detail/gitter/ldhcdmnhbafhckhidlhdbeekpifobpdc
[2015-03-10T20:32:05.404Z] <54d4a1d6db8155e6700f853b> landscape.io does not seem to be very mature yet. but could be cool and carl is pretty responsive
[2015-03-10T20:38:12.932Z] <52f10c205e986b0712ef525f> hello! yes, seems there are still several kinks to work out in the PR comparison logic
[2015-03-10T20:38:20.539Z] <52f10c205e986b0712ef525f> working on it!
[2015-03-10T20:46:22.978Z] <54d4a1d6db8155e6700f853b> haha didn't know you were here. Well your help is much appreciated!
[2015-03-10T20:46:48.459Z] <52f10c205e986b0712ef525f> @ragv just sent me an invite to the chatroom, probably to stop me cluttering up PR comments :)
[2015-03-10T20:47:18.708Z] <54d4a1d6db8155e6700f853b> :) comment whereever you like
[2015-03-10T20:48:36.515Z] <5474d9eadb8155e6700d8178> @carlio Not at all :) I added you so we could ping and trouble you whenever we hit a snag with landscape :p :P Thanks for the nice work!
[2015-03-10T20:50:20.278Z] <54d4a1d6db8155e6700f853b> @carlio so does a push to a PR trigger a restart? I realize there would be some delay, though on the master branch landscape.io was pretty fast. Coveralls takes like a day to visit a PR if ever
[2015-03-10T20:57:36.902Z] <52f10c205e986b0712ef525f> @amueller Yes, Landscape gets a GitHub push hook to trigger the check, so it should start within a few seconds. It's a bit wobbly right now. It also polls every 5 minutes or so (legacy behaviour for before I set up the push hooks to trigger on PRs)
[2015-03-10T21:01:24.093Z] <5474d9eadb8155e6700d8178> Does this (push to trigger) work for the old PRs too?
[2015-03-10T21:02:41.276Z] <52f10c205e986b0712ef525f> kinda, if they get a new pull request than yes
[2015-03-10T21:02:44.811Z] <52f10c205e986b0712ef525f> er, sorry
[2015-03-10T21:02:47.798Z] <52f10c205e986b0712ef525f> if they get a new commit
[2015-03-10T21:03:08.488Z] <5474d9eadb8155e6700d8178> Thats awesome! I'll try out ;)
[2015-03-10T21:05:50.098Z] <54d4a1d6db8155e6700f853b> This one didn't get a report for half an hour: https://github.com/scikit-learn/scikit-learn/pull/4381 still pending or something up there?
[2015-03-10T21:06:09.999Z] <54d4a1d6db8155e6700f853b> slow travis today :-/
[2015-03-10T21:08:18.647Z] <54d4a1d6db8155e6700f853b> maybe we should ask around if someone wants to pay 250 USD / month for more travis power ^^
[2015-03-10T21:08:20.728Z] <52f10c205e986b0712ef525f> I sort of broke it a bit but it's running now
[2015-03-10T21:16:21.733Z] <5474d9eadb8155e6700d8178> 
[2015-03-10T21:16:34.599Z] <5474d9eadb8155e6700d8178> @amueller I think you can manually restart it... In the travis build page there is an option to log in, once logged in you should get the option for restarting it...  
[2015-03-10T21:18:20.861Z] <5474d9eadb8155e6700d8178> incase you didn't know that already...
[2015-03-10T21:20:59.591Z] <54d4a1d6db8155e6700f853b> @ragv I know I can restart travis. The problem with travis is not that it is not restarting, the problem is that is is queueing.
[2015-03-10T21:22:02.764Z] <5474d9eadb8155e6700d8178> Ah... okay! Sorry for the noise!
[2015-03-10T21:48:11.722Z] <54d4a1d6db8155e6700f853b> closing issues as non-issues is fun. anyhow, I gotta run. ttyl
[2015-03-10T21:48:23.487Z] <54d4a1d6db8155e6700f853b> btw, which time zone are you on @ragv?
[2015-03-10T21:48:43.132Z] <5474d9eadb8155e6700d8178> See ya! I am in India GMT+05:30 :D
[2015-03-10T22:00:40.032Z] <5474d9eadb8155e6700d8178> Just throwing in a minor suggestion! We could perhaps have another CI build and test in parallel... like codeship / wercker... Let me know your opinion about that when you get online again!! both seem to be very easy to setup!
[2015-03-10T22:01:16.717Z] <52f10c205e986b0712ef525f> (I have nothing to do with this repository but I'm a big fan of circle-ci)
[2015-03-10T22:01:57.650Z] <5474d9eadb8155e6700d8178> Thanks for the suggestion! :)
[2015-03-11T14:26:09.153Z] <54d4a1d6db8155e6700f853b> @ogrisel why b2?
[2015-03-11T14:26:22.069Z] <54d4a1d6db8155e6700f853b> any major issues?
[2015-03-11T14:29:17.302Z] <541a528b163965c9bc2053de> no, it's just that if we keep on backporting stuff to the 0.16.X branch, I don't want the artifacts generated by the CI bots to be named 0.16b1 to avoid confusion.
[2015-03-11T14:30:15.717Z] <54d4a1d6db8155e6700f853b> ok
[2015-03-11T14:31:08.516Z] <54d4a1d6db8155e6700f853b> but the artifacts are only generated for tags, right?
[2015-03-11T14:35:19.913Z] <541a528b163965c9bc2053de> Our current configuration on appveyor generates them continuously for everything and they get uploaded on to http://windows-wheels.scikit-learn.org . But we never documented that URL publicly until now. It's just useful to help us automate the releases.
[2015-03-11T14:36:44.292Z] <541a528b163965c9bc2053de> What I would like to have is all tags get uploaded to http://wheels.scipy.org (both OSX and windows wheels) while development wheels (without tags) get uploaded to a separate container (e.g. http://wheels-dev.scikit-learn.og or something).
[2015-03-11T14:37:35.338Z] <541a528b163965c9bc2053de> but never found the time to do so so far.
[2015-03-11T14:42:07.763Z] <541a528b163965c9bc2053de> BTW, I fixed the wheelhouse-uploader bug under Python 2. If you want to try again: ``` pip install -U wheelhouse-uploader cd /path/to/scikit-learn python setup.py fetch_artifacts ```
[2015-03-11T17:07:31.338Z] <54d4a1d6db8155e6700f853b> today is my meeting day, don't expect much ;)
[2015-03-13T14:39:39.619Z] <541a528b163965c9bc2053de> Hi @amueller, I fixed a bug in @larsmans PR #4157 to optimize DBSCAN. It works great in my experiment. If we merge it quickly, I would like to get it in 0.16.
[2015-03-13T22:14:32.227Z] <54d4a1d6db8155e6700f853b> Fine with me :)
[2015-03-14T07:36:21.748Z] <5474d9eadb8155e6700d8178> since `svd_flip` is public, do you also want `_deterministic_vector_sign_flip` to be made public too, or I'll leave it as such?
[2015-03-14T12:51:31.576Z] <541a528b163965c9bc2053de> keep it private
[2015-03-14T12:51:48.734Z] <541a528b163965c9bc2053de> svd_flip should probably not have been private in the first place.
[2015-03-14T12:52:24.605Z] <541a528b163965c9bc2053de> BTW it's probably better to have this kind of specific technical discussions in the comment threads of the issue itself rather than on gitter
[2015-03-14T12:52:43.034Z] <5474d9eadb8155e6700d8178> Thanks! and yes sure!
[2015-03-16T16:04:02.599Z] <54d4a1d6db8155e6700f853b> we screwed up with the GSOC registration. I didn't remember you had to fill in melange and the form :-/
[2015-03-17T14:34:19.147Z] <541a528b163965c9bc2053de> yeah I forgot as well and I have missed many GSoC related emails...
[2015-03-17T14:41:48.545Z] <54d4a1d6db8155e6700f853b> more importantly, we were not listed on the PSF page. we are now, as I filled out the form as mod
[2015-03-17T14:44:12.789Z] <54d4a1d6db8155e6700f853b>  @ogrisel should we wait for larsmans to pull your changes for the DBSCAN
[2015-03-17T14:44:34.935Z] <541a528b163965c9bc2053de> I would like to review the dtype=object comment first.
[2015-03-17T14:44:50.830Z] <541a528b163965c9bc2053de> check why this is necessary, it's not clear to me
[2015-03-17T14:45:10.173Z] <54d4a1d6db8155e6700f853b> I can explain
[2015-03-17T14:45:43.879Z] <54d4a1d6db8155e6700f853b> before, when all the points had the same number of neighbors, an array of dtype int with shape (n_samples, n_neibhors) was returned.
[2015-03-17T14:46:50.405Z] <54d4a1d6db8155e6700f853b> sorry (n_samples, n_neighbors, n_features) I guess (because the points are returned)
[2015-03-17T14:47:02.214Z] <541a528b163965c9bc2053de> ok, so indeed it can be simplified now that all the neighbors models are consistent in that regard.
[2015-03-17T14:47:09.623Z] <54d4a1d6db8155e6700f853b> for actual data, that never happens and was an annoying special case in the API. Normaly an array of dtype object with shape (n_samples,) is returned
[2015-03-17T14:47:11.017Z] <541a528b163965c9bc2053de> I will simplify it in my branch
[2015-03-17T14:47:11.656Z] <54d4a1d6db8155e6700f853b> exactly
[2015-03-17T14:48:24.067Z] <541a528b163965c9bc2053de> Also I would have liked to get the opinion of @kno10 w.r.t. my last comments on https://github.com/scikit-learn/scikit-learn/pull/4334 before merging by rebased #4157.
[2015-03-17T14:49:20.971Z] <54d4a1d6db8155e6700f853b> btw, if you have any time, https://github.com/scikit-learn/scikit-learn/pull/4286 (polynomial features) is also ripe for merge
[2015-03-17T14:49:54.754Z] <54d4a1d6db8155e6700f853b> ok, let's wait for @kno10 but I think the cython version looks good.
[2015-03-17T14:50:04.552Z] <541a528b163965c9bc2053de> yeah that was on my todo list but go side tracked by Inria related activities
[2015-03-17T14:50:17.673Z] <541a528b163965c9bc2053de> I agree on the cython version
[2015-03-17T14:50:32.612Z] <54d4a1d6db8155e6700f853b> happens. I gotta do taxes and NYU stuff today, too. I did some review or the t-SNE
[2015-03-17T14:51:13.826Z] <54d4a1d6db8155e6700f853b> I'm a bit bummed no-one wants to review the decision_function for the sparse SVC ^^
[2015-03-17T14:51:54.995Z] <541a528b163965c9bc2053de> :)
[2015-03-17T14:54:09.817Z] <54d4a1d6db8155e6700f853b> did you see that yaroptik reported the OMPCV error on many debian machines?
[2015-03-17T14:55:44.286Z] <541a528b163965c9bc2053de> I will asked @scharron to add a comment to report that he tested your PR successfully.
[2015-03-17T14:57:21.520Z] <54d4a1d6db8155e6700f853b> who is that?
[2015-03-17T14:58:07.146Z] <541a528b163965c9bc2053de> > did you see that yaroptik reported the OMPCV error on many debian machines?  Yes, I did not have the time to look into it further. So this is a real problem, and not just for travis (we have the check_skip_travis skip for that ATM).
[2015-03-17T14:58:34.735Z] <541a528b163965c9bc2053de> IMO it's not a high priority issue though as I don't know anybody who runs sklearn on 32bit linux.
[2015-03-17T14:59:04.940Z] <54d4a1d6db8155e6700f853b> is travis 32 bit?
[2015-03-17T14:59:05.743Z] <541a528b163965c9bc2053de> it could be useful in mobile phones but not sure the OMPCV is that useful on an android phone anyway :)
[2015-03-17T14:59:10.869Z] <541a528b163965c9bc2053de> apparently
[2015-03-17T14:59:11.035Z] <54d4a1d6db8155e6700f853b> haha
[2015-03-17T15:04:02.342Z] <541a528b163965c9bc2053de> On the GSoC page I think we should have a proposal for general speed and memory improvements throughout the code base
[2015-03-17T15:05:04.427Z] <541a528b163965c9bc2053de> I prefer GSoC projects that contributes many small improvements rather a big monolithic chunk of code
[2015-03-17T15:05:45.711Z] <541a528b163965c9bc2053de> but we would need to identify chunks of code that are both useful and lack optimization
[2015-03-17T15:07:21.633Z] <54d4a1d6db8155e6700f853b> one the one hand I agree, because it makes it easier to review / merge parts.
[2015-03-17T15:07:47.584Z] <54d4a1d6db8155e6700f853b> on the other hand, that might make it harder for the student to focus, and also they have to dig through a lot of code
[2015-03-17T15:08:19.412Z] <54d4a1d6db8155e6700f853b> There are a lot of places were we are not efficient. For example RFECV and univariate selection, ARD
[2015-03-17T15:08:26.551Z] <54d4a1d6db8155e6700f853b> someone could pick up my old elkans k-means
[2015-03-17T15:14:10.235Z] <541a528b163965c9bc2053de> indeed
[2015-03-17T15:15:41.901Z] <541a528b163965c9bc2053de> the focus issue is a good point. It worked well with @MechCoder and Hamzeh though.
[2015-03-17T15:16:27.317Z] <541a528b163965c9bc2053de> Arguably the GSoC topic of @MechCoder was more well-defined (improve the penalized linear models algorithms)
[2015-03-17T15:17:21.633Z] <54d4a1d6db8155e6700f853b> I wasn't very present, so I can't say how well it worked. I'd take your word for it ;)
[2015-03-17T15:18:08.642Z] <54d4a1d6db8155e6700f853b> If we give a somewhat definite list, maybe with priorities or temporal sequence, the focus might be less of an issue
[2015-03-17T15:21:59.855Z] <54d4a1d6db8155e6700f853b> what was the virtual machine you usually use for testing?
[2015-03-17T15:27:46.122Z] <541a528b163965c9bc2053de> I don't remember, @kastnerkyle did those tests IIRC.
[2015-03-17T15:28:09.417Z] <541a528b163965c9bc2053de> Ah you mean in general?
[2015-03-17T15:28:54.669Z] <541a528b163965c9bc2053de> Most of the time I used docker (hence I cannot test 32 bit linux stuff as my host kernel is 64 bit). Otherwise I use rackspace for windows tests.
[2015-03-17T15:29:15.353Z] <541a528b163965c9bc2053de> on my mac I use boot2docker with virtualbox
[2015-03-17T15:29:27.316Z] <541a528b163965c9bc2053de> I think it's a 64 bit linux kernel as well.
[2015-03-17T15:29:47.233Z] <541a528b163965c9bc2053de> It's possible to use vagrant / virtualbox to test 32bit linux stuff though,.
[2015-03-17T15:29:58.388Z] <54d4a1d6db8155e6700f853b> vagrant was the one I wast trying to think of
[2015-03-17T15:30:03.443Z] <54d4a1d6db8155e6700f853b> I always forget the name
[2015-03-17T17:17:15.901Z] <54d4a1d6db8155e6700f853b> reproduced it
[2015-03-17T17:47:28.992Z] <54d4a1d6db8155e6700f853b> once. I could reproduce the ompcv failure once. Great.
[2015-03-17T17:48:47.710Z] <541a528b163965c9bc2053de> ....
[2015-03-17T17:48:56.395Z] <541a528b163965c9bc2053de> malediction
[2015-03-17T17:50:12.904Z] <54d4a1d6db8155e6700f853b> thanks for the dbscan merge
[2015-03-17T17:50:18.410Z] <541a528b163965c9bc2053de> I added a what's new entry and did the backport to 0.16.X for the cythonized DBSCAN
[2015-03-17T17:50:22.759Z] <541a528b163965c9bc2053de> :)
[2015-03-17T17:51:01.280Z] <54d4a1d6db8155e6700f853b> saw it. sweet.
[2015-03-17T17:51:17.910Z] <54d4a1d6db8155e6700f853b> so you want to do the backports directly? There might have been other things to backport
[2015-03-17T17:51:18.809Z] <541a528b163965c9bc2053de> I think it's a great feature for 0.16. Based on feedback from various startup people, DBSCAN is very useful to clean geo data.
[2015-03-17T17:51:53.975Z] <541a528b163965c9bc2053de> I already cherry-picked the cython DBSCAN to 0.16.X.
[2015-03-17T17:52:31.328Z] <541a528b163965c9bc2053de> If you have other fixes / optim that have been merged to master, feel free to cherry-pick them to 0.16.X.
[2015-03-17T17:53:12.763Z] <541a528b163965c9bc2053de> We need to keep the what's new entry consistent between the 2 branches (master and 0.16.X though). It can be a hassle at times.
[2015-03-17T17:55:09.297Z] <54d4a1d6db8155e6700f853b> There were a couple of doc improvements that we could include in the release. I'll cherry pick them
[2015-03-17T17:55:34.208Z] <54d4a1d6db8155e6700f853b> the OVR decision function might also be good, as then we don't change behavior between releases
[2015-03-17T18:07:48.491Z] <541a528b163965c9bc2053de> ok
[2015-03-17T18:07:59.636Z] <541a528b163965c9bc2053de> I am off now. See you tomorrow.
[2015-03-17T18:08:10.344Z] <54d4a1d6db8155e6700f853b> alright. good night :)
[2015-03-17T19:18:39.625Z] <54d4a1d6db8155e6700f853b> ran the test 100k times, no issue. run ``make`` three times, reproduces.
[2015-03-17T21:03:48.308Z] <54d4a1d6db8155e6700f853b> I FIXED IT :beers:
[2015-03-17T21:05:07.290Z] <5474d9eadb8155e6700d8178> Awesome! :beers: :)
[2015-03-17T21:06:14.128Z] <54d4a1d6db8155e6700f853b> there is and "if scipy.__version__ >= 0.12" in the code. And we wonder why we can't reproduce....
[2015-03-17T21:06:18.161Z] <54d4a1d6db8155e6700f853b> *an
[2015-03-17T21:08:34.247Z] <5474d9eadb8155e6700d8178> Too close scrutiny :D ![image](https://cloud.githubusercontent.com/assets/9487348/6697615/cf03f120-cd17-11e4-9742-c629d3bf8b57.png) 
[2015-03-17T21:11:23.321Z] <5474d9eadb8155e6700d8178> Why does this doctest failure come up randomly? - https://travis-ci.org/scikit-learn/scikit-learn/jobs/54779847 (I think I saw it somewhere else too)
[2015-03-17T21:12:40.627Z] <54d4a1d6db8155e6700f853b> this is not doctests, it is tests
[2015-03-17T21:12:44.616Z] <54d4a1d6db8155e6700f853b> and why do you think it is randomly?
[2015-03-17T21:12:52.880Z] <54d4a1d6db8155e6700f853b> it says mixture of tabs and spaces
[2015-03-17T21:13:17.372Z] <54d4a1d6db8155e6700f853b> which is plausible because I edited it in some just set up virtual machine
[2015-03-17T21:15:34.261Z] <54d4a1d6db8155e6700f853b> ok gotta run. should be fixed now
[2015-03-17T21:38:49.980Z] <5474d9eadb8155e6700d8178> Ah... must be my mistake :) bye :)
[2015-03-18T14:48:15.759Z] <5385f2fe048862e761fa2d40> Can anyone explain to me how to implement Affinity Propogation in Map/Reduce? http://www.chinacloud.cn/upload/2015-01/15011111364805.pdf
[2015-03-18T14:48:24.137Z] <5385f2fe048862e761fa2d40> I don't really understand the paper
[2015-03-18T14:48:51.457Z] <5385f2fe048862e761fa2d40> and the English is pretty much well... chinese :P
[2015-03-18T14:54:56.108Z] <541a528b163965c9bc2053de> scikit-learn is not a community of mapreduce users so I doubt you will get good feedback on here. You might rather ask on a discussion forum with spark or mahout users. I am not sure that using the hadoop mareduce API is a good thing for iterative machine learning anyway. It's probably better to build upon higher level parallel construct like allreduce or the spark API in general.
[2015-03-18T14:55:49.325Z] <5385f2fe048862e761fa2d40> The thing is that I have a huge dataset and I don't want to use K-Means since that means I have to guess the optimal number of clusters each time
[2015-03-18T14:56:09.491Z] <541a528b163965c9bc2053de> Also if you still want to ask questions about the paper on a discussion forum, you should ask specific questions, otherwise you probably won't get any interesting answer.
[2015-03-18T14:56:23.851Z] <5385f2fe048862e761fa2d40> I have no idea where to start
[2015-03-18T14:56:38.915Z] <5385f2fe048862e761fa2d40> How do I adapt the existing algorithm to be parallel?
[2015-03-18T14:56:52.886Z] <541a528b163965c9bc2053de> Use minibatch kmeans on a subset with init_size=int(1e4) and batch_size=int(1e3)
[2015-03-18T14:56:53.682Z] <5385f2fe048862e761fa2d40> I'm not much of an ML guy but I'm trying to learn
[2015-03-18T14:59:00.312Z] <541a528b163965c9bc2053de> if you are trying to learn, start with smaller datasets (e.g. a random subset) where algo run fast. To learn stuff you will have to fail many times to learn from your mistakes. If each failures take days of cluster programming and execution you will learn slowly :) By working on a subset that fits in memory on your laptop you will learn much faster.
[2015-03-18T14:59:30.047Z] <5385f2fe048862e761fa2d40> But working on a subset of the data is meaningless
[2015-03-18T14:59:37.626Z] <5385f2fe048862e761fa2d40> I can't even work on 10,000 nodes
[2015-03-18T15:00:32.679Z] <541a528b163965c9bc2053de> Also your clustering will fail not because of the algorithm but because of the way you extract features and fail to normalize them, see for instance: https://www.youtube.com/watch?v=TC5cKYBZAeI
[2015-03-18T15:01:02.432Z] <541a528b163965c9bc2053de> > I can't even work on 10,000 nodes  What are "nodes"?
[2015-03-18T15:02:28.445Z] <541a528b163965c9bc2053de> > But working on a subset of the data is meaningless  I am not sure about that. If you are "not much of an ML guy", start with a smaller / simpler problem first.
[2015-03-18T15:03:04.765Z] <5385f2fe048862e761fa2d40> I asked our ML guy. Working with 10,000 data points is meaningless in my context
[2015-03-18T15:03:26.946Z] <5385f2fe048862e761fa2d40> nodes = data points in the matrix
[2015-03-18T15:03:44.603Z] <541a528b163965c9bc2053de> minibatch kmeans can work with millions of high dimensional points, as long as they fit in memory
[2015-03-18T15:04:01.882Z] <541a528b163965c9bc2053de> init_size is just a parameter for the subset used to initialize the centroids
[2015-03-18T15:04:37.789Z] <5385f2fe048862e761fa2d40> But I still have to optimize the number of clusters
[2015-03-18T15:05:02.375Z] <541a528b163965c9bc2053de> you will have to do that anyway, whatever the algorithm
[2015-03-18T15:05:28.585Z] <541a528b163965c9bc2053de> there is always at least one hyperparameter that controls directly or indirectly the number of clusters
[2015-03-18T15:06:09.182Z] <5385f2fe048862e761fa2d40> As far as I understand AF figures that out
[2015-03-18T15:08:01.519Z] <541a528b163965c9bc2053de> it does something by default that might or might not reflect what you expect to be a "good" number of clusters
[2015-03-18T15:08:23.178Z] <5385f2fe048862e761fa2d40> I'm working with geolocation data (x, y)
[2015-03-18T15:08:42.608Z] <5385f2fe048862e761fa2d40> I think that eucelidian distances is a good choice
[2015-03-18T15:08:50.953Z] <541a528b163965c9bc2053de> but hyperparameters such as "preference" in the scikit-learn implementation of AP will impact the clustering outcome
[2015-03-18T15:09:08.586Z] <541a528b163965c9bc2053de> yes +1 for euclidean distance for geo data.
[2015-03-18T15:09:15.312Z] <541a528b163965c9bc2053de> How many samples?
[2015-03-18T15:09:32.924Z] <5385f2fe048862e761fa2d40> 200 milion
[2015-03-18T15:10:45.399Z] <541a528b163965c9bc2053de> If you use scikit-learn master you might want to try DBSCAN on a 1M subset with eps the distance in meters of two points that are close enough to be considered part of a common cluster (assuming x and y are meters as well)
[2015-03-18T15:11:16.129Z] <541a528b163965c9bc2053de> the implementation of DBSCAN in sklearn 0.15.2 will be much to slow.
[2015-03-18T15:11:17.562Z] <5385f2fe048862e761fa2d40> x & y are coordinates
[2015-03-18T15:11:27.300Z] <54d4a1d6db8155e6700f853b> affinity propagation is not a great method imho. people rarely use it in practice I think, in particular not on such large data
[2015-03-18T15:11:58.463Z] <54d4a1d6db8155e6700f853b> dbscan or birch or any other method that selects the number of clusters are much likelier candidates
[2015-03-18T15:12:05.929Z] <541a528b163965c9bc2053de> > x & y are coordinates  I understand, but which unit? meters, km, miles, GPS degrees?
[2015-03-18T15:12:25.411Z] <5385f2fe048862e761fa2d40> GPS degrees
[2015-03-18T15:13:24.333Z] <541a528b163965c9bc2053de> they decide how much GPS degrees should be considered close points. Start with lower values to generate smaller clusters.
[2015-03-18T15:14:10.304Z] <541a528b163965c9bc2053de> Birch is probably a good candidate as well if you want to compress your 200M points into a smaller summary dataset.
[2015-03-18T15:14:13.900Z] <54d4a1d6db8155e6700f853b> btw @ogrisel if you have the time, it would be awesome if you could work through some of the MRG + 1 PRs. There is a ton of them
[2015-03-18T15:14:23.282Z] <541a528b163965c9bc2053de> But it's probably harder to use correctly.
[2015-03-18T15:14:31.753Z] <541a528b163965c9bc2053de> @amueller alright.
[2015-03-18T15:15:01.916Z] <54d4a1d6db8155e6700f853b> otherwise we keep duplicating fixes
[2015-03-18T15:15:04.595Z] <5385f2fe048862e761fa2d40> It's 200M unique points
[2015-03-18T15:16:59.940Z] <5385f2fe048862e761fa2d40> That's why I was looking at map/reduce
[2015-03-18T15:22:16.295Z] <541a528b163965c9bc2053de> ``` >>> 200e6 * 2 * 8 / 1e9 3.2 ```  3.2GB of double precision floats => it fits in memory
[2015-03-18T15:22:30.714Z] <541a528b163965c9bc2053de> minibatch kmeans and birch can eat it
[2015-03-18T15:22:31.312Z] <5385f2fe048862e761fa2d40> AF raises MemoryError
[2015-03-18T15:22:42.061Z] <541a528b163965c9bc2053de> yes AF is not scalable
[2015-03-18T15:22:58.165Z] <5385f2fe048862e761fa2d40> Unless you're able to run it on multiple nodes which makes it scalable
[2015-03-18T15:23:24.414Z] <541a528b163965c9bc2053de> I am pretty sure that minibatch kmeans will converge in less than an hour
[2015-03-18T15:23:42.075Z] <54d4a1d6db8155e6700f853b> @omerzimp why are you so set on AF?
[2015-03-18T15:23:51.403Z] <541a528b163965c9bc2053de> try on 1M first, look at the results (plot the clusters of on map)
[2015-03-18T15:23:55.283Z] <5385f2fe048862e761fa2d40> Because I like automatic things :P
[2015-03-18T15:24:06.466Z] <54d4a1d6db8155e6700f853b> it is a lot less automatic than any of the other methods
[2015-03-18T15:24:08.154Z] <5385f2fe048862e761fa2d40> And I really want to learn to apply ML on M/R
[2015-03-18T15:24:08.759Z] <541a528b163965c9bc2053de> it's not automatic, it's lying to you
[2015-03-18T15:24:09.130Z] <54d4a1d6db8155e6700f853b> it is really hard to tune
[2015-03-18T15:24:34.323Z] <541a528b163965c9bc2053de> k=10 for KMeans is as automatic as preference=median for AP
[2015-03-18T15:24:48.550Z] <54d4a1d6db8155e6700f853b> all clustering algorithms have parameters that influence the number of clusters. some are explicit, like k-means, some are implicit, as in mean-shift, dbscan and birch.
[2015-03-18T15:24:58.307Z] <541a528b163965c9bc2053de> exactly
[2015-03-18T15:25:06.363Z] <54d4a1d6db8155e6700f853b> only AF has the most non-intuitive parametrization of the implicit assumptions
[2015-03-18T15:25:26.941Z] <541a528b163965c9bc2053de> and sometimes you have "natural" clusters at differrent scales (nested clusters)
[2015-03-18T15:25:31.820Z] <541a528b163965c9bc2053de> in your data
[2015-03-18T15:25:48.216Z] <541a528b163965c9bc2053de> so there is no "true" / "good" number of clusters
[2015-03-18T15:25:57.705Z] <5385f2fe048862e761fa2d40> That's why the presented AF M/R is hierarchical
[2015-03-18T15:25:58.063Z] <54d4a1d6db8155e6700f853b> yeah I think it is rare that you have a single scale. either there are clusters on multiple levels or none at all ;)
[2015-03-18T15:26:13.929Z] <541a528b163965c9bc2053de> the good number depends on what kind of application you want to use the result of the clustering for
[2015-03-18T15:26:17.883Z] <54d4a1d6db8155e6700f853b> there is also AgglomerativeClustering, which is much faster and easier to understand than AF
[2015-03-18T15:26:26.617Z] <54d4a1d6db8155e6700f853b> and provides a hierarchical clustering
[2015-03-18T15:26:43.403Z] <5385f2fe048862e761fa2d40> AF also has a hierarchical version but not in sklearn
[2015-03-18T15:26:52.842Z] <5385f2fe048862e761fa2d40> just saying yeh?
[2015-03-18T15:27:10.767Z] <541a528b163965c9bc2053de> but is probably not scalable to 200MB unless you impose neighbors constraints which will be similar to DBSCAN or Birch
[2015-03-18T15:27:38.716Z] <54d4a1d6db8155e6700f853b> I am just asking why you want AF.
[2015-03-18T15:27:40.957Z] <5385f2fe048862e761fa2d40> even if you run it on multiple nodes?
[2015-03-18T15:28:04.970Z] <541a528b163965c9bc2053de> no, but for 200M points x 2D it's probably overkill to use a cluster
[2015-03-18T15:28:23.829Z] <5385f2fe048862e761fa2d40> Because I have a paper on it that explains (somewhat) how to implement it in M/R which is something that I want to be able to understand and implement
[2015-03-18T15:28:47.224Z] <5385f2fe048862e761fa2d40> The number will increase and we have other jobs executing with even more data
[2015-03-18T15:28:57.047Z] <541a528b163965c9bc2053de> but you can use the spark MLlib clustering implementations if you really want to use a cluster
[2015-03-18T15:29:13.924Z] <54d4a1d6db8155e6700f853b> well ok if your point is to understand how to implement AF on MR then go for that. I just don't see why you would want to do that, as AF is a crappy algorithm.
[2015-03-18T15:29:35.455Z] <54d4a1d6db8155e6700f853b> There are a also papers about implementing good clustering algorithms on MR
[2015-03-18T15:30:18.251Z] <541a528b163965c9bc2053de> do not focus on MR, they are better ways to distribute machine learning on a cluster: spark and the H20 runtime
[2015-03-18T15:31:04.882Z] <541a528b163965c9bc2053de> http://mahout.apache.org/ : even mahout is moving away from mapreduce: 25 April 2014 - Goodbye MapReduce  The Mahout community decided to move its codebase onto modern data processing systems that offer a richer programming model and more efficient execution than Hadoop MapReduce. Mahout will therefore reject new MapReduce algorithm implementations from now on. We will however keep our widely used MapReduce algorithms in the codebase and maintain them.  We are building our future implementations on top of a DSL for linear algebraic operations which has been developed over the last months. Programs written in this DSL are automatically optimized and executed in parallel on Apache Spark.  Furthermore, there is an experimental contribution undergoing which aims to integrate the h20 platform into Mahout.
[2015-03-18T15:33:31.607Z] <5385f2fe048862e761fa2d40> We're using Druid over here
[2015-03-18T15:38:49.719Z] <5385f2fe048862e761fa2d40> And the jobs are written in python. Not java
[2015-03-18T15:39:13.716Z] <541a528b163965c9bc2053de> @amueller I merged @lesteve's PR with doc fixes. I have to catch my bus. Will probably reconnect later tonight.
[2015-03-18T15:40:07.683Z] <541a528b163965c9bc2053de> spark and h20 are JVM stuff as well. But it's a detail in practice. What matters is how the memory is used, how the algo scales and can it be efficiently be distributed on a cluster or not.
[2015-03-18T15:40:26.449Z] <5385f2fe048862e761fa2d40> I know spark
[2015-03-18T15:40:43.199Z] <5385f2fe048862e761fa2d40> I haven't written anything that uses it yet
[2015-03-18T15:41:02.163Z] <5385f2fe048862e761fa2d40> We got disco and druid over here
[2015-03-18T15:41:11.321Z] <54d4a1d6db8155e6700f853b> @ogrisel cool :) there are sooo many reviews to be done.... 
[2015-03-18T15:41:16.550Z] <541a528b163965c9bc2053de> yes
[2015-03-18T15:41:20.709Z] <5385f2fe048862e761fa2d40> There's much better python support there
[2015-03-18T15:41:52.328Z] <5385f2fe048862e761fa2d40> I'm trying AgglomerativeClustering on 10k points to see what happens in comparance to K-MEANS
[2015-03-18T15:46:34.877Z] <5385f2fe048862e761fa2d40> @ogrisel Do you know a Python library that is similar to mahout?
[2015-03-18T15:46:51.061Z] <54d4a1d6db8155e6700f853b> btw @ogrisel if we merge one Pr every day, we will still be going at Chrismas (if no-one opens any more).
[2015-03-18T15:47:35.176Z] <54d4a1d6db8155e6700f853b> omerzimp there is none. Pyspark is the closest, I'd think. there are also python interfaces for h2o and graphlab/dato
[2015-03-18T15:48:05.620Z] <5385f2fe048862e761fa2d40> I already have Druid (druid.io) and pydruid
[2015-03-18T15:48:38.866Z] <5385f2fe048862e761fa2d40> I'm talking about a batched implementation of ML algos in Python that integrates with tools like spark or druid
[2015-03-18T15:48:45.993Z] <5385f2fe048862e761fa2d40> I can adapt spark to druid
[2015-03-18T15:52:26.698Z] <5385f2fe048862e761fa2d40> @ogrisel I tried AgglomerativeClustering and I can't find where to fetch the cluster centers from
[2015-03-18T15:52:59.045Z] <54d4a1d6db8155e6700f853b> np.unique(clustering.labels_)
[2015-03-18T15:53:30.304Z] <5385f2fe048862e761fa2d40> I only get the cluster numbers
[2015-03-18T15:53:44.262Z] <5385f2fe048862e761fa2d40> ``` In [34]: np.unique(ac.labels_) Out[34]:  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,        68, 69]) ```
[2015-03-18T15:54:26.011Z] <5385f2fe048862e761fa2d40> k means has an attribute that contains the cluster centers
[2015-03-18T15:56:34.177Z] <5385f2fe048862e761fa2d40> @amueller Can you explain what I'm looking at right now?
[2015-03-18T18:10:26.007Z] <541a528b163965c9bc2053de> `ac.labels_` gives you the cluster membeship of each sample (row) in the matrix `X` with shape `(n_samples, n_features)`, in your case `n_features==2`
[2015-03-18T18:11:46.184Z] <541a528b163965c9bc2053de> `AgglomerativeClustering` has no notion of center. The clusters can have non-convex (e.g. folded) shapes.
[2015-03-18T18:12:08.794Z] <541a528b163965c9bc2053de> Same for `DBSCAN` (and `Birch` to some extent).
[2015-03-18T18:13:00.942Z] <541a528b163965c9bc2053de> (Minibatch) k-means makes the convex clusters assumption, hence the cluster centers are meaningful and computed by default.
[2015-03-18T18:15:17.657Z] <541a528b163965c9bc2053de> Although whatever the clustering algorithm you can always compute the center of mass of any cluster a posteriori with basic numpy operations: ```python center_of_cluster_42 = X[ac.labels_ == 42].mean(axis=0) ``` assuming `X` is a numpy array.
[2015-03-18T18:22:24.990Z] <54d4a1d6db8155e6700f853b> Btw, AF also has no notion of centers ;)
[2015-03-18T19:13:57.229Z] <54d4a1d6db8155e6700f853b> hurray, thanks for merging the OMP fix @ogrisel. I'm quite confident that it is the right fix, but only time will actually tell ^^
[2015-03-18T19:26:13.712Z] <541a528b163965c9bc2053de> I agree.
[2015-03-18T19:26:46.739Z] <541a528b163965c9bc2053de> It's no big deal if it fails though. We can still re-add the travis skip as a temporary fix.
[2015-03-18T19:30:49.921Z] <54d4a1d6db8155e6700f853b> yeah definitely
[2015-03-18T19:39:13.790Z] <54d4a1d6db8155e6700f853b> I was confused by all the commits showing up twice in my notifications, but just realized they are for the two branches ^^
[2015-03-18T19:40:50.214Z] <54d4a1d6db8155e6700f853b> Merging this one soon will probably also help: #4370 not sure if it needs two reviews, it is just removing deprecated stuff
[2015-03-18T19:41:00.255Z] <54d4a1d6db8155e6700f853b> Just don't backport it ;)
[2015-03-18T19:41:13.307Z] <54d4a1d6db8155e6700f853b> btw, did we set a date for 0.16?
[2015-03-18T19:41:21.370Z] <54d4a1d6db8155e6700f853b> I guess 0.16.0
[2015-03-18T19:43:58.462Z] <5474d9eadb8155e6700d8178> Hey which do you feel is better? `if n is not None` or `if n`?
[2015-03-18T19:46:50.046Z] <54d4a1d6db8155e6700f853b> they are different. If you want to ask "if n is not None" you should do that.
[2015-03-18T19:47:09.279Z] <54d4a1d6db8155e6700f853b> the second one will also be false if n is 0
[2015-03-18T19:47:41.599Z] <5474d9eadb8155e6700d8178> Ah! explicit is always better as usual :) thanks!!
[2015-03-18T19:56:23.318Z] <5474d9eadb8155e6700d8178> @ogrisel @amueller could you kindly take a look at this comment - https://github.com/scikit-learn/scikit-learn/pull/4294#issuecomment-83123205 - This stands in the way of completion of the rest of the PR...
[2015-03-18T19:56:54.530Z] <541a528b163965c9bc2053de> No official date for 0.16.0 but maybe we could target next thursday?
[2015-03-18T19:57:36.521Z] <54d4a1d6db8155e6700f853b> fine with me
[2015-03-18T19:58:19.805Z] <54d4a1d6db8155e6700f853b> @ragv currently the PR doesn't yet use the new method in the GridSearchCV etc, right? Isn't that the big thing to do for that PR?
[2015-03-18T19:58:45.869Z] <541a528b163965c9bc2053de> from the 30th of March to April 1st we have a team retreat at work so I won't be able to work on the release. Then there is the oreilly webcast & PyData Paris and it would be great to have it released at that time.
[2015-03-18T19:59:23.932Z] <54d4a1d6db8155e6700f853b> I agree. lets do next thursday (the 26th)
[2015-03-18T19:59:46.420Z] <5474d9eadb8155e6700d8178> @amueller Oh! I haven't touched `grid_search.py` :/ Thanks! I'll work on that for now :)
[2015-03-18T20:01:05.735Z] <54d4a1d6db8155e6700f853b> have you fixed cross_val_score?
[2015-03-18T20:01:19.398Z] <54d4a1d6db8155e6700f853b> and make sure to keep them backward compatible with custom CV objects people might have written
[2015-03-18T20:01:26.888Z] <54d4a1d6db8155e6700f853b> I also commented on you question in the issue
[2015-03-18T20:02:12.358Z] <5474d9eadb8155e6700d8178> Not yet! Thanks a lot!! :) and okay sure! ( Sorry for pestering :p )
[2015-03-18T20:11:35.272Z] <541a528b163965c9bc2053de> @amueller off to the movie theater to watch citizenfour. Will resume PR reviews tomorrow morning a bit, otherwise Friday. See you!
[2015-03-18T20:11:59.576Z] <54d4a1d6db8155e6700f853b> thanks, that's awesome! have fun!
[2015-03-18T20:12:36.538Z] <54d4a1d6db8155e6700f853b> I'll try to figure out the test that crashes on all kind of weird combinations of python and numpy
[2015-03-18T20:16:59.601Z] <54c084dbdb8155e6700eed4c> @amueller I was also chanting while standing on one leg, and waving burning sage around during the test passes, not sure if that's relevant.
[2015-03-18T20:20:52.541Z] <54d4a1d6db8155e6700f853b> :feelsgood:
[2015-03-18T20:21:13.394Z] <54d4a1d6db8155e6700f853b> thanks for your extensive investigation, this one is .... interesting
[2015-03-18T20:22:52.057Z] <54d4a1d6db8155e6700f853b> /play bezos
[2015-03-18T20:23:03.631Z] <54d4a1d6db8155e6700f853b> damn, would have been to good if that worked
[2015-03-18T20:25:11.258Z] <54d4a1d6db8155e6700f853b> the selection of sounds supported by campfire is great: http://www.emoji-cheat-sheet.com/
[2015-03-18T20:28:23.540Z] <54c084dbdb8155e6700eed4c> haha. yeah no problem. i can investigate more, but having two systems that build without failing is nice too
[2015-03-18T20:30:49.298Z] <54d4a1d6db8155e6700f853b> Well if you want, you can try to track down what are the changes in python and numpy that cause this to fail ;)
[2015-03-18T20:31:06.603Z] <54d4a1d6db8155e6700f853b> I have to work on organizational stuff for the rest of the day, so I can't track this down much further at the moment
[2015-03-18T20:32:26.970Z] <54c084dbdb8155e6700eed4c> i was skimming through python's change log and nothing stood out. will take a more in depth glance at both this evening.
[2015-03-18T20:33:46.587Z] <54d4a1d6db8155e6700f853b> just if you have nothing better to do ;) I'm not sure about how to move forward. It seems strange that it works with the much older version on travis and not with the newer versions. What you could do is create a virtualenv with the travis 2.6 version of python and numpy and see if that also fails for you
[2015-03-18T20:38:13.123Z] <54c084dbdb8155e6700eed4c> ill try to do that on the linux box tonight. 
[2015-03-18T20:38:48.535Z] <54d4a1d6db8155e6700f853b> thanks
[2015-03-18T20:48:17.975Z] <54d4a1d6db8155e6700f853b> btw @ogrisel is there a reason not to enable OS X with travis?
[2015-03-19T09:22:06.164Z] <541a528b163965c9bc2053de> to enable OSX on travis we would need to adapt our CI script, but it should be doable.
[2015-03-19T10:14:39.698Z] <5385f2fe048862e761fa2d40> how do I plot AgglomerativeClustering correctly?
[2015-03-19T13:10:26.663Z] <54d4a1d6db8155e6700f853b> @omerzimp are you looking for dendograms? https://github.com/scikit-learn/scikit-learn/pull/3464 or what do you want to plot?
[2015-03-19T13:11:08.100Z] <5385f2fe048862e761fa2d40> I have a scatter plot
[2015-03-19T13:11:34.414Z] <5385f2fe048862e761fa2d40> I want to show where the clusters are and color them according to the number of data points in a cluster
[2015-03-19T13:12:26.678Z] <54d4a1d6db8155e6700f853b> what do you mean by where the clusters are? A common way to plot a clustering is to plot he points and color by cluster membership
[2015-03-19T13:13:28.175Z] <5385f2fe048862e761fa2d40> That's exactly what I want but I want to rate them in green shades, yellow shades and red shades according to the number of data points in a cluster
[2015-03-19T13:14:56.999Z] <54d4a1d6db8155e6700f853b> or so what is the question? how to get the right colors?
[2015-03-19T13:15:08.651Z] <5385f2fe048862e761fa2d40> yes
[2015-03-19T13:15:30.041Z] <5385f2fe048862e761fa2d40> I don't know how to get the number of data points in a cluster
[2015-03-19T13:15:35.848Z] <54d4a1d6db8155e6700f853b> you can get the number of clusters by np.bincount(agg.labels_)
[2015-03-19T13:16:47.860Z] <5385f2fe048862e761fa2d40> I need the number of datapoints in a cluster
[2015-03-19T13:17:27.187Z] <5385f2fe048862e761fa2d40> Yep that works
[2015-03-19T13:17:31.683Z] <5385f2fe048862e761fa2d40> why does it work
[2015-03-19T13:18:19.377Z] <54d4a1d6db8155e6700f853b> http://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html
[2015-03-19T13:21:20.620Z] <5385f2fe048862e761fa2d40> and a label is the cluster number in this case?
[2015-03-19T13:26:14.878Z] <5385f2fe048862e761fa2d40> thanks. It's pretty accurate
[2015-03-19T13:26:24.003Z] <5385f2fe048862e761fa2d40> How come the results are very similar to K-MEANS?
[2015-03-19T13:27:44.608Z] <5385f2fe048862e761fa2d40> Also I still don't understand where the cluster centers are
[2015-03-19T14:28:01.400Z] <54d4a1d6db8155e6700f853b> there are no cluster centers in agglomerative clustering
[2015-03-19T14:34:16.544Z] <5385f2fe048862e761fa2d40> Ok that's good to know
[2015-03-19T14:34:48.658Z] <5385f2fe048862e761fa2d40> How do I check if a value would end up in a cluster? I have predict in K-MEANS but not in agglomerative clustering
[2015-03-19T14:39:52.193Z] <5385f2fe048862e761fa2d40> @amueller Is there a parallel version of agglomerative clustering? I see that K-MEANS has one that uses joblib
[2015-03-19T14:53:02.354Z] <54d4a1d6db8155e6700f853b> the k-means uses joblib just to parallelize the restarts. there is no parallel version of agglomerative clustering, but it should be pretty fast
[2015-03-19T14:53:42.383Z] <54d4a1d6db8155e6700f853b> the way the clustering is constructed there is not really a way to predict in agglomerative clustering, but you could assign clusters to new points using nearest neighbors for example
[2015-03-19T15:02:58.287Z] <5385f2fe048862e761fa2d40> I've seen papers about parallelizing them
[2015-03-19T15:12:45.716Z] <5385f2fe048862e761fa2d40> @amueller See http://www.cs.cornell.edu/~kb/publications/irt08.pdf
[2015-03-19T15:14:19.847Z] <5385f2fe048862e761fa2d40> Clause 3.3
[2015-03-19T16:26:17.892Z] <54d4a1d6db8155e6700f853b> this seems to be somewhat tricky...
[2015-03-19T16:26:28.752Z] <5385f2fe048862e761fa2d40> but doable right?
[2015-03-19T16:27:53.219Z] <54d4a1d6db8155e6700f853b> which version? they talk about the locally oriented version which is described in a different paper
[2015-03-19T16:28:40.786Z] <5385f2fe048862e761fa2d40> Both are parallelizable according to 3.3
[2015-03-19T16:29:05.919Z] <54d4a1d6db8155e6700f853b> yes but they don't say how
[2015-03-19T16:29:19.755Z] <5385f2fe048862e761fa2d40> You have to look at other papers
[2015-03-19T16:29:44.597Z] <54d4a1d6db8155e6700f853b> I could but I have other things to do. and without looking at it, how should I say if it is doable?
[2015-03-20T03:26:36.562Z] <54c084dbdb8155e6700eed4c> @amueller ... you around? should i also update `y_numeric` for https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/kernel_ridge.py#L144 and https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/linear_model/stochastic_gradient.py#L868 ? Both are explicitly regressors. there's a couple others that use fit between classifiers and regressors too... gbm, adaboost, bagging... Not sure I want to touch them for 0.16 though, would be more involved than a +1/-1 change
[2015-03-20T03:27:17.034Z] <54c084dbdb8155e6700eed4c> presumably all of the above get through tests somehow though...
[2015-03-20T04:14:02.567Z] <54c084dbdb8155e6700eed4c> nm. i copied these questions to the PR. you can comment there if you like, but i think those do not call the offending np function
[2015-03-20T14:41:11.233Z] <54d4a1d6db8155e6700f853b> if the tests pass, I don't think we need to do anything
[2015-03-20T15:45:22.779Z] <54d4a1d6db8155e6700f853b> thanks for all the merges @ogrisel :)
[2015-03-20T15:45:33.325Z] <54d4a1d6db8155e6700f853b> as a thank you, I pinged you in 4 other issues ^^
[2015-03-20T15:51:42.991Z] <54c084dbdb8155e6700eed4c> K. Well #4422 should be good then. It passes all tests locally on 1.8.0 
[2015-03-20T15:54:14.393Z] <54d4a1d6db8155e6700f853b> thanks, looks good and I marked for backport
[2015-03-20T15:54:46.584Z] <54d4a1d6db8155e6700f853b> that will save us some eror reports on the new release!
[2015-03-20T15:57:33.269Z] <54c084dbdb8155e6700eed4c> excellent
[2015-03-20T18:13:23.676Z] <5474d9eadb8155e6700d8178> Hey :) @ogrisel @amueller Could I take up "Multiple metric support for cross-validation and gridsearches" as my GSoC project...? Sorry for the delay in my proposal... Final semester takes up a lot of my time :| I chose that since so far no one has proposed for the same and also I am working on a related PR...
[2015-03-20T18:16:31.205Z] <54d4a1d6db8155e6700f853b> yes, that would be good and could also tie into finishing up the cross-validation stuff you are working on
[2015-03-20T18:16:43.571Z] <54d4a1d6db8155e6700f853b> btw does anyone remember a PR adding more git rebase docs to the developer documentation?
[2015-03-20T18:16:52.860Z] <54d4a1d6db8155e6700f853b> I though someone did it but I can't find it any more
[2015-03-20T18:17:59.520Z] <5474d9eadb8155e6700d8178> "git rebase docs" you mean contributor docs??
[2015-03-20T18:20:26.158Z] <54d4a1d6db8155e6700f853b> docs for the contributors on how to do git magic, like rebasing, not merging in master, and squashing
[2015-03-20T18:21:09.287Z] <54d4a1d6db8155e6700f853b> we were talking about that somewhere (ML? issues?) and I though someone made PR. but maybe that was just wishful thinking
[2015-03-20T18:21:28.844Z] <54d4a1d6db8155e6700f853b> apparently today is minor doc fix day. third push to master in a row.
[2015-03-20T18:52:57.835Z] <54d4a1d6db8155e6700f853b> @ogrisel in a recent PR you posted "only 202 PRs to go". Now it's 227. GSoC I guess ;) And that even with pretty aggressive merging...
[2015-03-20T18:53:23.748Z] <5474d9eadb8155e6700d8178> (shamefully) Thats me :p Joel had posted an issue asking for a better contributor docs... I am still doing that :| btw I did update wiki with a neat tree outlining the structure of our improved contributors guide... https://github.com/scikit-learn/scikit-learn/wiki/Contributors-Guide
[2015-03-20T19:26:12.125Z] <54c084dbdb8155e6700eed4c> Something I spend way too much time doing when writing new stuff, or figuring out what's happening in an existing method (and perhaps there's already an easy way that this dum dum doesn't know)... But would adding the actual source code file in which a given developer func is located to the sklearn.utils.x functions' docstrings be helpful?
[2015-03-20T19:28:02.036Z] <54c084dbdb8155e6700eed4c> (only for non-public functions in utils I think)
[2015-03-20T20:05:48.399Z] <54d4a1d6db8155e6700f853b> trevorstephens: psource should give you the source in ipython
[2015-03-20T20:08:46.862Z] <54c084dbdb8155e6700eed4c> that is magical... thx! but doesnt seem to tell the file it's in. :-/
[2015-03-21T09:09:27.207Z] <5474d9eadb8155e6700d8178> You could also do a `git grep "def function_name"` right? Thats the easiest I think! :)
[2015-03-21T15:44:21.467Z] <54d4a1d6db8155e6700f853b> for the file you can use function.__file__
[2015-03-21T15:44:32.396Z] <54d4a1d6db8155e6700f853b> that is ``function.__file__``
[2015-03-21T16:44:28.797Z] <54c084dbdb8155e6700eed4c> __file__ didnt work, but func.__code__ seems to get what i want. thanks!
[2015-03-21T16:44:49.964Z] <54c084dbdb8155e6700eed4c> that is `func.__code__`
[2015-03-21T18:56:09.314Z] <54d4a1d6db8155e6700f853b> it might be that __file__ only works for modules, not functions
[2015-03-21T18:56:14.547Z] <54d4a1d6db8155e6700f853b> psource should give you the same as file
[2015-03-21T18:56:17.319Z] <54d4a1d6db8155e6700f853b> err code
[2015-03-22T14:08:16.277Z] <5474d9eadb8155e6700d8178> Given that there is a huge interest among students in learning about ML, do you think it would be within the scope of/beneficial to skl to have all the exercises and/or concepts, from a good quality book (ESL / PRML / Murphy) or an academic course like NG's CS229 (not the less rigorous coursera version), implemented using sklearn? Or perhaps we could instead enhance our tutorials and examples, to be a self study guide to learn about ML? I was planning to include this in my GSoC proposal... does it seem like an useful idea? (Also is this a correct place to discuss this or the Mailing list might be better for such questions?)
[2015-03-22T14:08:48.297Z] <5474d9eadb8155e6700d8178> Or would it be better if I simply add more examples?
[2015-03-22T17:52:29.691Z] <5385f2fe048862e761fa2d40> Yes please! 
[2015-03-22T17:52:46.886Z] <5385f2fe048862e761fa2d40> I really want to learn ML and it's pretty hard as it is
[2015-03-22T17:53:14.131Z] <5385f2fe048862e761fa2d40> An extensive tutorial would be lovely. 
[2015-03-22T17:55:04.851Z] <5474d9eadb8155e6700d8178> Thanks for the response!! Lets wait for a confirmation from the core devs, since any additional code does come with its own maintenance cost... They would be the best at judging if that additional maintenance is worth the benefit it offers :)
[2015-03-23T00:16:59.942Z] <5474d9eadb8155e6700d8178> > Also is this a correct place to discuss this or the Mailing list might be better for such questions?  NM! I've copied this to the ML, so as to reach a wider audience :) Please let me know your views there!
[2015-03-23T08:33:59.514Z] <541a528b163965c9bc2053de> @ragv +1 for a GSoC on cross-validation improvements. I can volunteer to be a mentor on that one.
[2015-03-23T08:34:59.966Z] <5474d9eadb8155e6700d8178> Thanks!! :D would you be able to take a look at my proposal at https://github.com/scikit-learn/scikit-learn/wiki/GSoC-2015-Proposal:-Multiple-metric-support-for-CV-and-grid_search-and-other-general-improvements and let me know your views?
[2015-03-23T08:37:00.906Z] <541a528b163965c9bc2053de> will do.
[2015-03-23T08:39:57.532Z] <5474d9eadb8155e6700d8178> Thanks! :)
[2015-03-23T12:58:21.309Z] <54d4a1d6db8155e6700f853b> @ragv I don't know about NG's course, but for the books, sklearn is useless for the exercises, right? They are mostly mathematical proofs. How would sklearn help with that?
[2015-03-23T12:59:24.428Z] <541a528b163965c9bc2053de> @ragv I think we should focus your GSoC on improving cross-val, writing a generic tutorial to ML is interesting but too long to do in addition to a GSoC
[2015-03-23T13:00:48.206Z] <541a528b163965c9bc2053de> for the cross-val, we could have the data-independent refactoring and then for the second part of the GSoC experiment with high level helper API to do out-of-core cross-validation for models that support partial_fit
[2015-03-23T13:01:19.017Z] <54d4a1d6db8155e6700f853b> I thought we wanted to do multiple metrics?
[2015-03-23T13:01:23.572Z] <541a528b163965c9bc2053de> I have personally not started to thing about what such an API would look like but I think this is an important use case
[2015-03-23T13:01:35.246Z] <541a528b163965c9bc2053de> multiple metrics is interesting as well
[2015-03-23T13:02:04.670Z] <54d4a1d6db8155e6700f853b> btw have you looked at any of the gsoc proposals yet?
[2015-03-23T13:02:12.328Z] <541a528b163965c9bc2053de> but https://github.com/scikit-learn/scikit-learn/pull/4294 should definitely be part of the GSoC
[2015-03-23T13:02:22.973Z] <541a528b163965c9bc2053de> just https://github.com/scikit-learn/scikit-learn/wiki/GSoC-2015-Proposal:-Multiple-metric-support-for-CV-and-grid_search-and-other-general-improvements
[2015-03-23T13:21:54.435Z] <54d4a1d6db8155e6700f853b> I guess I need to review them all...
[2015-03-23T14:31:16.898Z] <54d4a1d6db8155e6700f853b> btw, @ogrisel I thought about doing the split of the ``utils`` module into the private and public modules, that people have been talking about for ever. What do you think about that?
[2015-03-23T14:45:46.220Z] <54c084dbdb8155e6700eed4c> Hey all, I have noticed [here](http://sourceforge.net/p/scikit-learn/mailman/message/24403926/) and [here](http://mail.scipy.org/pipermail/scipy-dev/2010-January/013709.html) that there was once a genetic algorithm module in scikits.learn, it appears to have been removed mostly due to code rot, maybe API differences too, but does anyone know if there is an underlying general issue with genetic algorithms that are not scikit-learn friendly? 
[2015-03-23T14:46:30.754Z] <54c084dbdb8155e6700eed4c> For context, I am writing a symbolic regression class that constrains genetic programming's flexibility to the main use cases found in scikit-learn (regression, classification, transformation) and sticks with the existing scikit-learn API style. So just wanted to check in to ensure I'm not going off the deep end as I'm nearing a functional regressor already... Though still a fair ways from a PR :smile: 
[2015-03-23T14:59:11.627Z] <54d4a1d6db8155e6700f853b> @ogrisel green button on https://github.com/scikit-learn/scikit-learn/pull/4432/files to avoid merge conflicts?
[2015-03-23T15:01:47.175Z] <54d4a1d6db8155e6700f853b> @trevorstephens genetic algorithms are probably going off the mariana trench. what is your application of symbolic regression?
[2015-03-23T15:02:51.038Z] <54c084dbdb8155e6700eed4c> haha. what do you mean by application? where would it be used?
[2015-03-23T15:04:22.379Z] <54c084dbdb8155e6700eed4c> its just a regressor, except that the final result is expressed as a non-linear equation.
[2015-03-23T15:04:52.208Z] <54c084dbdb8155e6700eed4c> could also be used for automated feature extraction in a supervised transformer
[2015-03-23T15:06:35.706Z] <54c084dbdb8155e6700eed4c> basic idea is to take an initial sample of random equations and apply genetic operations such as mutation, reproduction, etc to the fittest individuals in a population. the equations are expressed like LISP trees... well im just using python lists, but similar structure
[2015-03-23T15:09:01.632Z] <541a528b163965c9bc2053de> @amueller about the split of utils I have no strong opinions. I am +1 on introducing new private utils with a `_` prefix.
[2015-03-23T15:09:03.141Z] <54d4a1d6db8155e6700f853b> Ok you are just building a regressor. By application I mean: does this ever work better than a random forest? Also, is that what people currently use in symbolic regression? And does that work better than greedy expansions of variables in a linear model?
[2015-03-23T15:09:51.423Z] <54d4a1d6db8155e6700f853b> @ogrisel would you still have them in the ``.utils`` module? I thought about introducing ``._utils`` and just moving (backward-compatible) all the non-public API there?
[2015-03-23T15:10:10.118Z] <54d4a1d6db8155e6700f853b> but maybe I should rather spend my time on reviewing the LDA and GP PRs  or finishing the MLP.
[2015-03-23T15:10:55.517Z] <54d4a1d6db8155e6700f853b> Btw, for the MLP, I'm not 100% certain on how to do nesterovs momentum. I find the paper was not very clearly written, but maybe I was just tired
[2015-03-23T15:13:15.996Z] <54c084dbdb8155e6700eed4c> ive seen people using symbolic regression in combination with stacking on kaggle (the higgs boson comp was memorable) to extract new features that helped their gbm's latch onto some very interesting segments of the feature space. there is a lot of research into competitive results though i dont know if they have been compared to RFs
[2015-03-23T15:14:42.455Z] <54c084dbdb8155e6700eed4c> "Also, is that what people currently use in symbolic regression?", do you mean LISP trees? yes, it is very common. basically a flattened tree representation
[2015-03-23T15:16:14.995Z] <541a528b163965c9bc2053de> @amueller about the MLP PR, I have implemented an adaptative schedule for the learning rate here: https://github.com/ogrisel/scikit-learn/commit/3c4cc13b39fdb6a91be44a0977766e16d45ed5dc . It seems to be very useful in practice, although Ilya Sutskever recommends to use a validation set instead of the training score. Using a validation set is complicated from an API point of view though.
[2015-03-23T15:17:16.179Z] <541a528b163965c9bc2053de> Nesterov momentum is not that complicated. Have you read:  http://www.cs.toronto.edu/~fritz/absps/momentum.pdf ?
[2015-03-23T15:17:51.914Z] <541a528b163965c9bc2053de> it's mostly the ordering of the update.
[2015-03-23T15:19:52.651Z] <541a528b163965c9bc2053de> @amueller this experimental notebook might help http://nbviewer.ipython.org/github/ogrisel/notebooks/blob/master/Gradient.ipynb
[2015-03-23T15:21:11.008Z] <541a528b163965c9bc2053de> also I am currently experimenting with a from scratch implementation in theano to have a comparision point (and more NN experience): http://nbviewer.ipython.org/github/ogrisel/notebooks/blob/master/representations/MNIST%20experiments.ipynb
[2015-03-23T15:22:00.136Z] <541a528b163965c9bc2053de> about the utils stuff it does not seem to be particularly high priority to me but feel free to work on that if you find it important yourself.
[2015-03-23T15:26:02.326Z] <54d4a1d6db8155e6700f853b> I read the momentum pdf. but I'll have a look at your notebook. I feel we should merge this asap as it has been lying around for so long. adding monitoring etc can always be done afterwards
[2015-03-23T15:26:23.709Z] <54d4a1d6db8155e6700f853b> and the use of a validation set would be great but is a whole other can of worms
[2015-03-23T15:27:07.091Z] <54d4a1d6db8155e6700f853b> @trevorstephens sorry for being ambiguous. I meant are people using genetic programming for symbolic regression.
[2015-03-23T15:33:55.765Z] <541a528b163965c9bc2053de> I am not sure we should merge that early. The optimizer is clearly suboptimal, the one in my branch seems to be much more robust but changes the meaning of the 'constant' hyperparameter.
[2015-03-23T15:34:13.096Z] <541a528b163965c9bc2053de> I think it's very important to have a robust hyperparameter by default.
[2015-03-23T15:34:28.243Z] <541a528b163965c9bc2053de> But I want to focus on the 0.16 release first.
[2015-03-23T15:37:16.699Z] <541a528b163965c9bc2053de> @trevorstephens encourage you to implement that as a third party project first. If it proves empirically useful then we might consider it for inclusion in the future. But Genetic Programming stuff is culturally very different from the sklearn spirit. Especially we do not want to have a generic Evoluationary Algorithm module as part of sklearn as the API would not be suited for it.
[2015-03-23T15:38:02.897Z] <541a528b163965c9bc2053de> A black box Genetic programming solver hidden in a SymbolicRegressor estimator might be interesting though.
[2015-03-23T15:39:13.419Z] <541a528b163965c9bc2053de> but it's utility would have to be proven first. So better implement that in a dedicated python package first.
[2015-03-23T15:47:45.711Z] <54d4a1d6db8155e6700f853b> @ogrisel is there much to do for 0.16?
[2015-03-23T15:48:16.694Z] <54d4a1d6db8155e6700f853b> @ogrisel is there anything to be done for the EML branch? It has no +1 yet.
[2015-03-23T16:04:54.430Z] <54d4a1d6db8155e6700f853b> this one would be nice: https://github.com/scikit-learn/scikit-learn/pull/4350
[2015-03-23T16:11:55.243Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4436 just passed
[2015-03-23T16:46:29.682Z] <5474d9eadb8155e6700d8178> @amueller @ogrisel Thanks for the reviews!! Based on your comments I'll replace that section of my prop. with a more significant work > They are mostly mathematical proofs. How would sklearn help with that?  I was thinking more on the lines of http://www-bcf.usc.edu/~gareth/ISL/code.html.. But like you said for the practical part of it, we do have some nice books! Perhaps out of GSoC, it would  be better if I simply cleaned up existing examples and added a few more perhaps! 
[2015-03-23T17:07:09.807Z] <54c084dbdb8155e6700eed4c> @amueller , yes, it is the 'classic' use of GP. 
[2015-03-23T17:09:22.290Z] <54c084dbdb8155e6700eed4c> @ogrisel . "A black box Genetic programming solver hidden in a SymbolicRegressor estimator might be interesting though." Yep. That's exactly what I'm going after. Though understand if you don't want it in the package yet, makes perfect sense.
[2015-03-23T17:10:45.538Z] <54c084dbdb8155e6700eed4c> FWIW, here's the (did I mention super-early) code: https://github.com/trevorstephens/scikit-learn/blob/genetic_programming/sklearn/genetic.py
[2015-03-23T17:12:53.535Z] <54c084dbdb8155e6700eed4c> running is as simple as `gp = SymbolicRegressor(random_state=415)`  `gp.fit(diabetes.data, diabetes.target)`  `print gp.program_`
[2015-03-23T17:24:32.144Z] <541a528b163965c9bc2053de> @amueller I am working on pinpointing numpy version issues for #3747 at the moment
[2015-03-23T17:25:06.199Z] <541a528b163965c9bc2053de> ho you merged it already.
[2015-03-23T17:25:13.286Z] <541a528b163965c9bc2053de> Did you do the backport as well ?
[2015-03-23T17:25:36.240Z] <541a528b163965c9bc2053de> I am not sure about the 1.9 version comparison in the test
[2015-03-23T17:25:44.381Z] <541a528b163965c9bc2053de> I am testing with numpy 1.8.0
[2015-03-23T17:28:18.279Z] <541a528b163965c9bc2053de> Ok the tests pass with 1.8 as well :)
[2015-03-23T17:31:41.303Z] <541a528b163965c9bc2053de> @trevorstephens would be great to extract that as a new library. You can write some sklearn compat tests with stuff in`sklearn.utils.estimator_checks`.
[2015-03-23T17:32:25.065Z] <541a528b163965c9bc2053de> you can make it easy to install by writing a simple setup.py.
[2015-03-23T17:33:07.360Z] <541a528b163965c9bc2053de> As you don't need compiled extensions, you don't need the complicated numpy.distutils, you can just use the regular distutils or setuptools.
[2015-03-23T17:33:32.449Z] <541a528b163965c9bc2053de> you could name your project symbolicregressor or something
[2015-03-23T17:33:37.245Z] <541a528b163965c9bc2053de> symregressor
[2015-03-23T17:34:27.171Z] <54c084dbdb8155e6700eed4c> billie-gene has a nice ring to it
[2015-03-23T17:34:34.189Z] <54c084dbdb8155e6700eed4c> :smile: 
[2015-03-23T17:37:16.236Z] <541a528b163965c9bc2053de> @ragv I would move generic tutorial out of the scope of your GSoC but you can expand the documentation item of your GSoC proposal to include a tutorial on how to do proper cross-validation: how to select the CV strategy for a given problem, how to use stratification, how to check that the i.i.d. assumption is not violated...
[2015-03-23T18:05:37.317Z] <54c084dbdb8155e6700eed4c> thanks for the advice as well @ogrisel 
[2015-03-23T18:11:01.578Z] <5474d9eadb8155e6700d8178> @ogrisel Thanks for the suggestion! On it :) Do the other sections look okay...?
[2015-03-23T18:15:09.759Z] <541a528b163965c9bc2053de> I have to go now, I will review the other sections and give you finer feedback tomorrow
[2015-03-23T18:15:56.649Z] <5474d9eadb8155e6700d8178> Okay! bye :)
[2015-03-24T14:07:04.846Z] <54d4a1d6db8155e6700f853b> @ogrisel the thing about the mlp is, that as long as it is a PR, we will not get feedback about it from anyone. But once it is merged, people will use it, and people will sent PRs. I don't think we need to "nail it" before it is merged. The naive end-user will only use it after the release
[2015-03-24T16:17:33.714Z] <5474d9eadb8155e6700d8178> That seems like a good idea... More after merging to master, it becomes easier for anyone to contribute to it by a normal PR rather than a PR to a PR... (for whatever my comment is worth) +1 from me for that! :)
[2015-03-24T16:19:20.517Z] <5474d9eadb8155e6700d8178> also, if it is not considered convoluted, we could raise a `BetaModule` warning like `DeprecationWarning` to warn users not to use it in production code?
[2015-03-24T17:47:46.729Z] <54d4a1d6db8155e6700f853b> well, if it is the dev version, people should know
[2015-03-24T18:40:59.720Z] <54d4a1d6db8155e6700f853b> I have the common tests on OneClassSVM (I think) hanging randomly on my box. no good.
[2015-03-24T18:52:09.885Z] <5474d9eadb8155e6700d8178> @amueller Should #1674 be closed in favor of #1626, since @mblondel has been positive about the same in his last comment?
[2015-03-24T19:12:40.283Z] <54d4a1d6db8155e6700f853b> which comment?
[2015-03-24T19:13:30.484Z] <5474d9eadb8155e6700d8178> https://github.com/scikit-learn/scikit-learn/issues/1674#issuecomment-13982364
[2015-03-24T19:16:01.033Z] <54d4a1d6db8155e6700f853b> well he said he understood my idea
[2015-03-24T19:16:13.519Z] <54d4a1d6db8155e6700f853b> not that it solves his issue / replaces his
[2015-03-24T19:16:29.811Z] <54d4a1d6db8155e6700f853b> I should reread my proposal
[2015-03-24T19:16:37.519Z] <54d4a1d6db8155e6700f853b> It has been two years (sic!)
[2015-03-24T19:19:04.560Z] <5474d9eadb8155e6700d8178> Well.. I thought of including it in my proposal ;) I feel this is a tough one and will take easily around 1.5 months? (Is that adequate amount of time that could be allocated for the same?)
[2015-03-24T19:19:42.035Z] <54d4a1d6db8155e6700f853b> I would have to re-read but it tries to address some of the points that I mentioned in my email
[2015-03-24T19:21:27.458Z] <5474d9eadb8155e6700d8178> Yea :) please take your time... I'll just put it tentatively as 1.5 months for now... but you'd know better, given my previous work and my 8hr a day schedule... :)
[2015-03-24T19:22:24.187Z] <54d4a1d6db8155e6700f853b> :)
[2015-03-24T19:22:48.306Z] <54d4a1d6db8155e6700f853b> the main question would be how to pass it the validation set so to make it pipeline compatible and GridSearchCV compatible
[2015-03-24T20:44:53.940Z] <54d4a1d6db8155e6700f853b> any GSOC applicant looking for stuff to do can check: https://github.com/scikit-learn/scikit-learn/issues/4442#issuecomment-85683185
[2015-03-24T20:45:04.957Z] <54d4a1d6db8155e6700f853b> (ragv you have enough contribs and don't need to worry about it ;)
[2015-03-24T20:45:24.727Z] <54d4a1d6db8155e6700f853b> not that help would not be appreciated, but I think you have enough stuff to do
[2015-03-24T20:46:13.346Z] <5474d9eadb8155e6700d8178> LOL okay :D I am a bit busy this month due to my academics moreover, thats why I am not able to spend enough time on scikit-learn  :cry:
[2015-03-24T20:48:48.917Z] <541a528b163965c9bc2053de> @ragv have you put you proposal on melange?
[2015-03-24T20:48:53.343Z] <541a528b163965c9bc2053de> I cannot find it
[2015-03-24T20:49:09.797Z] <541a528b163965c9bc2053de> if so please edit the title to add "scikit-learn" in it
[2015-03-24T20:49:32.972Z] <5474d9eadb8155e6700d8178> Sure! I haven't yet... I was fine tuning it a bit.. sorry :)
[2015-03-24T20:50:50.454Z] <541a528b163965c9bc2053de> I think it's better to put it on melange early so that we can comment on it and read each others comments
[2015-03-24T20:51:01.688Z] <541a528b163965c9bc2053de> you can still edit it afterwards
[2015-03-24T20:51:12.781Z] <5474d9eadb8155e6700d8178> I am doing that now... sorry for the delay :)
[2015-03-24T20:56:53.932Z] <5474d9eadb8155e6700d8178> @ogrisel Done! but the formatting is awefully bad... A little more description is needed too... I'll fix both ASAP :)
[2015-03-24T20:59:58.060Z] <5474d9eadb8155e6700d8178> Is "path algorithms" a good name to mean all cv related objects?
[2015-03-24T21:00:45.632Z] <54d4a1d6db8155e6700f853b> no
[2015-03-24T21:01:01.087Z] <54d4a1d6db8155e6700f853b> wait, depends on what you mean by cv related objects
[2015-03-24T21:01:21.411Z] <54d4a1d6db8155e6700f853b> It applies to LinearModelCV objects
[2015-03-24T21:01:38.552Z] <5474d9eadb8155e6700d8178> cross_validation / learning_curve / model_selection etc... oh.. sorry then I'll call them CV objects simply :)
[2015-03-24T21:01:39.531Z] <54d4a1d6db8155e6700f853b> anyhow, I commented on melange that I think it is not a good name
[2015-03-24T21:01:54.896Z] <54d4a1d6db8155e6700f853b> I would just call it model selection and evaluation maybe
[2015-03-24T21:01:57.294Z] <5474d9eadb8155e6700d8178> Thanks :D
[2015-03-24T21:02:59.251Z] <5474d9eadb8155e6700d8178> Does this seem okay? - "scikit-learn: Enhance cross validation and related modules."
[2015-03-24T21:03:03.210Z] <54d4a1d6db8155e6700f853b> I think you will have a great proposal. I haven't read your most recent version, I just wanted to reiterate that you should try to focus, in particular provide concrete deliverables
[2015-03-24T21:03:39.369Z] <54d4a1d6db8155e6700f853b> sound more appropriate than the current title.
[2015-03-24T21:04:01.043Z] <5474d9eadb8155e6700d8178> Okay :)
[2015-03-24T21:04:37.756Z] <54d4a1d6db8155e6700f853b> sorry if my feedback today is a bit short, I am feeling sick and wanted to at least briefly comment on all submission
[2015-03-24T21:04:38.855Z] <54d4a1d6db8155e6700f853b> s
[2015-03-24T21:07:42.282Z] <5474d9eadb8155e6700d8178> Not an issue at all! Feel free to comment whenever you feel like :) And more over I got the basic idea and hence can work out my proposal according to your guidelines :) Also take care :) Sorry to trouble you at the last min... 
[2015-03-24T21:11:05.045Z] <54d4a1d6db8155e6700f853b> haha well we just started to review now so it is our fault ;)
[2015-03-24T21:11:29.536Z] <5474d9eadb8155e6700d8178> HI5 :p 
[2015-03-24T21:21:08.710Z] <541a528b163965c9bc2053de> +1 on the new title and focus
[2015-03-24T21:34:10.931Z] <54d4a1d6db8155e6700f853b> I at least gave some cursory comments on all proposals. I think all the mentors should review at least one that they are interested in.
[2015-03-24T21:35:01.789Z] <54d4a1d6db8155e6700f853b> @ogrisel do you want to put your name on one or more proposals on the list (more than one meaning one of these will be selected)
[2015-03-24T21:49:42.766Z] <541a528b163965c9bc2053de> @amueller you mean in the google doc or on melange?
[2015-03-24T21:59:19.423Z] <54d4a1d6db8155e6700f853b> google doc
[2015-03-24T22:00:01.938Z] <54d4a1d6db8155e6700f853b> @ogrisel do you think this is a good idea: https://github.com/scikit-learn/scikit-learn/issues/4445 we could ask cangermueller to do it, he didn't have much opportunity to prove his coding skills yet, I think
[2015-03-24T22:01:11.978Z] <54d4a1d6db8155e6700f853b> heading over to facebook for free drinks now ^^
[2015-03-24T22:01:13.867Z] <54d4a1d6db8155e6700f853b> ttyl
[2015-03-24T22:03:06.810Z] <541a528b163965c9bc2053de> cheers!
[2015-03-25T00:19:12.267Z] <541a528b163965c9bc2053de> ok I did a pass on the GSoC proposals. I need to go to sleep now. Tomorrow will be very busy with meetings and meetups.
[2015-03-25T00:21:26.301Z] <541a528b163965c9bc2053de> I will probably be back online on Thursday morning to resume work on GSoC reviews and sklearn 0.16 release.
[2015-03-25T18:39:32.322Z] <54d4a1d6db8155e6700f853b> I might cherry-pick some more things today, I have to check
[2015-03-25T20:58:44.959Z] <5474d9eadb8155e6700d8178> @amueller do you think we should probably fine tune landscape settings to avoid reporting not-so-useful fixes that are probably ignored... Thing is without it raising red flags only for important issues that a core dev would normally frown upon (like PEP8, imports, the docstring format), I am afraid this will eventually be ignored like the coveralls bot. :/ WDYT?
[2015-03-25T21:03:28.339Z] <54d4a1d6db8155e6700f853b> the main problem is that it reports new problems that are not related to the code at all.
[2015-03-25T21:18:55.149Z] <5474d9eadb8155e6700d8178> Ah... We'll then just wait for it to get better ;)
[2015-03-25T21:22:10.001Z] <54d4a1d6db8155e6700f853b> maybe ;)
[2015-03-25T21:23:28.954Z] <54d4a1d6db8155e6700f853b> @ogrisel do you think there is a chance @GaelVaroquaux will review and / or put his name next to some of the proposals? It would be nice to have tentative mentors.
[2015-03-25T21:42:04.510Z] <54d4a1d6db8155e6700f853b> @ogrisel I backported some doc fixes and the faster polynomial features
[2015-03-26T01:08:12.793Z] <5474d9eadb8155e6700d8178> Will I be able to edit my prop after 27th? :p 
[2015-03-26T01:10:41.818Z] <54d4a1d6db8155e6700f853b> I don't think so. the mentors might
[2015-03-26T01:10:46.503Z] <54d4a1d6db8155e6700f853b> but you should not count on it ;)
[2015-03-26T01:11:37.306Z] <5474d9eadb8155e6700d8178> Okay! Would you be able to take a look at the revised prop and leave your comments? :)
[2015-03-26T01:11:57.161Z] <54d4a1d6db8155e6700f853b> tomorrow. It's 21h in NYC
[2015-03-26T01:12:40.114Z] <5474d9eadb8155e6700d8178> Oh!! Sorry :P how are you today btw?
[2015-03-26T01:20:17.685Z] <5474d9eadb8155e6700d8178> melange's formatting is very bad :neutral_face:  The wiki pages look neat compared to melage ... 
[2015-03-26T01:20:52.565Z] <550f53e215522ed4b3dda5f6> You could copy paste, I think
[2015-03-26T01:21:02.236Z] <54d4a1d6db8155e6700f853b> still sick, meh
[2015-03-26T01:21:16.864Z] <5474d9eadb8155e6700d8178> Thats bad :/ tc! 
[2015-03-26T01:21:22.026Z] <5474d9eadb8155e6700d8178> Hey @xuewei4d :)
[2015-03-26T01:21:44.504Z] <550f53e215522ed4b3dda5f6> GSOC 2016: melange
[2015-03-26T01:22:00.754Z] <5474d9eadb8155e6700d8178> I tried but its still very bad :(
[2015-03-26T01:22:15.479Z] <5474d9eadb8155e6700d8178> This site was useful for me tho :D - http://markable.in/editor/
[2015-03-26T01:22:36.332Z] <5474d9eadb8155e6700d8178> I edited entirely in md and copy pasted the html code into melange :P
[2015-03-26T01:23:30.016Z] <550f53e215522ed4b3dda5f6> This is what I did. I use sublime to preview markdown, then copy paste html page
[2015-03-26T01:24:18.633Z] <5474d9eadb8155e6700d8178> haha... subl seems to be better in so many ways... hmm I guess time to move away from vim...
[2015-03-26T01:27:08.858Z] <54d4a1d6db8155e6700f853b> noooo don't do it ;)
[2015-03-26T01:28:22.524Z] <5474d9eadb8155e6700d8178> Thanks atleast I got one person saying that :O Every other person I meet recommends subl or pycharm... I love vim but hate them ranting about their shiny editors :p 
[2015-03-26T01:28:34.257Z] <5474d9eadb8155e6700d8178> What do you use? :)
[2015-03-26T02:36:32.471Z] <54d4a1d6db8155e6700f853b> vim
[2015-03-26T02:36:35.405Z] <54d4a1d6db8155e6700f853b> ;)
[2015-03-26T02:36:42.879Z] <54d4a1d6db8155e6700f853b> I should probably switch at some point
[2015-03-26T03:23:22.842Z] <54c084dbdb8155e6700eed4c> "i've been using vim for three years, but that's only because i cant figure out how to exit"
[2015-03-26T07:47:33.870Z] <541a528b163965c9bc2053de> @trevorstephens you released gplearn? nice!
[2015-03-26T07:48:39.978Z] <541a528b163965c9bc2053de> you should create an `examples/` folder with a sample script on some regression dataset from scikit-learn (e.g. load_boston) and another on a synthetic data
[2015-03-26T07:48:57.353Z] <541a528b163965c9bc2053de> where you know the symbolic ground truth
[2015-03-26T10:18:53.682Z] <541a528b163965c9bc2053de> @amueller I am checking the documentation of the 0.16.X branch. It looks good. Will run trough the release checklist next.
[2015-03-26T10:19:17.934Z] <541a528b163965c9bc2053de> let me know if you find any release blocker in the mean time.
[2015-03-26T10:31:15.030Z] <5385f2fe048862e761fa2d40> I think that everyone in this room should read http://www.amazon.com/Scaling-Machine-Learning-Distributed-Approaches/dp/0521192242
[2015-03-26T10:31:24.861Z] <5385f2fe048862e761fa2d40> This is f***ing awesome!
[2015-03-26T10:32:58.697Z] <541a528b163965c9bc2053de> Thanks
[2015-03-26T10:59:16.185Z] <5385f2fe048862e761fa2d40> np
[2015-03-26T14:45:42.498Z] <54d4a1d6db8155e6700f853b> I didn't know about it. But it seems a bit dated (2011)
[2015-03-26T14:46:06.652Z] <54d4a1d6db8155e6700f853b> @ogrisel no blockers that I know of. Anything you want me to work on?
[2015-03-26T14:47:18.655Z] <54d4a1d6db8155e6700f853b> scheduling the release for the day before the GSoC deadline was a genious move on our part ^^
[2015-03-26T14:49:32.211Z] <54d4a1d6db8155e6700f853b> this needs backporting I think: https://github.com/scikit-learn/scikit-learn/pull/4448
[2015-03-26T14:49:43.012Z] <5385f2fe048862e761fa2d40> @amueller I'm sure there is a new edition somewhere
[2015-03-26T14:53:21.021Z] <54d4a1d6db8155e6700f853b> @omerzimp I wouldn't expect that.
[2015-03-26T14:56:25.036Z] <54c084dbdb8155e6700eed4c> Hi @ogrisel . Just reserved the name on Pypi and am getting the hang of all the code review tools last few days. Still a long way to go before I'm satisfied enough to release it. Definitely need to add a lot of tests (coverage at 4% haha), documentation, examples, etc etc. But it'll get there
[2015-03-26T14:58:05.118Z] <54c084dbdb8155e6700eed4c> I'd plan on some practical examples like boston, and then another like x^3 + x^2 + x + 1 or something, maybe in two dims
[2015-03-26T14:58:41.077Z] <54c084dbdb8155e6700eed4c> Maybe I'll try to write some docs for sklearn on the process of setting up your own <plugin>learn or something
[2015-03-26T15:00:52.188Z] <5474d9eadb8155e6700d8178> First step would be to build at a nice testing framework (#3810) I feel :)
[2015-03-26T15:02:21.697Z] <54c084dbdb8155e6700eed4c> So long as it remains stable. A lot of thought right now going into how I'll support various versions of sklearn. I may need to grab a copy of a lot of the tests and utils to keep from being harassed by bug reports
[2015-03-26T15:02:40.174Z] <54c084dbdb8155e6700eed4c> Since those don't go through deprication cycles so far as I know
[2015-03-26T15:02:55.700Z] <54c084dbdb8155e6700eed4c> But yeah, that looks like a good start @ragv 
[2015-03-26T15:12:44.844Z] <54d4a1d6db8155e6700f853b> @ogrisel I just did the backport
[2015-03-26T15:21:49.382Z] <541a528b163965c9bc2053de> ok, thanks
[2015-03-26T15:22:05.182Z] <541a528b163965c9bc2053de> about the version number, shall we use 0.16.0 or 0.16?
[2015-03-26T15:22:26.527Z] <541a528b163965c9bc2053de> Last time we did 0.15.0. But I used 0.16b1 instead of 0.16.0b1
[2015-03-26T15:22:58.174Z] <541a528b163965c9bc2053de> I think we should do 0.16.0 for lexicographical sorting of folders and stuff like that
[2015-03-26T15:34:28.222Z] <541a528b163965c9bc2053de> @amueller shall we do the `git log <last_release>.. | git shortlog -s -n` report for this release, or not?
[2015-03-26T15:35:44.123Z] <541a528b163965c9bc2053de> as you said earlier it, this vanity contest might encourage contributors not to squash their PR by default (and it does not reflect review work).
[2015-03-26T15:38:47.092Z] <54d4a1d6db8155e6700f853b> I'm -0. We could do alphabetical order?
[2015-03-26T15:39:28.370Z] <54d4a1d6db8155e6700f853b> Is 0.16.0 according to the pep thing? I think 0.16.0b1 was not, so we didn't do it. I think 0.16.0 is good
[2015-03-26T15:40:52.125Z] <54d4a1d6db8155e6700f853b> The whatsnew already mentioned the contributors next to the changes. Maybe that's enough vanity? That encourages cool things ;)
[2015-03-26T15:41:13.527Z] <54d4a1d6db8155e6700f853b> FUCK again broke the SVC trying to rebase on master. That is really finnicky
[2015-03-26T15:46:58.448Z] <54d4a1d6db8155e6700f853b> @ogrisel can you do me a favor and physically force @GaelVaroquaux to review #4189 so we can merge it? I only pick him because no-one else is in physical proximity ;)
[2015-03-26T15:48:24.303Z] <54d4a1d6db8155e6700f853b> why is fabian so high up in the commits?
[2015-03-26T15:48:59.285Z] <54d4a1d6db8155e6700f853b> oh I think my git log was wrong
[2015-03-26T15:49:24.498Z] <5474d9eadb8155e6700d8178> >  physically force @GaelVaroquaux to review #4189  Haha :laughing: 
[2015-03-26T15:51:30.910Z] <54d4a1d6db8155e6700f853b> @ogrisel any parts of the release you want me to do? update the links in the website? built the website?
[2015-03-26T17:47:28.155Z] <541a528b163965c9bc2053de> all 0.16b1 0.16.0b1 0.16 0.16.0 are valid according to pep 440
[2015-03-26T17:48:10.561Z] <541a528b163965c9bc2053de> +1 for not including the stats
[2015-03-26T17:48:45.089Z] <550f53e215522ed4b3dda5f6> +1 0.16.0
[2015-03-26T17:48:47.645Z] <541a528b163965c9bc2053de> I had to leave the office early (going to a meetup to try and hire graduating students to work on sklearn next year) ...
[2015-03-26T17:48:56.838Z] <541a528b163965c9bc2053de> ok for 0.16.0 then
[2015-03-26T17:49:59.262Z] <541a528b163965c9bc2053de> Let's merge #4189: it's mostly a fix, no new API, no hyperparams, no documentation or example to update. It should not be controversial.
[2015-03-26T17:50:56.145Z] <541a528b163965c9bc2053de> git log 0.15.2..0.16.X | git shortlog -s -n
[2015-03-26T17:51:03.193Z] <541a528b163965c9bc2053de> if you want the stats
[2015-03-26T17:53:37.842Z] <541a528b163965c9bc2053de> @amueller I let you do the cherry-pick for https://github.com/scikit-learn/scikit-learn/pull/4189/commits into 0.16.X
[2015-03-26T17:53:51.519Z] <541a528b163965c9bc2053de> to fix your ranking for 0.16.0 commit number :)
[2015-03-26T18:01:20.862Z] <5474d9eadb8155e6700d8178> @ogrisel @amueller Any final comments on my revised prop? I made it a bit ambitious but I think it is doable with full time involvement. WDYT?
[2015-03-26T18:02:34.535Z] <541a528b163965c9bc2053de> not there? let me do it. Then I will change the version number and start fixing the links in the doc.
[2015-03-26T18:05:52.876Z] <54d4a1d6db8155e6700f853b> @ogrisel I'm back
[2015-03-26T18:05:55.888Z] <54d4a1d6db8155e6700f853b> just out for lunch
[2015-03-26T18:07:00.847Z] <54d4a1d6db8155e6700f853b> @ragv I'll do it in a bit
[2015-03-26T18:07:09.261Z] <541a528b163965c9bc2053de> argl actually the cherry-pick of #4189 is not trivial. We probably also need to bacport #4326 too but this one is not trivial either...
[2015-03-26T18:07:34.296Z] <541a528b163965c9bc2053de> I have to go to the meetup soon, I won't have time to do the #4189 backport today.
[2015-03-26T18:07:45.774Z] <54d4a1d6db8155e6700f853b> I'll do it, I can release afterwards.
[2015-03-26T18:07:46.265Z] <5474d9eadb8155e6700d8178> Thanks... sorry for hijacking into your 0.16 discussions... :)
[2015-03-26T18:07:46.302Z] <541a528b163965c9bc2053de> @ragv let me do another pass on your proposal
[2015-03-26T18:08:19.072Z] <54d4a1d6db8155e6700f853b> damn I though #4326 was in
[2015-03-26T18:08:31.316Z] <541a528b163965c9bc2053de> no pbm, it's our fault to have scheduled to do the release on the same week as the GSoC deadline
[2015-03-26T18:08:44.777Z] <541a528b163965c9bc2053de> maybe it is in then
[2015-03-26T18:09:16.424Z] <541a528b163965c9bc2053de> I had conflicts that looked non trivial when picking #4189 so it did a git reset --hard on my sandbox
[2015-03-26T18:11:37.330Z] <54d4a1d6db8155e6700f853b> #4326 was before branching even
[2015-03-26T18:16:14.459Z] <54d4a1d6db8155e6700f853b> @ogrisel it was the docstring stuff by @ragv that caused the cherry-pick error. I backported it
[2015-03-26T18:16:50.290Z] <54d4a1d6db8155e6700f853b> pushed to 0.16.X should be fine now
[2015-03-26T18:21:52.698Z] <5474d9eadb8155e6700d8178> Yayy I got 50 commits :P
[2015-03-26T18:22:49.180Z] <54d4a1d6db8155e6700f853b> @ogrisel what is the status now? do you want to do it or should I? Also, should we have a "highlights" section in whatsnew?
[2015-03-26T18:25:26.102Z] <54d4a1d6db8155e6700f853b> maybe not
[2015-03-26T18:26:50.242Z] <54d4a1d6db8155e6700f853b> next we should push the 0.16.0 version, trigger the buildbot, and move the docs, right?
[2015-03-26T18:27:05.533Z] <54d4a1d6db8155e6700f853b> are you working on any of these?
[2015-03-26T18:30:27.436Z] <541a528b163965c9bc2053de> @ragv I would move the out-of-core cross-val as a low priority optional in case everything else is implemented first.
[2015-03-26T18:30:49.511Z] <541a528b163965c9bc2053de> I doubt we will have the time to implement everything else but one never knows :)
[2015-03-26T18:31:12.329Z] <54d4a1d6db8155e6700f853b> hum, https://github.com/scikit-learn/scikit-learn/pull/4420 would have been nice, but without a review by a PLS person I'm doubtful
[2015-03-26T18:31:18.474Z] <541a528b163965c9bc2053de> if you feel like it
[2015-03-26T18:31:24.839Z] <541a528b163965c9bc2053de> @amueller would be great to have a highlight section.
[2015-03-26T18:31:30.489Z] <54d4a1d6db8155e6700f853b> ok
[2015-03-26T18:31:40.033Z] <5474d9eadb8155e6700d8178> 
[2015-03-26T18:31:48.774Z] <54d4a1d6db8155e6700f853b> @ogrisel I'll make a quick PR so you can review
[2015-03-26T18:32:48.102Z] <541a528b163965c9bc2053de> other than that, version change to 0.16.0, update the links in the menus for the doc, put the 0.16.0 tag and push it, update the submodule in the MacPython repo to get travis build wheels for OSX, wait for appveyor to do the same for windows. Then let me know, I will manually test install on my mac and a windows VM
[2015-03-26T18:33:52.172Z] <5474d9eadb8155e6700d8178> @ogrisel Okay! Thanks for the review.... :) Should I perhaps concentrate on gen cv and early stopping for the month of July?
[2015-03-26T18:36:55.905Z] <5474d9eadb8155e6700d8178> Except for the month of July, I believe I have framed a satisfactory (to myself :p) timeline. It is the month of July I am not quite sure, what I will get to work on that could be useful for sk and also be feasible for me...
[2015-03-26T18:40:32.406Z] <541a528b163965c9bc2053de> my presentation will start soon, then there will be beers so I won't be of any use tonight.
[2015-03-26T18:40:54.447Z] <541a528b163965c9bc2053de> but if appveyor and macpython / travis are all green, I can do the manual tests tomorrow morning
[2015-03-26T18:41:15.099Z] <541a528b163965c9bc2053de> and build the doc to rsync the new version.
[2015-03-26T18:42:15.375Z] <54d4a1d6db8155e6700f853b> https://github.com/amueller/scikit-learn/commit/dbe3cd33145677cdae9bdbcbef0c3791bf94bca3
[2015-03-26T18:42:29.706Z] <541a528b163965c9bc2053de> @ragv don't worry too much, I think there is a lot of testing /  benchmarking / polishing / documentation cleaning to do
[2015-03-26T18:42:38.947Z] <54d4a1d6db8155e6700f853b> can you have a brief look at the commit https://github.com/amueller/scikit-learn/commit/dbe3cd33145677cdae9bdbcbef0c3791bf94bca3 @ogrisel ?
[2015-03-26T18:43:26.340Z] <5474d9eadb8155e6700d8178> @ogrisel Thanks I'll just remove ooc... pl let me know if you feel I should do any more modifications to my prop :)
[2015-03-26T18:43:46.989Z] <541a528b163965c9bc2053de> @amueller maybe put a word on the input validation stuff: "Improved and more consistent error messages when fitting estimators on invalid input data."
[2015-03-26T18:44:48.822Z] <541a528b163965c9bc2053de> LSH is Locality-sensitive hashing
[2015-03-26T18:44:57.056Z] <541a528b163965c9bc2053de> not local-sensitive hashing.
[2015-03-26T18:45:29.039Z] <541a528b163965c9bc2053de> Maybe reword as "Scalable approximate nearest neighbors search with Locality-sensitive hashing forests"
[2015-03-26T18:45:43.769Z] <541a528b163965c9bc2053de> the auto-tuning part could still be improved :)
[2015-03-26T18:46:29.708Z] <541a528b163965c9bc2053de> Maybe we should explicitly mention DBSCAN for the speed improvements
[2015-03-26T18:46:31.751Z] <54d4a1d6db8155e6700f853b> ok
[2015-03-26T18:46:57.814Z] <541a528b163965c9bc2053de> "speed improvements, notably DBSCAN, ..."
[2015-03-26T18:47:09.771Z] <541a528b163965c9bc2053de> or maybe the phrasing is bad
[2015-03-26T18:47:10.599Z] <54d4a1d6db8155e6700f853b> input validation was already mostly in 0.14, right?
[2015-03-26T18:47:21.423Z] <541a528b163965c9bc2053de> 0.15
[2015-03-26T18:47:58.017Z] <541a528b163965c9bc2053de> but it has been improved: the utils were there in 0.15 but they were not consistently used throughout the code base.
[2015-03-26T18:47:59.814Z] <54d4a1d6db8155e6700f853b> that's what I ment
[2015-03-26T18:48:00.812Z] <54d4a1d6db8155e6700f853b> yeah
[2015-03-26T18:48:03.499Z] <54d4a1d6db8155e6700f853b> true
[2015-03-26T18:48:16.542Z] <541a528b163965c9bc2053de> remember the work you did in test_common over the past 6 months :P ?
[2015-03-26T18:48:17.815Z] <54d4a1d6db8155e6700f853b> - Improved error messages and better validation when using malformed input data.
[2015-03-26T18:48:27.594Z] <541a528b163965c9bc2053de> great phrasing :+1:
[2015-03-26T18:49:11.922Z] <54d4a1d6db8155e6700f853b> what I did when in test_common is mostly a blur ;) I remember touching every single file during the last sprint when removing check_arrays lol
[2015-03-26T18:49:53.027Z] <541a528b163965c9bc2053de> :)
[2015-03-26T18:50:12.708Z] <54d4a1d6db8155e6700f853b> DBSCAN mentioning jay or nay?
[2015-03-26T18:50:23.007Z] <54d4a1d6db8155e6700f853b> maybe also "Many speed improvements, reduced memory requirements, bug-fixes and better default settings."
[2015-03-26T18:50:46.632Z] <541a528b163965c9bc2053de> as you wish.
[2015-03-26T18:50:58.007Z] <541a528b163965c9bc2053de> I think many users are interested in DBSCAN
[2015-03-26T18:52:20.197Z] <541a528b163965c9bc2053de> @ragv I think your proposal is fine
[2015-03-26T18:53:36.430Z] <54d4a1d6db8155e6700f853b> https://github.com/amueller/scikit-learn/commit/4aaaaae3ecdea54f5bd6d073a712efc389668529
[2015-03-26T18:54:47.429Z] <541a528b163965c9bc2053de> Looks great to me
[2015-03-26T18:55:30.600Z] <541a528b163965c9bc2053de> Don't forget to cherry-pick the paragraph both in master and 0.16.
[2015-03-26T18:55:33.651Z] <54d4a1d6db8155e6700f853b> ok. I'll push it, do the docs stuff and push the docs. I think we can do this now.
[2015-03-26T18:55:47.417Z] <54d4a1d6db8155e6700f853b> whatsnew changes will go to both branches
[2015-03-26T18:57:15.628Z] <5474d9eadb8155e6700d8178> @ogrisel thanks :D
[2015-03-26T19:00:40.048Z] <541a528b163965c9bc2053de> thanks
[2015-03-26T19:10:56.903Z] <54d4a1d6db8155e6700f853b> @ogrisel have you looked at Vinayak's proposal by any chance?
[2015-03-26T19:17:09.413Z] <550f53e215522ed4b3dda5f6> Hi, I am wondering how many slots does scikit-learn have this year, if it is not a top secret? I remember the number is 4 in 2014.
[2015-03-26T19:20:58.268Z] <54d4a1d6db8155e6700f853b> https://wiki.python.org/moin/SummerOfCode/FrequentlyAskedQuestions#How_many_slots_does_python_get.3F__How_many_does_project_.24x_get.3F
[2015-03-26T19:21:37.514Z] <54d4a1d6db8155e6700f853b> we currently have 5 mentors registered (if no one else registered) which means we would get a max of 5 slots
[2015-03-26T19:31:11.584Z] <550f53e215522ed4b3dda5f6> OK. Thanks! Hope we have 5.
[2015-03-26T19:48:41.894Z] <551061f615522ed4b3ddb1c0> Hello everyone! Just got an invitation to join the chat here. Any final bit of advice on my proposal?
[2015-03-26T19:49:00.171Z] <5474d9eadb8155e6700d8178> @amueller 
[2015-03-26T19:49:06.064Z] <5474d9eadb8155e6700d8178> ^
[2015-03-26T19:49:09.465Z] <54d4a1d6db8155e6700f853b> ?
[2015-03-26T19:49:35.438Z] <5474d9eadb8155e6700d8178> Sorry wrong key presses :worried: 
[2015-03-26T19:50:20.028Z] <54d4a1d6db8155e6700f853b> hi @bryandeng I have to look at your proposal again. Sorry, we are a bit busy today, we are also doing a perfectly timed release today
[2015-03-26T19:51:06.317Z] <54d4a1d6db8155e6700f853b> The work-load seemed a bit light. The proposal on the idea page was not super fleshed out, unfortunately
[2015-03-26T19:51:55.373Z] <54d4a1d6db8155e6700f853b> Maybe you can give a bit more background on the improvements for the existing algorithms. currently it is only half a sentence.
[2015-03-26T19:53:00.771Z] <54d4a1d6db8155e6700f853b> Do you have any other ideas in the semi-supervised scope?
[2015-03-26T19:53:14.355Z] <551061f615522ed4b3ddb1c0> Got it.
[2015-03-26T19:58:02.591Z] <551061f615522ed4b3ddb1c0> I think I can implement more than one semi-supervised algorithms, candidates of which can be discussed in the community bonding period.
[2015-03-26T20:06:46.647Z] <54d4a1d6db8155e6700f853b> I know it is pretty late now, but it would be great if you could propose some. In the other semi-supervised proposal I mentioned transductive SVMs. I'm not entirely sure they are the best way to go, but at least they are a common benchmark. The more your proposal shows you are familiar with the material and already looked into it, the better
[2015-03-26T20:34:16.367Z] <551061f615522ed4b3ddb1c0> OK. My original intention to write like this is that I want to serve the needs of the community to the greatest extent. Since what algorithms we most want in sklearn.semi_supervised hasn't been fully discussed in the community, I decided not to show personal preferences. Now I'll pick some algorithms according to my understandings.
[2015-03-26T20:39:15.666Z] <54d4a1d6db8155e6700f853b> I understand your motivation, and it would have been better if we could have had a broader discussion previously on the mailing list. Unfortunately, mostly because of lack of time of the developers, that didn't happen.
[2015-03-26T20:40:00.306Z] <54d4a1d6db8155e6700f853b> For your proposal to be strong, you do need to say more than you currently say, though.
[2015-03-27T14:14:43.010Z] <54d4a1d6db8155e6700f853b> @ogrisel right, I forgot to fix the menu. Is there a good way to upload just the html so you don't have to optimize the pngs again?
[2015-03-27T14:32:54.698Z] <541a528b163965c9bc2053de> I was about to find a way to not optimize the png again :)
[2015-03-27T14:33:24.048Z] <541a528b163965c9bc2053de> I tested on OSX, now on testing on windows and the sdist from linux in a docker container in //
[2015-03-27T14:37:22.033Z] <54d4a1d6db8155e6700f853b> Well I can rebuild the docs in the folder with the optimized png once I get into the office
[2015-03-27T14:37:27.709Z] <54d4a1d6db8155e6700f853b> if you want to wait for an hour
[2015-03-27T14:42:31.002Z] <541a528b163965c9bc2053de> I already fetched them local with rsync
[2015-03-27T14:42:53.687Z] <541a528b163965c9bc2053de> actually not locally, to some rackspace VM but this is the same
[2015-03-27T14:46:30.124Z] <54d4a1d6db8155e6700f853b> good
[2015-03-27T14:46:38.832Z] <54d4a1d6db8155e6700f853b> I just decided to stay at home, I'm too sick
[2015-03-27T14:52:44.453Z] <54d4a1d6db8155e6700f853b> do you need help with anything? Otherwise I might turn around and sleep on
[2015-03-27T14:54:16.892Z] <541a528b163965c9bc2053de> I think I can do it all.
[2015-03-27T14:54:37.043Z] <54d4a1d6db8155e6700f853b> let me know when you tweet so I can retweet ;)
[2015-03-27T14:54:50.097Z] <541a528b163965c9bc2053de> I have pbm testing under windows as apparently the latest scipy from christoph gohlke under Python 3.4 is broken.
[2015-03-27T14:54:59.101Z] <541a528b163965c9bc2053de> will try on python 2.7 instead
[2015-03-27T14:55:04.418Z] <541a528b163965c9bc2053de> ok
[2015-03-27T14:56:16.342Z] <541a528b163965c9bc2053de> for the GSoC do you think we need to do anything else in the short term? We can still enable the edit mode on the GSoC proposals that students on a case by case basis for 2 weeks after today's deadline if we need to.
[2015-03-27T14:58:18.424Z] <54d4a1d6db8155e6700f853b> ok. well it would be good to reread the final versions. I did that only with like two of them. But we can do that later
[2015-03-27T15:03:03.492Z] <541a528b163965c9bc2053de> yes
[2015-03-27T15:03:27.188Z] <541a528b163965c9bc2053de> I'll put some feedback on the semi-supervised proposal (directly as comment on melange)
[2015-03-27T15:05:11.122Z] <551061f615522ed4b3ddb1c0> @ogrisel I'm still in the process of adding some stuff. Will be finished in 40 minutes.
[2015-03-27T15:06:58.074Z] <541a528b163965c9bc2053de> ok great
[2015-03-27T15:09:28.989Z] <550f53e215522ed4b3dda5f6> My proposal in the google-melange has unnecessary html marks, like underscores. I think it comes from google-melange, since I did not add them at all. I also submitted a dropbox link to a PDF version, just in case.
[2015-03-27T15:10:36.225Z] <541a528b163965c9bc2053de> @xuewei4d Can you try to clean up the formatting?
[2015-03-27T15:11:40.877Z] <550f53e215522ed4b3dda5f6> Yeah, I am on it.
[2015-03-27T15:16:57.600Z] <541a528b163965c9bc2053de> thanks
[2015-03-27T15:17:46.788Z] <550f53e215522ed4b3dda5f6> OK. Now it's clean. Copy/paste the html source code instead of paste into the melange own editor
[2015-03-27T15:18:12.342Z] <541a528b163965c9bc2053de> ok great
[2015-03-27T16:22:36.859Z] <541a528b163965c9bc2053de> @amueller let's the tweeting storm start!
[2015-03-27T16:23:15.773Z] <5474d9eadb8155e6700d8178> Yayy 0.16 :beers: 
[2015-03-27T16:23:26.956Z] <541a528b163965c9bc2053de> :beers: :
[2015-03-27T16:23:50.807Z] <5474d9eadb8155e6700d8178> We should probably change the gitter channel status like some do in IRC?
[2015-03-27T16:24:48.344Z] <541a528b163965c9bc2053de> can you do it?
[2015-03-27T16:25:00.742Z] <541a528b163965c9bc2053de> I don't remember by nickserv passwd
[2015-03-27T16:25:12.382Z] <541a528b163965c9bc2053de> so I cannot do op stuff anymore
[2015-03-27T16:27:45.921Z] <5474d9eadb8155e6700d8178> I meant here in gitter but I'll try the same for IRC too :)
[2015-03-27T16:27:56.912Z] <5474d9eadb8155e6700d8178> [![blob](https://files.gitter.im/scikit-learn/scikit-learn/g3A7/thumb/blob.png)](https://files.gitter.im/scikit-learn/scikit-learn/g3A7/blob)
[2015-03-27T16:29:38.935Z] <550f53e215522ed4b3dda5f6> :beers: 
[2015-03-27T16:31:14.957Z] <5474d9eadb8155e6700d8178> It says I need to be channel op to do that... How do I become one?
[2015-03-27T16:34:35.510Z] <541a528b163965c9bc2053de> you need to find another op :)
[2015-03-27T16:34:50.185Z] <541a528b163965c9bc2053de> which I think I used to be but cannot find my account info anymore
[2015-03-27T16:34:50.561Z] <5474d9eadb8155e6700d8178> yea on it ;)
[2015-03-27T16:34:56.091Z] <541a528b163965c9bc2053de> there might be others
[2015-03-27T16:35:08.006Z] <541a528b163965c9bc2053de> maybe @NelleV and @amueller are op
[2015-03-27T16:35:09.846Z] <541a528b163965c9bc2053de> ops
[2015-03-27T16:35:16.254Z] <541a528b163965c9bc2053de> not 100% sure though
[2015-03-27T16:35:53.731Z] <5474d9eadb8155e6700d8178> @NelleV is around I'll ask her :) (her right? :p)
[2015-03-27T16:37:47.858Z] <5474d9eadb8155e6700d8178> `scikit-learn 0.16 is out! http://scikit-learn.org/0.16/whats_new.html... Try out the same with "pip install scikit-learn==0.16"` Would be good?
[2015-03-27T16:39:27.450Z] <541a528b163965c9bc2053de> `pip install -U scikit-learn` would do
[2015-03-27T16:39:43.169Z] <541a528b163965c9bc2053de> @ragv yes it's "her"
[2015-03-27T16:40:26.094Z] <5474d9eadb8155e6700d8178> Ah :) BTW Only could do it for gitter (by double clicking on the channel status) ;)
[2015-03-27T16:42:25.906Z] <541a528b163965c9bc2053de> no problem
[2015-03-27T16:50:34.969Z] <551061f615522ed4b3ddb1c0> :beers: 
[2015-03-27T20:23:37.982Z] <54d4a1d6db8155e6700f853b> I think I'm the only IRC op ;)
[2015-03-27T20:31:52.503Z] <54d4a1d6db8155e6700f853b> @ogrisel the oreilly people asked for the slides for the webcast on Monday night ^^ we should probably talk about the content
[2015-03-27T20:34:48.034Z] <541a528b163965c9bc2053de> yes
[2015-03-27T20:35:22.380Z] <541a528b163965c9bc2053de> which topics do you want to cover?
[2015-03-27T20:36:11.694Z] <541a528b163965c9bc2053de> I am generic intro slides in there: https://speakerdeck.com/ogrisel/machine-learning-in-python-with-scikit-learn-1
[2015-03-27T20:36:40.840Z] <541a528b163965c9bc2053de> but they overlap a lot with the slides I presented for the 0.15 release.
[2015-03-27T20:36:50.614Z] <541a528b163965c9bc2053de> and do not cover the new stuff
[2015-03-27T20:37:24.541Z] <541a528b163965c9bc2053de> I can work on sunday on new slides to present stuff like LSH Forest, DBSCAN and / or Birch
[2015-03-27T20:37:50.340Z] <541a528b163965c9bc2053de> we can use google docs to work collaboratively on a new deck
[2015-03-27T20:38:20.256Z] <541a528b163965c9bc2053de> those slides are in keynote, but feel free to do as many screen grabs as you want
[2015-03-27T20:40:57.502Z] <54d4a1d6db8155e6700f853b> I feel super sick, I hope I'll be well enough tomorrow to work on new slides. But I also have to work on slides for a talk I give on Monday :-/
[2015-03-27T20:41:05.559Z] <541a528b163965c9bc2053de> I think we should prepare a slide on t-SNE too
[2015-03-27T20:41:26.956Z] <541a528b163965c9bc2053de> Hope you will get better
[2015-03-27T20:41:52.389Z] <54d4a1d6db8155e6700f853b> google docs seems like a good idea
[2015-03-27T20:42:06.905Z] <541a528b163965c9bc2053de> tomorrow is going to get complicated for me. But sunday I should be able to work on it for some reasonable amount of time.
[2015-03-27T20:45:41.542Z] <54d4a1d6db8155e6700f853b> I'll try to make some slides on T-SNE, LDA and the GP, ok? We also need slide for Birch, the logistic path algorithm (?) and calibartion
[2015-03-27T20:45:58.939Z] <54d4a1d6db8155e6700f853b> do we want to talk about MLPs and do you already have slides for that?
[2015-03-27T20:46:07.054Z] <541a528b163965c9bc2053de> I forgot about calibration, I can do that indeed
[2015-03-27T20:46:30.161Z] <541a528b163965c9bc2053de> no good slide for MLPs but would indeed say a couple of words about that
[2015-03-27T20:46:54.478Z] <541a528b163965c9bc2053de> I can review the logistic stuff
[2015-03-27T20:47:21.659Z] <54d4a1d6db8155e6700f853b> I can also do the calibration. I have no idea about Birch. Do you?
[2015-03-27T20:47:32.801Z] <54d4a1d6db8155e6700f853b> I think I should go out and find a doctor now
[2015-03-27T20:52:21.363Z] <541a528b163965c9bc2053de> a bit yes
[2015-03-27T20:52:44.882Z] <541a528b163965c9bc2053de> ok take care
[2015-03-28T02:13:19.733Z] <54c084dbdb8155e6700eed4c> Thanks for all the work on releasing 0.16 guys! It is much appreciated! :beers: 
[2015-03-28T21:13:28.768Z] <5474d9eadb8155e6700d8178> @ogrisel Any reviews for #4362? :)
[2015-03-28T21:29:08.848Z] <5474d9eadb8155e6700d8178> There is an unrelated [test failure](https://travis-ci.org/scikit-learn/scikit-learn/jobs/56248127) in Python 3.4 `:/ `
[2015-03-28T21:40:21.598Z] <5474d9eadb8155e6700d8178> [Using code formatted smiley in gitter looks good `:D`]
[2015-03-28T21:45:22.282Z] <5474d9eadb8155e6700d8178> @xuewei4d You could also use commit headers like `ENH` `FIX` `TST` `COSMIT` `MAINT` etc... to describe your commits `:)` just a minor suggestion... feel free to ignore `:)`
[2015-03-28T21:49:55.544Z] <550f53e215522ed4b3dda5f6> Sure.
[2015-03-28T21:50:35.258Z] <550f53e215522ed4b3dda5f6> COSMIT means cosmetic?
[2015-03-28T21:54:11.110Z] <5474d9eadb8155e6700d8178> Yeah `:)`
[2015-03-28T22:24:04.518Z] <54d4a1d6db8155e6700f853b> I think @ogrisel is busy today and I'm sick and need to make slides :-/
[2015-03-28T22:24:12.089Z] <54d4a1d6db8155e6700f853b> I re-triggered travis for you though
[2015-03-28T23:03:32.886Z] <5474d9eadb8155e6700d8178> Thanks! and take care `:)`
[2015-03-29T15:51:52.744Z] <54d4a1d6db8155e6700f853b> @ogrisel are you around?
[2015-03-29T15:52:38.229Z] <541a528b163965c9bc2053de> yes
[2015-03-29T15:52:51.104Z] <541a528b163965c9bc2053de> are you feeling better?
[2015-03-29T15:53:08.036Z] <54d4a1d6db8155e6700f853b> yeah, somewhat. So do we do only slides, no notebooks?
[2015-03-29T15:53:30.663Z] <541a528b163965c9bc2053de> apparently yes, this is a constraint of their platform apparently
[2015-03-29T15:53:43.453Z] <54d4a1d6db8155e6700f853b> ok. and use google presentation?
[2015-03-29T15:55:11.258Z] <541a528b163965c9bc2053de> actually it's possible to have a screen share for live demo but it needs flash and or java
[2015-03-29T15:55:17.981Z] <541a528b163965c9bc2053de> I would not count on it too much
[2015-03-29T15:55:33.503Z] <541a528b163965c9bc2053de> we can use google doc and export the slides as PDF
[2015-03-29T15:55:35.391Z] <541a528b163965c9bc2053de> I think
[2015-03-29T15:55:38.750Z] <541a528b163965c9bc2053de> let's try
[2015-03-29T15:57:23.319Z] <541a528b163965c9bc2053de> I sent you an invite
[2015-03-29T15:58:15.709Z] <54d4a1d6db8155e6700f853b> thanks
[2015-03-29T15:58:25.757Z] <54d4a1d6db8155e6700f853b> That sounds like a good strategy
[2015-03-30T23:12:03.908Z] <541a528b163965c9bc2053de> @amueller I think I am ok on my side for the slides.
[2015-03-30T23:35:39.593Z] <541a528b163965c9bc2053de> @amueller I let you send the slides to yasmina and ben once you are happy with them
[2015-03-31T10:51:30.239Z] <5385f2fe048862e761fa2d40> What's the difference between sklearn's kmeans implementation and pylearn2's implementation?
[2015-03-31T14:39:14.060Z] <54d4a1d6db8155e6700f853b> @ogrisel will do
[2015-03-31T14:40:18.741Z] <54d4a1d6db8155e6700f853b> @omerzimp pylearn2 has gpu support, but I don't know anything about their kmeans implementation. didn't know they had one
[2015-03-31T14:40:49.008Z] <5385f2fe048862e761fa2d40> @amueller They do but it's not gpu accelerated
[2015-03-31T14:41:16.217Z] <54d4a1d6db8155e6700f853b> are you sure? I thought all operations are based on theano?
[2015-03-31T14:43:17.944Z] <54d4a1d6db8155e6700f853b> hum looks to be numpy. then the difference is probably that ours is faster, supports sparse matrices, and better initialization
[2015-03-31T15:56:54.339Z] <5395efa3a9176b500d1cd7fb> wow, ur server is down? Update enjoyment?
[2015-03-31T16:03:19.052Z] <54d4a1d6db8155e6700f853b> nope. just sourceforge
[2015-03-31T16:03:31.174Z] <54d4a1d6db8155e6700f853b> hum sourceforge is up, though
[2015-03-31T16:03:34.940Z] <54d4a1d6db8155e6700f853b> maybe the dns is down?
[2015-03-31T16:03:55.025Z] <5395efa3a9176b500d1cd7fb> whats the ip of ur website?
[2015-03-31T16:04:27.155Z] <54d4a1d6db8155e6700f853b> no, doesn't seem to be dns either, ping works.
[2015-03-31T16:04:28.950Z] <5395efa3a9176b500d1cd7fb> then i could try.
[2015-03-31T16:04:56.637Z] <5395efa3a9176b500d1cd7fb> to do with Travis being sad? #4270
[2015-03-31T16:09:26.111Z] <54d4a1d6db8155e6700f853b> nope, completely unrelated.
[2015-03-31T16:09:55.994Z] <54d4a1d6db8155e6700f853b> accorting to ping the sourceforge vhost 216.34.181.97
[2015-03-31T16:11:08.275Z] <54d4a1d6db8155e6700f853b> but I don't think there is anything we can do except for moving our hosting
[2015-03-31T16:11:20.286Z] <5395efa3a9176b500d1cd7fb> ah yes, could have done it myself, knowing that the ping works. 
[2015-03-31T16:11:52.643Z] <5395efa3a9176b500d1cd7fb> bad experiences with sourceforge?
[2015-03-31T16:16:37.115Z] <54d4a1d6db8155e6700f853b> yeah, also uploading is a bit annoying
[2015-03-31T16:20:17.067Z] <54d4a1d6db8155e6700f853b> @ogrisel I tried to create a cool illustration of IncrementalPCA, but it really seems to perform not that great :-/
[2015-03-31T17:48:53.081Z] <54d4a1d6db8155e6700f853b> @ogrisel not super happy with my slides but I think I'll just sent them out. We have quite a lot of material already
[2015-03-31T18:19:56.230Z] <541a528b163965c9bc2053de> @amueller alright. IncrementalPCA is not expected to be faster than PCA
[2015-03-31T18:20:01.794Z] <541a528b163965c9bc2053de> just out of core
[2015-03-31T18:20:55.258Z] <541a528b163965c9bc2053de> we could implement IncrementalPCA with the `randomized_svd` solver internally. It should be both fast (for low `n_components`) and out of core.
[2015-03-31T19:13:02.476Z] <54d4a1d6db8155e6700f853b> yeah
[2015-03-31T19:13:36.823Z] <54d4a1d6db8155e6700f853b> If you don't think it is horrible, I think I'll leave it as is
[2015-04-01T12:32:47.460Z] <5474d9eadb8155e6700d8178> @ogrisel around?
[2015-04-01T12:42:19.870Z] <541a528b163965c9bc2053de> @ragv yes
[2015-04-01T12:46:18.991Z] <541a528b163965c9bc2053de> > If you don't think it is horrible, I think I'll leave it as is  @amueller I only see a single slide with bullet bullet points for incremental PCA. Is it this slide you are talking about or do you have a figure for IncrementalPCA?
[2015-04-01T14:05:15.130Z] <54d4a1d6db8155e6700f853b> @ogrisel I don't have a figure for IncrementalPCA. I couldn't produce a good one
[2015-04-01T14:05:41.518Z] <54d4a1d6db8155e6700f853b> I could have added a code block showing partial fit, but I felt that added little
[2015-04-01T14:23:16.457Z] <541a528b163965c9bc2053de> no pbm
[2015-04-01T14:23:21.944Z] <541a528b163965c9bc2053de> I think it's fine like this
[2015-04-01T14:23:41.446Z] <541a528b163965c9bc2053de> there is a lot of material to cover already
[2015-04-01T14:27:29.536Z] <54d4a1d6db8155e6700f853b> I agree
[2015-04-01T16:44:19.147Z] <5474d9eadb8155e6700d8178> @ogrisel I saw you online and thought of pestering you to review #3907 `;) :p`
[2015-04-01T19:27:06.687Z] <541a528b163965c9bc2053de> @ragv  I am too tired to do it now, I put that on my todo list for tomorrow morning. Don't hesitate to ping me again if I fail to deliver :)
[2015-04-01T23:01:02.909Z] <5474d9eadb8155e6700d8178> Thanks :D > Don't hesitate to ping me again if I fail to deliver  don't worry about that `:p`
[2015-04-02T14:46:01.411Z] <54d4a1d6db8155e6700f853b> sprinters here?
[2015-04-02T14:49:12.235Z] <54d4a1d6db8155e6700f853b> I feel excluded :-/
[2015-04-02T15:23:38.809Z] <541a528b163965c9bc2053de> hi @amueller sorry I was in the metro to get back home for the webcast
[2015-04-02T15:24:51.916Z] <541a528b163965c9bc2053de> there are still people at the sprint but I think nobody is on gitter
[2015-04-02T15:25:12.870Z] <541a528b163965c9bc2053de> maybe @NelleV is on IRC
[2015-04-02T15:28:11.336Z] <541a528b163965c9bc2053de> @amueller the call starts in 3 mins right? I wanted to make sure that I am not off by one hour because of the summer time stuff.
[2015-04-02T15:34:10.212Z] <54d4a1d6db8155e6700f853b> @ogrisel you are on time :) 
[2015-04-02T15:34:20.785Z] <54d4a1d6db8155e6700f853b> at least the same time I think it is
[2015-04-02T15:35:42.854Z] <541a528b163965c9bc2053de> I will call with my phone
[2015-04-02T17:12:49.229Z] <541a528b163965c9bc2053de> good!
[2015-04-02T17:12:50.651Z] <541a528b163965c9bc2053de> :)
[2015-04-02T18:07:24.887Z] <550f53e215522ed4b3dda5f6> sprinter? Is there any event recently? So many new PRs ...
[2015-04-02T18:17:47.581Z] <541a528b163965c9bc2053de> yes there was a short one day sprint in Paris today (it should be over now). There was ~15 people in the room when I was there earlier this afternoon.
[2015-04-02T18:19:26.210Z] <550f53e215522ed4b3dda5f6> Glad to see these new contributors. :)
[2015-04-02T18:54:51.839Z] <5474d9eadb8155e6700d8178> Wow looking forward to  participating in one!!! :D :D
[2015-04-02T22:12:27.789Z] <54d4a1d6db8155e6700f853b> ragv you'll be at the epi-center of sprints soon, I heard :)
[2015-04-02T22:12:53.299Z] <54d4a1d6db8155e6700f853b> I home I can come to paris for the next one, will be awesome!
[2015-04-03T16:52:00.867Z] <5474d9eadb8155e6700d8178> Yeaa :D Thats awesome... I'm really looking forward to that :)
[2015-04-03T17:38:54.366Z] <54d4a1d6db8155e6700f853b> this looks pretty bad: https://github.com/scikit-learn/scikit-learn/pull/4507
[2015-04-03T17:39:11.251Z] <54d4a1d6db8155e6700f853b> how about we do a bug-fix release when this is done with the fix to isotonic, my CCA fix, and this?
[2015-04-04T18:12:32.612Z] <54d4a1d6db8155e6700f853b> @ogrisel where was your mlp notebook again?
[2015-04-04T18:22:52.554Z] <54d4a1d6db8155e6700f853b> @ogrisel it looks like the current partial_fit goes over the data multiple times. That seems odd.
[2015-04-06T12:19:27.569Z] <541a528b163965c9bc2053de> +1 for a 0.16.1 release with such bad bug fixes.
[2015-04-06T12:20:13.455Z] <541a528b163965c9bc2053de> I created the milestone. However I have to work on my talks for PyCon now. Maybe I can help for the 0.16.1 release during the sprints next week.
[2015-04-06T13:41:37.821Z] <54d4a1d6db8155e6700f853b> The k-means fortran layout bug might need another fix and we should check if the bug appears elsewhere, too....
[2015-04-06T13:49:55.915Z] <541a528b163965c9bc2053de> yes we could do a new common test for that, leveraging @ragv's `assert_same_model` utility.
[2015-04-06T14:00:56.109Z] <54d4a1d6db8155e6700f853b> or we could just use ``fit_predict``....
[2015-04-06T14:01:22.374Z] <54d4a1d6db8155e6700f853b> Ok, I'll try to use his branch and see if that works...
[2015-04-06T14:02:15.344Z] <541a528b163965c9bc2053de> `fit_predict` or `fit_transform` would do as well.
[2015-04-06T14:02:48.587Z] <541a528b163965c9bc2053de> BTW, I had forgotten to upload the 0.16.0 artifacts to sourceforge, this is fixed.
[2015-04-06T14:06:16.773Z] <54d4a1d6db8155e6700f853b> oh damn, I didn't think of that.
[2015-04-06T14:06:36.508Z] <54d4a1d6db8155e6700f853b> btw, can you ping gael on gsoc?
[2015-04-06T14:06:41.955Z] <54d4a1d6db8155e6700f853b> we need to move forward
[2015-04-06T14:06:46.717Z] <54d4a1d6db8155e6700f853b> to get the right number of slots
[2015-04-06T14:35:38.742Z] <541a528b163965c9bc2053de> I think Gael is offline till tomorrow.
[2015-04-06T15:24:54.376Z] <54d4a1d6db8155e6700f853b> ok
[2015-04-06T15:25:55.799Z] <541a528b163965c9bc2053de> ok back to my PyCon preparation
[2015-04-06T16:00:54.360Z] <54d4a1d6db8155e6700f853b> @ogrisel I cherry picked some stuff in the 0.16.X branch, I'll work on the kmeans and then I think this should be good to go.
[2015-04-06T16:01:10.974Z] <54d4a1d6db8155e6700f853b> The isotonic is a major concern for me as we introduced something that seems to be pretty broken.
[2015-04-06T16:12:10.054Z] <541a528b163965c9bc2053de> I agree.
[2015-04-06T21:37:28.994Z] <541a528b163965c9bc2053de> @amueller in your latest comment on #3907, you link to #3907 itself.
[2015-04-06T21:40:06.394Z] <54d4a1d6db8155e6700f853b> fixed
[2015-04-06T21:40:09.912Z] <54d4a1d6db8155e6700f853b> should have been #4535
[2015-04-06T21:40:43.336Z] <54d4a1d6db8155e6700f853b> I'd like to think that #4535 wasn't as bad before I introduced ``check_array`` and that I broke it and that scikit-learn wasn't always i that state...
[2015-04-06T22:58:03.648Z] <54d4a1d6db8155e6700f853b> ok I was just being silly. There are no breakages with fortran ordering, at least not with default settings.
[2015-04-06T23:11:25.448Z] <54d4a1d6db8155e6700f853b> the k-means fix in #4531 seems good....
[2015-04-07T14:50:43.390Z] <550f53e215522ed4b3dda5f6> I don't quite understand #4507 and #4531. What's the problem there?
[2015-04-07T16:04:37.605Z] <54d4a1d6db8155e6700f853b> The problem is that the results on fortran-ordered data are garbage with precompute_distances=False
[2015-04-07T16:06:24.948Z] <54d4a1d6db8155e6700f853b> results should be independent of the memory layout of the data.
[2015-04-07T16:06:31.061Z] <54d4a1d6db8155e6700f853b> If you run his code, the cluster-assignments are [0, 0, 1] which is clearly garbage, as the two last points are identical
[2015-04-07T17:29:49.790Z] <550f53e215522ed4b3dda5f6> I see. Thanks!
[2015-04-07T19:05:41.353Z] <54d4a1d6db8155e6700f853b> favourite bug of the day: a pandas dataframe with a "dtype" column
[2015-04-07T21:35:44.882Z] <541a528b163965c9bc2053de> haha
[2015-04-07T22:31:04.752Z] <551061f615522ed4b3ddb1c0> @amueller Just saw your comment in Melange.
[2015-04-07T22:38:43.328Z] <551061f615522ed4b3ddb1c0> I did some investigation several days ago. Zhu has a nice tutorial giving introduction on how to implement S3VMs:  http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf
[2015-04-07T22:46:12.533Z] <551061f615522ed4b3ddb1c0> It introduces 5 implementations, of which SVM^light has corresponding implementation in C: http://svmlight.joachims.org/ . We may write a wrapper for it.
[2015-04-07T23:11:36.992Z] <551061f615522ed4b3ddb1c0> I can also consult the author of libSVM, Professor Lin, to get some suggestions.
[2015-04-08T17:50:17.136Z] <54d4a1d6db8155e6700f853b> Don't worry about asking the libSVM author. We can't use SVM^light because of licensing issues, also we don't want to wrap more c code.
[2015-04-08T17:50:46.991Z] <54d4a1d6db8155e6700f853b> @bryandeng sorry for the late reply. Don't worry too much about it, I think your proposal is quite good already.
[2015-04-08T18:02:30.163Z] <54d4a1d6db8155e6700f853b> A review on #4541 would be cool, as that might be an additional nice fix for 0.16.1
[2015-04-08T18:03:31.291Z] <54d4a1d6db8155e6700f853b> [not the weird .dtype column part, the part where having dataframes with dtype object inside doesn't get correctly cast]
[2015-04-08T18:03:33.444Z] <551061f615522ed4b3ddb1c0> @amueller I'm glad that you like it. And sorry for being inactive on Github these days. I'm writing a term paper (Hausarbeit) and playing with deep neural networks. I'll come back to scikit-learn this week. It's still during semester break so I have pretty much time.
[2015-04-08T18:17:49.452Z] <54d4a1d6db8155e6700f853b> cool :) yeah being a bit more active would be great.
[2015-04-08T18:18:04.889Z] <54d4a1d6db8155e6700f853b> You are welcome to help us with the MLP if you like ;)
[2015-04-08T18:18:19.697Z] <54d4a1d6db8155e6700f853b> does anyone know how to disable the comments by coverall?
[2015-04-08T18:51:33.292Z] <54c084dbdb8155e6700eed4c> [![Untitled.png](https://files.gitter.im/scikit-learn/scikit-learn/hYei/thumb/Untitled.png)](https://files.gitter.im/scikit-learn/scikit-learn/hYei/Untitled.png)
[2015-04-08T18:51:51.226Z] <54c084dbdb8155e6700eed4c> should show up at the bottom of https://coveralls.io/r/scikit-learn/scikit-learn for the owner(s)
[2015-04-08T19:04:11.632Z] <54c084dbdb8155e6700eed4c> assuming you mean PR bot comments @amueller ... Otherwise check the notifications tab to turn off emails, etc. which i think is personalized per user.. https://coveralls.io/r/scikit-learn/scikit-learn/notifications/email
[2015-04-08T20:02:45.803Z] <54d4a1d6db8155e6700f853b> I don't have that showing up at the bottom, maybe because I'm not an owner. Which is weird since I'm a repo owner
[2015-04-08T20:34:24.630Z] <54c084dbdb8155e6700eed4c> That's strange. Are you logged into coveralls? It uses your GH login but I don't think it automatically logs you in
[2015-04-08T21:11:57.712Z] <54d4a1d6db8155e6700f853b> yeah I logged in
[2015-04-08T21:47:29.141Z] <54c084dbdb8155e6700eed4c> maybe this? https://github.com/lemurheavy/coveralls-public/issues/199
[2015-04-08T21:54:31.791Z] <54c084dbdb8155e6700eed4c> ie visit https://coveralls.io/refresh?private=true ...? 
[2015-04-08T21:56:24.357Z] <54c084dbdb8155e6700eed4c> or this if you dont want coveralls to know about private repos perhaps: https://developer.github.com/v3/orgs/members/#publicize-a-users-membership
[2015-04-08T21:59:02.426Z] <54c084dbdb8155e6700eed4c> though im pretty sure you're a public owner of skl. \
[2015-04-09T14:17:49.599Z] <541a528b163965c9bc2053de> I just logged-in to coveralls and changed the settings.
[2015-04-09T14:18:41.799Z] <541a528b163965c9bc2053de> [![Screen Shot 2015-04-09 at 10.18.06 AM.png](https://files.gitter.im/scikit-learn/scikit-learn/4caF/thumb/Screen-Shot-2015-04-09-at-10.18.06-AM.png)](https://files.gitter.im/scikit-learn/scikit-learn/4caF/Screen-Shot-2015-04-09-at-10.18.06-AM.png)
[2015-04-09T14:19:41.811Z] <541a528b163965c9bc2053de> Let's see how it works with those new settings. We can always relax the coverage failures percentages later if they prove too annoying
[2015-04-09T15:27:24.905Z] <54d4a1d6db8155e6700f853b> @ogrisel I just realized that our install page lists the "unofficial windows binaries" shouldn't we advise to use pip to install wheels?
[2015-04-09T15:31:47.385Z] <541a528b163965c9bc2053de> we already suggest to use pip before at the top of the install page
[2015-04-09T15:40:08.251Z] <54d4a1d6db8155e6700f853b> do you think the unofficial binaries add any value?
[2015-04-09T15:53:03.543Z] <541a528b163965c9bc2053de> yes, if you want to install numpy / scipy on Python 64 bit on windows
[2015-04-09T15:53:36.764Z] <541a528b163965c9bc2053de> at the moment the official binary distribution for numpy and scipy from sourceforge are only built for 32 bit python.
[2015-04-09T15:54:03.730Z] <54d4a1d6db8155e6700f853b> ah, ok
[2015-04-09T15:54:38.927Z] <541a528b163965c9bc2053de> numpy and scipy developers are working on official windows wheels both for 32 and 64 bit Python but there are some issues to resolve with the embedded openblas on some platforms first.
[2015-04-09T15:55:28.978Z] <541a528b163965c9bc2053de> BTW our windows wheels are binary compatible with christop gohlke's packages of numpy and scipy. We actually use them on appveyor
[2015-04-09T18:04:27.318Z] <541a528b163965c9bc2053de> @amueller another fix for 0.16.1: #4560
[2015-04-09T18:14:29.785Z] <54d4a1d6db8155e6700f853b> I'm struggeling with # 4511  :-/
[2015-04-09T18:14:41.460Z] <54d4a1d6db8155e6700f853b>  #4511
[2015-04-09T18:15:47.461Z] <541a528b163965c9bc2053de> yes...
[2015-04-09T18:20:06.026Z] <54d4a1d6db8155e6700f853b> I didn't add the whatsnew for the kmeans fix, damn. Also we need to add the header for 0.16.1 to whatsnew
[2015-04-09T18:21:21.338Z] <541a528b163965c9bc2053de> off to grab something to eat. See you later.
[2015-04-09T18:22:32.955Z] <54d4a1d6db8155e6700f853b> ttyl
[2015-04-09T18:24:43.820Z] <54d4a1d6db8155e6700f853b> I just tried to run a test for the reshape PR on 0.15, which made me realize how many API bugs I fixed since then ^^
[2015-04-09T19:13:37.216Z] <54d4a1d6db8155e6700f853b> @ogrisel I pushed whatsnew to 0.16.X, we can port it to 0.17d1 when we we release
[2015-04-09T20:39:24.616Z] <54d4a1d6db8155e6700f853b> I'm just reviving https://github.com/scikit-learn/scikit-learn/pull/2008 after two years lol
[2015-04-09T21:34:21.112Z] <550f53e215522ed4b3dda5f6> :beers: 
[2015-04-09T23:10:08.474Z] <5474d9eadb8155e6700d8178> @amueller Thanks a lot for the comment in melange :) Sorry I got a little busy with my exams :/ Will be back in 2 days ;)
[2015-04-09T23:21:39.229Z] <54d4a1d6db8155e6700f853b> @ragv dont worry about it too much, though I think slot allocation happens on Sunday
[2015-04-10T20:40:12.461Z] <5385f2fe048862e761fa2d40> Won't this fail with an attribute error if there are no empty clusters? https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/cluster/_k_means.pyx#L289
[2015-04-10T20:51:22.574Z] <5385f2fe048862e761fa2d40> 
[2015-04-10T21:55:39.926Z] <54d4a1d6db8155e6700f853b> @omerzimp the loops goes over the empty clusters. If there are none, it never gets executed
[2015-04-11T09:13:50.679Z] <5385f2fe048862e761fa2d40> @amueller I noticed it a while after I sent that message 
[2015-04-11T09:13:57.276Z] <5385f2fe048862e761fa2d40> Why not just nest it in the if?
[2015-04-11T09:23:38.311Z] <5385f2fe048862e761fa2d40> @amueller Here's a PR that does just that https://github.com/scikit-learn/scikit-learn/pull/4570
[2015-04-11T09:24:31.695Z] <5385f2fe048862e761fa2d40> Also am I missing something in https://github.com/scikit-learn/scikit-learn/pull/4568 ?
[2015-04-11T10:01:06.116Z] <5385f2fe048862e761fa2d40> How good is the test coverage?
[2015-04-11T10:01:15.435Z] <5385f2fe048862e761fa2d40> I'm not sure if I broke something or not
[2015-04-13T15:40:34.402Z] <54d4a1d6db8155e6700f853b> @ogrisel when do the sprints start? Any specific plans?
[2015-04-13T15:43:46.733Z] <54d4a1d6db8155e6700f853b> @omerzimp #4568 supposed to be a speed improvement? issparse is just an instance check, so pretty neglible compared to everything else.
[2015-04-13T15:44:15.093Z] <5385f2fe048862e761fa2d40> Yeh but it's something :P
[2015-04-13T15:44:21.772Z] <5385f2fe048862e761fa2d40> I contribute what I can
[2015-04-13T15:45:23.431Z] <54d4a1d6db8155e6700f853b> I would call this premature / overoptimizing. It makes the code a bit longer and a bit harder to read, but doesn't improve anything really.
[2015-04-13T15:47:12.734Z] <5385f2fe048862e761fa2d40> Feel free to close it
[2015-04-13T15:50:15.636Z] <5385f2fe048862e761fa2d40> How neglegable is it when you have a lot of data points?
[2015-04-13T17:06:46.612Z] <541a528b163965c9bc2053de> Hi @amueller, sorry I was busy chatting in the real life, I had not checked the gitter room yet
[2015-04-13T17:07:16.103Z] <541a528b163965c9bc2053de> So the sprints have just started today, we are 4 people at the sklearn table at the moment.
[2015-04-13T17:07:32.925Z] <541a528b163965c9bc2053de> We are digging down easy fix issues for first time contributors
[2015-04-13T17:13:19.156Z] <541a528b163965c9bc2053de> > I contribute what I can  But you have to keep in mind that the goal of the project is to stay maintainable and therefore code simplicity is an asset. We need to find the right trade-offs between simplicity and performance.
[2015-04-13T19:20:17.482Z] <54d4a1d6db8155e6700f853b> @ogrisel  ok I'll keep an eye on the tracker.
[2015-04-13T19:20:27.114Z] <54d4a1d6db8155e6700f853b> @omerzimp the check is independent of the dataset size
[2015-04-13T20:17:44.372Z] <54d4a1d6db8155e6700f853b> @ogrisel btw if anyone at the sprint wants a brain-teaser, I recommend this one: https://github.com/scikit-learn/scikit-learn/pull/4435
[2015-04-13T20:17:51.335Z] <54d4a1d6db8155e6700f853b> no machine learning required ^^
[2015-04-14T15:33:40.218Z] <54d4a1d6db8155e6700f853b> I think we should do 0.16.1 soon. This is the only one I'd like to get in that hasn't been merged: https://github.com/scikit-learn/scikit-learn/pull/4541
[2015-04-14T15:46:00.873Z] <54d4a1d6db8155e6700f853b> ok just got merged. I'll need to do two backports and rewrite whatsnew, then I think we are in good shape.
[2015-04-14T15:46:53.866Z] <541a528b163965c9bc2053de> I agree. Do you want me to backport 4541
[2015-04-14T15:46:54.722Z] <541a528b163965c9bc2053de> ?
[2015-04-14T15:49:10.804Z] <54d4a1d6db8155e6700f853b> I'm just doing it
[2015-04-14T15:49:29.385Z] <541a528b163965c9bc2053de> ok
[2015-04-14T15:51:41.243Z] <54d4a1d6db8155e6700f853b> should I also backport your astype fix?
[2015-04-14T16:02:05.508Z] <54d4a1d6db8155e6700f853b> @ogrisel astype fix backport yes / no? otherwise tagging now
[2015-04-14T16:02:10.809Z] <541a528b163965c9bc2053de> I don't think it fixes any user bug in itself.
[2015-04-14T16:02:17.681Z] <541a528b163965c9bc2053de> Let's tag
[2015-04-14T16:02:44.807Z] <54d4a1d6db8155e6700f853b> alright :)
[2015-04-14T16:05:22.923Z] <54d4a1d6db8155e6700f853b> gah, forgot to add an entry to the "news" on the website...
[2015-04-14T16:06:19.743Z] <541a528b163965c9bc2053de> :)
[2015-04-14T16:06:35.365Z] <541a528b163965c9bc2053de> appveyor will have to do another 1h build :)
[2015-04-14T16:10:04.539Z] <54d4a1d6db8155e6700f853b> ok, fixed. I'll update the mac build thing, I guess, and then we check the sdists...
[2015-04-14T16:10:24.298Z] <54d4a1d6db8155e6700f853b> and build the website and minimize the PNGs ... fun :)
[2015-04-14T16:15:18.851Z] <54d4a1d6db8155e6700f853b> macpython should be building
[2015-04-14T16:20:24.580Z] <541a528b163965c9bc2053de> great
[2015-04-14T17:00:09.134Z] <54d4a1d6db8155e6700f853b> is it possible to unqueue on appveyor? it'll take 8 hours at least to run through the queue
[2015-04-14T17:03:47.205Z] <541a528b163965c9bc2053de> yes I just did that
[2015-04-14T17:04:16.586Z] <541a528b163965c9bc2053de> I will send you the password to the github account to log in and cancel / restart builds
[2015-04-14T17:05:24.487Z] <541a528b163965c9bc2053de> in your mail box
[2015-04-14T17:05:57.950Z] <541a528b163965c9bc2053de> when unqueuing stuff, it better to first unqueue (cancel button) the from the most recent to the most ancient queued job
[2015-04-14T17:07:50.340Z] <54d4a1d6db8155e6700f853b> why is that better?
[2015-04-14T17:08:26.345Z] <541a528b163965c9bc2053de> otherwise you get the next ancient job in state running, and canceling running jobs takes more time than queued jobs
[2015-04-14T17:08:58.153Z] <541a528b163965c9bc2053de> BTW, if you are interested in all of this windows build I gave a talk at pycon on that: https://twitter.com/ogrisel/status/587326055171694594
[2015-04-14T17:09:49.012Z] <541a528b163965c9bc2053de> off to lunch, see you later! It's great to have this release out this week. Thanks so much!
[2015-04-14T17:10:14.743Z] <54d4a1d6db8155e6700f853b> off to lunch? oh, right, you are in my timezone now ^^
[2015-04-14T18:18:33.356Z] <541a528b163965c9bc2053de> @amueller the windows build is up: http://windows-wheels.scikit-learn.org/
[2015-04-14T18:19:15.271Z] <541a528b163965c9bc2053de> the OSX wheels are up as well: http://wheels.scipy.org/
[2015-04-14T19:28:29.553Z] <54d4a1d6db8155e6700f853b> oh cool. png's are optimized, too. So I'll upload the docs, then
[2015-04-14T19:31:34.561Z] <541a528b163965c9bc2053de> Do you want me to do the upload to PyPI and sourceforge or do you want to do it?
[2015-04-14T19:57:09.329Z] <54d4a1d6db8155e6700f853b> The docs are up. Can you do pypi upload please?
[2015-04-14T19:57:14.359Z] <54d4a1d6db8155e6700f853b> how do you upload the wheels btw?
[2015-04-14T19:58:25.009Z] <541a528b163965c9bc2053de> you can either use upload_all or the twine command
[2015-04-14T19:58:38.745Z] <54d4a1d6db8155e6700f853b> maybe I'll try upload_all 
[2015-04-14T20:00:37.416Z] <54d4a1d6db8155e6700f853b> or maybe you do it ;) I still get the "unknown url type error"
[2015-04-14T20:01:13.944Z] <541a528b163965c9bc2053de> Have you updated wheelhouse-uploader ?
[2015-04-14T20:03:44.123Z] <54d4a1d6db8155e6700f853b> oh, right
[2015-04-14T20:03:46.930Z] <54d4a1d6db8155e6700f853b> now it works
[2015-04-14T20:04:17.621Z] <541a528b163965c9bc2053de> it works with python 2.7 on a new virtualenv were I just pip installed wheelhouse-uploader
[2015-04-14T20:04:29.528Z] <54d4a1d6db8155e6700f853b> yeah It does work. Did you upload already?
[2015-04-14T20:05:58.926Z] <541a528b163965c9bc2053de> yes
[2015-04-14T20:06:05.430Z] <541a528b163965c9bc2053de> I just did, with twine
[2015-04-14T20:06:17.130Z] <541a528b163965c9bc2053de> to avoid TLS man in the middle attacks :)
[2015-04-14T20:06:43.589Z] <54d4a1d6db8155e6700f853b> ok. what is twine?
[2015-04-14T20:06:48.328Z] <54d4a1d6db8155e6700f853b> I'm just drafting the ann mail, ok?
[2015-04-14T20:07:40.657Z] <541a528b163965c9bc2053de> https://pypi.python.org/pypi/twine
[2015-04-14T20:07:55.600Z] <541a528b163965c9bc2053de> ok please go a ahead
[2015-04-14T20:07:58.640Z] <541a528b163965c9bc2053de> for the ANN
[2015-04-14T20:08:01.946Z] <541a528b163965c9bc2053de> and the tweet
[2015-04-14T20:17:51.339Z] <54d4a1d6db8155e6700f853b> done
[2015-04-14T20:17:54.877Z] <54d4a1d6db8155e6700f853b> ah, twine makes sense ^^
[2015-04-14T20:18:28.023Z] <54d4a1d6db8155e6700f853b> I'll err... foward-port (?) the whatsnew to 0.17 
[2015-04-14T20:19:56.227Z] <541a528b163965c9bc2053de> ok
[2015-04-14T21:10:18.439Z] <541a528b163965c9bc2053de> @amueller is your LGTM still valid in light of the latest changes to #4590?
[2015-04-14T21:17:15.668Z] <541a528b163965c9bc2053de> I uploaded the release to sourceforge as well
[2015-04-15T01:51:46.166Z] <54d4a1d6db8155e6700f853b> thanks
[2015-04-19T17:57:15.403Z] <54d4a1d6db8155e6700f853b> @agramfort https://github.com/scikit-learn/scikit-learn/pull/4550
[2015-04-19T17:59:01.889Z] <54d4a1d6db8155e6700f853b> @agramfort this one would be cool: https://github.com/scikit-learn/scikit-learn/pull/4534 
[2015-04-19T17:59:40.682Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4526
[2015-04-19T18:01:32.204Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4467
[2015-04-19T18:02:09.886Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/4365
[2015-04-19T18:44:21.853Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/issues/3855
[2015-04-19T18:44:30.764Z] <54d4a1d6db8155e6700f853b> that last one is about changing the number of samples
[2015-04-22T02:09:42.396Z] <5537027215522ed4b3df56ab> Hey guys, I know this is slightly off topic, but is there any recommendation regarding structured/sequence learning libraries in Python?
[2015-04-22T02:10:33.464Z] <5537027215522ed4b3df56ab> I have been using crfsuite but unforunately it's only first order and not very good for named entity recognition
[2015-04-22T02:11:57.004Z] <5537027215522ed4b3df56ab> The Stanford NER Java lib is crazy huge/unwieldy -_-
[2015-04-22T02:19:20.834Z] <5537027215522ed4b3df56ab> nm looks like @amueller has ChainCRF in PyStruct! I hope it's fast. Please be fast.
[2015-04-22T02:30:52.902Z] <5537027215522ed4b3df56ab> even has great docs =)
[2015-04-22T07:04:12.490Z] <541a528b163965c9bc2053de> PyStruct and seqlearn are two projects maintained by scikit-learn developers (@amueller and @larsmans respectively). 
[2015-04-22T14:30:06.041Z] <54d4a1d6db8155e6700f853b> @ldqc the docs are new and work in progress ;) pystruct implements maximum margin learning and perceptron, seqlearn implements HMMs and perceptron,  I think. So both don't implement maximum likelihood CRFs
[2015-04-23T03:28:41.559Z] <5537027215522ed4b3df56ab> looks like i can't use sparse matrices for yours atm
[2015-04-23T17:33:42.277Z] <54d4a1d6db8155e6700f853b> @lqdc unfortunately yes. hopefully soon(ish)
[2015-04-24T01:45:29.325Z] <544906e2db8155e6700cdd16> Hello guys! I'm having problems with a django application that uses a random forest classifier to classify items. The error that I'm receiving says: [ 'Thread' object has no attribute '_children' ] and googling it leads to http://stackoverflow.com/questions/9749875/strange-error-while-starting-threads-inside-django-application On the other hand, the exact line where the application throws the error is "clf.predict_proba(items)" and I'm not using threads at all but I set n_jobs=-1 in the initialization of the classifier so I wonder if this error could be related to joblib (it uses ThreadPool in the method "  call  " of the class Parallel). Any idea? Can I modify the n_jobs variable in order avoid parallelism?
[2015-04-24T08:52:21.787Z] <541a528b163965c9bc2053de> @mac2bua please create a new stackoverflow question with a minimalistic reproduction script that generates its own test data.
[2015-04-24T16:27:25.515Z] <544906e2db8155e6700cdd16> Done! http://stackoverflow.com/questions/29852680/thread-object-has-no-attribute-children-django-scikit-learn
[2015-04-24T16:52:47.889Z] <541a528b163965c9bc2053de> answered. Please include the full traceback to make it possible for us to fix the real cause of the problem.
[2015-04-24T17:11:30.296Z] <544906e2db8155e6700cdd16> Thanks @ogrisel the error seems to be fixed after I set the n_jobs parameter to 1.
[2015-04-24T17:13:49.322Z] <544906e2db8155e6700cdd16> Here is the complete traceback: ``` File "/home/cristian/env/local/lib/python2.7/site-packages/django/core/handlers/base.py" in get_response line 111.                     response = wrapped_callback(request, *callback_args, **callback_kwargs) File "/home/cristian/env/local/lib/python2.7/site-packages/django/views/decorators/csrf.py" in wrapped_view line 57.         return view_func(*args, **kwargs) File "/home/cristian/env/local/lib/python2.7/site-packages/django/views/generic/base.py" in view line 69.             return self.dispatch(request, *args, **kwargs) File "/home/cristian/env/local/lib/python2.7/site-packages/rest_framework/views.py" in dispatch line 452.             response = self.handle_exception(exc) File "/home/cristian/env/local/lib/python2.7/site-packages/rest_framework/views.py" in dispatch line 449.             response = handler(request, *args, **kwargs) File "/home/cristian/env/local/lib/python2.7/site-packages/rest_framework/decorators.py" in handler line 50.             return func(*args, **kwargs) File "/home/cristian/filters/classifiers/views.py" in classify_item line 70. 			y_pred = clf.predict_proba(pd.DataFrame(item_dict)) File "/home/cristian/env/local/lib/python2.7/site-packages/sklearn/pipeline.py" in predict_proba line 159.         return self.steps[-1][-1].predict_proba(Xt) File "/home/cristian/env/local/lib/python2.7/site-packages/sklearn/ensemble/forest.py" in predict_proba line 468.             for i in range(n_jobs)) File "/home/cristian/env/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py" in __call__ line 568.             self._pool = ThreadPool(n_jobs) File "/usr/lib/python2.7/multiprocessing/pool.py" in __init__ line 685.         Pool.__init__(self, processes, initializer, initargs) File "/usr/lib/python2.7/multiprocessing/pool.py" in __init__ line 136.         self._repopulate_pool() File "/usr/lib/python2.7/multiprocessing/pool.py" in _repopulate_pool line 199.             w.start() File "/usr/lib/python2.7/multiprocessing/dummy/__init__.py" in start line 73.         self._parent._children[self] = None  Exception Type: AttributeError at /items/ Exception Value: 'Thread' object has no attribute '_children' ```
[2015-04-24T17:17:55.877Z] <541a528b163965c9bc2053de> Please edit the stackoverlow report instead.
[2015-04-24T17:18:17.712Z] <541a528b163965c9bc2053de> Also quoting is done with backticks, not forward ticks :)
[2015-04-24T17:22:07.921Z] <544906e2db8155e6700cdd16> Sorry! I wasn't able to find the backticks in my spanish keyboard :/
[2015-04-24T17:47:02.471Z] <544906e2db8155e6700cdd16> I've just added the traceback to stackoverflow!
[2015-04-25T19:31:27.410Z] <5474d9eadb8155e6700d8178> finalllllly all my exams got over :D been inactive for too long :/ full time scikit-learn from today B)
[2015-04-25T21:24:11.632Z] <54d4a1d6db8155e6700f853b> sweet :)
[2015-04-27T10:57:26.299Z] <541a528b163965c9bc2053de> welcome back @ragv, unfortunately myself I will be busy for the next couple of weeks. (strata in london / then offline for vacation / the moving to a new flat).
[2015-04-27T10:57:49.455Z] <5474d9eadb8155e6700d8178> sure :) no problem :) I'll take care of all the pending works for now :))
[2015-04-27T10:58:00.947Z] <5474d9eadb8155e6700d8178> and I do have a lot of pending stuff :O
[2015-04-27T19:28:22.796Z] <5474d9eadb8155e6700d8178> heyyy I got in GSoC ;) Thanks a lot @amueller @ogrisel @jnothman and @MechCoder   :) Congrats to @xeuwei4d and @barmaley-exe too :)
[2015-04-27T19:31:26.444Z] <553e8e1015522ed4b3df97f7> Congrats @ragv!
[2015-04-27T19:31:46.985Z] <5474d9eadb8155e6700d8178> Thanks a lot Vinayak :)
[2015-04-27T19:32:03.026Z] <553e8e1015522ed4b3df97f7> and to @xuewei4d and @Barmaley-exe!
[2015-04-27T19:50:11.045Z] <54d4a1d6db8155e6700f853b> hurray :)
[2015-04-27T20:40:56.261Z] <550f53e215522ed4b3dda5f6> Thanks! It will be a great summer!
[2015-04-27T22:19:13.367Z] <54d4a1d6db8155e6700f853b> @ogrisel can I get a +1 on #4371?
[2015-04-28T04:48:49.065Z] <551084ad15522ed4b3ddb3b0> Greetings! I've done a pure Python implementation of the k-modes algorithm for clustering categorical data: https://github.com/nicodv/kmodes
[2015-04-28T04:49:09.462Z] <551084ad15522ed4b3ddb3b0> It's modeled after the k-means code in sklearn. Any interest in this?
[2015-04-28T12:59:17.310Z] <551061f615522ed4b3ddb1c0> Congratulations! @ragv @xuewei4d @Barmaley-exe 
[2015-04-28T13:02:22.379Z] <551061f615522ed4b3ddb1c0> Though not accepted into GSoC :worried: , I'll continue working on the tasks proposed.
[2015-04-28T15:57:58.774Z] <54d4a1d6db8155e6700f853b> great, thanks :)
[2015-04-28T15:58:21.163Z] <54d4a1d6db8155e6700f853b> I'm sorry you didn't make it, we didn't have enough mentors for all the projects.
[2015-04-28T22:07:27.059Z] <54d4a1d6db8155e6700f853b> @nicodv we could link to your code in related projects, but I think we decided against including kmodes in the past because it was very slow. is that not the case? I forgot the details.
[2015-04-28T23:35:23.898Z] <551084ad15522ed4b3ddb3b0> @amueller In pure Python, it's almost exactly an order of magnitude slower than k-means. But it scales roughly the same as k-means in terms of number of points (but worse in terms of n_clusters and dimensions)
[2015-04-28T23:50:14.386Z] <551084ad15522ed4b3ddb3b0> It's less that an order of magnitude, actually. Let's say 5 to 10 times slower.
[2015-04-29T00:46:20.324Z] <54d4a1d6db8155e6700f853b> wait, I think i confused it with k-mediod. Sorry, never mind. medians is just the l1 variant. that should be pretty easy to add to the current code, I think.
[2015-04-29T08:07:55.796Z] <541a528b163965c9bc2053de> how do you compute the ndim medians in l1 space?
[2015-04-29T18:38:28.252Z] <54d4a1d6db8155e6700f853b> per-coordinate median, right?
[2015-04-29T18:38:32.861Z] <551084ad15522ed4b3ddb3b0> from k-medians Wikipedia: "The median is computed in each single dimension in the Manhattan-distance formulation of the k-medians problem"
[2015-04-29T18:39:15.719Z] <551084ad15522ed4b3ddb3b0> but k-modes, my code, does not use Euclidean space because it clusters categorical variables
[2015-04-29T18:39:52.756Z] <551084ad15522ed4b3ddb3b0> so, quite different from k-medians or k-medoids
[2015-04-29T18:40:55.933Z] <54d4a1d6db8155e6700f853b> argh, ok, got double confused, then.
[2015-04-29T18:41:59.275Z] <54d4a1d6db8155e6700f853b> Feel free to sent a PR to include it as related project. We don't really have anything for categorical variables at the moment, and we haven't really figured out the API. How do you denote which variables are categorical and what are the inputs? Or are just all features assumed to be categorical?
[2015-04-29T18:43:27.134Z] <551084ad15522ed4b3ddb3b0> there's k-modes, for which all is assumed categorical; and there's k-prototypes (this combines k-modes and k-means), which receives X as a list of 2 arrays, one for numerical and one for categorical variables
[2015-04-29T18:45:44.250Z] <54d4a1d6db8155e6700f853b> ok. So this list would mess with the sklearn api a lot, for cross-validation tries to sample along the first axis.
[2015-04-29T18:48:08.958Z] <551084ad15522ed4b3ddb3b0> another option would be to take a single X, and a "is_categorical" variable that specifies which columns are categorical
[2015-04-29T18:50:04.937Z] <54d4a1d6db8155e6700f853b> yeah, that is what I think we would like to do for the forests, but I'm not sure. It is a bit awkward that they are float then, but not a big deal I guess
[2015-04-29T18:50:28.647Z] <54d4a1d6db8155e6700f853b> using pandas dataframes would also be an option, maybe not in scikit-learn though.
[2015-04-30T16:15:21.669Z] <54d4a1d6db8155e6700f853b> anyone a quick +1 for #4526 ? should be an easy fix
[2015-04-30T22:08:30.345Z] <54d4a1d6db8155e6700f853b> I'm always complaining about the many github notifications, and I just sent 74 for #3306 ^^ I'm glad I don't get them in my inbox
[2015-05-01T02:41:49.271Z] <54c084dbdb8155e6700eed4c> Hey @amueller ... Just a FYI, ran your check_estimator API on my package. It works for the most part. Though I raise a copied version of the NotFittedError and get a fail since it isn't explicitly using the scikit-learn version (I wanted to support 0.15.2 as well so exported a bunch of functions to reside in gplearn.skutils.etc).
[2015-05-01T16:29:54.661Z] <54d4a1d6db8155e6700f853b> Thanks for the feedback. Is there a reason your NotFittedError doesn't inherit from the sklearn one? Well I guess actually we wanted people to be able to provide compatible code without needing to rely on sklearn.... hum...
[2015-05-01T16:30:50.887Z] <54d4a1d6db8155e6700f853b> @trevorstephens maybe I'm slow, how is that related to the remark in the parentheses?
[2015-05-01T16:48:38.304Z] <54c084dbdb8155e6700eed4c> NotFittedError was new in 0.16.0 I think, so I'd fail tests on my own Travis builds based on 0.15.2 if I tried to inherit from sklearn I guess
[2015-05-01T16:49:50.492Z] <54c084dbdb8155e6700eed4c> And to guard against other changes to the non-public API, I grabbed a few key utils modules from 0.16.0 and stuffed them into a folder in my project
[2015-05-01T16:51:21.610Z] <54c084dbdb8155e6700eed4c> I could potentially wrap all the important stuff in try blocks, like the fixes module in sklearn. But that seems like a lot of work given how interconnected some of the utils are
[2015-05-01T17:14:35.114Z] <54d4a1d6db8155e6700f853b> yeah no, don't do that. Actually we should aim at allowing people to pass tests without inheriting from sklearn.
[2015-05-01T17:29:56.876Z] <54d4a1d6db8155e6700f853b> @trevorstephens gael and I think we shouldn't check for NotFittedError, but a public one. I'm not sure if ValueError or AttributeError
[2015-05-01T17:32:32.385Z] <54c084dbdb8155e6700eed4c> that'd work. mine is a direct copy of the scikitlearn error. probably other's are using older code bases where I think a ValueError was directly raised when not fitted
[2015-05-01T18:34:43.758Z] <54c084dbdb8155e6700eed4c> actually maybe not... https://github.com/scikit-learn/scikit-learn/pull/4029/files shows a mix of both were in the code base. perhaps check for either of them. i think checking from both is overkill and makes an unnecessary burden on people who want to work with sklearn, but not require it.
[2015-05-01T20:36:45.763Z] <54d4a1d6db8155e6700f853b> yeah, probably.
[2015-05-02T00:35:14.433Z] <54df2ad815522ed4b3dc0295> Hi! Any tips regarding GradientBoostingClassifier vs. class imbalance?  Contrary to e.g. LogisticRegression, there is no class_weight parameter.  Without doing anything, I get high precision but tiny recall.
[2015-05-02T00:35:26.272Z] <54df2ad815522ed4b3dc0295> I guess I could just pre-process the dataset manually (adding copies of the less represented class) but that feels dirty.  Surely there's a better way?
[2015-05-02T02:02:22.617Z] <54c084dbdb8155e6700eed4c> @pasky , you could use the function `compute_sample_weight` found at https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/class_weight.py#L68-L166 like so:  from sklearn.utils.class_weight import compute_sample_weight # "auto" class weights inversely proportional to class frequencies sample_weight = compute_sample_weight("auto", y) # dict to define them yourself with {class_symbol: weight} sample_weight = compute_sample_weight({1: 2, 2: 1}, y) ... then just feed that as sample_weight to the fit method
[2015-05-02T02:02:55.747Z] <54c084dbdb8155e6700eed4c> geeze. apparently python comments are taken to mean bold... but you get the idea :smile: 
[2015-05-02T02:06:44.010Z] <54c084dbdb8155e6700eed4c> it's a private util function, so not really advertised. its used under the hood in 0.16.0's random forest and decision tree classifiers.
[2015-05-02T02:23:03.916Z] <54df2ad815522ed4b3dc0295> Oh, that sounds pretty nice! Thanks, I'll try that out. I completely forgot about the option to also pass the sample weights to fit() method instead of specifying class weights in constructor.
[2015-05-02T02:40:53.306Z] <54c084dbdb8155e6700eed4c> Yep, it's kind of sort of an indirect method to oversample/undersample.
[2015-05-03T03:19:03.407Z] <54d4a1d6db8155e6700f853b> we should probably add class_weights to the gradient boosting classifier
[2015-05-03T05:17:03.887Z] <54c084dbdb8155e6700eed4c> @amueller ... #4215 is just waiting on a #4347 merge so that there isnt more refactoring on your part required.
[2015-05-03T05:17:29.586Z] <54c084dbdb8155e6700eed4c> unless you want me to address the comments and add more work to your pile??
[2015-05-03T05:19:19.540Z] <54c084dbdb8155e6700eed4c> im good either way :smile: 
[2015-05-03T05:22:15.661Z] <54c084dbdb8155e6700eed4c> ... it would effect gbm, as well as the  adaboost and bagging meta-ensembles
[2015-05-03T15:08:09.652Z] <54d4a1d6db8155e6700f853b> oh, I forgot that PR.
[2015-05-03T15:10:19.184Z] <54d4a1d6db8155e6700f853b> #4215 that is. My PR needs work to deprecate the class_weight in trees as you know. I should do that, but I didn't really get any reviews yet :-/
[2015-05-03T15:19:50.322Z] <54c084dbdb8155e6700eed4c> that's why I figured I'd wait. Boosting has the subsample option too
[2015-05-04T09:27:08.082Z] <541a528b163965c9bc2053de> @trevorstephens  ```python try:     from sklearn.utils.validation import NotFittedError except ImportError:     # backward compat for scikit-learn < 0.16.0     class NotFittedError(Exception):         pass ```  should work.
[2015-05-04T13:39:57.907Z] <54d4a1d6db8155e6700f853b> @ogrisel what do you think of #4661 ?
[2015-05-04T14:58:52.800Z] <54d4a1d6db8155e6700f853b> after three years, I'm apparently still confused by scale_C vs n_samples
[2015-05-04T16:27:03.018Z] <54d4a1d6db8155e6700f853b> @ogrisel if you have time, your input on #4597 would be nice.
[2015-05-05T03:07:00.854Z] <54c084dbdb8155e6700eed4c> Thanks @ogrisel , that's what I was thinking of, though I have several other scikit-learn utils that I've included in my package in order to avoid dependency hell-fire. Only a few of them are actually used so it might not be that heavy, I guess, if I was to pick out only the ones that matter. Maybe once I get 0.1.0 released I'd think about making it more sensible on the utils.
[2015-05-05T03:13:38.321Z] <54c084dbdb8155e6700eed4c> @amueller .. I think you know the appropriate emoji for dependency hell-fire :smile: 
[2015-05-05T18:31:43.789Z] <54d4a1d6db8155e6700f853b> haha
[2015-05-05T18:32:00.144Z] <54d4a1d6db8155e6700f853b> And believe me, I have been there, more than once ;)
[2015-05-05T18:37:47.738Z] <54d4a1d6db8155e6700f853b> @ogrisel the #4597 issue is not really with pandas, it is with Cython, which doesn't support read-only buffers. So my question was more: why does joblib produce a read-only buffer there?
[2015-05-05T18:39:13.352Z] <54d4a1d6db8155e6700f853b> ah, I haven't read your comment there, sorry
[2015-05-05T21:27:00.101Z] <541a528b163965c9bc2053de> @amueller indeed I read some more discussions in this thread: https://mail.python.org/pipermail/cython-devel/2013-February/003384.html and then replied the following: https://github.com/pydata/pandas/issues/10043#issuecomment-99227037
[2015-05-05T21:27:36.898Z] <54d4a1d6db8155e6700f853b> makes sense, but we can also not wait for the fix in pandas.
[2015-05-05T21:28:14.861Z] <54d4a1d6db8155e6700f853b> @ogrisel so I think we should maybe just copy the DF in the "rare" situation that happens and throw a warning that people should use .values to avoid the copy?
[2015-05-05T21:35:40.559Z] <541a528b163965c9bc2053de> Calling `.values` will just force a copy if am not mistaken. The "real" fix can only be done in pandas by using the ndarray type instead of a typed memoryview (or even better in Cython by adding support for readonly typed memoryviews).
[2015-05-05T21:49:26.664Z] <54d4a1d6db8155e6700f853b> I don't think values will force a copy always. It is not writeable here, so I don't think a copy was made. Well the real fix is clearly in cython but we have to be backward compatible, so we need to do a workaround now matter what
[2015-05-05T22:05:52.033Z] <541a528b163965c9bc2053de> Indeed `.values` does not copy for single block data frames. but it does for multiple blocks dfs 
[2015-05-05T22:10:18.492Z] <54d4a1d6db8155e6700f853b>  can you reproduce the error with multiple block dfs?
[2015-05-05T22:10:35.819Z] <54d4a1d6db8155e6700f853b> I posted my try at #4597
[2015-05-05T22:24:34.591Z] <541a528b163965c9bc2053de> I cannot reproduce the error without manually assigning a readonly memmap to `df._data.blocks[0].values` or replicating what the joblib.pool.MemmapingPool class does (that is replacing np.ndarray instances by np.memmap instances at pickling time).
[2015-05-05T22:26:08.438Z] <541a528b163965c9bc2053de> Let me work on fixing the joblib.load with `mmap_mode='r'` on structures that have numpy arrays with dtype=object inside.
[2015-05-05T22:26:23.296Z] <541a528b163965c9bc2053de> in joblib master
[2015-05-05T22:48:54.511Z] <54d4a1d6db8155e6700f853b> @ogrisel do you know anything about the issue in #4421 ? some warnings are not raised / caught ....
[2015-05-05T23:23:56.728Z] <541a528b163965c9bc2053de> Ok going to bed now. Tomorrow is second day of strata london. I gave a tutorial today. Tomorrow I will just attend the conf and maybe work on sklearn issues if the talks are boring.
[2015-05-05T23:24:18.358Z] <541a528b163965c9bc2053de> see you
[2015-05-06T00:25:37.428Z] <54d4a1d6db8155e6700f853b> cool. say hi to everybody from me ;)
[2015-05-07T18:02:57.253Z] <54d4a1d6db8155e6700f853b> @ragv you had a PR to include some help on git to the dev docs, right?
[2015-05-08T14:35:09.341Z] <54d4a1d6db8155e6700f853b> @ogrisel do you have time for #4362 ?
[2015-05-09T21:42:11.997Z] <54d4a1d6db8155e6700f853b> @rvraghav93 @ragv I know you don't have much time, but if you could point me again to where you did the improvement of the contrib docs, I could maybe work on that. I think having some more comments on git would really help some people.
[2015-05-09T23:35:44.074Z] <54c084dbdb8155e6700eed4c> AFAIK I think the intended framework was just put on the wiki for now - https://github.com/scikit-learn/scikit-learn/wiki/Contributors-Guide 
[2015-05-14T20:03:43.826Z] <53135b495e986b0712efc453> @amueller Sorry for the delayed response... as @trevorstephens pointed out that was the proposed structure... I'd love your comments on the same :)
[2015-05-14T20:30:09.981Z] <54d4a1d6db8155e6700f853b> it looks good
[2015-05-15T08:29:05.315Z] <54e07d6515522ed4b3dc0858> @rvraghav93 @amueller oh that looks really good. One thing I noticed though is that there's overlap between "API design" and our current "rolling your own estimator", and users do get confused about what they can and can't do in `__init__`, and why things fail afterwards. Do you have any ideas on how to make it better?
[2015-05-15T12:43:46.061Z] <53135b495e986b0712efc453> We could use ideas from the existing page and make it into a single page or a section "Custom designed estimators" under "API design"... BTW I think I'll start a PR for the same and it will be easier for you to comment and advice me... :)
[2015-05-15T12:44:34.245Z] <54e07d6515522ed4b3dc0858> I was just wondering why we can't add line-comments to github wiki pages :)
[2015-05-15T12:46:11.062Z] <53135b495e986b0712efc453> haha :D I'll make it easier by raising a PR ;) But incase you want to comment to the wiki pages... You could just edit it and add a comment "(@vene: This should be removed)" etc... at the particular place and make it bold... I'll take note of the same :)
[2015-05-15T18:52:32.307Z] <54d4a1d6db8155e6700f853b> @vene I have wondered that myself from time to time ;)
[2015-05-15T20:54:04.767Z] <54d4a1d6db8155e6700f853b> @bdholt1 just showed up on IRC and said he's back :)
[2015-05-15T20:54:45.375Z] <55565ccb15522ed4b3e07834> hi all!
[2015-05-15T20:55:57.622Z] <54d4a1d6db8155e6700f853b> hey :)
[2015-05-15T20:58:48.365Z] <54d4a1d6db8155e6700f853b> My favourite GSOC students, @rvraghav93 @xuewei4d @Barmaley-exe how are things? Reading up on your projects? ;)
[2015-05-16T04:49:27.592Z] <54c084dbdb8155e6700eed4c> @bdholt1 
[2015-05-16T04:49:30.379Z] <54c084dbdb8155e6700eed4c> oops
[2015-05-16T04:49:34.527Z] <54c084dbdb8155e6700eed4c> haha
[2015-05-16T04:51:08.148Z] <54c084dbdb8155e6700eed4c> what i meant to say, was, @amueller .. sorry, i noticed your tag on #4732 today and then your #4711 comment asking for a new issue. Rather crazy week, will see if I can solve it though.
[2015-05-16T04:51:17.081Z] <54c084dbdb8155e6700eed4c> and hi @bdholt1  :smile: 
[2015-05-16T16:45:05.636Z] <550f53e215522ed4b3dda5f6> Yes. I am currently reading the Murphy's paper 'Fitting a Conditional Gaussian Distribution'. That's the paper described three kinds of co-variance matrix in current  GMM implementation. But it seems a little harder to understand in terms of notations. @amueller 
[2015-05-16T16:46:49.212Z] <53135b495e986b0712efc453> @amueller yeah ;) :P working on completing my exiting PRs :)
[2015-05-18T15:42:44.616Z] <54d4a1d6db8155e6700f853b> @rvraghav93 cool :)
[2015-05-18T15:43:08.049Z] <54d4a1d6db8155e6700f853b> @xuewei4d have you talked with your mentors yet?
[2015-05-18T15:43:35.241Z] <54d4a1d6db8155e6700f853b> it would be great to get a first blog post from both of you ;)_
[2015-05-18T17:28:02.503Z] <550f53e215522ed4b3dda5f6> Not yet. I will email them soon. I have published a post several days ago, which is an introduction to my project and myself.
[2015-05-18T17:31:02.678Z] <550f53e215522ed4b3dda5f6> I am trying to derive the updating functions of VBGMM with other three kinds of covariance matrix, sphere, diag and tied following PRML.  
[2015-05-18T17:47:36.479Z] <54d4a1d6db8155e6700f853b> Xuewei4d: did you mail your blog post to the mailing list? maybe I overlooked it, sorry
[2015-05-18T17:48:07.350Z] <54d4a1d6db8155e6700f853b> xuewei4d: that sounds great. Make sure you have your mentors looped in so they know what is going on!
[2015-05-18T17:52:02.755Z] <54d4a1d6db8155e6700f853b> btw @ogrisel are you around?
[2015-05-18T17:54:27.043Z] <550f53e215522ed4b3dda5f6> Ohh, I will post it into the mailing list. Sorry.
[2015-05-18T17:56:54.864Z] <54d4a1d6db8155e6700f853b> I think it is good practice to post each blog post to the mailing list for maximum visibility
[2015-05-18T17:57:26.790Z] <54d4a1d6db8155e6700f853b> I have to admit I didn't rss subscribe, and I don't usually use RSS, so i am likely to miss it if you don't post ;)
[2015-05-18T17:57:51.190Z] <54d4a1d6db8155e6700f853b> @rvraghav93 btw why did you change your github handle?
[2015-05-18T17:58:28.632Z] <54d4a1d6db8155e6700f853b> @rvraghav93 also: for wrapping up the partial_fit testing, I think the most important part is to simplify _compare_attributes
[2015-05-18T19:37:24.540Z] <54d4a1d6db8155e6700f853b> any one here familiar enough with LDA to do a final review?
[2015-05-18T20:54:49.464Z] <54d4a1d6db8155e6700f853b> master is broken with a heisenfailure
[2015-05-18T20:54:50.242Z] <54d4a1d6db8155e6700f853b> I don't like it
[2015-05-18T22:36:29.648Z] <54d4a1d6db8155e6700f853b> anyone who has an opinion on how back-links from the references to the user-guide should look like should speak here or be forever silent: https://github.com/scikit-learn/scikit-learn/pull/4723
[2015-05-18T22:37:05.721Z] <53135b495e986b0712efc453> @amueller Sorry for the confusion... I just merged my github profiles ragv and the old one rvraghav93 into one to sync with my email rvraghav93@gmail.com ... :) I earlier created ragv as a temporary profile...  And yea I just pushed it ;) could you pl take a look? :)
[2015-05-18T22:39:13.350Z] <54d4a1d6db8155e6700f853b> ok, I will. not sure I have time to go through all of it now
[2015-05-18T22:39:51.606Z] <53135b495e986b0712efc453> Sure :) 
[2015-05-19T14:00:40.784Z] <541a528b163965c9bc2053de> @amueller the heisenfailure (the nans in solve_triangular called by OMP) only happens on scipy 0.9.0 from ubuntu precise right? What about skipping that test if scipy is too old?
[2015-05-19T14:35:55.043Z] <54d4a1d6db8155e6700f853b> yeah, but we still support scipy 0.9.0, right?
[2015-05-19T14:35:59.503Z] <54d4a1d6db8155e6700f853b> I tried reproducing but failed. I fear it is something silly like last time, where there was an if on the scipy version
[2015-05-19T14:37:34.097Z] <541a528b163965c9bc2053de> Have you tried to reproduce with ubuntu 12.04?
[2015-05-19T14:40:23.698Z] <54d4a1d6db8155e6700f853b> not yet
[2015-05-19T14:40:49.539Z] <541a528b163965c9bc2053de> ok I can try tomorrow if you don't do it in the mean time.
[2015-05-19T14:40:57.154Z] <541a528b163965c9bc2053de> Need to run now, see you later.
[2015-05-19T14:42:09.739Z] <54d4a1d6db8155e6700f853b> ok. I think I have a vagrant box, I'll have a look
[2015-05-19T14:42:21.608Z] <54d4a1d6db8155e6700f853b> btw if you had time to look at the mlp branch, this would be great
[2015-05-19T15:08:03.920Z] <54d4a1d6db8155e6700f853b> @rvraghav93 could you maybe start with a first blog post on your plans for the summer?
[2015-05-19T15:23:58.589Z] <54e07d6515522ed4b3dc0858> @amueller @rvraghav93 Maybe we could find the time to sync and discuss an outline of the blog post. It's also a good opportunity to think about the upcoming steps.
[2015-05-19T15:32:39.510Z] <54d4a1d6db8155e6700f853b> Sure
[2015-05-19T15:34:20.210Z] <54e07d6515522ed4b3dc0858> BTW, I think it's good to be aware of each other's time zones, so we can plan better. I'm currently on Central European (Summer) Time until Sunday, and then New York time. (We can take this to a private chat too if you want.)
[2015-05-19T15:35:26.928Z] <54d4a1d6db8155e6700f853b> where are you going vlad? Will you be around?
[2015-05-19T15:39:07.898Z] <54e07d6515522ed4b3dc0858> I will actually be in New York for about a week, if everything goes well. I have to apply for a Chinese visa.
[2015-05-19T15:39:20.333Z] <54e07d6515522ed4b3dc0858> Afterwards it's back to boring Ithaca.
[2015-05-19T15:40:01.507Z] <54e07d6515522ed4b3dc0858> Currently in Florence for WWW
[2015-05-19T15:40:21.696Z] <54e07d6515522ed4b3dc0858> Very beautiful city!
[2015-05-19T15:43:33.522Z] <54d4a1d6db8155e6700f853b> nice! When are you in NYC? Let's have a beer!
[2015-05-19T15:43:43.758Z] <54d4a1d6db8155e6700f853b> next week?
[2015-05-19T15:45:05.855Z] <54e07d6515522ed4b3dc0858> Sure! Yes, Monday-Friday I think.
[2015-05-19T15:45:15.678Z] <54e07d6515522ed4b3dc0858> Gotta run for a while, talk to you later!
[2015-05-19T15:45:48.414Z] <54d4a1d6db8155e6700f853b> ttyl!
[2015-05-19T18:19:41.335Z] <53135b495e986b0712efc453> @amueller I just PM-ed @vene about the blog post :) Will make one before 20th and share the link :)
[2015-05-19T18:22:29.031Z] <54d4a1d6db8155e6700f853b> great!
[2015-05-19T18:57:56.774Z] <54d4a1d6db8155e6700f853b> @tomdlt btw we have this thing here were we hang out and chat ;)
[2015-05-20T09:28:33.837Z] <541a528b163965c9bc2053de> @amueller I think I understand part of the pbm for the _gram_omp failure on old scipy although I cannot reproduce it in ubuntu 12.04 docker container with scipy 0.9.0. Will submit a PR.
[2015-05-20T14:06:08.246Z] <54d4a1d6db8155e6700f853b> @ogrisel thanks! I tried vagrant but didn't reproduce
[2015-05-20T14:13:16.943Z] <541a528b163965c9bc2053de> I think we can merge.
[2015-05-20T14:17:52.412Z] <541a528b163965c9bc2053de> @amueller #4743
[2015-05-20T14:37:06.835Z] <54d4a1d6db8155e6700f853b> damn, yeah I'm stupid of not having seen that @ogrisel 
[2015-05-20T14:40:22.587Z] <541a528b163965c9bc2053de> Hopefully, this will fix the issue. But travis is so slow nowadays. I opened #4749 to tackle travis speed on the longer term.
[2015-05-20T14:41:20.649Z] <54d4a1d6db8155e6700f853b> pretty sure that will fix the issue
[2015-05-20T14:53:02.951Z] <54e07d4015522ed4b3dc0856> #4749 would be really, really nice. I did not know travis was starting to support that - awesome!
[2015-05-20T15:08:05.718Z] <54d4a1d6db8155e6700f853b> @ogrisel so do you definitely want to do 0.16.2? I'm not sure. Maybe if we have the jaccard fix?
[2015-05-20T15:17:54.512Z] <54d4a1d6db8155e6700f853b> Btw, @ogrisel if you have time reviews of these should be quick: #4741 #4739 #4714
[2015-05-20T15:18:20.737Z] <54d4a1d6db8155e6700f853b> maybe we should have added some more whatsnew entries
[2015-05-20T18:45:59.851Z] <54e07e1715522ed4b3dc0866> This is not necessarily for sklearn (more for say mne-python, nilearn, sklearn-theano, etc): would the change mentioned in the blog post referenced in #4749 make certain data-intense (but fast) test cases possible with datasets stored in S3?
[2015-05-20T18:49:10.737Z] <54d4a1d6db8155e6700f853b> depends on how large, right? I guess we don't know which datacenter, but even between datacenters I think ec2 is pretty fast
[2015-05-20T18:54:11.363Z] <54e07e1715522ed4b3dc0866> ah yes - I thought that data was represented in several locations and always near to where you need it, but that is probably wishful thinking. Cost-wise,  as far as I understand data transfer from S3 to EC2 machines is free, so that shouldn't be a hindrance. Then the only question is whether practically out of these containers one can 'see' S3 as one can from EC2.
[2015-05-20T19:21:50.244Z] <54e07d4015522ed4b3dc0856> probably not without some kind of credentials or something - you would have to authorize the EC2 instance that it is "OK" to access your s3 data
[2015-05-20T19:24:43.141Z] <54d4a1d6db8155e6700f853b> well that is the same for all s3 access, right? ec2 machines are no different from any other machines on the internet wrt to s3 access iirc
[2015-05-20T19:33:10.894Z] <54e07d4015522ed4b3dc0856> I am thinking more if your data was in a private S3 bucket - in the case where people are accessing your data publicly it would be fine though it would cost $$
[2015-05-20T19:33:47.091Z] <54e07d4015522ed4b3dc0856> but if you wanted to only allow data access for,  say, nightly tests on master branch to cut down cost, you would need some kind of authorization.
[2015-05-20T19:34:17.862Z] <54e07d4015522ed4b3dc0856> So if Amazon gives free S3 to open source (or Travis), that would work. But otherwise I don't think we can rely on it without a bill.
[2015-05-20T21:20:35.242Z] <54d4a1d6db8155e6700f853b> @ogrisel do you think we can ask intel for an MKL licence for building our wheels?
[2015-05-20T21:21:28.118Z] <54d4a1d6db8155e6700f853b> I just realized that if I wanted to test the neural nets with mkl I have to wait until we release and continuum builds it for me... that seems slightly silly...
[2015-05-20T22:14:11.712Z] <54d4a1d6db8155e6700f853b> hum, thinking about it again, how do we build this on travis? That uses MKL, right?
[2015-05-21T00:06:12.695Z] <54e07d4015522ed4b3dc0856> Yes I think one of the anaconda builds on Travis is MKL - do you have the academic version of Anaconda? It is free for you and would allow a conda env with MKL if I remember right
[2015-05-21T01:31:11.561Z] <54d4a1d6db8155e6700f853b> yeah I do. but what blas does sklearn link against? anaconda doesn't come with the library to link against, right?
[2015-05-21T02:26:17.759Z] <54e07d4015522ed4b3dc0856> The academic version does
[2015-05-21T02:26:43.709Z] <54e07d4015522ed4b3dc0856> you have to register with .edu address - not sure how Travis has it but I am sure they have some license from Continuum
[2015-05-21T03:30:07.049Z] <54d4a1d6db8155e6700f853b> interesting, I have to check. I thought I had the academic license but I ran into trouble when trying to built sklearn using it
[2015-05-21T07:24:46.582Z] <541a528b163965c9bc2053de> >  Yes I think one of the anaconda builds on Travis is MKL - do you have the academic version of Anaconda? It is free for you and would allow a conda env with MKL if I remember right  on travis we just use the one month evaluation period of MKL in anaconda. As a travis build tend to last less than one month, it works :)
[2015-05-21T07:26:23.715Z] <541a528b163965c9bc2053de> sklearn probably does not build against MKL on travis with anaconda, but the included numpy and scipy packages are linked against it.
[2015-05-21T16:40:35.445Z] <54d4a1d6db8155e6700f853b> @ogrisel would you mind reviewing the mlp? I haven't added the early stopping yet, but mostly because I didn't see a case where it helped
[2015-05-21T16:41:43.171Z] <54d4a1d6db8155e6700f853b> Also, I'm not sure how much the adaptive learning rate helps
[2015-05-21T18:44:45.709Z] <54e07d4015522ed4b3dc0856> SGD is unreasonably effective ;) and I am surprised you didn't find a case where early stopping helped. But how are you testing against validation data inside sklearn API? I have been hacking my own code to take fit(X, y, valid_X=None, valid_y=None)
[2015-05-21T18:45:10.158Z] <54e07d4015522ed4b3dc0856> I really should help review that code but NIPS is looming :(
[2015-05-21T18:46:00.241Z] <54d4a1d6db8155e6700f853b> yeah it would be great if you could help
[2015-05-21T18:46:20.131Z] <54d4a1d6db8155e6700f853b> do you know what the right gain is in the initialization for the different non-linearities?
[2015-05-21T18:49:12.641Z] <54d4a1d6db8155e6700f853b> I tested against validation data currently using warm-start.
[2015-05-21T18:49:24.184Z] <54d4a1d6db8155e6700f853b> but what I am implementing right now is doing a split inside fit
[2015-05-21T19:07:06.772Z] <54e07d4015522ed4b3dc0856> what do you mean by gain? initializations are mostly (in my exp) about how tricky it is to get the right settings of the optimizer/avoid gradient explosion or vanishing
[2015-05-21T19:07:35.634Z] <54e07d4015522ed4b3dc0856> glorot init is normally the "right thing" for basically all nets, though I hear orthogonal is good too.
[2015-05-21T19:08:19.284Z] <54e07d4015522ed4b3dc0856> I don't know that you should expect a gain in performance on many tasks due to init settings, but you will certainly tell when you want to apply a net to a brand new dataset
[2015-05-21T19:51:26.960Z] <54d4a1d6db8155e6700f853b> you need to multiply the 1/sqrt(fan_in + fan_out) by a constant that is dependent on whether you do relu, tanh or sigm
[2015-05-21T19:51:46.251Z] <54d4a1d6db8155e6700f853b> in lasagna that is called the gain factor
[2015-05-21T23:06:16.982Z] <54e07d4015522ed4b3dc0856> Ah ok. I usually go by this, page 15
[2015-05-21T23:06:18.098Z] <54e07d4015522ed4b3dc0856> http://arxiv.org/pdf/1206.5533v2.pdf
[2015-05-21T23:06:24.033Z] <54e07d4015522ed4b3dc0856> 4 * for  sigm, tanh
[2015-05-21T23:06:27.738Z] <54e07d4015522ed4b3dc0856> 1 * for relu
[2015-05-21T23:07:15.365Z] <54e07d4015522ed4b3dc0856> should be sqrt(6/fan_in + fan_out)
[2015-05-21T23:07:41.190Z] <54e07d4015522ed4b3dc0856> though I guess you could pull out the 6 and adjust the "gain" to compensate. I just stick to the script
[2015-05-22T01:31:11.132Z] <550f53e215522ed4b3dda5f6> Hi @ogrisel I am current working on the derivation of VBGMM. I have done the full and diag type covariance matrix. Do I need to write the intermediate step of the derivations in the next blog for double-check?
[2015-05-22T08:24:54.727Z] <541a528b163965c9bc2053de> @xuewei4d that would be nice, thanks!
[2015-05-22T08:27:46.803Z] <541a528b163965c9bc2053de> @kastnerkyle for the init, IIRC recent work advertise gaussian init `std == np.sqrt(2) / n` for ReLU and `std == 1/n`for tanh where `n = (n_fan_in + n_fan_out) / 2`. Do you think uniform init is better?
[2015-05-22T08:28:46.038Z] <541a528b163965c9bc2053de> maybe to be less likely to be close to the saddle point at 0.
[2015-05-22T08:29:20.528Z] <541a528b163965c9bc2053de> http://arxiv.org/pdf/1502.01852.pdf
[2015-05-22T08:31:01.647Z] <541a528b163965c9bc2053de> actually, http://arxiv.org/abs/1412.6558 find that a gain of 1. is optimal for linear but 1.1 is empirically better for tanh
[2015-05-22T08:31:23.074Z] <541a528b163965c9bc2053de> and sqrt(2) is good for ReLU (confirmed)
[2015-05-22T15:18:21.637Z] <54e07d4015522ed4b3dc0856> I would go with MSR paper (1502.01852)
[2015-05-22T15:19:35.973Z] <54e07d4015522ed4b3dc0856> I don't really like gaussian init personally but it doesn't seem to make huge difference once things are optimizing. Just finding the right settings can be really annoying with poor init or optimizer.
[2015-05-22T22:50:46.902Z] <53135b495e986b0712efc453> BTW We reached 6k stars :beers: ;)
[2015-05-26T18:16:56.177Z] <54d4a1d6db8155e6700f853b> Sanders said gaussian / uniform doesn't make a difference and I trust his judgement
[2015-05-26T18:17:38.470Z] <54d4a1d6db8155e6700f853b> @kastnerkyle thanks I think I'll go with the script
[2015-05-27T07:10:39.492Z] <541a528b163965c9bc2053de> Well, this is weird: https://travis-ci.org/scikit-learn/scikit-learn/jobs/64079397 . cross_val_score, GridSearchCV and SVC and the iris dataset should all be deterministic.
[2015-05-27T14:09:29.170Z] <54d4a1d6db8155e6700f853b> indeed weird
[2015-05-27T14:11:10.318Z] <541a528b163965c9bc2053de> maybe some corrupted memory on the travis host? we should keep this failure in mind if it ever happen a second time
[2015-05-27T14:57:51.516Z] <54d4a1d6db8155e6700f853b> corrupted memory sounds unlikely
[2015-05-27T14:58:20.123Z] <54d4a1d6db8155e6700f853b> btw, why does pip install on OS X do a compile? https://github.com/scikit-learn/scikit-learn/issues/4766 when are the wheels used?
[2015-05-27T20:14:54.647Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I just started reading your blog post. I wouldn't argue with google search hits, as they are google-bubble dependent. Yours and mine are very likely biased heavily towards sklearn.
[2015-05-27T20:16:33.991Z] <53135b495e986b0712efc453> Vlad advised me on a few improvements  and I am working on it too :D 
[2015-05-27T20:16:58.812Z] <54d4a1d6db8155e6700f853b> @rvraghav93 end of may is pretty soon, btw. What is the status of the data-dependend CV iterators?  and why is the SVM infamous?
[2015-05-27T20:17:20.947Z] <53135b495e986b0712efc453> BTW this is my blog url rvraghav93.blogspot.in (so the rest of the people could take a look too) 
[2015-05-27T20:18:02.274Z] <53135b495e986b0712efc453> infamous was a wrong usage :/ correcting it :)
[2015-05-27T20:18:54.955Z] <53135b495e986b0712efc453> And I am working on it... The final consensus was that the code must be duplicated right... one with the deprecations and one without... Will push soon ;)
[2015-05-27T20:19:06.817Z] <54d4a1d6db8155e6700f853b> ok thanks.
[2015-05-27T20:19:23.647Z] <54d4a1d6db8155e6700f853b> ping me once you incorporated vlads comments
[2015-05-27T20:19:28.846Z] <53135b495e986b0712efc453> sure :)
[2015-05-27T20:20:57.601Z] <53135b495e986b0712efc453> btw I intentionally aimed it to be biased towards scikit... I wanted to give a view where in the end user might see what they get out of my work... like Vlad had advised in the email... Is that okay? 
[2015-05-27T20:22:45.329Z] <54d4a1d6db8155e6700f853b> What I meant is that if you use google, google knows you contribute to scikit-learn, so it will show scikit-learn results on top.
[2015-05-27T20:23:05.729Z] <54d4a1d6db8155e6700f853b> if someone else reads your blog and clicks the links, but they are an R user, it might show them links to R libraries, and no scikit-learn anywhere
[2015-05-27T20:26:27.077Z] <53135b495e986b0712efc453> I just checked for "cross validation" using an online proxy server... our documentation page for cross validation still ranks at 3 ;)
[2015-05-27T20:26:51.958Z] <53135b495e986b0712efc453> actually 2 if you consider the first 2 wikipedia pages as one
[2015-05-27T20:31:27.914Z] <54d4a1d6db8155e6700f853b> fair enough
[2015-05-27T20:31:34.163Z] <53135b495e986b0712efc453> :)
[2015-05-27T20:31:36.271Z] <54d4a1d6db8155e6700f853b> woah my google cred is improving
[2015-05-27T20:31:47.833Z] <53135b495e986b0712efc453> :beers: 
[2015-05-27T20:38:19.373Z] <53135b495e986b0712efc453> and may end as in without counting code reviews and revisions which I could do in parallel with the next goal :)
[2015-05-27T20:39:26.976Z] <54d4a1d6db8155e6700f853b> hehe ok
[2015-05-27T20:39:29.045Z] <54d4a1d6db8155e6700f853b> loooool http://en.wikipedia.org/wiki/Andreas_M%C3%BCller
[2015-05-27T20:56:00.932Z] <54e07e1715522ed4b3dc0866> nice :) It appears you have been there for more than a year http://en.wikipedia.org/w/index.php?title=Andreas_M%C3%BCller&type=revision&diff=597996618&oldid=573147763
[2015-05-27T20:56:11.416Z] <54e07e1715522ed4b3dc0866> time to fill in that page
[2015-05-27T20:56:13.718Z] <54e07e1715522ed4b3dc0866> ;)
[2015-05-27T20:58:28.371Z] <53135b495e986b0712efc453> awesome ;) we are filling it up :P
[2015-05-27T20:58:33.165Z] <54d4a1d6db8155e6700f853b> lol
[2015-05-27T20:58:39.196Z] <54d4a1d6db8155e6700f853b> I'm not that interesting
[2015-05-28T02:37:56.817Z] <54c084dbdb8155e6700eed4c> Hey @amueller , regarding #4767 , just remembered your #4347 now... do you think I should pause work there until that merges? Do you think it will be merged? Also applies to #4215 I suppose... I guess both of these PRs would not necessarily require deprecation since they would not be in a public release, but would be more work for you. Should I press on with @vmichel 's PR comments, or put both on hold pending renewed class_weight naming/implementation? 
[2015-05-28T02:38:01.384Z] <54c084dbdb8155e6700eed4c> Reviewing these, I begin to feel that I am a one-trick pony :smiley:
[2015-05-28T15:43:40.895Z] <54d4a1d6db8155e6700f853b> #4347 should be merged. There were no real reviews yet, though.
[2015-05-28T15:44:48.996Z] <54d4a1d6db8155e6700f853b> I'm pretty sure you have more tricks up your leave, though @trevorstephens ;)
[2015-05-28T15:45:03.872Z] <54d4a1d6db8155e6700f853b> I'm not sure, I would love some reviews for #4347. I'll rebase now. Maybe @ogrisel has time to have a look?
[2015-05-29T03:04:19.757Z] <54c084dbdb8155e6700eed4c> Well I'll leave #4215 alone for now then. If PassAgg gets merged, it should be pretty simple to change it over in your PR I guess. Unless you want me to advertise #4347 there? I'm fine either way.
[2015-06-01T02:16:14.045Z] <53135b495e986b0712efc453> @vene @amueller @ogrisel Hey this is the updated blog post incorporating all your suggestions... I am still a newbie at ML and might have made a few stupid mistakes... Please take a look at the post and feel free to point out if there are any :)
[2015-06-01T02:16:19.422Z] <53135b495e986b0712efc453> http://rvraghav93.blogspot.com/2015/05/gsoc-2015-with-python-software.html
[2015-06-01T10:48:50.715Z] <551418d115522ed4b3dddd7b> @rvraghav93 doesn't Wei Xue work on Gaussian Mixture Models? I thought that bayesian hyperoptimization didn't make it into accepted projects
[2015-06-01T13:18:39.370Z] <54d4a1d6db8155e6700f853b> yeah, that is correct
[2015-06-01T13:19:01.164Z] <54d4a1d6db8155e6700f853b> I'll have a look at the blog post probably tomorrow, I am sprinting with @pprett and @GaelVaroquaux today
[2015-06-01T15:59:31.359Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/issues/3560
[2015-06-01T16:03:52.728Z] <54d4a1d6db8155e6700f853b> There is a sprint in boston!
[2015-06-01T16:04:06.883Z] <54d4a1d6db8155e6700f853b> (like, today)
[2015-06-01T16:04:20.317Z] <54d4a1d6db8155e6700f853b> if anyone here wants to join
[2015-06-01T16:05:07.349Z] <54d4a1d6db8155e6700f853b> like @llllllllll 
[2015-06-01T16:05:08.223Z] <54d4a1d6db8155e6700f853b> lol
[2015-06-01T16:05:11.530Z] <54d4a1d6db8155e6700f853b> that is the worst name
[2015-06-01T16:48:37.251Z] <54d4a1d6db8155e6700f853b> @GaelVaroquaux do you want to merge this? https://github.com/scikit-learn/scikit-learn/pull/4785
[2015-06-01T17:36:00.438Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/issues/4784
[2015-06-02T07:37:37.289Z] <53135b495e986b0712efc453> @Barmaley-exe thanks! :) @xuewei4d apologies for the same ;)
[2015-06-02T18:28:23.416Z] <54e07d6515522ed4b3dc0858> @amueller @llllllllll worst name, or *best* name? :smile: 
[2015-06-02T18:34:10.645Z] <54e07d4015522ed4b3dc0856> I think you could go a level further @l1Ill11IIlll111III
[2015-06-02T18:34:21.970Z] <54e07d4015522ed4b3dc0856> just totally destroy people with certain fonts
[2015-06-02T20:45:10.701Z] <550f53e215522ed4b3dda5f6> Hi, @rvraghav93 I think you need to update the RSS feed of your blog in Terri's website, (link)[https://github.com/terriko/gsoc/blob/master/blog-aggregator-configs/config2015.ini]
[2015-06-03T15:16:59.195Z] <54e07d6515522ed4b3dc0858> @xuewei4d wow, it's been a while since I've seen an .ini file!
[2015-06-03T15:22:16.401Z] <54d4a1d6db8155e6700f853b> haha
[2015-06-03T15:22:46.287Z] <54d4a1d6db8155e6700f853b> @vene @llllllllll thinks it is the best. I just feel it is hard to type ;)
[2015-06-03T15:23:05.223Z] <54d4a1d6db8155e6700f853b> @rvraghav93 which PR are you currently working on? I think the data independend CV should have priority.
[2015-06-03T15:48:44.706Z] <54d4a1d6db8155e6700f853b> @rvraghav93 in the blog post, "improvise" should probably be "improve"
[2015-06-03T16:08:48.731Z] <54e07d6515522ed4b3dc0858> @amueller good thing Gitter has autocompletion
[2015-06-03T16:10:57.004Z] <54e07d6515522ed4b3dc0858> Can I ask a quick joblib question here? https://github.com/joblib/joblib/blame/master/doc/memory.rst#L187 it says r+ and w+ "will propagate the changes to disk". Shouldn't that be "will NOT propagate"?
[2015-06-03T17:40:45.896Z] <54d4a1d6db8155e6700f853b> ping @ogrisel ?
[2015-06-03T19:15:33.963Z] <54d4a1d6db8155e6700f853b> I am fascinated time and again by which PRs and issues get attention
[2015-06-03T19:16:33.915Z] <54e07d6515522ed4b3dc0858> What do you mean? The CallableVectorizer?
[2015-06-03T19:16:40.163Z] <54e07d6515522ed4b3dc0858> *CallableTransformer?
[2015-06-03T19:18:41.399Z] <54d4a1d6db8155e6700f853b> yeah
[2015-06-03T19:18:56.295Z] <54d4a1d6db8155e6700f853b> I mean it is neat, but like 6 core devs in a day?
[2015-06-03T19:19:27.984Z] <54e07d6515522ed4b3dc0858> I think it's because all of us hacked up one at some point or another
[2015-06-03T19:19:40.145Z] <54d4a1d6db8155e6700f853b> yeah probably
[2015-06-03T19:19:52.976Z] <54d4a1d6db8155e6700f853b> but the FeatureUnion thing didn't get as much attention, I think
[2015-06-03T19:21:01.318Z] <54d4a1d6db8155e6700f853b> I am unreasonably happy about the backlinks
[2015-06-03T19:26:00.454Z] <54e07d6515522ed4b3dc0858> Those are great.
[2015-06-03T19:26:31.105Z] <54e07d6515522ed4b3dc0858> For users who learn by hacking around in IPython, it was so easy to miss the User Guide completely
[2015-06-03T19:30:52.311Z] <54d4a1d6db8155e6700f853b> well but from IPython you don't get a clickable link, only a useless reference, right?
[2015-06-03T19:31:27.833Z] <54e07d6515522ed4b3dc0858> good point... but at least you know it exists
[2015-06-03T19:34:04.362Z] <54d4a1d6db8155e6700f853b> true
[2015-06-03T20:13:49.683Z] <550f53e215522ed4b3dda5f6> @amueller @ogrisel I think I need more time to write down all equations of VBGMM and DPGMM. Currently I have those for full and diag covariance. https://www.dropbox.com/s/8hlbb7dlwllwcry/VBGMM.pdf?dl=0
[2015-06-03T20:16:30.468Z] <54d4a1d6db8155e6700f853b> so you are missing spherical? Shouldn't that be easiest?
[2015-06-03T20:17:51.842Z] <54d4a1d6db8155e6700f853b> I'll try to have a look tomorrow, but it would be great if @ogrisel and loic could have a look
[2015-06-03T20:20:04.000Z] <550f53e215522ed4b3dda5f6> Well, I read through  PRML and equations for full covariance. Since there are some repeated routines, I choose to do them in order of 'full', 'diag', 'sphere' and 'tied'.
[2015-06-03T20:21:19.251Z] <550f53e215522ed4b3dda5f6> since 'diag' share some similarities with 'full'
[2015-06-03T20:22:11.378Z] <54d4a1d6db8155e6700f853b> ok
[2015-06-03T20:23:49.689Z] <54d4a1d6db8155e6700f853b> @rvraghav93 "digits" is not the same dataset as MNIST, it is much smaller. in your blog post, you mention mnist but link to a digits example.
[2015-06-03T20:27:48.093Z] <54d4a1d6db8155e6700f853b> @rvraghav93 why do you use alpha when plotting points?
[2015-06-03T20:30:39.335Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I feel this sentence is unclear: "Even when the model is optimized with the constrain of maximizing the score based upon the test set, there is still a chance of overfitting as the information about the test set can leak into the model and hence the model could be optimized for the test set alone."  it would be more explicit to say the information leaks via the selection of hyperparameters.
[2015-06-03T20:31:50.417Z] <54d4a1d6db8155e6700f853b> @rvraghav93 and cross-validation does not entirely overcome this. Overfitting to cross-validation is harder than overfitting to a single test set, but it is still possible, which is why people do nested cross-validation. 
[2015-06-03T20:32:02.544Z] <54d4a1d6db8155e6700f853b> @rvraghav93 grid.best_estimator_.score(X_test, y_test) is also not great btw. You can just use grid.score
[2015-06-03T20:32:46.389Z] <54d4a1d6db8155e6700f853b> @rvraghav93 talking about gamma=0 for the SVM is also a bit weird. This is an odd way that we used to select the default, which is 1. / n_features ,I think.
[2015-06-03T20:36:05.297Z] <54e07d6515522ed4b3dc0858> "which is why people do nested cross-validation" I think that's where @rvraghav93 is trying to lead to.
[2015-06-03T21:49:42.149Z] <550f53e215522ed4b3dda5f6> Thanks, @amueller . The text in the draft is kind of vague, but I think you could get ideas just looking at equations.
[2015-06-03T21:51:46.256Z] <550f53e215522ed4b3dda5f6> Hope you don't mind.
[2015-06-04T07:25:00.310Z] <541a528b163965c9bc2053de> > Can I ask a quick joblib question here? https://github.com/joblib/joblib/blame/master/doc/memory.rst#L187 it says r+ and w+ "will propagate the changes to disk". Shouldn't that be "will NOT propagate"?  Not it is correct. Both `r+` and `w+` open the file in read-write mode. `r` is read-only. The difference between `r+` and `w+` is that `w+` will delete any existing file before creating a new one from scratch.
[2015-06-04T09:10:05.513Z] <541a528b163965c9bc2053de> @xuewei4d will have a look thanks. Another thing we could try to address during your GSoC is the ability to add a `partial_fit` function for incremental / out-of-core fitting of (classical) GMM, for instance http://arxiv.org/abs/0712.4273. Of course the priority is fixing issues on the current code base. I can currently familiarizing myself with this part of the code base that I don't know well enough to comment on the open PRs / issues.
[2015-06-04T14:42:03.894Z] <550f53e215522ed4b3dda5f6> Thanks @ogrisel . I just finished the derivations for VBGMM.
[2015-06-04T14:42:46.234Z] <53135b495e986b0712efc453> @xuewei4d Thanks!! I just updated the same :)
[2015-06-04T14:43:02.700Z] <53135b495e986b0712efc453> @amueller thanks for the feedback will update my blog post accordingly :)
[2015-06-04T14:45:26.531Z] <550f53e215522ed4b3dda5f6> great, but the webpage http://terri.toybox.ca/python-soc/ seems not updated yet.
[2015-06-04T14:46:56.051Z] <53135b495e986b0712efc453> I think Terri should merge the PR then only it will refresh :)
[2015-06-04T15:12:49.224Z] <54e07d4015522ed4b3dc0856> @ogrisel Would the partial_fit version be EM style, or SGD? I think EM style is "easier" from a convergence perspective but I am not sure how you would do it in minibatch fashion
[2015-06-04T15:13:13.181Z] <54e07d4015522ed4b3dc0856> Though I think David Cournapeau had some good papers on it he showed at PyCon
[2015-06-04T15:13:20.952Z] <54e07d4015522ed4b3dc0856> I have the links somewhere
[2015-06-04T15:41:06.400Z] <54d4a1d6db8155e6700f853b> I think we should focus on fixing what we have before implementing new algorithms
[2015-06-04T15:58:14.832Z] <550f53e215522ed4b3dda5f6> I agree with @amueller.  May I ask what is EM style @kastnerkyle ?
[2015-06-04T16:12:33.384Z] <551418d115522ed4b3dddd7b> @xuewei4d I think he meant that in order to do partial_fit (update model rather than retrain it) you can just do several Expectation Maximization iterations from the point you've stopped at previously
[2015-06-04T16:16:20.363Z] <551418d115522ed4b3dddd7b> Though I don't get SGD part of it. I'm not sure of how severe expenses of a single EM iteration are, but I don't think they're so huge that we can't afford even a minibatch iteration
[2015-06-04T17:03:27.770Z] <54e07d4015522ed4b3dc0856> Expectation-maximization style instead of gradient descent by minibatches. I am weaker in EM than SGD approaches, but I have done SGD style learning for GMMs in the very recent past. This is why I asked - trying to gauge what I would need to read :)
[2015-06-04T17:04:21.465Z] <54e07d4015522ed4b3dc0856> Also, +1 to @amueller comment. Nothing can really happen until there is something that is well documented and understood by several people is there to experiment with/on
[2015-06-04T20:20:55.309Z] <54d4a1d6db8155e6700f853b> there was once a PR that summarized all classifiers, I think. Does anyone know where that went?
[2015-06-04T20:27:33.498Z] <53135b495e986b0712efc453> Hey @amueller Would it not be better to have `model_selection/validation.py` instead of `validate.py`? 
[2015-06-04T20:30:14.672Z] <54d4a1d6db8155e6700f853b> yeah sounds good
[2015-06-04T20:30:24.779Z] <53135b495e986b0712efc453> thanks!
[2015-06-04T21:00:23.512Z] <541a528b163965c9bc2053de> @kastnerkyle  I was thinking of online EM as described in http://arxiv.org/abs/0712.4273, but if you have good references for SGD for GMM, that's interesting too. I agree fixing existing stuff is the priority over implementing new incremental solvers but I also think that incremental solvers would make GMMs more practically useful so it would be good to review the literature on that topic.
[2015-06-04T21:02:43.073Z] <54e07d4015522ed4b3dc0856> You know me - partial fit for all the things! But this link looks good - I will read up once I get spare time. 
[2015-06-04T21:04:46.871Z] <541a528b163965c9bc2053de> @xuewei4d how different are your derivations from http://scikit-learn.org/dev/modules/dp-derivation.html ?
[2015-06-04T21:05:57.220Z] <541a528b163965c9bc2053de> David recommended to read http://leon.bottou.org/publications/pdf/online-1998.pdf as an intro to some of the concept of the online EM paper.
[2015-06-04T21:08:58.457Z] <550f53e215522ed4b3dda5f6> lol. Actually, the doc that the link points is for DPGMM, not VBGMM
[2015-06-04T21:10:25.571Z] <550f53e215522ed4b3dda5f6> I am trying to figure out that Blei's paper for DPGMM now.
[2015-06-04T21:17:26.448Z] <550f53e215522ed4b3dda5f6> @ogrisel 
[2015-06-04T22:07:30.494Z] <54d4a1d6db8155e6700f853b> does anyone have opinions on the heterogeneous feature union interface?
[2015-06-04T22:07:31.312Z] <54d4a1d6db8155e6700f853b> 3886
[2015-06-04T22:07:33.177Z] <54d4a1d6db8155e6700f853b> #3886
[2015-06-04T22:07:34.054Z] <54d4a1d6db8155e6700f853b> ?
[2015-06-04T22:07:40.751Z] <54e07d6515522ed4b3dc0858> hi Andy
[2015-06-04T22:08:12.588Z] <54e07d6515522ed4b3dc0858> I also had thought about what you just proposed `(estimator, column_name, weight)`
[2015-06-04T22:08:49.322Z] <54e07d6515522ed4b3dc0858> but I think it's not self-documenting enough
[2015-06-04T22:13:10.774Z] <54e07d6515522ed4b3dc0858> and also it makes it hard if you don't need weights. Pass explicit `None`s? ugly
[2015-06-04T22:13:26.256Z] <54d4a1d6db8155e6700f853b> well you could just leave them out, that could be supported.
[2015-06-04T22:13:28.239Z] <54d4a1d6db8155e6700f853b> but still ugly
[2015-06-04T22:14:02.293Z] <54e07d6515522ed4b3dc0858> I'd something like `dict(name='date', estimator=DateExtractor(), column='timestamp', weight=0.5)`
[2015-06-04T22:14:06.753Z] <54e07d6515522ed4b3dc0858> but without a dict
[2015-06-04T22:14:25.786Z] <54e07d6515522ed4b3dc0858> namedtuple maybe?
[2015-06-04T22:16:32.105Z] <54e07d6515522ed4b3dc0858> it'd be nice to also support `('date', DateExtractor(), column='timestamp')`, it'd be almost like a pipeline with optional arguments
[2015-06-04T22:16:47.411Z] <54e07d6515522ed4b3dc0858> is that even doable in Python?
[2015-06-04T22:17:03.515Z] <54d4a1d6db8155e6700f853b> with namedtuples
[2015-06-04T22:17:11.215Z] <54d4a1d6db8155e6700f853b> right?
[2015-06-04T22:17:19.461Z] <54e07d6515522ed4b3dc0858> I never used them, let me check
[2015-06-04T22:17:22.291Z] <54d4a1d6db8155e6700f853b> but it would be super cumbersome for the user
[2015-06-04T22:17:32.568Z] <54d4a1d6db8155e6700f853b> because they need to import this particular named tuple class
[2015-06-04T22:19:10.558Z] <54e07d6515522ed4b3dc0858> if only there existed anonymous namedtuples
[2015-06-04T22:19:11.923Z] <54d4a1d6db8155e6700f853b> I think if we want a default argument for weight, we need to define a custom class. But for the user that doesn't look much different from a namedtuple
[2015-06-04T22:19:20.199Z] <54d4a1d6db8155e6700f853b> how do you mean anonymous?
[2015-06-04T22:19:59.515Z] <54e07d6515522ed4b3dc0858> like ad-hoc, you just write (a, b, d='something'). Something like a function call argument list, but without the function
[2015-06-04T22:20:20.700Z] <54d4a1d6db8155e6700f853b> hehe yeah that's not possible in Python
[2015-06-04T22:20:33.501Z] <54d4a1d6db8155e6700f853b> because () calls the tuple constructor
[2015-06-04T22:20:40.823Z] <54d4a1d6db8155e6700f853b> I guess we could monkey-patch it :P
[2015-06-04T22:21:02.100Z] <54e07d6515522ed4b3dc0858> I feel dirty just having this conversation
[2015-06-04T22:21:14.670Z] <54d4a1d6db8155e6700f853b> haha
[2015-06-04T22:21:39.916Z] <54d4a1d6db8155e6700f853b> the other option would be a syntax more like the make_stuff helpers
[2015-06-04T22:21:48.205Z] <54d4a1d6db8155e6700f853b> but that would require kwargs
[2015-06-04T22:22:14.737Z] <54d4a1d6db8155e6700f853b> ColumnTransformer(some_name=(CountVectorizer(), column_name, weight), some_name2=(OneHotEncoder(), column_name, weight))
[2015-06-04T22:22:30.362Z] <54d4a1d6db8155e6700f853b> still wouldn't document what the weight is, though
[2015-06-04T22:25:19.706Z] <54d4a1d6db8155e6700f853b> I think I'm going with
[2015-06-04T22:25:32.011Z] <54d4a1d6db8155e6700f853b> ColumnTransformer({'some_name': (CountVectorizer(), column_name), 'some_name2': (OneHotEncoder(), column_name)}, weights=[weight1, weight2])
[2015-06-04T22:25:55.673Z] <54d4a1d6db8155e6700f853b> err
[2015-06-04T22:26:22.165Z] <54d4a1d6db8155e6700f853b>  ColumnTransformer({'some_name': (CountVectorizer(), column_name), 'some_name2': (OneHotEncoder(), column_name)}, weights={'some_name':weight1, 'some_name2':weight2}) 
[2015-06-04T22:31:59.242Z] <54e07d6515522ed4b3dc0858> I wish they could all be grouped in the same place
[2015-06-04T22:33:49.762Z] <550f53e215522ed4b3dda5f6> a quick question. Where should I add deprecation warnings in GMM? Is that good adding warning  just after ```class GMM```, (not within any function)
[2015-06-04T22:33:51.146Z] <54e07d6515522ed4b3dc0858> this is a mix of grouping by row and grouping by column
[2015-06-04T22:35:03.708Z] <54e07d6515522ed4b3dc0858> the other extreme would be ColumnTransformer(names=['a', 'b', 'c'], estimators=[CountVectorizer()] * 3, columns=['title', 'content', 'comments'], weights=[1, 1, 2])
[2015-06-04T22:35:17.452Z] <54e07d6515522ed4b3dc0858> hey, what if for ColumnTransformer we drop the names completely and use the column as the name?
[2015-06-04T22:37:24.654Z] <54d4a1d6db8155e6700f853b> then you can't grid-search if you have multiple transformers on the same column
[2015-06-04T22:38:01.484Z] <54d4a1d6db8155e6700f853b> hm if we change the data structure of how we store the transformers from FeatureUnion, we'll have a lot of code duplication :-/
[2015-06-04T22:38:07.737Z] <54e07d6515522ed4b3dc0858> correct
[2015-06-04T22:38:35.735Z] <54e07d6515522ed4b3dc0858> @xuewei4d maybe in `__init__`?
[2015-06-04T22:38:52.401Z] <54e07d6515522ed4b3dc0858> I can't find any examples
[2015-06-04T22:40:03.079Z] <54d4a1d6db8155e6700f853b> You can look at the rename of LDA to LinearDiscriminantAnalysis. well actually there it was in the file. for GMM the init would be good
[2015-06-04T22:42:12.734Z] <54e07d6515522ed4b3dc0858> that's how Ward was deprecated
[2015-06-04T22:42:14.791Z] <54e07d6515522ed4b3dc0858> looks god
[2015-06-04T22:42:15.210Z] <54e07d6515522ed4b3dc0858> good
[2015-06-04T22:42:15.993Z] <54e07d6515522ed4b3dc0858> https://github.com/scikit-learn/scikit-learn/pull/4370/files#diff-d7365adec1b76c4ff63051e4d1dd32b0L932
[2015-06-04T22:42:56.776Z] <54d4a1d6db8155e6700f853b> hm if we use dicts we also need to sort them every time we use them lol
[2015-06-04T22:43:22.679Z] <54e07d6515522ed4b3dc0858> why?
[2015-06-04T22:45:58.634Z] <54d4a1d6db8155e6700f853b> updated #3886
[2015-06-04T22:46:32.721Z] <54d4a1d6db8155e6700f853b> because dictionaries have undefined sorting, and if we iterate over them in transform we might get them in a different order then in fit
[2015-06-04T22:46:42.016Z] <54d4a1d6db8155e6700f853b> i.e. the features would be shuffled
[2015-06-04T22:47:13.150Z] <54e07d6515522ed4b3dc0858> but aren't they ever only accessed by key?
[2015-06-04T22:50:32.797Z] <54e07d6515522ed4b3dc0858> ahhh, I know what you mean now
[2015-06-04T22:51:06.130Z] <54e07d6515522ed4b3dc0858> yes, this is probably the reason why Pipeline and FeatureUnion aren't {name: Estimator()} dicts, but lists of tuples
[2015-06-04T22:52:08.627Z] <54e07d6515522ed4b3dc0858> sorting isn't good, we really want to keep the order the user gives. Otherwise there'll be a world of confusion
[2015-06-04T22:53:38.118Z] <54e07d6515522ed4b3dc0858> Now, the question is:  `ColumnTransformer([('name', (Est(), 'col')), ...]), transformer_weights=...)` vs. `ColumnTransformer([('name', Est(), 'col'), ...]), transformer_weights=...)` 
[2015-06-04T22:59:48.514Z] <54e07d4015522ed4b3dc0856> I think you can use OrderedDict from collections also. 
[2015-06-04T23:00:17.733Z] <54e07d4015522ed4b3dc0856> I like the flat one personally
[2015-06-04T23:01:13.484Z] <54e07d6515522ed4b3dc0858> @kastnerkyle yes, but then the user needs to do `ColumnTransformer(OrderedDict(...))`
[2015-06-04T23:06:58.932Z] <54e07d4015522ed4b3dc0856> Was thinking you could do d= OrderedDict(); d.items = user_d.items internally, though I have no idea if this would work. Probably more trouble than it is worth
[2015-06-04T23:07:42.965Z] <54e07d4015522ed4b3dc0856> maybe sorting is just as easy. But I like the flat list version better
[2015-06-04T23:07:51.569Z] <54e07d4015522ed4b3dc0856> er list of tuple
[2015-06-05T03:21:20.521Z] <54d4a1d6db8155e6700f853b> Pipeline is not a dict because it has a sequence, FeatureUnion is not a dict becaues I'm stupid.
[2015-06-05T03:21:28.563Z] <54d4a1d6db8155e6700f853b> Look at the issue, I went with dict.
[2015-06-05T03:21:51.504Z] <54d4a1d6db8155e6700f853b> why do you think sorting isn't good?
[2015-06-05T03:22:00.709Z] <54d4a1d6db8155e6700f853b> because people don't know which indices correspond to what?
[2015-06-05T03:22:08.969Z] <54d4a1d6db8155e6700f853b> damn I just spend two hours on that.
[2015-06-05T03:28:04.568Z] <54e07d6515522ed4b3dc0858> Well if you put it that way
[2015-06-05T03:29:25.494Z] <54e07d6515522ed4b3dc0858> It's not a lot different from classes_ being sorted. Which also is a bit confusing for the user. But it is cleaner.
[2015-06-05T03:29:55.558Z] <54e07d6515522ed4b3dc0858> It would be good to support OrderedDicts if e user so wishes
[2015-06-05T13:00:38.098Z] <541a528b163965c9bc2053de> @xuewei4d wouldn't you happen to have a PDF version of PRML? I am working at home today and I left my hardcover copy in our lab.
[2015-06-05T13:01:26.461Z] <550f53e215522ed4b3dda5f6>  Yes, I have
[2015-06-05T13:03:05.451Z] <550f53e215522ed4b3dda5f6> https://www.dropbox.com/s/7u13hvokr1lh2fa/Pattern%20Recognition%20and%20Machine%20Learning.pdf?dl=0
[2015-06-05T13:05:11.627Z] <541a528b163965c9bc2053de> thanks :)
[2015-06-05T13:38:16.800Z] <550f53e215522ed4b3dda5f6> :smile: Let me know if there is any problem in the derivation draft.
[2015-06-05T14:04:29.493Z] <541a528b163965c9bc2053de> yeah sorry, I am slow to review your work. I have been busy helping a colleague with a nips submission this week. The deadline is tonight. I hope to be more responsive next week.
[2015-06-05T17:25:09.220Z] <54d4a1d6db8155e6700f853b> @rvraghav93 any update on the generalized CV? It would really be great if you'd report more regularly so we can follow what is happening.
[2015-06-05T17:57:31.464Z] <53135b495e986b0712efc453> Sory sory! :( will update that soon...!! I am unable to pass all the tests :/
[2015-06-05T17:59:47.331Z] <53135b495e986b0712efc453> BTW can I go ahead and add the exceptions module or should I wait for a reply from Lars (#4309)?
[2015-06-05T18:01:34.871Z] <54d4a1d6db8155e6700f853b> even if tests are failing, you can still push
[2015-06-05T18:01:51.425Z] <53135b495e986b0712efc453> Okay :)
[2015-06-05T18:02:03.111Z] <54d4a1d6db8155e6700f853b> I am not saying "work harder" but "communicate more" ;)
[2015-06-05T18:02:34.456Z] <54d4a1d6db8155e6700f853b> making tests pass is not always easy, and it is hard for me or @vene to help if we don't see the code
[2015-06-05T18:02:52.370Z] <54d4a1d6db8155e6700f853b> do you need the exceptions module for the cv pr?
[2015-06-05T18:03:04.424Z] <53135b495e986b0712efc453> Yes sure... apologies for the lack of regular communications :)
[2015-06-05T18:03:56.166Z] <53135b495e986b0712efc453> and yea it would be cleaner to put those in exceptions... coz we are already duplicating a lot of code it would be great if we could group those together into the exceptions module... (not a big issue though)
[2015-06-05T18:04:17.382Z] <54d4a1d6db8155e6700f853b> feel free to do it
[2015-06-05T18:04:21.531Z] <53135b495e986b0712efc453> Thanks :)
[2015-06-05T18:24:50.116Z] <54d4a1d6db8155e6700f853b> @vene @ogrisel do you remember the estimator summary PR? I think it was by @mblondel ?
[2015-06-05T18:46:29.615Z] <54d4a1d6db8155e6700f853b> is there a more readable alternative to mgrid with complex numbers? this seems like the most horrifying hack.
[2015-06-05T18:57:46.026Z] <541a528b163965c9bc2053de> I don't remember...
[2015-06-05T19:03:30.285Z] <54d4a1d6db8155e6700f853b> maybe I'm imagining things...
[2015-06-05T19:17:15.336Z] <54e07d6515522ed4b3dc0858> @amueller what are you referencing re: mgrid? is it in any scikit-learn code?
[2015-06-05T19:52:09.963Z] <550f53e215522ed4b3dda5f6> I just noticed that the problem setting in the current derivation of DPMM is simpler than mine. You could find it in my new blog post http://xuewei4d.github.io/2015/06/05/gsoc-week2-vbgmm-and-gmm-api.html. @amueller @ogrisel @lesteve.
[2015-06-05T20:05:53.877Z] <54d4a1d6db8155e6700f853b> @vene yes, in the examples. np.mgrid[1:2:10j] means "do ten steps from 1 to 2"
[2015-06-05T20:06:03.240Z] <54d4a1d6db8155e6700f853b> it is a multi-dimensional version of linspace
[2015-06-05T20:06:21.769Z] <54d4a1d6db8155e6700f853b> without the j it means "step"
[2015-06-05T20:07:22.405Z] <54d4a1d6db8155e6700f853b> so mgrid implements a multi-dimensional arange if the third argument is real, and a multi-dimensional linspace if it is complex.
[2015-06-05T20:08:15.846Z] <54d4a1d6db8155e6700f853b> not sure if :rage4: or :trollface: 
[2015-06-05T20:10:08.872Z] <54e07d6515522ed4b3dc0858> So there is no function for this without a slice api?
[2015-06-05T20:13:10.292Z] <541a528b163965c9bc2053de> Thanks for the wrap-up @xuewei4d! I will have a deeper look at it next week.
[2015-06-05T20:15:36.593Z] <54d4a1d6db8155e6700f853b> @vene that is what I was asking
[2015-06-05T20:16:19.691Z] <54d4a1d6db8155e6700f853b> and the slicing API with complex number that do not mean steps seems a really awkward construct
[2015-06-05T20:19:34.867Z] <54d4a1d6db8155e6700f853b> isinstance(sparse.csr_matrix([[1, 2]]), containers.Mapping) == True. # that is all
[2015-06-05T20:19:47.458Z] <54d4a1d6db8155e6700f853b> gitter is weird
[2015-06-05T20:19:55.235Z] <541a528b163965c9bc2053de> @xuewei4d about the API issues, we need to make sure that the score API (in particular the shape) is not conflicting with the score method of other models in scikit-learn in particular models that are not density estimators. I think we would have a `density` or `log_density` methods to have more explicit names and avoid conflicts
[2015-06-05T20:20:04.959Z] <54d4a1d6db8155e6700f853b>  isinstance(sparse.csr_matrix([[1, 3], [5, 3]]), containers.Mapping) == True. # that is all 
[2015-06-05T20:20:19.197Z] <541a528b163965c9bc2053de> will come back to you to discuss that on the relevant github issues next week
[2015-06-05T20:22:03.646Z] <541a528b163965c9bc2053de> BTW thanks for the effort to typeset the derivation in latex with clear formatting, this is well appreciated.
[2015-06-05T20:45:22.481Z] <54d4a1d6db8155e6700f853b> @xuewei4d indeed, that is pretty cool
[2015-06-05T20:46:26.412Z] <54d4a1d6db8155e6700f853b> hum, if I want to one-hot encode ['paris', 'paris', 'london', 'new york'] I have to use ``LabelBinarizer``, not ``OneHotEncoder``. That seems odd.
[2015-06-05T20:46:51.575Z] <54d4a1d6db8155e6700f853b> And if it is ['paris', 'paris', 'london'] I only get a single column....
[2015-06-05T20:47:00.483Z] <54e07d6515522ed4b3dc0858> @amueller the mapping thing is horrifying
[2015-06-05T20:47:48.941Z] <54d4a1d6db8155e6700f853b> more or less horrifying than the complex slicing?
[2015-06-05T20:53:32.089Z] <54d4a1d6db8155e6700f853b> Ok so I want to do an example for the heterogeneous feature union / ColumnTransformer that processes `` ['paris', 'paris', 'london', 'new york'] `` as a categorical variable. Is this really not possible with scikit-learn?
[2015-06-05T20:57:11.800Z] <54e07d6515522ed4b3dc0858> Less. CSR is naturally a dict-like structure
[2015-06-05T20:58:09.708Z] <54d4a1d6db8155e6700f853b> ;)
[2015-06-05T20:58:36.191Z] <54d4a1d6db8155e6700f853b> but how do I solve my one-hot-encoding problem now? Should I change OneHotEncoder to work with strings?
[2015-06-05T20:59:10.971Z] <54e07d6515522ed4b3dc0858> That really should work
[2015-06-05T21:02:39.120Z] <54d4a1d6db8155e6700f853b> I can already hear gael shouting ^^
[2015-06-05T21:04:32.686Z] <54e07d6515522ed4b3dc0858> We could code a gael-bot for gutter
[2015-06-05T21:06:19.214Z] <54d4a1d6db8155e6700f853b> what should the allowed input types for OneHotEncoder be?
[2015-06-05T21:06:27.032Z] <54d4a1d6db8155e6700f853b> currently it is integer arrays
[2015-06-05T21:07:31.551Z] <54e07d6515522ed4b3dc0858> Anything that can be turned into a set and indexed?
[2015-06-05T21:08:03.428Z] <54d4a1d6db8155e6700f853b> sorry, I didn't get that
[2015-06-05T21:54:23.993Z] <54e07d6515522ed4b3dc0858> list of strings should work too
[2015-06-06T17:07:33.114Z] <54d4a1d6db8155e6700f853b> and how about lists of lists of strings?
[2015-06-06T17:07:34.334Z] <54d4a1d6db8155e6700f853b> ;)
[2015-06-06T18:01:30.926Z] <54e07d6515522ed4b3dc0858> @amueller what is the use case? I'd just use CountVectorizer without a tokenizer there :D
[2015-06-06T18:02:07.232Z] <54e07d6515522ed4b3dc0858> In your example above, `['paris', 'paris', 'london', 'new york']` is the entire column (4 values) or a single value?
[2015-06-06T18:02:58.925Z] <54e07d6515522ed4b3dc0858> if the former, OneHotEncoder would work, right?
[2015-06-06T18:05:46.938Z] <54e07d6515522ed4b3dc0858> @amueller try this: ``` x = [['paris', 'paris', 'london'], ['london', 'nyc']] CountVectorizer(analyzer=lambda x: x).fit_transform(x).todense() ```
[2015-06-06T18:06:03.276Z] <54d4a1d6db8155e6700f853b> the entire column
[2015-06-06T18:06:12.159Z] <54d4a1d6db8155e6700f853b> four samples
[2015-06-06T18:06:24.105Z] <54d4a1d6db8155e6700f853b> it is just one categorical value
[2015-06-06T18:06:32.437Z] <54d4a1d6db8155e6700f853b> OneHotEncoder only works on integers
[2015-06-06T18:07:22.937Z] <54d4a1d6db8155e6700f853b> LabelBinarizer kind of works, but is not really made for this usecase and doesn't really have a transformer interface
[2015-06-06T18:08:54.552Z] <54e07d6515522ed4b3dc0858> this works: ``` In [12]:  x = [['paris'], ['paris'], ['london'], ['new york']] CountVectorizer(analyzer=lambda x: x).fit_transform(x).toarray()  Out[12]: array([[0, 0, 1],        [0, 0, 1],        [1, 0, 0],        [0, 1, 0]]) ```
[2015-06-06T18:09:14.591Z] <54d4a1d6db8155e6700f853b> true. It seems odd to me, though.
[2015-06-06T18:09:32.665Z] <54d4a1d6db8155e6700f853b> Is that the interface we want?
[2015-06-06T18:09:50.582Z] <54e07d6515522ed4b3dc0858> I think OneHotEncoder should support it
[2015-06-06T18:10:02.395Z] <54e07d6515522ed4b3dc0858> what I meant yesterday is that it can support anything that's an object
[2015-06-06T18:10:11.309Z] <54e07d6515522ed4b3dc0858> as long as you can assign integers to different objects you encounter
[2015-06-06T18:10:18.297Z] <54d4a1d6db8155e6700f853b> and I feel like I also want to support data that has one column that is city and one column that is color. But maybe ColumnTransformer is for that
[2015-06-06T18:11:02.403Z] <54d4a1d6db8155e6700f853b> ok but what is the type / shape of X? Would you support this for X being a list of arbitrary objects? Or for X being an 2d array of arbitrary objects?
[2015-06-06T18:11:44.612Z] <54e07d6515522ed4b3dc0858> I'd say list (or 1d array) of arbitrary objects
[2015-06-06T18:11:51.829Z] <54e07d6515522ed4b3dc0858> why 2d array? for city and color?
[2015-06-06T18:12:51.900Z] <54e07d6515522ed4b3dc0858> once you have more than one field of categorical variables, you could encode them as dict(city='new york', color='red') in which case dictvectorizer works, right?
[2015-06-06T18:13:36.819Z] <54e07d6515522ed4b3dc0858> or encode them as dict(cities=['nyc', 'paris'], colors=['red', 'yellow']) and then ColumnTransformer + OneHotEncoder should work
[2015-06-06T18:18:37.697Z] <54e07d6515522ed4b3dc0858> for your example you could do ``` X = {'post_content': ["long string 1", "long string 2"...],         'metadata': [{location='nyc', category='misc'}, {location='paris', category='programming'}...] ``` 
[2015-06-06T18:19:05.368Z] <54e07d6515522ed4b3dc0858> and ColumnTransformer(dict(post_content=CountVectorizer(), metadata=DictVectorizer()))
[2015-06-06T18:28:09.297Z] <54d4a1d6db8155e6700f853b> I feel the nested dicts are ugly.
[2015-06-06T18:28:15.791Z] <54d4a1d6db8155e6700f853b> I just updated the example but something is wrong :-/
[2015-06-06T18:36:28.305Z] <54d4a1d6db8155e6700f853b> ah
[2015-06-06T18:36:51.285Z] <54d4a1d6db8155e6700f853b> ```python x = ['paris', 'paris', 'london', 'new york'] CountVectorizer(analyzer=lambda x: [x]).fit_transform(x).toarray() ```
[2015-06-06T18:36:55.394Z] <54d4a1d6db8155e6700f853b> is what I want
[2015-06-06T18:37:01.376Z] <54d4a1d6db8155e6700f853b> how do you do the code highlighting again?
[2015-06-06T18:37:14.598Z] <529c6c25ed5ab0b3bf04d824> backticks
[2015-06-06T18:37:24.472Z] <54d4a1d6db8155e6700f853b> right
[2015-06-06T18:42:47.607Z] <54e07d6515522ed4b3dc0858> that works, but the analyzer lambda is super opaque
[2015-06-06T18:44:05.046Z] <54e07d6515522ed4b3dc0858> idea: why not deprecate DictVectorizer and create a CategoricalVectorizer with the same interface
[2015-06-06T18:44:30.678Z] <54e07d6515522ed4b3dc0858> except if you pass it a 2d array, it would treat each column as a different implicit key
[2015-06-06T18:45:15.797Z] <54e07d6515522ed4b3dc0858> so then you can do `['paris', 'paris', 'new york', 'london']` as well as `[['paris, 'red'], ['paris', 'green'], ...]`
[2015-06-06T18:55:52.481Z] <54d4a1d6db8155e6700f853b> hm... maybe just add that?
[2015-06-06T18:56:06.365Z] <54d4a1d6db8155e6700f853b> I added a somewhat interesting example to the pr
[2015-06-06T18:56:08.010Z] <54e07d6515522ed4b3dc0858> yes but then it's no longer a **dict** vectorizer :)
[2015-06-06T18:56:27.473Z] <54d4a1d6db8155e6700f853b> I meant just adding a different class with a different interface
[2015-06-06T18:58:05.009Z] <54e07d6515522ed4b3dc0858> or that
[2015-06-06T21:20:19.772Z] <54e07d6515522ed4b3dc0858> IThe example is very nice
[2015-06-07T00:49:46.625Z] <54d4a1d6db8155e6700f853b> thanks :)
[2015-06-07T11:50:31.654Z] <53135b495e986b0712efc453> Why do we have the `_check_cv` function? It is called by `check_cv` which does nothing additionally? Am I missing something? https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/cross_validation.py#L1431
[2015-06-07T12:11:30.233Z] <53135b495e986b0712efc453> It should be removed... I opened a PR #4829 for that... Please review @vene @amueller ! :)
[2015-06-07T12:11:49.986Z] <53135b495e986b0712efc453> and @ogrisel
[2015-06-07T21:54:20.503Z] <54e07d6515522ed4b3dc0858> @amueller can `sklearn.utils.testing.ignore_warnings` ignore *specific types of warnings*?
[2015-06-07T21:54:39.804Z] <54e07d6515522ed4b3dc0858> the code looks odd
[2015-06-07T21:55:07.319Z] <54e07d6515522ed4b3dc0858> (this is in reference to #4824)
[2015-06-07T22:31:59.091Z] <54e07d6515522ed4b3dc0858> so have we decided to just never use the words "extreme learning machine" in docstrings/documentation? 
[2015-06-08T00:53:55.304Z] <54e07d4015522ed4b3dc0856> That is my opinion. Though it is weird cause that is what people call it. So I am of 2 minds at once
[2015-06-08T00:54:33.949Z] <54e07d4015522ed4b3dc0856> But the paper citation stuff is really pretty shady so that is tough too.
[2015-06-08T02:33:19.939Z] <54e07d6515522ed4b3dc0858> Do we care about being googlable for this?
[2015-06-08T11:16:57.740Z] <53135b495e986b0712efc453> Just a general question... Is there a way to track changes in a particular module and get notified if that gets merged? (w.r.t #4294) (ref [comment](https://github.com/scikit-learn/scikit-learn/pull/4829#issuecomment-109952865))
[2015-06-08T11:27:18.867Z] <53135b495e986b0712efc453> Ah its easier to just check the history of the file ;) sorry for the noise!
[2015-06-08T13:53:15.875Z] <54d4a1d6db8155e6700f853b> @kastnerkyle btw I'm going to seriously start on the tutorials now, I was pretty busy with other things before
[2015-06-08T13:54:23.137Z] <54d4a1d6db8155e6700f853b> @vene I think we should use the word Extreme Learning Machine in the narrative and maybe as a remark in the docstrings, but not as the name.
[2015-06-08T13:54:39.724Z] <54d4a1d6db8155e6700f853b> Like "This can be used to implement so-called Extreme Learning Machines" or something like that
[2015-06-08T14:16:40.004Z] <54e07d6515522ed4b3dc0858> That's probably wise.
[2015-06-08T14:17:31.298Z] <54e07d6515522ed4b3dc0858> Also, scikit-learn should have the power to change the way researchers call algorithms. Maybe our naming decision will fix this mess a bit.
[2015-06-08T14:18:06.290Z] <54e07d6515522ed4b3dc0858> I've seen researchers calling svms SMO because that's what the solver class is called in Weka
[2015-06-08T14:20:56.574Z] <54d4a1d6db8155e6700f853b> omg
[2015-06-08T14:40:35.614Z] <54e07d6515522ed4b3dc0858> I remember Fabian had started wrapping liblinear's CD solver. Now that SAG is joining the family of solvers available for logistic regression, we might be able to simplify the codebase by picking that up
[2015-06-08T14:40:44.447Z] <54e07d6515522ed4b3dc0858> assuming it matches the interface of scipy optimizers
[2015-06-08T14:41:33.940Z] <54e07d6515522ed4b3dc0858> https://github.com/fabianp/pytron/
[2015-06-08T14:42:12.336Z] <54e07d6515522ed4b3dc0858> (question triggered by @amueller's [comment](https://github.com/scikit-learn/scikit-learn/pull/4738#issuecomment-108592200))
[2015-06-08T18:22:27.700Z] <54d4a1d6db8155e6700f853b> @kastnerkyle when do you have time to discuss the tutorial? Do you think we should put exercises after each sections or do "morning lecture, morning exercises, afternoon lecture, afternoon exercises"? Maybe multiple short breaks would be good? four hours is such a long time. Maybe a four 45 blocks with 15 minutes exercises? Not sure.
[2015-06-08T20:35:10.412Z] <550f53e215522ed4b3dda5f6> Hi, I am almost done the derivation draft. I fixed some typos and errors, and completed the DP part. What is left is the lower bound and predictive distribution for   two cases. I think I could finish it tomorrow. The difference from current derivation includes, the initial parameters and the updating functions for Wishart distribution. The rest of them are the same. I hope I could find out the reason of the latter.
[2015-06-08T20:43:03.194Z] <550f53e215522ed4b3dda5f6> With regards to the new names of DPGMM and VBGMM, I think these two names are not suitable, just like someone calls SVM as SMO. Actually, the models are Bayesian GMM, Dirichlet Process Bayesian GMM (DPGMM is often used) respectively. Both of them are solved by variational inference. In other words, VBGMM is not a good name. The new names, I think, should have the meaning of 'Bayesian GMM solved by VB', 'DP(B)GMM solved by VB'.
[2015-06-08T21:17:45.800Z] <54d4a1d6db8155e6700f853b> @tw991 the two PRs with the mlp code are #3939 and #3204. #3204 contains adagrad
[2015-06-08T21:18:58.855Z] <54d4a1d6db8155e6700f853b> @xuewei4d I agree wrt VB. It should be "bayesian GMM"
[2015-06-08T21:19:04.942Z] <54d4a1d6db8155e6700f853b> or something similar
[2015-06-08T22:24:41.382Z] <54e07d4015522ed4b3dc0856> @amueller I have time. Just started my internship today so I should be able to take a look at it now :) I think 45 min blocks + excercises is good but we should also budget for questions *during*. And hopefully we will not be only 2 who can help when questions arise - maybe some advanced sklearn users in audience can help too
[2015-06-08T22:25:48.425Z] <54e07d4015522ed4b3dc0856> Though I am expecting more question during advanced section for sure. We could do that in 30/30 blocks
[2015-06-08T22:26:03.359Z] <54e07d4015522ed4b3dc0856> if necessary. Also the first day tutorial might inform us of mods to make for second day
[2015-06-08T22:27:41.697Z] <54d4a1d6db8155e6700f853b> @kastnerkyle cool. I basically just copied the 2013 as a start, but I want to do some reorganization. I'm not entirely certain about the structure and the cluster stuff
[2015-06-08T22:29:21.500Z] <54d4a1d6db8155e6700f853b> I am now going through the lectures again and I'll draft a new toc tomorrow. I think having a bit more intro about what ML is in the beginning would be good, and I'll try to recycle some of my diagrams
[2015-06-08T22:30:45.090Z] <54d4a1d6db8155e6700f853b> Actually the current notebooks are pretty close to the toc in the proposal, with a bit of reorganization
[2015-06-08T22:35:40.938Z] <54d4a1d6db8155e6700f853b> @kastnerkyle is there any part you'd like to work on particularly so that we don't conflict? Also, when do you have time or a beer in the city?
[2015-06-08T22:36:08.008Z] <54d4a1d6db8155e6700f853b> I think I'd like to work on the intro for now.
[2015-06-08T22:51:20.234Z] <54e07d4015522ed4b3dc0856> I am planning right now to pop in over the weekend. So if you have a day or time which is good I am game. I am probably stronger talking about PCA, GP and friends than random forests, SVM and the like if we are gonna go into theoretical aspects. But if not then I have no preference.
[2015-06-08T23:17:15.302Z] <54e07d4015522ed4b3dc0856> Also I am terrible at the text preprocessor stuff. But I think it is important
[2015-06-08T23:17:42.883Z] <54e07d4015522ed4b3dc0856> DictVectorizer etc. Might be a crucial thing for examples. Raw text -> classification ala your troll detection model
[2015-06-08T23:26:21.117Z] <54d4a1d6db8155e6700f853b> I don't think we will do much theory, and I don't think we should include GPs. I want to talk a bit more about details about some of the commonly used supervised models.
[2015-06-08T23:29:22.924Z] <54d4a1d6db8155e6700f853b> I think Sunday would work for me.
[2015-06-08T23:45:40.129Z] <54e07d4015522ed4b3dc0856> OK cool. I will let you know later in the week what is up but I can try to be in NY on Sunday. What part are you in?
[2015-06-08T23:57:48.844Z] <54d4a1d6db8155e6700f853b> I'm in east village but I'm pretty free on Sunday, so I could travel a bit
[2015-06-09T13:41:16.997Z] <54e07d4015522ed4b3dc0856> That sounds good to me. I will email you and set up something. I will be the country kid in the Big Apple ;)
[2015-06-09T15:29:23.593Z] <54d4a1d6db8155e6700f853b> @kastnerkyle one thing  I noticed about the notebooks is that they are pretty text-heavy. I'm not sure how I feel about it. I guess it depends on whether you think of it more as a presentation or as an "in your own time" thing. While someone is speaking, the text seems more distracting than helpful. I'm not sure about it, though.
[2015-06-09T15:30:15.031Z] <54e07d4015522ed4b3dc0856> I agree. The text is useful "after the fact". But our presentation should basically be the content contained in that text IMO, so we can focus on the pretty pictures
[2015-06-09T15:30:41.561Z] <54e07d4015522ed4b3dc0856> We could make a stripped down version of all, with just images. Or just scroll so that images are the focus
[2015-06-09T15:32:23.486Z] <54d4a1d6db8155e6700f853b> So, you suggest do develop one with text for people to work though it at home afterwards, and drop the text for the presentation? Which one do we distribute then for the tutorial? The no-text one?
[2015-06-09T15:39:35.430Z] <54d4a1d6db8155e6700f853b> do we have a real-world dataset that uses dict-vectorizer? Or any real-world dataset that has categorical features encoded as strings? Btw, what is the recommended method to deal with that? Pandas? Or converting to dict and DictVectorizer?
[2015-06-09T15:40:47.082Z] <54e07d4015522ed4b3dc0856> I would say it depends how much we reuse old tutorials. If it is all new (unlikely) generating that much content will be tough - in that case I would go with pics only. But if we mostly reuse I think we should do text + images in main notebooks we put in tutorial repo, then just have a separate folder of "presentation ready" which is basically titles, pictures and key math or whatever else is necessary to talk on. Or vice-versa (text versions in a separate folder called like "self_teaching") to avoid confusion
[2015-06-09T15:45:48.259Z] <54d4a1d6db8155e6700f853b> sounds good
[2015-06-09T15:46:02.701Z] <54d4a1d6db8155e6700f853b> I'd go with the "self teaching" approach
[2015-06-09T15:46:37.956Z] <54e07d4015522ed4b3dc0856> yeah. that way it takes extra effort to open the wrong content :) though I am sure it will happen anyways...
[2015-06-09T21:27:55.603Z] <54d4a1d6db8155e6700f853b> @kastnerkyle I don't see where cross-validation is introduced in the notebooks... hum...
[2015-06-10T09:37:39.184Z] <53135b495e986b0712efc453> ``` from sklearn.utils.extmath import fast_dot from sklearn.exceptions import EfficiencyWarning import warnings warnings.simplefilter('always', EfficiencyWarning) import numpy as np fast_dot(np.array([1, 2, 3]), np.array([4, 5, 6])) ``` This code which is supposed to raise a warning doesn't raise one!  However this one does -_- ``` from sklearn.utils.extmath import _fast_dot from sklearn.exceptions import EfficiencyWarning import warnings warnings.simplefilter('always', EfficiencyWarning) import numpy as np _fast_dot(np.array([1, 2, 3]), np.array([4, 5, 6])) ```  Ref: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/extmath.py#L151
[2015-06-10T13:35:25.890Z] <550f53e215522ed4b3dda5f6> The GMM model in http://scikit-learn.org/stable/modules/dp-derivation.html is not standard. The distribution of \mu_k  does not have variance depending on the Gamma distribution. It is just a constant. I think that is why the current implementation is kind of weird....
[2015-06-10T23:00:32.102Z] <53135b495e986b0712efc453> The `NonBLASDotWarning` (to be converted to `EfficiencyWarning`) doesn't seem to work as intended! 
[2015-06-10T23:01:24.546Z] <54d4a1d6db8155e6700f853b> how do you mean?
[2015-06-10T23:02:16.167Z] <53135b495e986b0712efc453> Please check the above code sample :)
[2015-06-10T23:03:03.656Z] <53135b495e986b0712efc453> The `EfficiencyWarning` in the above code is supposed to be `NonBLASDotWarning`...
[2015-06-10T23:05:16.523Z] <53135b495e986b0712efc453> It is being disabled at [utils/validation.py](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py#L42).. maybe it has something to do with it?
[2015-06-10T23:06:14.373Z] <53135b495e986b0712efc453> Nope I tried removing that line and this issue still persists!
[2015-06-10T23:07:50.206Z] <54d4a1d6db8155e6700f853b> I am not very good with working with the warnings registry.
[2015-06-10T23:08:25.686Z] <53135b495e986b0712efc453> hmm okay! Thanks for looking into it :) Does this issue seem worthy enough  for a new issue on github?
[2015-06-10T23:09:23.061Z] <54d4a1d6db8155e6700f853b> probably not.
[2015-06-10T23:09:28.226Z] <54d4a1d6db8155e6700f853b> Maybe ping @ogrisel ?
[2015-06-10T23:09:47.754Z] <53135b495e986b0712efc453> Okay! meanwhile I'll also investigate :)
[2015-06-10T23:10:37.446Z] <54d4a1d6db8155e6700f853b> great!
[2015-06-10T23:35:52.253Z] <550f53e215522ed4b3dda5f6> I noticed that gmm code is a little messy. Some functions should be decomposed, and the way of initializing parameters is not completely implemented. According to the derivation draft, different estimators of responsibility, weight, mean, covariance could be combined together to represent GMM, BGMM, DPGMM. I think, in terms of maintainability,  it is good to create bunches of estimators with inheritance and then combine them on demand in  just use one class to represent all three models with four types of covariance. Is that a good idea?
[2015-06-10T23:51:09.915Z] <54d4a1d6db8155e6700f853b> usually we try to restrict inheritance to mixins, so that there is no complex overloading of functions. If you can implement it by providing mixins for the four covariance types, that would be great. I'm not sure how well these factorize, though.
[2015-06-10T23:51:29.262Z] <54d4a1d6db8155e6700f853b> @kastnerkyle it would be great if you could give me your feedback on my redoing of the notebooks.
[2015-06-11T00:11:55.189Z] <54e07d4015522ed4b3dc0856> OK looking now. Key question - does StarCluster still work?
[2015-06-11T00:12:14.772Z] <54e07d4015522ed4b3dc0856> I was under the impression that it broke at some point a ways back but I am not super informed on these things
[2015-06-11T00:14:13.286Z] <54e07d4015522ed4b3dc0856> The hashing stuff / out-of-core stuff seems like maybe we should do it *before* parallel. It is quite nice I think. Now onto rendered_notebooks
[2015-06-11T00:16:40.652Z] <54e07d4015522ed4b3dc0856> I think we should focus on py 3.4 compat - seeing at least a few print blah in there. I can work on that if you want?
[2015-06-11T00:19:18.649Z] <54e07d4015522ed4b3dc0856> Also... describing all the different types of sparse matrices may not be pleasant in the intro. Maybe leave them there but gloss over subtleties of different representations? If you know guts I am all for it - but I am definitely a high-level sparse matrix user. I use what works normally and check stack overflow
[2015-06-11T00:41:11.345Z] <54e07d4015522ed4b3dc0856> Should we add an image telling what petal and sepal are? Or just say what it is. For sure *somebody* will ask  :)
[2015-06-11T07:54:35.503Z] <541a528b163965c9bc2053de> @xuewei4d do you think changing the handling of the \mu_k will have a significant impact on the runtime performance? Besides Bishop's PRML do you have another "standard" formulation / derivation of the Variational GMM in mind?
[2015-06-11T07:56:05.840Z] <541a528b163965c9bc2053de> +1 for not introducing a deep hierarchy of estimators for GMMs but ok for using mixin class and possibly a _BaseGMM abstract base class if that can help factoring too redundant code.
[2015-06-11T07:59:46.755Z] <541a528b163965c9bc2053de> @kastnerkyle I have not tried to launch a StarCluster instance in a long time but the project is still active. The configuration might have changed a bit (e.g. AMIs ids) so it should be possible to adapt it to make it run again. However I would not do that during a tutorial if you are not a regular user yourself. You can just mention that it exists in passing.
[2015-06-11T10:56:24.430Z] <53135b495e986b0712efc453> Is it just me or this page takes forever to load :@ - I've been trying since yesterday ;( https://travis-ci.org/scikit-learn/scikit-learn/jobs/66302262
[2015-06-11T11:32:50.251Z] <541a528b163965c9bc2053de> it works here
[2015-06-11T11:33:06.944Z] <53135b495e986b0712efc453> Thanks a lot for checking :)
[2015-06-11T11:33:08.458Z] <541a528b163965c9bc2053de> try https://s3.amazonaws.com/archive.travis-ci.org/jobs/66302262/log.txt
[2015-06-11T11:33:34.702Z] <541a528b163965c9bc2053de> if it does not work, I can paste-bin it for you
[2015-06-11T11:35:19.324Z] <53135b495e986b0712efc453> Thankss a ton for this txt log link! Will be really useful for me! :D and yea it does work :)
[2015-06-11T11:37:19.374Z] <53135b495e986b0712efc453> Hey @ogrisel BTW could you check why  ``` from sklearn.utils.extmath import fast_dot from sklearn.exceptions import NonBLASDotWarning import warnings warnings.simplefilter('always', NonBLASDotWarning) import numpy as np fast_dot(np.array([1, 2, 3]), np.array([4, 5, 6])) ``` doesn't raise the intended warning? Am sure I must be missing something simple here :|
[2015-06-11T11:55:43.864Z] <541a528b163965c9bc2053de> @rvraghav93 which PR number is this again?
[2015-06-11T11:57:11.688Z] <53135b495e986b0712efc453> #4826 :)
[2015-06-11T11:58:07.954Z] <53135b495e986b0712efc453> Please do take a look if you are able to find time :)
[2015-06-11T12:03:10.182Z] <541a528b163965c9bc2053de> this warning is only raised for old versions of numpy
[2015-06-11T12:03:12.843Z] <541a528b163965c9bc2053de> < 1.7
[2015-06-11T12:03:25.279Z] <541a528b163965c9bc2053de> if np_version < (1, 7, 2) and _have_blas_gemm()
[2015-06-11T12:03:54.136Z] <53135b495e986b0712efc453> Ahhh... Thanks!!
[2015-06-11T13:40:30.594Z] <54e07d4015522ed4b3dc0856> @ogrisel @amueller pyspark now deserves a mention along with https://pypi.python.org/pypi/sparkit-learn/0.1 I think. 
[2015-06-11T13:40:44.545Z] <54e07d4015522ed4b3dc0856> Would be of interest for many of the same people who care about StarCluster
[2015-06-11T13:50:55.498Z] <541a528b163965c9bc2053de> also useful, although not directly related: - http://yelp.github.io/MOE/ - http://pythonhosted.org/airflow/
[2015-06-11T13:51:13.044Z] <541a528b163965c9bc2053de> I have not yet found to the time to test any of those
[2015-06-11T14:26:01.582Z] <550f53e215522ed4b3dda5f6> @ogrisel The distinction is that whether \mu_k depends on \Lambda_k. PRML and MLAPP(P750) models that dependence. In the literature, some work has that ,some work does not. I think those are two kinds of modeling. Modeling the dependence would give more accurate approximation. The exercise 10.20 in PRML says if you have many data, the pdf of q(\mu, \Lambda) will become a delta function, which recover the classic EM algorithm. But the pdf of current variational distribution will not, since the variance of \mu is fixed.  For refactoring, I would intend to build a BaseGaussianMixtureModel and with different estimators for different variables. For example, there are 8 covariance estimators. full, diag, spherical, tied, times variational or not. Then GaussianMixtureModel could be implemented by inheriting from base class and combined with one of 8 estimators for covariance variables. I don't know estimators should be taken as a mixin class. I would prefer to let GMM includes the estimators.
[2015-06-11T14:29:10.088Z] <541a528b163965c9bc2053de> I would rather keep the covariance choice as an hyper-parameter of the class instead of dedicating it a sub-class.
[2015-06-11T14:31:10.674Z] <541a528b163965c9bc2053de> side remark, I think for the full covariance type, it might be interesting to experiment with a shrinkage estimator such as ledoit-wolf, at least in the Maximum likelihood / EM formulation. If that can improve the cross-validated log-likelihood we might consider it for inclusion.
[2015-06-11T14:32:59.732Z] <550f53e215522ed4b3dda5f6> so the GMM would be like ```class GMM(FullCovMixin, BaseGMM)```,```class GMM(DiagCovMixin, BaseGMM)``` ?
[2015-06-11T14:33:30.398Z] <541a528b163965c9bc2053de> http://scikit-learn.org/stable/modules/generated/sklearn.covariance.ledoit_wolf.html
[2015-06-11T14:34:43.219Z] <541a528b163965c9bc2053de> @xuewei4d please feel free to open a [WIP] PR with that refactoring with mixin / base classes so that we can have a discussion on concrete code.
[2015-06-11T14:35:18.075Z] <541a528b163965c9bc2053de> Also private classes should start with a `_`.
[2015-06-11T14:35:39.232Z] <550f53e215522ed4b3dda5f6> OK. I will try to build some prototypes :)
[2015-06-11T14:36:01.916Z] <541a528b163965c9bc2053de> thanks
[2015-06-11T14:37:32.033Z] <550f53e215522ed4b3dda5f6> So what about the approximation? Do you like to consider the dependence?
[2015-06-11T14:43:47.865Z] <54d4a1d6db8155e6700f853b> @kastnerkyle the "rendered notebooks" are still the old ones. I haven't redone them. I agree we should do more out-of-core stuff before doing clusters.
[2015-06-11T14:44:12.462Z] <54d4a1d6db8155e6700f853b> @kastnerkyle I am currently somewhere around 3. and 4.
[2015-06-11T14:46:36.948Z] <550f53e215522ed4b3dda5f6> http://scikit-learn.org/stable/modules/generated/sklearn.covariance.ledoit_wolf.html The section 'notes' seems has a little problem. '+' sign is interpreted as a list mark.
[2015-06-11T14:50:15.931Z] <541a528b163965c9bc2053de> Indeed we need to escape this.
[2015-06-11T14:53:07.577Z] <541a528b163965c9bc2053de> > So what about the approximation? Do you like to consider the dependence?  It depends how the runtime, memory usage and the  complexity of the code base will evolve if we do so :) I am still clear about the details. Reading PRML at the moment. It would be great if we could have an example that demonstrates that the VBGMM asymptotically joins the solution of the MLE estimate on some toy dataset
[2015-06-11T14:56:36.298Z] <541a528b163965c9bc2053de> leveraging ledoit wolf shrinkage is not a priority as we already have the `min_covar` hack to regularize the covariance estimation. But I think we should keep it in mind and it would be great to explore the importance of covariance regularization, especially on high dim data
[2015-06-11T15:05:52.077Z] <550f53e215522ed4b3dda5f6> Great. I would continue to work on the PR #4802
[2015-06-11T15:11:27.361Z] <541a528b163965c9bc2053de> I think we should also improve the examples to discuss model selections for GMMs. I started to run some experiments here: https://github.com/ogrisel/notebooks/blob/master/gmm/Model%20Selection%20for%20GMM.ipynb
[2015-06-11T15:21:48.284Z] <541a528b163965c9bc2053de> I have to go offline now, see you later.
[2015-06-11T15:22:00.506Z] <550f53e215522ed4b3dda5f6> I tried some toy experiments with VBGMM before, but it did not work correctly. May I ask why would you like to do model selection for GMM? See you
[2015-06-11T15:25:50.726Z] <54e07d4015522ed4b3dc0856> @amueller I noticed the other ones were shorter and swapped. Only got to 2.x but I can try to do some PRs tonight.
[2015-06-11T15:28:06.679Z] <54d4a1d6db8155e6700f853b> @kastnerkyle cool :) I'm working on the intro to unsupervised currently
[2015-06-11T15:29:07.972Z] <54d4a1d6db8155e6700f853b> @xuewei4d could you have a look at #4845 ?
[2015-06-11T15:31:24.024Z] <550f53e215522ed4b3dda5f6> Gotcha.
[2015-06-11T15:48:20.897Z] <550f53e215522ed4b3dda5f6> Where is the discussion about #4511?
[2015-06-11T15:52:09.956Z] <550f53e215522ed4b3dda5f6> I mean on the ML. Thanks~
[2015-06-11T15:52:25.695Z] <54d4a1d6db8155e6700f853b> the conclusion was that we want to raise a value error
[2015-06-11T15:52:38.410Z] <54d4a1d6db8155e6700f853b> that is deprecate it for now and raise a value error in the future
[2015-06-11T15:54:14.093Z] <54d4a1d6db8155e6700f853b> @xuewei4d https://sourceforge.net/p/scikit-learn/mailman/scikit-learn-general/thread/20150501175859.GE1362450%40phare.normalesup.org/#msg34075913
[2015-06-11T15:59:55.607Z] <550f53e215522ed4b3dda5f6> OK.
[2015-06-11T20:43:19.466Z] <54d4a1d6db8155e6700f853b> @ogrisel what do you think about adding a ``shuffle`` option to cross_val_score and GridSearchCV (@jnothman or anyone else feel also free to chime in;) ? 
[2015-06-11T20:43:31.732Z] <54d4a1d6db8155e6700f853b> I feel it would be useful for cv=integer
[2015-06-12T04:06:41.860Z] <5537027215522ed4b3df56ab> Hey guys, does anyone else have issues with big memory usage because of Python dicts going crazy with high dimentional data for text vectorizers?
[2015-06-12T04:07:40.777Z] <5537027215522ed4b3df56ab> I was gonna implement it as a Trie, but it would be a big change and maybe change external API unless we do a dict abstraction
[2015-06-12T04:08:06.753Z] <5537027215522ed4b3df56ab> i went from 50gb used to 200mb
[2015-06-12T04:08:14.173Z] <5537027215522ed4b3df56ab> so no need to use hashingvect
[2015-06-12T04:12:26.507Z] <5537027215522ed4b3df56ab> another tangentially related question... since the cost of creating a vectorizer with millions of features is so large in terms of memory, there is a need for preemptive feature selection
[2015-06-12T04:13:04.718Z] <5537027215522ed4b3df56ab> i mean for me... things like forward selection, mcmc based, etc. I am not sure if it belongs in scikit-learn
[2015-06-12T04:13:54.764Z] <5537027215522ed4b3df56ab> this is to avoid generating the large matrix with unnecessary features when they will likely be discarded anyway
[2015-06-12T12:11:02.754Z] <54e07d4015522ed4b3dc0856> @lqdc I like the idea of the Trie - even if we just called it something else (in case where it can't match external API) it sounds insanely useful. As for pre-emptive feature selection it would be cool if this can be done in a general way, but all the tricks I know are domain specific. Any ideas in that direction seem nice, since it is a real-world issue
[2015-06-12T14:52:26.547Z] <54d4a1d6db8155e6700f853b> @lqdc there is some very simple feature selection based in min_df and max_df. But that needs to built the whole dictionary first.
[2015-06-12T14:53:01.893Z] <54d4a1d6db8155e6700f853b> how large is your dictionary? The idea of a Trie came up before. So you actually implemented it?
[2015-06-12T15:56:47.332Z] <54d4a1d6db8155e6700f853b> some discussion on ties here: https://github.com/scikit-learn/scikit-learn/issues/2639
[2015-06-12T16:59:09.697Z] <5537027215522ed4b3df56ab> yeah looks like it's not happening
[2015-06-12T17:00:40.909Z] <5537027215522ed4b3df56ab> and yes, the feature selection would be for avoiding building the whole dict which perhaps wouldn't be a problem in the first place if we used a trie for medium-sized datasets
[2015-06-12T17:06:41.336Z] <5537027215522ed4b3df56ab> I don't remember the size of the dictionary exactly but it was taking up 50ish gb
[2015-06-12T17:10:54.300Z] <54d4a1d6db8155e6700f853b> what do you mean by "looks like it's not happening"?
[2015-06-12T17:11:25.812Z] <54d4a1d6db8155e6700f853b> the question is a bit how complex the code is and the speed and memory compared to C++ dicts and python dicts
[2015-06-12T17:17:58.366Z] <54d4a1d6db8155e6700f853b> in the PR, the memory footprint was 1/3 of CountVectorizer. You reported 1/200 above, right?
[2015-06-12T17:20:22.659Z] <5537027215522ed4b3df56ab> yeah
[2015-06-12T17:20:47.428Z] <5537027215522ed4b3df56ab> his earlier tests
[2015-06-12T17:20:49.119Z] <5537027215522ed4b3df56ab>       CountVectorizer(): 94MB;     CountVectorizer(ngram_range=(1,2): 666MB;     MarisaCountVectorizer(): 1.2MB;     MarisaCountVectorizer(ngram_range=(1,2)): 13.3MB; 
[2015-06-12T17:22:05.518Z] <5537027215522ed4b3df56ab> also he was doing it in a way that doesn't help my casse. basically  he made the python dict fist and then populated a trie with the dict then replaced the dict with the trie
[2015-06-12T17:23:43.707Z] <5537027215522ed4b3df56ab> the use case he has is build the vocab on a beefy machine then when you actually want to use it, unpickle and use
[2015-06-12T17:32:00.979Z] <5537027215522ed4b3df56ab> I was also using MARISA trie
[2015-06-12T17:44:01.582Z] <5537027215522ed4b3df56ab> but building it from the streaming input. anyway, as @larsmans put it in that thread, there is understandable hesitation of merging a large c++ dependency that no one fully understands besides people who wrote the trie I assume.
[2015-06-12T18:32:34.145Z] <54d4a1d6db8155e6700f853b> well but allowing it as an optional replacement might work
[2015-06-12T19:39:50.933Z] <544879efdb8155e6700cdb21> Hello, I have a question about pull requesting policy. I have a PR and I made some changes, what I should to do with new changes:  add new commit to PR, amend initial commit? I used to use amended commits, it keeps history look nice, but PR discussions seems ambiguous because of `outdated diffs`. 
[2015-06-12T19:43:28.485Z] <54d4a1d6db8155e6700f853b> Either is fine
[2015-06-12T19:43:44.303Z] <54d4a1d6db8155e6700f853b> usually we ask to squash commits before merging, so if you always amend you don't have to do that
[2015-06-12T19:44:05.167Z] <54d4a1d6db8155e6700f853b> the PR discussions are not handled in a great way by github, no matter which method you use.
[2015-06-13T01:29:41.334Z] <544879efdb8155e6700cdb21> Hello, I'm not sure that gitter is proper place to ask this question, if so please point me the right place.  I have a problem with building the whole project, when I do `make` i get this tests result: `FAILED (SKIP=14, errors=2)`  ``` ERROR: sklearn.tests.test_cross_validation.test_cross_val_score_pandas ... IndexError: arrays used as indices must be of integer (or boolean) type ```  pandas.__version__ = 0.13.1 numpy.__version__ = 1.6.2  Thank you
[2015-06-13T12:53:58.305Z] <53135b495e986b0712efc453> Hey @mr0re1 ... do you have a particular PR number for which this test fails... or incase you haven't already, could you just raise one so we can all see the modified code that caused this test failure? :)
[2015-06-13T13:23:03.711Z] <53135b495e986b0712efc453> And btw this is indeed the place to ask such questions :)
[2015-06-13T15:44:26.754Z] <544879efdb8155e6700cdb21> Tests fail in master branch. There is no my changes. It seems like problem is in my environment. 
[2015-06-13T15:53:21.884Z] <551418d115522ed4b3dddd7b> @mr0re1 the problem might be in sklearn. Testing doesn't cover all possible combinations of platforms and third-party libraries. I suggest you create an issue and put all debug information about failed testcases
[2015-06-13T16:32:00.607Z] <54e07d6515522ed4b3dc0858> @mr0re1, that test behaves differently whether pandas is installed or not. I assume the error occurs on the Pandas-only code path. Pandas is known to break API often. This is a problem with the test, in my opinion, but your installation seems to be mostly functional. The test might pass if you update pandas. Still, could you raise an issue for this on github? It's something I think we should fix.  What is the other error, by the way? You said you get 2 errors but only showed us one.
[2015-06-13T16:32:56.977Z] <54e07d6515522ed4b3dc0858> @rvraghav93, since this is a cross-validation indexing issue, could you look into it? If you use anaconda you can easily set up a virtual environment with a specific version of pandas.
[2015-06-13T16:33:15.022Z] <53135b495e986b0712efc453> Sure I'll look into it :)
[2015-06-13T16:33:41.418Z] <54e07d6515522ed4b3dc0858> also, @rvraghav93, when you said PR number above, did you mean opening a Github issue?
[2015-06-13T16:34:18.613Z] <544879efdb8155e6700cdb21> @vene, will open an issue, the second error is the same. 
[2015-06-13T16:35:02.577Z] <53135b495e986b0712efc453> Since @mr0re1 was asking about raising a PR a few chats above, I assumed he had been working on something which had failed the tests ;) So I suggested that he raise a PR... not that the failure is in master... that is moot :P
[2015-06-13T16:35:20.305Z] <53135b495e986b0712efc453> *now
[2015-06-13T16:35:34.059Z] <54e07d6515522ed4b3dc0858> Ah I see
[2015-06-13T16:35:39.564Z] <53135b495e986b0712efc453> :D
[2015-06-13T16:36:25.645Z] <54e07d6515522ed4b3dc0858> @mr0re1 what test do you get the error for, I mean?
[2015-06-14T13:44:14.143Z] <53135b495e986b0712efc453> This [link](http://eprints.pascal-network.org/archive/00006964/01/vedaldi10.pdf) which is a reference to additive chi2 sampler seems to be down!
[2015-06-14T13:45:14.787Z] <53135b495e986b0712efc453> There was an issue regarding broken links right?
[2015-06-14T13:46:31.238Z] <53135b495e986b0712efc453> #4344
[2015-06-14T13:47:17.967Z] <53135b495e986b0712efc453> This [comment](https://github.com/scikit-learn/scikit-learn/issues/4344#issuecomment-77744354) in particular!
[2015-06-14T20:40:48.561Z] <53135b495e986b0712efc453> chatting from the gitter irc bridge!
[2015-06-14T20:44:42.922Z] <54d4a1d6db8155e6700f853b> :)
[2015-06-14T20:49:00.932Z] <53135b495e986b0712efc453> Its cool!! I am planning to resume work on the irc-gitter bridging thing that we discussed long back (when gael wasn't happy with us using gitter over irc) when I find time!
[2015-06-14T20:49:07.727Z] <53135b495e986b0712efc453> i.e apart from my regular work ;)
[2015-06-14T20:51:02.795Z] <54e07d6515522ed4b3dc0858> I actually really like gitter's interface, what were Gael's concerns?
[2015-06-14T21:05:44.127Z] <53135b495e986b0712efc453> That the discussions were getting diluted at multiple platforms... (gitter, irc, ml, github etc...)
[2015-06-14T21:06:06.745Z] <54e07d6515522ed4b3dc0858> good point, but wasn't IRC kind of dead?
[2015-06-14T21:06:34.797Z] <53135b495e986b0712efc453> https://github.com/scikit-learn/scikit-learn/pull/4248#issuecomment-74413361
[2015-06-14T21:06:53.760Z] <53135b495e986b0712efc453> yes!! but its active during sprints I think..
[2015-06-14T21:08:00.514Z] <54e07d6515522ed4b3dc0858> i like the auto-links to issues,  and the activity pane in gitter
[2015-06-14T21:09:48.814Z] <53135b495e986b0712efc453> And history, code formatting, markdown too! ;) 
[2015-06-14T21:12:13.231Z] <53135b495e986b0712efc453> Speaking of activity pane :p @vene could you take a look at #4860 its a very minor PR! :)
[2015-06-14T21:28:37.999Z] <54e07d6515522ed4b3dc0858> I left a comment there
[2015-06-15T00:12:31.245Z] <54e07d6515522ed4b3dc0858> @rvraghav93 what do you plan to write about in this week's blog post?
[2015-06-15T00:14:21.495Z] <53135b495e986b0712efc453> Nested CV!! Is that okay? Hey BTW do u happen to have a link of the mailing list thread that u had mentioned previously? I am unable to find it :/
[2015-06-15T00:15:53.143Z] <53135b495e986b0712efc453> And I'll resume work on cross validation as soon as I am done with fit reset / partial fit tests... :)
[2015-06-15T00:28:08.980Z] <54e07d6515522ed4b3dc0858> @rvraghav93 the discussion was here. I think this thread has some very valuable insight about evaluation in machine learning. http://sourceforge.net/p/scikit-learn/mailman/message/34102242/
[2015-06-15T00:29:16.332Z] <53135b495e986b0712efc453> Thanks!!
[2015-06-15T00:31:32.988Z] <54e07d6515522ed4b3dc0858> I would acknowledge @eickenberg and @satra and maybe even link to the thread too.
[2015-06-15T00:32:30.647Z] <54e07d6515522ed4b3dc0858> The "extreme" example (where the dataset has two consistent but different biases) would make for a nice running example
[2015-06-15T00:33:10.773Z] <53135b495e986b0712efc453> Okay and yes sure!!
[2015-06-15T00:38:30.764Z] <53135b495e986b0712efc453> And I am 2 blog posts behind -_- nested CV was supposed to be last Sunday's ! For this sunday can I post about online learning / `partial_fit` support in sklearn and the usefulness of the proposed tests (in ensuring `partial_fit` behaves as expected)?
[2015-06-15T00:41:59.825Z] <54e07d6515522ed4b3dc0858> That sounds good, I think you can do a smaller post about this mid-next week. This is more internal stuff, it's hard to write too much interesting stuff about it.
[2015-06-15T00:43:14.823Z] <53135b495e986b0712efc453> Okay!! 
[2015-06-15T00:44:29.537Z] <54e07d6515522ed4b3dc0858> Maybe talk about how useful it is to have common tests that enforce API conventions to future code as well
[2015-06-15T00:45:58.358Z] <53135b495e986b0712efc453> Sure! :)
[2015-06-15T00:47:25.687Z] <54e07d6515522ed4b3dc0858> @amueller what do you think?
[2015-06-15T00:52:26.978Z] <54e07d6515522ed4b3dc0858> also @rvraghav93 could you put down a brief plan for what you think we can get done in the next 2-3 weeks?
[2015-06-15T00:52:37.701Z] <54e07d6515522ed4b3dc0858> A bit of structure might be useful, and I think this is better than just going back to the original timeline, since things are always in flow :)
[2015-06-15T14:17:59.590Z] <53135b495e986b0712efc453> Sure I'll do that! :) 
[2015-06-15T18:06:44.816Z] <550f53e215522ed4b3dda5f6> Any comment on #4802? I mean in terms of class definition. Most of methods are not implemented yet, but I hope I am on the right track.
[2015-06-15T18:42:55.239Z] <54d4a1d6db8155e6700f853b> btw irc is totally unused during sprints
[2015-06-15T18:42:56.692Z] <54d4a1d6db8155e6700f853b> ^^
[2015-06-15T18:43:18.747Z] <54d4a1d6db8155e6700f853b> btw @rvraghav93 what is the status of the data-dependent cv?
[2015-06-15T18:43:23.175Z] <54d4a1d6db8155e6700f853b> sorry I was out for the weekend
[2015-06-15T18:43:36.061Z] <54d4a1d6db8155e6700f853b> it would be great if you could catch up on the blog posts. The IRC bridge is really not that important
[2015-06-15T18:43:57.795Z] <54d4a1d6db8155e6700f853b> and I saw there was a lot of discussion on the assert helpers. are they needed for any of the gsoc PRs?
[2015-06-15T19:09:15.768Z] <53135b495e986b0712efc453> I just wanted to finish it off as it was lying around for a long time :/ I'll resume work on it by tomorrow :) Planning to finish off my blog post, the helpers and tests by today :)
[2015-06-16T06:24:24.641Z] <54f0341115522ed4b3dc8e00> hi there
[2015-06-16T06:26:03.530Z] <54f0341115522ed4b3dc8e00> im using gridsearch to train a visual object detection pipeline with a few skimage transformers, pca and svm... since i acquired my larger dataset, gridsearch explodes in a very strange way <unconvertable> deep in python: http://nopaste.ghostdub.de/?1132 <unconvertable> and i cant quite make any sense of that :( ... would anyone happen to have an idea in which direction i could search?
[2015-06-16T13:49:40.039Z] <54d4a1d6db8155e6700f853b> @Nebukadneza try with n_jobs=1 that should make it easier to debug
[2015-06-16T14:26:00.126Z] <54f0341115522ed4b3dc8e00> with single threading it doesnt happen at all :(
[2015-06-16T14:54:04.362Z] <54d4a1d6db8155e6700f853b> does all of it run through? it is maybe one specific parameter setting that does that 
[2015-06-16T15:05:49.318Z] <54f0341115522ed4b3dc8e00> yes, it looks like all of it runs
[2015-06-16T15:09:45.558Z] <54f0341115522ed4b3dc8e00> trying to dig into the delayed and multiprocessing pool with ipdb now Oo but i just dont see where this format-string-fu even comes from or what its used for Oo
[2015-06-16T20:18:13.577Z] <53135b495e986b0712efc453> @vene Thanks for that ML link! It was really useful!! 
[2015-06-16T21:35:36.328Z] <54d4a1d6db8155e6700f853b> TIL: don't try to make a learning curve example with a non-parametric model
[2015-06-16T21:37:39.277Z] <53135b495e986b0712efc453> Why do you say so? :)
[2015-06-16T21:37:55.803Z] <54d4a1d6db8155e6700f853b> because the training error doesn't go up with the number of samples
[2015-06-16T21:39:58.458Z] <53135b495e986b0712efc453> Oh! TIL ^ :P
[2015-06-16T23:08:19.716Z] <53135b495e986b0712efc453> Hey Andy,  Earlier you had given me the feedback for my 1st blogpost! Sorry for the delay in response...  > why do you use alpha when plotting points?  That makes it look a little faded and better... I think this was a suggestion by someone when I was working on silhoute plot example ;) Do you feel I should remove that?  > I feel this sentence is unclear: "Even when the model is optimized with the constrain of maximizing the score based upon the test set, there is still a chance of overfitting as the information about the test set can leak into the model and hence the model could be optimized for the test set alone." it would be more explicit to say the information leaks via the selection of hyperparameters.  Have updated so! Thanks!  > cross-validation does not entirely overcome this. Overfitting to cross-validation is harder than overfitting to a single test set, but it is still possible, which is why people do nested cross-validation.  Like Vlad said a few chats below yours, that was what I was getting at... I have reworded it to make it clear!  > grid.bestestimator.score(X_test, y_test) is also not great btw. You can just use grid.score  fixed :)  > talking about gamma=0 for the SVM is also a bit weird. This is an odd way that we used to select the default, which is 1. / n_features , I think.  I've fixed it to 0.5... which is (1 / n_features)  I am now working on the 2nd blog post (Nested CV) :)
[2015-06-16T23:29:47.120Z] <53135b495e986b0712efc453> @amueller @vene I've also started a ML thread for my GSoC project to interact more! :)
[2015-06-16T23:33:19.458Z] <53135b495e986b0712efc453> http://sourceforge.net/p/scikit-learn/mailman/message/34213648/
[2015-06-17T14:02:45.572Z] <54d4a1d6db8155e6700f853b> @ogrisel do you have a second?
[2015-06-17T14:18:11.785Z] <5581814615522ed4b3e20c6a> How scikit can help beginners?
[2015-06-17T14:18:43.558Z] <53135b495e986b0712efc453> @BastinRobin http://scikit-learn.org/stable/tutorial/
[2015-06-17T14:27:56.754Z] <541a528b163965c9bc2053de> @amueller yes, sorry I was on the phone
[2015-06-17T14:29:25.266Z] <541a528b163965c9bc2053de> > TIL: don't try to make a learning curve example with a non-parametric model > because the training error doesn't go up with the number of samples  this is actually an interesting example if you constrast it with the learning curve of a parametric model
[2015-06-17T14:36:48.668Z] <54d4a1d6db8155e6700f853b> yeah, but maybe to advanced for an introductory course.
[2015-06-17T14:37:21.045Z] <54d4a1d6db8155e6700f853b> never mind, I was confused by the timing of https://github.com/scikit-learn/scikit-learn/pull/4844, but I think the code is just overly complicated
[2015-06-17T17:16:46.717Z] <53135b495e986b0712efc453> Anybody around? :) I have a few (probably lame) questions regarding nested CV!
[2015-06-17T17:46:59.543Z] <54e07d6515522ed4b3dc0858> hi @rvraghav93 
[2015-06-17T17:49:14.833Z] <54d4a1d6db8155e6700f853b> yeah I'm around
[2015-06-17T17:49:30.616Z] <54d4a1d6db8155e6700f853b> I have a meeting in 10 minutes but I'll answer stuff here
[2015-06-17T17:53:06.109Z] <53135b495e986b0712efc453> Why is nested CV not generically possible with our current API... I understand what needs to be done to make the iterators data indep. but I don't get why nested cv is difficult as Mathieu had commented in that issue description... `cross_val_score(GridSearchCV(est, ....))` would be enough right?
[2015-06-17T17:55:07.416Z] <54e07d6515522ed4b3dc0858> this works currently if you use e.g. `cv=3` in the inner one
[2015-06-17T17:55:21.186Z] <54d4a1d6db8155e6700f853b> if anyone has time, the timing on #4844 really confuses me btw.
[2015-06-17T17:55:40.447Z] <54d4a1d6db8155e6700f853b> Slicing an euclidean distance into smaller bits makes the code run faster?!
[2015-06-17T17:55:47.176Z] <54e07d6515522ed4b3dc0858> but if you need to pass a CV object that takes y, what do you set y to?
[2015-06-17T17:56:34.796Z] <54d4a1d6db8155e6700f853b> or even n_samples. If the size of your dataset is not divisible by the cv in the outer loop, the training sets in the inner loop will have different lengths
[2015-06-17T17:57:06.630Z] <54e07d6515522ed4b3dc0858> exactly
[2015-06-17T17:57:34.161Z] <54e07d6515522ed4b3dc0858> or LeaveOneLabelOut
[2015-06-17T17:57:52.908Z] <54e07d6515522ed4b3dc0858> (such a nesting bug with LOLO bit me really hard a few months ago)
[2015-06-17T17:58:37.792Z] <54e07d6515522ed4b3dc0858> (:baby: :baby_bottle:) 
[2015-06-17T17:58:54.015Z] <54e07d6515522ed4b3dc0858> I can't even get my emoji right, I'm useless
[2015-06-17T17:59:48.823Z] <53135b495e986b0712efc453> This is a general apology for all lame questions that may follow :P please bear with me!
[2015-06-17T17:59:50.802Z] <53135b495e986b0712efc453> Ok so the inner loop does hyper param optimization using a separate cross validation and finds the best model which the outer loop uses to find the cross validated score... why should these two affect each other? ( Like apologized earlier, please bear with me :( )
[2015-06-17T18:00:21.437Z] <54e07d6515522ed4b3dc0858> don't even think that you have a GridSearch on the inside
[2015-06-17T18:00:30.794Z] <54e07d6515522ed4b3dc0858> consider the simpler case with just a cross_val_score inside a cross_val_score
[2015-06-17T18:01:01.004Z] <53135b495e986b0712efc453> [offtopic - I think gitter supports only a subset of the emojis ;) ]
[2015-06-17T18:01:23.402Z] <54e07d6515522ed4b3dc0858> [the bracket messed it up I think: :baby: :baby_bottle: ]
[2015-06-17T18:01:32.385Z] <53135b495e986b0712efc453> ah :P
[2015-06-17T18:01:42.320Z] <550f53e215522ed4b3dda5f6> If I need to discuss  the current code, should I open a new issue or add comments on my working PR which is addressing the issues?
[2015-06-17T18:02:00.639Z] <54e07d6515522ed4b3dc0858> hi @xuewei4d 
[2015-06-17T18:02:05.318Z] <54e07d6515522ed4b3dc0858> what do you mean by current code?
[2015-06-17T18:02:17.098Z] <53135b495e986b0712efc453> and if its not too much trouble could you give me a line or two of code that will help me clearly understand this?
[2015-06-17T18:02:22.183Z] <550f53e215522ed4b3dda5f6> I mean the code of master branch
[2015-06-17T18:02:29.859Z] <54e07d6515522ed4b3dc0858> if it's in the context of GMMs I think commenting in your PR would work well
[2015-06-17T18:02:47.334Z] <550f53e215522ed4b3dda5f6> ok.
[2015-06-17T18:02:51.092Z] <54e07d6515522ed4b3dc0858> since most people who could answer are already following the PR
[2015-06-17T18:03:18.508Z] <54e07d6515522ed4b3dc0858> also you could use `git blame` and ping the author(s) of the piece of code
[2015-06-17T18:04:18.752Z] <54e07d6515522ed4b3dc0858> BTW I still am in favor of `GaussianMixture` vs `GaussianMixtureModel`
[2015-06-17T18:05:03.879Z] <54e07d6515522ed4b3dc0858> @rvraghav93 let's think about it
[2015-06-17T18:05:24.761Z] <54e07d6515522ed4b3dc0858> say we have a dataset (X, y) with 100 samples and want to use `KFold`
[2015-06-17T18:05:34.448Z] <54e07d6515522ed4b3dc0858> we need to fill in the blanks in the following
[2015-06-17T18:06:00.281Z] <54e07d6515522ed4b3dc0858> 
[2015-06-17T18:06:02.008Z] <54e07d6515522ed4b3dc0858> 
[2015-06-17T18:06:34.135Z] <53135b495e986b0712efc453> you can edit gitter chat messages :)
[2015-06-17T18:07:10.916Z] <54e07d6515522ed4b3dc0858> ``` clf = GridSearchCV(grid, cv=KFold(n_samples=?, n_folds=3)) cross_val_score(clf, X, y, cv=KFold(n_samples=?, n_folds=3)) ```
[2015-06-17T18:08:47.727Z] <54e07d6515522ed4b3dc0858> (ignore the fact that the parameter is currently called `n` and not `n_samples`)
[2015-06-17T18:09:42.789Z] <54e07d6515522ed4b3dc0858> how would you fill the question marks?
[2015-06-17T18:09:50.585Z] <54e07d6515522ed4b3dc0858> the one on the 2nd line is easy
[2015-06-17T18:10:07.901Z] <53135b495e986b0712efc453> won't both be 100?
[2015-06-17T18:10:09.976Z] <53135b495e986b0712efc453> :P
[2015-06-17T18:10:25.635Z] <53135b495e986b0712efc453> ahhhh I get it !
[2015-06-17T18:10:36.155Z] <54e07d6515522ed4b3dc0858> no, because the inner `clf` (the GridSearchCV) only gets a fold each time
[2015-06-17T18:10:56.693Z] <53135b495e986b0712efc453> yes.. sory.. this is too lame :| 
[2015-06-17T18:10:59.505Z] <54e07d6515522ed4b3dc0858> if `len(X)` were `99`, you could set the first `?` to `66` I think
[2015-06-17T18:11:01.183Z] <53135b495e986b0712efc453> 
[2015-06-17T18:11:09.421Z] <53135b495e986b0712efc453> thanks a lot :)
[2015-06-17T18:11:43.278Z] <54e07d6515522ed4b3dc0858> but 1) this would be hacky 2) users shouldn't need to do this kind of error-prone math 3) this doesn't work at all for many cross-val strategies
[2015-06-17T18:12:36.547Z] <53135b495e986b0712efc453> This is clear now!! Will finish up my blog and resume the work :) Thanks!! 
[2015-06-17T18:12:42.756Z] <54e07d6515522ed4b3dc0858> oh God why does gitter display inline gifs?
[2015-06-17T18:12:50.503Z] <54e07d6515522ed4b3dc0858> I'm starting to understand Gael's hate for it :D
[2015-06-17T18:12:52.544Z] <53135b495e986b0712efc453> Is it bad? :P I'll remove :P
[2015-06-17T18:13:06.838Z] <53135b495e986b0712efc453> haha!
[2015-06-17T18:13:18.838Z] <54e07d6515522ed4b3dc0858> also the fact that you can delete and edit messages is a bit worrysome
[2015-06-17T18:13:55.793Z] <53135b495e986b0712efc453> but u can do so only for 10 minutes... 
[2015-06-17T18:14:16.294Z] <54e07d6515522ed4b3dc0858> anyway, glad I could help, if you want me to take a look at the blogpost I'll be around today
[2015-06-17T18:15:03.765Z] <53135b495e986b0712efc453> sure!! I'll publish in an hour or two! and also post it to our ML...
[2015-06-17T18:15:36.181Z] <53135b495e986b0712efc453> btw if you have time could you check if the current implementation of the assert helpers look okay?
[2015-06-17T18:16:36.087Z] <54e07d6515522ed4b3dc0858> I will try to do this later today
[2015-06-17T18:17:01.987Z] <53135b495e986b0712efc453> Thanks! whats your timezone btw?
[2015-06-17T18:17:12.717Z] <54e07d6515522ed4b3dc0858> EST (I think)
[2015-06-17T18:17:17.439Z] <54e07d6515522ed4b3dc0858> it's 2pm
[2015-06-17T18:17:22.288Z] <53135b495e986b0712efc453> okay :)
[2015-06-17T18:17:23.225Z] <54e07d6515522ed4b3dc0858> 2:17
[2015-06-17T18:28:43.731Z] <54e07d6515522ed4b3dc0858> @amueller for #4844 do you get the same timing on your computer?
[2015-06-17T18:45:53.087Z] <54d4a1d6db8155e6700f853b> @rvraghav93 btw, midterm is rather soon...
[2015-06-17T18:47:00.895Z] <54d4a1d6db8155e6700f853b> @vene yeah. The student just showed me that doing array ** 2 is super-linear in the array size
[2015-06-17T18:47:18.806Z] <54e07d6515522ed4b3dc0858> how about array *= array?
[2015-06-17T18:47:27.029Z] <54d4a1d6db8155e6700f853b> so if you want to square an array it is faster to do so by chunking it... that seems wrong
[2015-06-17T18:48:02.309Z] <54e07d6515522ed4b3dc0858> even with chunks of size 2?
[2015-06-17T18:48:08.992Z] <54e07d6515522ed4b3dc0858> how about size 1? That would just be a loop over the items
[2015-06-17T18:50:13.224Z] <54d4a1d6db8155e6700f853b> for the code in #4844 chunks of size 1 are fastest
[2015-06-17T18:50:24.477Z] <54d4a1d6db8155e6700f853b> %timeit array *= array doesn't work lol
[2015-06-17T18:50:48.087Z] <54d4a1d6db8155e6700f853b> having the loop over samples be the fastest just seems so wrong
[2015-06-17T18:51:38.492Z] <54e07d6515522ed4b3dc0858> I was thinking in #4844 there might be some indexing thing, but if you narrowed it down to np.pow, that's very wrong
[2015-06-17T18:53:15.804Z] <54e07d6515522ed4b3dc0858> how about np.square?
[2015-06-17T18:54:36.957Z] <54e07d6515522ed4b3dc0858> This works though (but adds the overhead of a copy)
[2015-06-17T18:54:47.979Z] <54e07d6515522ed4b3dc0858> ``` In [11]: %timeit Xco = X.copy(); Xco *= Xco The slowest run took 4.31 times longer than the fastest. This could mean that an intermediate result is being cached 1000 loops, best of 3: 969 <unconvertable> s per loop  In [12]: %timeit Xco = X.copy(); Xco ** 2 1000 loops, best of 3: 1.25 ms per loop  In [13]: %timeit Xco = X.copy() The slowest run took 4.42 times longer than the fastest. This could mean that an intermediate result is being cached 1000 loops, best of 3: 525 <unconvertable> s per loop ```
[2015-06-17T18:57:32.336Z] <54e07d6515522ed4b3dc0858> `[elem * elem for row in Xco for elem in row]` is much slower
[2015-06-17T19:08:34.829Z] <53135b495e986b0712efc453> @amueller you mean Gsoc midterm? it usually comes in July only right?
[2015-06-17T19:09:37.648Z] <54e07d6515522ed4b3dc0858> @rvraghav93 it's June 26
[2015-06-17T19:09:56.714Z] <54e07d6515522ed4b3dc0858> it opens June 26 until July 3rd I mean
[2015-06-17T19:12:57.432Z] <53135b495e986b0712efc453> Ah its from 26 - 3 july... How much would you like to see me completed with my goals before the midterm? I am thinking  1. model_selection refactoring 2. Data independent CV Iterators. 3. Multiple Metric support - I won't be able to complete this though :/  Does it look okay?
[2015-06-17T19:15:17.601Z] <54e07d6515522ed4b3dc0858> I think 1&2 completed (in such a way in which there's a MRG branch where all tests pass and one can do nested CV nicely) would be good. But by MRG I mean MRG :)
[2015-06-17T19:15:24.317Z] <54e07d6515522ed4b3dc0858> @amueller, what do you think?
[2015-06-17T20:12:27.389Z] <54d4a1d6db8155e6700f853b> yeah 1 & 2 merged would be great
[2015-06-17T20:17:31.385Z] <54d4a1d6db8155e6700f853b> I also thought there was something wrong with the slicing but I'm very confused now :-/
[2015-06-17T20:18:12.858Z] <54d4a1d6db8155e6700f853b> and the problem is both in the squaring and in the outer product computation
[2015-06-17T20:18:25.933Z] <54d4a1d6db8155e6700f853b> I feel stupid for not seeing what is happening
[2015-06-18T00:33:44.764Z] <53135b495e986b0712efc453> @vene @amueller My second blog post - http://rvraghav93.blogspot.com/2015/06/gsoc-2015-psf-scikit-learn-nested-cross.html
[2015-06-18T00:36:09.349Z] <53135b495e986b0712efc453> Please take a look and let me know your views!
[2015-06-18T00:37:22.243Z] <53135b495e986b0712efc453> I'll also mail it to the ML as soon as I get a +1 from either of you! :)
[2015-06-18T03:15:16.368Z] <54d4a1d6db8155e6700f853b> Thanks. I'll have a look tomorrow first thing in  the morning
[2015-06-18T14:57:50.917Z] <54d4a1d6db8155e6700f853b> @tw991 I'm still not sure about #4844, I hope I have time to look at it soon. In the meantime, once #4874 is done, you could either look to finish https://github.com/scikit-learn/scikit-learn/pull/4539 which is boring but straight-forward, or investigate how to make sure the two k-means algorithms always give the same results in #2008, which is more interesting but also more involved
[2015-06-18T15:10:56.776Z] <54e07d6515522ed4b3dc0858> @rvraghav93 I think the book in your blog post is just by Petersohn, and John Vogt Verlag is the publisher (Verlag means something like publisher in German I think)
[2015-06-18T15:11:31.411Z] <53135b495e986b0712efc453> Oh :laughing:  thanks!!
[2015-06-18T15:12:29.463Z] <54e07d6515522ed4b3dc0858> But it's a pretty simple idea and a pretty obscure book
[2015-06-18T15:12:55.828Z] <54e07d6515522ed4b3dc0858> I think you can explain it better semi-formally without including that
[2015-06-18T15:13:09.007Z] <54d4a1d6db8155e6700f853b> yeah
[2015-06-18T15:13:17.602Z] <54d4a1d6db8155e6700f853b> if anything I'd try to reference esl
[2015-06-18T15:13:30.033Z] <54d4a1d6db8155e6700f853b> (which is what I always reference for everything)
[2015-06-18T15:13:47.354Z] <54e07d6515522ed4b3dc0858> for cross-val stuff I started referencing Gilles' thesis :)
[2015-06-18T15:14:43.251Z] <54d4a1d6db8155e6700f853b> I stil have not really read that :-/
[2015-06-18T15:16:01.383Z] <54e07d6515522ed4b3dc0858> Me neither, not fully, just the first two parts, but what I've read is great, very readable. Better than most ML textbooks.
[2015-06-18T15:16:44.032Z] <54d4a1d6db8155e6700f853b> sweet
[2015-06-18T15:16:46.012Z] <54e07d6515522ed4b3dc0858> so, @rvraghav93, could you simplify a bit the 3-step description of nested CV that you currently have? I find it a bit verbose, and it kind of makes everything seem more complicated than it is
[2015-06-18T15:17:20.042Z] <53135b495e986b0712efc453> Okay! I'll remove that reference and make that description simpler :)
[2015-06-18T15:17:33.278Z] <53135b495e986b0712efc453> Does the example seem okay?
[2015-06-18T15:17:35.022Z] <54e07d6515522ed4b3dc0858> there are things that you can save for later in the blog post
[2015-06-18T15:17:48.992Z] <54e07d6515522ed4b3dc0858> such as "based on the selected scoring technique. (At present only one loss function..."
[2015-06-18T15:18:18.546Z] <5582dd0915522ed4b3e21b33> Hi, can anyone point me in the direction of a explanation of how to do model ensembling?
[2015-06-18T15:18:20.678Z] <54e07d6515522ed4b3dc0858> you can leave this for a kicker later
[2015-06-18T15:20:02.640Z] <53135b495e986b0712efc453> Okay! thanks for the feedback :) @Callipygian0 http://scikit-learn.org/stable/modules/ensemble.html
[2015-06-18T15:20:23.241Z] <54e07d6515522ed4b3dc0858> Sure! I'm still reading through the blog post so give me a few more minutes please
[2015-06-18T15:20:35.135Z] <53135b495e986b0712efc453> Please take your time!!
[2015-06-18T15:20:54.298Z] <5582dd0915522ed4b3e21b33> Thanks :)
[2015-06-18T15:22:46.809Z] <54e07d6515522ed4b3dc0858> @Callipygian0 If you mean ensembling heterogeneous models, you might want the [VotingClassifier](http://scikit-learn.org/dev/modules/ensemble.html#votingclassifier) in the current development version, not available in the last stable release.
[2015-06-18T15:24:51.156Z] <54e07d6515522ed4b3dc0858> so, @rvraghav93 I'd actually not manually calculate `n_samples` that way
[2015-06-18T15:26:01.162Z] <54e07d6515522ed4b3dc0858> If you want to show an example that's currently possible, I would use `cv=3` instead
[2015-06-18T15:26:25.495Z] <54e07d6515522ed4b3dc0858> this currently does stratified kfold if given a classification dataset 
[2015-06-18T15:26:29.030Z] <54e07d6515522ed4b3dc0858> (I think)
[2015-06-18T15:26:58.135Z] <54e07d6515522ed4b3dc0858> and then you can say something like...
[2015-06-18T15:28:12.862Z] <54e07d6515522ed4b3dc0858> if you needed more customization, or a different CV such as LeaveOneLabelOut, it wouldn't work anymore
[2015-06-18T15:28:48.699Z] <54e07d6515522ed4b3dc0858> oh I just noticed you do nested CV with a for loop
[2015-06-18T15:28:59.212Z] <5582dd0915522ed4b3e21b33> I'm using version 0.15.2
[2015-06-18T15:29:03.759Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I wouldn't say cleaner way in the first sentence. Many things are straight up not possible. I would say to enable cross-validation with cross-validation objects. Or make it more flexible....
[2015-06-18T15:29:42.753Z] <54d4a1d6db8155e6700f853b> @Callipygian0 do you want to ensemble heterogeneous models? Then there is nothing to help you. Though implementing a voting classifier is pretty trivial.
[2015-06-18T15:31:05.143Z] <54d4a1d6db8155e6700f853b> @rvraghav93 : " In each iteration (split), the dataset (X, y) is partitioned into training, validation set.` " should be "into a training and a validation set" also there is a backtick
[2015-06-18T15:31:20.753Z] <54d4a1d6db8155e6700f853b> the no should be number.
[2015-06-18T15:31:37.587Z] <54e07d6515522ed4b3dc0858> also this thing "This becomes necessary especially when the dataset is too small to split it into three"
[2015-06-18T15:31:55.395Z] <54e07d6515522ed4b3dc0858> it kind of depends on your audience, but technically, it's never too small (unless you have two samples)
[2015-06-18T15:32:05.322Z] <5582dd0915522ed4b3e21b33> I had all my models vote but it didnt really seem to work very well. This is my first machine learning experience so i'm very new! There is a kaggle style competition at my work. I was doing very well with GBM but everyone is overtaking me with ensemble now!
[2015-06-18T15:32:08.332Z] <54d4a1d6db8155e6700f853b> @vene would you not agree? Well you could argue it is always more robust.
[2015-06-18T15:32:21.476Z] <54d4a1d6db8155e6700f853b> GBM is an ensemble ;)
[2015-06-18T15:32:23.960Z] <54e07d6515522ed4b3dc0858> I fully agree, I just want to phrase it more clearly
[2015-06-18T15:32:45.735Z] <54d4a1d6db8155e6700f853b> I feel the split in bullet points is not very clear
[2015-06-18T15:33:15.932Z] <54e07d6515522ed4b3dc0858> technically if the data is truly IID, it wouldn't matter, would it?
[2015-06-18T15:33:47.241Z] <5582dd0915522ed4b3e21b33> I was told the best thing to do is combine like 5 different random forests, 5 different gbms 5 extra trees etc
[2015-06-18T15:34:06.363Z] <54d4a1d6db8155e6700f853b> well that could work...
[2015-06-18T15:34:19.004Z] <54d4a1d6db8155e6700f853b> @vene not sure what you mean
[2015-06-18T15:34:47.330Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I'm not sure it is necessary do mention RandomizedSearchCV, it is pretty unrelated to the issue, right?
[2015-06-18T15:36:33.889Z] <54e07d6515522ed4b3dc0858> So, say I have a bunch of data that I want to model. I'll leave out, say, 25% as a test set, do GridSearchCV on the train set, and report the score on the test set. This is probably the most straightforward way, right?
[2015-06-18T15:36:48.304Z] <54e07d6515522ed4b3dc0858> But what if I got lucky with my choice of test set?
[2015-06-18T15:37:25.996Z] <54d4a1d6db8155e6700f853b> well yeah
[2015-06-18T15:37:36.789Z] <54d4a1d6db8155e6700f853b> the variance will just be very high with a small dataset, right?
[2015-06-18T15:38:04.019Z] <54e07d6515522ed4b3dc0858> usually yes
[2015-06-18T15:38:05.863Z] <54d4a1d6db8155e6700f853b> @rvraghav93 The example with the code is pretty clear, why I feel the initial explanation is not.
[2015-06-18T15:38:38.028Z] <54e07d6515522ed4b3dc0858> well if your model is perfect and if your data is IID you can have small variance, right?
[2015-06-18T15:39:06.574Z] <54d4a1d6db8155e6700f853b> @rvraghav93 However, I wouldn't say you need to estimate n_samples. It is not something you are guessing or using statistical methods on. You just need to know it. but you can't with the current setup
[2015-06-18T15:40:00.891Z] <54e07d6515522ed4b3dc0858> "The final result of the nested CV is the collection of n best Models"
[2015-06-18T15:40:03.131Z] <54d4a1d6db8155e6700f853b> @vene I don't think it is. If you have three data points sampled from a Gaussian, you use two for training and one for test, and your model is fitting a gaussian to it, the variance of the log-likelyhood will be high
[2015-06-18T15:40:11.728Z] <54d4a1d6db8155e6700f853b> *likelihood
[2015-06-18T15:40:41.457Z] <54d4a1d6db8155e6700f853b> even though the data is perfectly iid and you are using the true model
[2015-06-18T15:41:10.421Z] <54e07d6515522ed4b3dc0858> unless the 3rd point is exactly in the middle of the two test points
[2015-06-18T15:41:11.053Z] <54e07d6515522ed4b3dc0858> hmm
[2015-06-18T15:41:26.500Z] <54e07d6515522ed4b3dc0858> you're right
[2015-06-18T15:41:36.260Z] <54d4a1d6db8155e6700f853b> well if you have three points in a line and do 3-fold cross valiation ....
[2015-06-18T15:42:13.928Z] <54d4a1d6db8155e6700f853b> variance of the estimate scales with the number of samples and cross-validation gives an unbiased estimate of the variance iirc
[2015-06-18T15:42:26.854Z] <54e07d6515522ed4b3dc0858> anyway I was only trying to say that it might not be clear what "too few samples to leave a test set out" means
[2015-06-18T15:45:50.924Z] <54e07d6515522ed4b3dc0858> it is indeed a question of variance
[2015-06-18T15:46:34.735Z] <54e07d6515522ed4b3dc0858> and because of the variance, you can get particularly lucky or unlucky if you do one single outer fold
[2015-06-18T15:46:45.910Z] <54e07d6515522ed4b3dc0858> on small data
[2015-06-18T15:52:25.502Z] <54e07d6515522ed4b3dc0858> so iris is small, and the outer CV variance in @rvraghav93's example is not large
[2015-06-18T15:54:18.456Z] <53135b495e986b0712efc453> By variance do you mean to say the variance in the hyper param points or the performance of the best models?
[2015-06-18T15:54:31.647Z] <54e07d6515522ed4b3dc0858> the performance of the best models
[2015-06-18T15:54:38.310Z] <53135b495e986b0712efc453> ok
[2015-06-18T15:55:00.936Z] <53135b495e986b0712efc453> > "The final result of the nested CV is the collection of n best Models"  You were going to say something about this right?
[2015-06-18T15:55:02.371Z] <54d4a1d6db8155e6700f853b> actually I think you should pick an example that can currently not be made to work
[2015-06-18T15:56:01.862Z] <54e07d6515522ed4b3dc0858> I'm fond of LeaveOneLabelOut :)
[2015-06-18T15:56:12.253Z] <54d4a1d6db8155e6700f853b> if you use StratifiedKFold with k=4 on iris
[2015-06-18T15:56:15.940Z] <54d4a1d6db8155e6700f853b> it will already be impossible
[2015-06-18T15:56:21.665Z] <54e07d6515522ed4b3dc0858> but that works if you do cv=4, no?
[2015-06-18T15:56:30.644Z] <54d4a1d6db8155e6700f853b> yes
[2015-06-18T15:57:24.746Z] <54d4a1d6db8155e6700f853b> let's say you want to shuffle, though ;)
[2015-06-18T15:57:36.173Z] <54d4a1d6db8155e6700f853b> or you want KFold
[2015-06-18T15:57:43.851Z] <54e07d6515522ed4b3dc0858> why you'd want KFold is hard to explain
[2015-06-18T15:57:49.567Z] <54e07d6515522ed4b3dc0858> if it doesn't shuffle by default that's perfect!
[2015-06-18T15:58:17.461Z] <54d4a1d6db8155e6700f853b> maybe a better example: use regression and say you want to shuffle
[2015-06-18T15:58:29.526Z] <54d4a1d6db8155e6700f853b> because we currently have no stratification for regression
[2015-06-18T15:58:35.145Z] <54e07d6515522ed4b3dc0858> yep
[2015-06-18T15:59:01.262Z] <53135b495e986b0712efc453> what would stratification look like on regression?
[2015-06-18T15:59:02.131Z] <54d4a1d6db8155e6700f853b> draw a line, fit something to it, and oh no! because we don't shuffle we don't generalize
[2015-06-18T15:59:22.845Z] <54e07d6515522ed4b3dc0858> that might suggest that the problem is not shuffling by default
[2015-06-18T15:59:29.047Z] <54d4a1d6db8155e6700f853b> discussion: https://github.com/scikit-learn/scikit-learn/issues/4757
[2015-06-18T16:00:23.952Z] <54d4a1d6db8155e6700f853b> @vene there are long arguments about that. shuffling might hide correlations. If you data order has meaning, like being temporal, then shuffling will give you too optimistic results
[2015-06-18T16:01:21.763Z] <54e07d6515522ed4b3dc0858> I'm just saying the phrasing should be such that it doesn't lead to "just make shuffling default"
[2015-06-18T16:01:33.381Z] <54e07d6515522ed4b3dc0858> but instead to "oh, we need to be able to tweak parameters of the CV object"
[2015-06-18T16:01:36.800Z] <54d4a1d6db8155e6700f853b> I was thinking about adding a shuffle keyword to GridSearchCV and cross_val_score at multiple points
[2015-06-18T16:01:44.441Z] <54d4a1d6db8155e6700f853b> alright
[2015-06-18T16:02:06.704Z] <54d4a1d6db8155e6700f853b> but wait
[2015-06-18T16:02:07.923Z] <54d4a1d6db8155e6700f853b> no
[2015-06-18T16:02:13.045Z] <54d4a1d6db8155e6700f853b> the argument should be different
[2015-06-18T16:02:23.123Z] <54d4a1d6db8155e6700f853b> if you use cv=4 on the outside with iris
[2015-06-18T16:02:29.219Z] <54d4a1d6db8155e6700f853b> you can't use shuffle split on the inside
[2015-06-18T16:02:33.555Z] <54d4a1d6db8155e6700f853b> I'm stupid
[2015-06-18T16:02:43.901Z] <54e07d6515522ed4b3dc0858> you can't?
[2015-06-18T16:03:00.698Z] <54e07d6515522ed4b3dc0858> can't you use cv=4 both outside and inside?
[2015-06-18T16:03:16.596Z] <54d4a1d6db8155e6700f853b> yes. But you can't use shuffle split on the inside
[2015-06-18T16:03:29.557Z] <54d4a1d6db8155e6700f853b> because shuffle split needs the number of samples
[2015-06-18T16:03:44.286Z] <54e07d6515522ed4b3dc0858> ah, yes
[2015-06-18T16:03:58.578Z] <54d4a1d6db8155e6700f853b> I think that is the right example
[2015-06-18T16:04:05.694Z] <54e07d6515522ed4b3dc0858> so say you want more iterations for the inner loop?
[2015-06-18T16:04:16.931Z] <54e07d6515522ed4b3dc0858> first show an example with cv=4 both outside and inside
[2015-06-18T16:04:23.732Z] <54e07d6515522ed4b3dc0858> ?
[2015-06-18T16:04:29.723Z] <54d4a1d6db8155e6700f853b> alright
[2015-06-18T16:05:16.602Z] <54e07d6515522ed4b3dc0858> btw, what's the intuition when choosing between StratifiedKFold with [Stratified?]ShuffleSplit?
[2015-06-18T16:06:26.750Z] <54e07d6515522ed4b3dc0858> the docs just say "finer control on the number of iterations and the proportion of samples"
[2015-06-18T16:08:28.849Z] <54e07d6515522ed4b3dc0858> I just shuffle first and do StratifiedKFold usually
[2015-06-18T16:26:20.432Z] <54d4a1d6db8155e6700f853b> well, you can control the number of repetitions and the test set size independently
[2015-06-18T16:26:33.443Z] <54d4a1d6db8155e6700f853b> because having too small a test-set will also give you a bad estimate
[2015-06-18T18:06:56.782Z] <54d4a1d6db8155e6700f853b> oh man, perfect post for a coffee break: http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html
[2015-06-18T18:09:37.386Z] <54e07d6515522ed4b3dc0858> loving the low level ones
[2015-06-18T18:11:42.376Z] <54d4a1d6db8155e6700f853b> I think I'll get a print of this for the office: http://1.bp.blogspot.com/-XZ0i0zXOhQk/VYIXdyIL9kI/AAAAAAAAAmQ/UbA6j41w28o/s1600/building-dreams.png
[2015-06-18T18:28:59.984Z] <5576063e15522ed4b3e19cc3> @amueller I updated the #4874. would you like to take a look? 
[2015-06-18T23:57:43.960Z] <53135b495e986b0712efc453> @amueller @vene I've revised the blog post based on all your suggestions... However the example is still an illustration of a working nested CV. I thought once the data indep iterator work is over... I will show an example using LOLO to highlight the benefit of having data independence! Please take a look now :) http://rvraghav93.blogspot.in/2015/06/gsoc-2015-psf-scikit-learn-nested-cross.html
[2015-06-19T00:03:10.837Z] <53135b495e986b0712efc453> Okay I'll sleep and finish this data indep before sunday :punch:   My next blog on mon/tue should be on nested CV using the data indep LOLO!! :) good night!!
[2015-06-19T00:10:04.498Z] <53135b495e986b0712efc453> BTW is the 3 part explanation still verbose?
[2015-06-19T14:17:21.966Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I'll have a look in a bit. I still think you should definitely also show an example that is currently not working. I feel the current breakage is pretty bad and showing it emphasizes how important your work is
[2015-06-19T14:40:06.258Z] <53135b495e986b0712efc453>  Okay :) will add one!!
[2015-06-19T15:19:11.337Z] <550f53e215522ed4b3dda5f6> Hi, I adjusted the displaying of verbose messages in ```GaussianMixture```, what do you think? The extra messages displayed when verbose=2 compared to those when verbose=1 are put the same line with 'Iteration'. I think that would be more clear. @ogrisel @amueller  
[2015-06-19T15:19:33.521Z] <550f53e215522ed4b3dda5f6> [Comment](https://github.com/scikit-learn/scikit-learn/pull/4802#issuecomment-113303471)
[2015-06-19T15:30:13.259Z] <550f53e215522ed4b3dda5f6> I have finished the most methods of ```_MixtureBase``` and methods of ```GaussianMixture``` related to full covariances. I think it's time to write tests before further implementation. In the master branch, the tests is implemented with ```unittest.TestCase```, while simple testing functions for other modules. Which one should I use?
[2015-06-19T15:34:15.234Z] <550f53e215522ed4b3dda5f6> I think displaying verbose messages makes ```fit``` a little messy. Any better idea?
[2015-06-19T15:35:00.737Z] <54d4a1d6db8155e6700f853b> @xuewei4d We usually prefer simple functions for testing. If you feel that using TestCase would simplify the testing code or make it more clear, you can use that, too.
[2015-06-19T16:05:33.057Z] <550f53e215522ed4b3dda5f6> Okay.
[2015-06-22T17:39:43.832Z] <54d4a1d6db8155e6700f853b> @xuewei4d btw, please also ping @lesteve when asking gmm questions, he is @ogrisel's co-mentor ;)
[2015-06-22T18:00:33.909Z] <550f53e215522ed4b3dda5f6> Okay. I forgot to ping him in the last comment.
[2015-06-22T18:12:12.129Z] <53135b495e986b0712efc453> @vene @amueller status update... the main part of data independent refactor is done.... all the new split / validate tests pass... working on grid search tests :) Will do the documentations and examples after pushing the grid search tests and an initial round of reviews (so as to finalize implementation) :)
[2015-06-22T18:14:57.896Z] <53135b495e986b0712efc453> one minor question
[2015-06-22T18:15:05.067Z] <53135b495e986b0712efc453> will ask at the PR itself...
[2015-06-22T18:20:44.195Z] <54d4a1d6db8155e6700f853b> Thanks @rvraghav93. I am super busy right now but I'll review your blog post and PR in the afternoon
[2015-06-22T18:23:15.066Z] <53135b495e986b0712efc453> Sure please take ur time :) I'll be done with all the tests by then :smile: 
[2015-06-22T18:40:45.979Z] <54e07d6515522ed4b3dc0858> Hi @rvraghav93, thanks for the update! I'll do my best and try to review tonight as well.
[2015-06-22T18:44:42.671Z] <53135b495e986b0712efc453> Thanks a lot! :)
[2015-06-22T21:02:51.351Z] <54d4a1d6db8155e6700f853b> I sent you detailed comments on the blog post per pm so as not to flood the channel. I still think it would be good to add an example that is currently impossible and will be possible with your contribution
[2015-06-22T21:03:14.747Z] <54d4a1d6db8155e6700f853b> Has anyone ever seen gcc errors with printf in cython code?
[2015-06-22T21:03:15.760Z] <54d4a1d6db8155e6700f853b> sklearn/manifold/_barnes_hut_tsne.c:7211:5: error: format not a string literal and no format arguments [-Werror=format-security]      printf(__pyx_k_t_SNE_Checking_tree_consistency); 
[2015-06-22T21:03:22.395Z] <54d4a1d6db8155e6700f853b> I get that on my box but not on travis.
[2015-06-22T21:17:39.914Z] <54d4a1d6db8155e6700f853b> @rvraghav93 so I should review #4294, right?
[2015-06-22T21:18:53.705Z] <54d4a1d6db8155e6700f853b> no wait, that is not the right one
[2015-06-22T21:19:39.630Z] <54d4a1d6db8155e6700f853b> @rvraghav93 you should reference the issues you are working on in the blog post ;)
[2015-06-22T21:54:03.664Z] <54d4a1d6db8155e6700f853b> any reviewers for https://github.com/scikit-learn/scikit-learn/pull/4621 btw?
[2015-06-22T21:54:14.022Z] <54d4a1d6db8155e6700f853b> or maybe https://github.com/scikit-learn/scikit-learn/pull/4840 ?
[2015-06-22T22:46:52.555Z] <54e07d6515522ed4b3dc0858>  Sorry, tonight is a bit tough for me for a more thorough review. I'll be on top of things in the morning.
[2015-06-22T22:50:41.161Z] <54d4a1d6db8155e6700f853b> no worries vladn :)
[2015-06-22T23:52:00.488Z] <53135b495e986b0712efc453> Thanks for the reviews! Will address them ASAP :)
[2015-06-23T14:32:33.077Z] <54d4a1d6db8155e6700f853b> @ogrisel and after barnes-hut and LDA you review the GP rewrite? ;)
[2015-06-23T14:39:14.980Z] <556705cb15522ed4b3e10f84> Hi @amueller  and @ogrisel, I tried to adress all comments in #4444 if you have time for a quick review :)
[2015-06-23T14:45:02.904Z] <53135b495e986b0712efc453> @amueller @vene Could I trouble you for a small doubt? - https://github.com/scikit-learn/scikit-learn/pull/4294#issuecomment-114523116
[2015-06-23T14:48:42.542Z] <54d4a1d6db8155e6700f853b> @rvraghav93 commented there
[2015-06-23T14:48:51.100Z] <53135b495e986b0712efc453> thanks!!
[2015-06-23T14:49:54.255Z] <54e07d6515522ed4b3dc0858> yes I think @amueller is right, returning cv.split(...) should do it
[2015-06-23T14:51:00.943Z] <54e07d6515522ed4b3dc0858> is check_cv in utils?
[2015-06-23T14:51:07.410Z] <54d4a1d6db8155e6700f853b> no in cross_validation
[2015-06-23T14:51:17.574Z] <54d4a1d6db8155e6700f853b> so there will be a new version now in model_selection
[2015-06-23T14:51:23.454Z] <54e07d6515522ed4b3dc0858> ah, yes
[2015-06-23T14:51:25.515Z] <54d4a1d6db8155e6700f853b> and the old version will behave the old way
[2015-06-23T14:51:32.286Z] <54e07d6515522ed4b3dc0858> perfect
[2015-06-23T14:51:49.129Z] <53135b495e986b0712efc453> Is there any reason why we can't have it to return the iterator? 
[2015-06-23T14:54:02.507Z] <54e07d6515522ed4b3dc0858> so there are instances when the len(new_cv.split(X, y)) doesn't work?
[2015-06-23T14:54:13.345Z] <53135b495e986b0712efc453> yes!
[2015-06-23T14:54:55.883Z] <54e07d6515522ed4b3dc0858> That's odd, that line contains enough information to know what the length should be
[2015-06-23T14:55:13.859Z] <54e07d6515522ed4b3dc0858> no?
[2015-06-23T14:56:02.526Z] <53135b495e986b0712efc453> not without expanding it right? I mean `new_cv.split(X, y)` returns an iterator... 
[2015-06-23T14:56:21.906Z] <54d4a1d6db8155e6700f853b> yeah just add ``new_cv.n_folds(X, y, labels)``
[2015-06-23T14:56:29.839Z] <53135b495e986b0712efc453> Thanks!
[2015-06-23T14:56:40.487Z] <54d4a1d6db8155e6700f853b> because we don't want to instantiate the whole thing there. we usually know this anyhow
[2015-06-23T14:57:19.476Z] <54e07d6515522ed4b3dc0858> add it where? I don't get what you propose
[2015-06-23T14:57:29.220Z] <54e07d6515522ed4b3dc0858> return the cv and the n_folds from check_cv?
[2015-06-23T14:58:25.442Z] <53135b495e986b0712efc453> add `get_n_folds(X, y, labels)` / `n_folds(X, y, labels)` it to the new cv classes
[2015-06-23T14:59:08.575Z] <54e07d6515522ed4b3dc0858> this means you'll have to change this line
[2015-06-23T14:59:09.021Z] <54e07d6515522ed4b3dc0858> https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/grid_search.py#L512
[2015-06-23T14:59:10.332Z] <54e07d6515522ed4b3dc0858> right?
[2015-06-23T14:59:25.946Z] <53135b495e986b0712efc453> Yes!
[2015-06-23T15:00:40.932Z] <54e07d6515522ed4b3dc0858> and you only need to support the new classes. I get it now, this is good.
[2015-06-23T15:00:41.677Z] <53135b495e986b0712efc453> Sorry to pester again! but why do you think we can't have `cv, len_cv = check_cv(...)`... is it so we can find the length without generating the cv?
[2015-06-23T15:01:18.742Z] <53135b495e986b0712efc453> That will make it support old cv classes too right?
[2015-06-23T15:01:35.238Z] <54d4a1d6db8155e6700f853b> what do you mean without generating the cv? the ``cv.n_folds(X, y, labels)`` desn't generate the cv, right?
[2015-06-23T15:01:59.371Z] <54d4a1d6db8155e6700f853b> and the wrapper of the old classes can just call ``__len__``
[2015-06-23T15:02:04.092Z] <53135b495e986b0712efc453> yes... but  check_cv(..) would... is that why you are suggesting so? :)
[2015-06-23T15:02:33.643Z] <54e07d6515522ed4b3dc0858> no, check_cv doesn't generate it either
[2015-06-23T15:02:47.012Z] <54e07d6515522ed4b3dc0858> not until you iterate over what it returns
[2015-06-23T15:02:48.901Z] <54e07d6515522ed4b3dc0858> right?
[2015-06-23T15:02:49.986Z] <54d4a1d6db8155e6700f853b> yeah
[2015-06-23T15:03:02.708Z] <54d4a1d6db8155e6700f853b> well what do you mean by "generate"?
[2015-06-23T15:03:11.545Z] <54e07d6515522ed4b3dc0858> I guess the same as you
[2015-06-23T15:03:17.506Z] <54e07d6515522ed4b3dc0858> instantiate the folds
[2015-06-23T15:03:33.946Z] <53135b495e986b0712efc453> oh! so you don't want it to `return cv.split(X, y, ...)`? Then fine!
[2015-06-23T15:03:57.466Z] <54d4a1d6db8155e6700f853b> no! it should just return a new-style cv object, given either an old-style or a new-style one
[2015-06-23T15:04:02.375Z] <54d4a1d6db8155e6700f853b> or a number
[2015-06-23T15:04:10.335Z] <53135b495e986b0712efc453> ahh! okay! thanks :)
[2015-06-23T15:04:37.867Z] <54d4a1d6db8155e6700f853b> @JeanKossaifi stupid question but is the splitting of the lables into folds equivalent to bin-packing?
[2015-06-23T15:08:13.995Z] <556705cb15522ed4b3e10f84> @amueller  at least it is very similar. If I get it right for bin-packing we want to spread different weights into the smallest possible amount of bags (all bags having the same size). Here the number of bags (folds) is fixed and we want them to have (approximately) the same weight at the end.
[2015-06-23T15:09:07.348Z] <556705cb15522ed4b3e10f84> @amueller thanks for the review :)
[2015-06-23T15:09:38.883Z] <54d4a1d6db8155e6700f853b> I'm just trying to figure out if the optimal solution is np hard or not ;)
[2015-06-23T15:11:00.388Z] <556705cb15522ed4b3e10f84> Yes, I had the same problem when I first needed that functionality. 
[2015-06-23T15:12:05.853Z] <54d4a1d6db8155e6700f853b> I think you can show equivalence with bin-packing by binary searching the bin-size
[2015-06-23T15:13:50.137Z] <54d4a1d6db8155e6700f853b> your heuristic was always adding to the smallest bin, right?
[2015-06-23T15:14:36.112Z] <556705cb15522ed4b3e10f84> yes, starting with the biggest weights
[2015-06-23T15:16:19.391Z] <54d4a1d6db8155e6700f853b> yeah seems good. I suggested minor refactorings
[2015-06-23T15:17:49.062Z] <54d4a1d6db8155e6700f853b> should we try to merge #4444 and #4583 before #4294?
[2015-06-23T15:18:04.458Z] <556705cb15522ed4b3e10f84> Yes, I'm correcting it at the moment, thanks a lot!
[2015-06-23T15:19:07.413Z] <54d4a1d6db8155e6700f853b> np. sorry for the delay. we have quite a few prs
[2015-06-23T15:21:11.422Z] <54d4a1d6db8155e6700f853b> @vene @ogrisel do you want to review #4583 ?
[2015-06-23T15:23:06.568Z] <54e07d6515522ed4b3dc0858> Sure
[2015-06-23T15:24:56.051Z] <54e07d6515522ed4b3dc0858> This gives me an idea for renaming the ugly `p` in `LeavePLabelOut` into `test_size`, WDYT?
[2015-06-23T15:27:53.911Z] <54d4a1d6db8155e6700f853b> I suggested n_labels
[2015-06-23T15:27:57.712Z] <54d4a1d6db8155e6700f853b> (or n_groups if we rename)
[2015-06-23T15:28:00.496Z] <54d4a1d6db8155e6700f853b> why test-size?
[2015-06-23T15:28:17.150Z] <54e07d6515522ed4b3dc0858> that's the meaning of `test_size` in #4583
[2015-06-23T15:28:20.556Z] <54e07d6515522ed4b3dc0858> if it's an integer
[2015-06-23T15:28:31.126Z] <54e07d6515522ed4b3dc0858> it means you'll have `test_size` labels in the test set
[2015-06-23T15:29:50.798Z] <54d4a1d6db8155e6700f853b> n_test_labels?
[2015-06-23T15:29:57.923Z] <54d4a1d6db8155e6700f853b> but ok, makes sense
[2015-06-23T15:30:19.056Z] <54e07d6515522ed4b3dc0858> well, what I mean is, if `test_size` isn't right, we should change it in #4583
[2015-06-23T15:30:48.089Z] <54e07d6515522ed4b3dc0858> `test_size` is a bit ambiguous (people could expect it to refer to samples, not labels)
[2015-06-23T15:30:49.209Z] <556705cb15522ed4b3e10f84> @amueller in the current implementation I sort tuples of (weight, corresponding labels). if I use np.bincout I will have to sort it anyway and keep the correspondence to the original labels, so the complexity would be the same, right?
[2015-06-23T15:31:15.039Z] <53135b495e986b0712efc453> `n_labels` seems good!!
[2015-06-23T15:33:28.464Z] <54e07d6515522ed4b3dc0858> How about for LeavePOut, would you suggest `n_samples`?
[2015-06-23T15:33:40.972Z] <54e07d6515522ed4b3dc0858> I wouldn't
[2015-06-23T15:35:01.015Z] <53135b495e986b0712efc453> ah! okay `test_size` it is!
[2015-06-23T15:35:20.370Z] <54e07d6515522ed4b3dc0858> wait, both have their problems
[2015-06-23T15:35:44.195Z] <54e07d6515522ed4b3dc0858> @rvraghav93 you're very quick to agree with things :) let's think about it
[2015-06-23T15:35:52.980Z] <53135b495e986b0712efc453> :P
[2015-06-23T15:36:07.847Z] <53135b495e986b0712efc453> `p_samples` ?
[2015-06-23T15:36:07.956Z] <54d4a1d6db8155e6700f853b> @JeanKossaifi you have to sort it, the correspondence would be stored in ``unique_labels``
[2015-06-23T15:36:37.400Z] <54d4a1d6db8155e6700f853b> the quadratic comes from looping over unique_labels and then doing fancy indexing. I want to avoid the fancy indexing
[2015-06-23T15:36:53.279Z] <54e07d6515522ed4b3dc0858> in #4583 `train_size` and `test_size` are natural because they're delegated up to `ShuffleSplit`. They're not the best names but they're the friendliest parametrization.
[2015-06-23T15:37:30.769Z] <54e07d6515522ed4b3dc0858> (Also, these parameter names are kind of mixing up test and validation...)
[2015-06-23T15:38:18.812Z] <54e07d6515522ed4b3dc0858> (It's hard to teach someone and ramble for 10min about validation vs test, and then you code test_size=0.25)
[2015-06-23T15:40:28.681Z] <54e07d6515522ed4b3dc0858> But ignoring this, `test_size` makes sense for LeavePOut (one could imagine even supporting fractions and `train_size`, but that's not important)
[2015-06-23T15:47:44.005Z] <54e07d6515522ed4b3dc0858> There are currently no common tests for cross-validation generators, right?
[2015-06-23T15:48:12.595Z] <53135b495e986b0712efc453> there are! `tests/test_cross_validation`?
[2015-06-23T15:48:51.590Z] <53135b495e986b0712efc453> which I've refactored  into `test_split.py` and `test_validate.py`
[2015-06-23T15:52:14.435Z] <54e07d6515522ed4b3dc0858> Those aren't really common tests, it's just regular tests
[2015-06-23T15:52:34.720Z] <54e07d6515522ed4b3dc0858> I mean something like https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/estimator_checks.py#L1213
[2015-06-23T15:52:55.988Z] <53135b495e986b0712efc453> oh! okay!!
[2015-06-23T16:10:36.994Z] <54e07d6515522ed4b3dc0858> Do you find the name of [`_check_is_partition`](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/cross_validation.py#L1107) appropriate? I just got totally misled by it.
[2015-06-23T17:01:46.955Z] <53135b495e986b0712efc453> How about `_is_permutation_of_arange_n`?
[2015-06-23T17:08:27.928Z] <54d4a1d6db8155e6700f853b> from the docstring it checks whether it is a permutation
[2015-06-23T17:08:46.896Z] <54d4a1d6db8155e6700f853b> so ``_is_permutation`` seems appropriate?
[2015-06-23T17:08:54.636Z] <54e07d6515522ed4b3dc0858> also from the code. I was just curious whether there's some obscure meaning of `partition` that I wasn't aware of.
[2015-06-23T17:10:27.076Z] <54d4a1d6db8155e6700f853b> @jnothman  raised a good point in the pr: we probably still want to support passing iterables
[2015-06-23T17:10:48.517Z] <54d4a1d6db8155e6700f853b> so maybe we want check_cv indeed to return an iterable?
[2015-06-23T17:11:04.033Z] <53135b495e986b0712efc453> yes!! That seems like a nice solution to me :)
[2015-06-23T17:11:13.330Z] <54e07d6515522ed4b3dc0858> The thing is, after all the refactoring, we'll want it to return the new-style CV object, right?
[2015-06-23T17:11:22.480Z] <53135b495e986b0712efc453> and about that helper I think we can do without it... its used only in one place... I'll remove that
[2015-06-23T17:12:34.327Z] <53135b495e986b0712efc453> IMHO check_cv is used only internally right? we will be able to do  ``` for tr, te in check_cv(...):    ... ``` if we return iterable...
[2015-06-23T17:12:56.964Z] <54d4a1d6db8155e6700f853b> @vene there is not really a reason to do that, right? the check_cv is instantiated where we actually have X and y
[2015-06-23T17:13:12.785Z] <54d4a1d6db8155e6700f853b> @rvraghav93 yeah
[2015-06-23T17:14:34.233Z] <54e07d6515522ed4b3dc0858> That will pass all the responsibility of proxying labels etc to check_cv
[2015-06-23T17:15:29.686Z] <54e07d6515522ed4b3dc0858> I'm not saying it's a bad thing, just that it makes the function pretty heavy
[2015-06-23T17:16:08.358Z] <54e07d6515522ed4b3dc0858> will the API of the new CV objects ever be used outside of check_cv then?
[2015-06-23T17:16:42.862Z] <54d4a1d6db8155e6700f853b> proxying labels? what do you mean?
[2015-06-23T17:17:15.356Z] <54e07d6515522ed4b3dc0858> passing weights, labels (sample_props in general) to the cv generator
[2015-06-23T17:17:21.195Z] <54d4a1d6db8155e6700f853b> It makes the function more heavy, but not that much. And no, then I think the ``split`` would only be called there. the ``n_folds`` will probably be called outside of it, which kind of makes it tricky again.
[2015-06-23T17:17:41.393Z] <53135b495e986b0712efc453> or we could have `get_cv_safe`?
[2015-06-23T17:17:42.435Z] <54d4a1d6db8155e6700f853b> currently we only have labels and they are present in all the function calls
[2015-06-23T17:17:50.621Z] <54d4a1d6db8155e6700f853b> what would that do?
[2015-06-23T17:19:01.965Z] <53135b495e986b0712efc453> I mean rename `check_cv` to `get_cv_safe` so ppl could use that?
[2015-06-23T17:20:31.094Z] <53135b495e986b0712efc453> I have a crazy suggestion... why don't we takle `sample_weights` along with this? will it make the PR too big?
[2015-06-23T17:20:35.915Z] <53135b495e986b0712efc453> tackle
[2015-06-23T17:20:46.532Z] <54d4a1d6db8155e6700f853b> I think we should change the name if it gets more responsibility but how would that impact how people can use it?
[2015-06-23T17:20:59.540Z] <54d4a1d6db8155e6700f853b> please don't include sample_weights changes in this pr
[2015-06-23T17:21:06.467Z] <53135b495e986b0712efc453> okay ;)
[2015-06-23T17:21:09.251Z] <54d4a1d6db8155e6700f853b> there is still quite a bit to do for this, I think
[2015-06-23T17:23:44.922Z] <53135b495e986b0712efc453> The main todo yet to be done is `check_cv`... other are minor right? documentation must be the next big thing... fixing examples should be quite easy... 
[2015-06-23T17:30:23.810Z] <54d4a1d6db8155e6700f853b> well yes, the way we now discussed check_cv there will be no changes to the estimatorCV code
[2015-06-23T17:30:36.059Z] <53135b495e986b0712efc453> yes :)
[2015-06-23T17:30:50.964Z] <54d4a1d6db8155e6700f853b> and make the tests pass
[2015-06-23T17:31:00.421Z] <53135b495e986b0712efc453> yep! on it!
[2015-06-23T17:31:08.745Z] <54d4a1d6db8155e6700f853b> alright :)
[2015-06-23T17:54:47.189Z] <556705cb15522ed4b3e10f84> @amueller Currently the shuffle parameter is not used given the heuristic used (I could shuffle the labels having a same weight but this case might not appear and the result could be misleading). 
[2015-06-23T17:56:16.087Z] <556705cb15522ed4b3e10f84> --sorry with the new notation it would be the labels having the same number of samples :)
[2015-06-23T19:38:59.438Z] <54d4a1d6db8155e6700f853b> oh, right. sorry. brainfart. Then please remove the shuffle parameter.
[2015-06-23T19:39:21.948Z] <54d4a1d6db8155e6700f853b> for shuffling people could use #4583
[2015-06-23T19:42:04.478Z] <556705cb15522ed4b3e10f84> Thanks, done!
[2015-06-23T20:03:52.149Z] <54d4a1d6db8155e6700f853b> I think it looks good now apart from minor cosmetic things that I commented on. Maybe find another reviewer ;)
[2015-06-23T20:09:28.077Z] <556705cb15522ed4b3e10f84> Great, thanks a lot! :)
[2015-06-23T20:11:45.362Z] <556705cb15522ed4b3e10f84> @vene since you already saw the code, would you have time to take a look? :)
[2015-06-24T03:05:31.547Z] <53135b495e986b0712efc453> @vene I am asking since you had raised the question on whether we had common tests for CV... could I add "Raise an issue to add common tests for CV iterators" as a todo to be done after `MRG+2`?
[2015-06-24T03:07:50.243Z] <54e07d6515522ed4b3dc0858> I don't think it's important at the moment
[2015-06-24T03:09:00.304Z] <53135b495e986b0712efc453> OK! thanks!
[2015-06-24T15:33:25.658Z] <550f53e215522ed4b3dda5f6> Hi, it looks like we don't have Old Faithful data set, right?
[2015-06-24T17:26:55.084Z] <541a528b163965c9bc2053de> @xuewei4d no we don't. As it's very small I think we could include a copy in the `sklearn.datasets` folder as we do for iris (just check that the copyright allow that but I am pretty sure it does).
[2015-06-24T19:42:16.529Z] <550f53e215522ed4b3dda5f6> OK. I will check it out. I would like to repeat some experiments described on PRML. @ogrisel 
[2015-06-24T20:00:54.039Z] <541a528b163965c9bc2053de> Would be a good sanity check indeed.
[2015-06-24T20:02:08.612Z] <541a528b163965c9bc2053de> If you include the old faithful dataset, please do so in a separate PR and rebase your GMM PR on top of it to be able to merge the dataset PR first (without waiting for the end of the GMM work) while still being able to use it in your GMM examples.
[2015-06-24T20:07:12.736Z] <550f53e215522ed4b3dda5f6> Got it.
[2015-06-24T21:09:15.685Z] <53135b495e986b0712efc453> @vene @amueller @ogrisel If you have a few mins to spare... could you take a look at #4294 and let me know if it looks okay so I can proceed with updating documentation and fixing examples in parallel with the main review? In particular please let me know if you feel `len_cv` `iter_cv` and the new impl of `check_cv` look okay?
[2015-06-24T23:37:32.829Z] <550f53e215522ed4b3dda5f6> There is a copy of data in R, which has GPL license. It definitely doesn't work. The original data is publish on JSTOR. Terms and Conditions of Use of JSTOR prohibits the commercial use, but which is permitted under sickout-learn's BSD-license. So I don't think we could add old-faithful data. @ogrisel 
[2015-06-24T23:38:06.987Z] <550f53e215522ed4b3dda5f6> [Terms and Conditions of Use of JSTOR](http://www.jstor.org/page/info/about/policies/terms.jsp)
[2015-06-25T07:08:12.007Z] <541a528b163965c9bc2053de> too bad.
[2015-06-25T07:34:41.471Z] <541a528b163965c9bc2053de> Maybe you could try to send an email to the original author of the paper / dataset to ask for explicit permission for inclusion of the data in the scikit-learn toolkit (mention explicitly that its license is the BSD license) if they have the copyright on this data? We will off-course credit their paper in the description of the dataset.
[2015-06-25T07:47:14.051Z] <541a528b163965c9bc2053de> @amueller @vene quickfix in #4893 by @jmschrei for the windows test failures that causes appveyor to be all red since recently: https://ci.appveyor.com/project/sklearn-ci/scikit-learn
[2015-06-25T07:54:56.386Z] <541a528b163965c9bc2053de> BTW, good news: I was contacted by the appveyor maintainer and we were upgraded to a much faster infrastructure (still for free). The builds run in 3-5 mins instead of 15-20min. This means that we might be able to run appveyor on the pull requests as we do for travis. Right now we only run them post-merge to master as it would have been too slow to process the full PR queues on the slow infrastructure.
[2015-06-25T14:35:28.609Z] <550f53e215522ed4b3dda5f6> OK. I will send the author an email, and cc to @ogrisel, @amueller. Who else should I cc to @ogrisel ?
[2015-06-25T16:35:12.846Z] <541a528b163965c9bc2053de> it would be great to put the mailing list in CC but it's not possible to reply if there are not subscribed. So just us is fine. In case of positive outcome we can forward there authorization to the mailing list for the record.
[2015-06-27T01:40:08.925Z] <53135b495e986b0712efc453> I have a question! Should the examples in the old classes (at `cross_validation.py` et al.) use imports from `model_selection` or should I leave it as such?
[2015-06-27T03:03:25.282Z] <53135b495e986b0712efc453> Any reviews for #4826 would be awesome! It will help in moving those Warnings out of the model_selection pr :)
[2015-06-28T05:40:39.851Z] <53135b495e986b0712efc453> virtualenvwrapper is cool! ;) Just incase any one is interested... This is a simple tutorial - http://simononsoftware.com/virtualenv-tutorial-part-2/
[2015-06-28T05:41:10.783Z] <53135b495e986b0712efc453> @ogrisel thats great!! btw why doesn't appveyor do the doc tests? only travis does it? (not that it should be of any concern)
[2015-06-28T23:14:06.976Z] <53135b495e986b0712efc453> Also is there a way I could debug appveyor failures without having a win build? virual box? any suggestions?
[2015-06-29T13:18:58.917Z] <54e07d6515522ed4b3dc0858> http://dev.modern.ie/tools/vms/
[2015-06-29T13:22:36.079Z] <541a528b163965c9bc2053de> > @ogrisel thats great!! btw why doesn't appveyor do the doc tests? only travis does it? (not that it should be of any concern)  Because on windows some type `repr` are slightly different (I think for int vs long on Python 2 IIRC) and some doctests would have a different representation. Porting the doctests to be cross-platform would be painful. doctests should be considered a way to check that the documentation is up to date with the code. So if it passes on one platform, we know that the doc is up to date. For unit tests on the other hand we want to test on all the supported platforms to make sure that the code is fully cross-platform.
[2015-06-29T13:23:28.501Z] <53135b495e986b0712efc453> Thanks :)
[2015-06-29T13:23:33.970Z] <53135b495e986b0712efc453> @vene thanks for the link :)
[2015-06-29T13:35:36.431Z] <541a528b163965c9bc2053de> Note that last time I checked, the modern.io vms were 32 bit only.
[2015-06-29T13:35:50.242Z] <541a528b163965c9bc2053de> That might be a limitation in some cases.
[2015-06-29T13:46:46.449Z] <54e07d6515522ed4b3dc0858> good point. @rvraghav93 you might be able to get a free Windows license through MSDN Academic Alliance or dreamspark, if your university is partnered with them.
[2015-06-29T13:47:09.829Z] <54e07d6515522ed4b3dc0858> I had a dreamspark win7 for a while
[2015-06-29T14:37:25.152Z] <53135b495e986b0712efc453> I too got one via the IEEE comsoc offer!! :D but never used it ;/  Anyway the current failure is in 32 bit/ Python 2.6.. so this should suffice for now :)
[2015-06-29T14:42:26.356Z] <53135b495e986b0712efc453> wow! @vene The setup is super fast... All I had to do was extract and open the ova file :O
[2015-06-29T15:14:31.163Z] <54e07d6515522ed4b3dc0858> I
[2015-06-29T16:27:06.347Z] <53135b495e986b0712efc453> BTW could I start resurrecting #2759 (multiple metric support) in parallel? But since this depends on the data indep PR, I am not sure how to proceed... Should I maybe start a ML thread to collect ideas?
[2015-06-30T03:05:51.088Z] <54d4a1d6db8155e6700f853b> @rvraghav93 let's finish the data dependent cv first
[2015-06-30T03:05:58.632Z] <54d4a1d6db8155e6700f853b> sorry I have been offline for the last 4 days
[2015-06-30T03:06:17.550Z] <53135b495e986b0712efc453> No issues :) Would you be able to spare a few mins to take a look at that? :)
[2015-06-30T03:06:44.762Z] <54d4a1d6db8155e6700f853b> tomorrow
[2015-06-30T03:07:03.909Z] <54d4a1d6db8155e6700f853b> I have 300+ unread emails and it is 23:06
[2015-06-30T03:07:07.649Z] <53135b495e986b0712efc453> Sure ;) I forgot its 11PM there :P
[2015-06-30T03:07:40.707Z] <53135b495e986b0712efc453> Just one more question!
[2015-06-30T03:07:43.403Z] <54d4a1d6db8155e6700f853b> sure
[2015-06-30T03:07:52.856Z] <53135b495e986b0712efc453> Can I finish the documentation / examples too? 
[2015-06-30T03:07:58.502Z] <53135b495e986b0712efc453> without waiting for the review?
[2015-06-30T03:08:07.576Z] <54d4a1d6db8155e6700f853b> yeah sure
[2015-06-30T03:08:20.086Z] <53135b495e986b0712efc453> Okay! I'll do that now... :) gn :)
[2015-06-30T03:13:50.211Z] <54d4a1d6db8155e6700f853b> thanks
[2015-06-30T14:57:59.032Z] <556705cb15522ed4b3e10f84> @amueller @jnothman @ogrisel are you happy with the changes in #4444? :)
[2015-06-30T18:10:41.850Z] <54d4a1d6db8155e6700f853b> @JeanKossaifi sorry I can not review any time soon
[2015-06-30T18:22:24.678Z] <54d4a1d6db8155e6700f853b> A friendly reminder to all the mentors that mid-terms are coming up this Friday!
[2015-06-30T18:55:23.155Z] <550f53e215522ed4b3dda5f6> I am writing the mid term evaluation, but I don't think my PR could merge right now. Do you think I need to pick ```GaussianMixture``` and ```_MixtureBase``` out of my current PR and make it ready to merge?  @amueller 
[2015-06-30T19:00:56.081Z] <54d4a1d6db8155e6700f853b> @xuewei4d no, I don't think you should do that
[2015-06-30T19:01:02.772Z] <54d4a1d6db8155e6700f853b> Its fine if there is good progress
[2015-06-30T19:28:49.360Z] <550f53e215522ed4b3dda5f6> Just submitted the evaluation form. Hope everything is fine.
[2015-06-30T19:33:33.802Z] <54e07d4015522ed4b3dc0856> Mentors... does anyone have access to Artem's GSoC evaluation? Apparently I am still not added correctly as a mentor! Working on getting the right access but would like to put an initial evaluation even if it means someone else copy-pastes in my words.
[2015-06-30T21:14:14.416Z] <5425a933163965c9bc206e53> Is there a reason RMSLE isn't in the metrics module, or would a PR for that be welcome?
[2015-06-30T22:18:26.502Z] <54e07d6515522ed4b3dc0858> @zacstewart what does RMSLE stand for?
[2015-06-30T22:18:49.273Z] <5425a933163965c9bc206e53> Root mean squared logarithmic error.
[2015-06-30T22:19:21.955Z] <5425a933163965c9bc206e53> Same as RMSE, but take the log(y_pred + 1) and log(y_true + 1) instead of just the values
[2015-06-30T22:21:07.530Z] <54e07d6515522ed4b3dc0858> is this a mainstream thing? I see the first result is from Kaggle :/
[2015-06-30T22:21:42.499Z] <5425a933163965c9bc206e53> I don't know if it is. I am bringing it up because it is the evaluation metric for a competition I am starting on today
[2015-06-30T22:22:03.055Z] <54e07d6515522ed4b3dc0858> and I can't find anything relevant on google scholar quickly
[2015-06-30T22:22:03.732Z] <5425a933163965c9bc206e53> Seems like a good idea for variables with a lot of variance
[2015-06-30T22:22:31.582Z] <5425a933163965c9bc206e53> But I'm admittedly more of a programmer than a statistician
[2015-06-30T22:22:40.949Z] <54e07d6515522ed4b3dc0858> anyway, you can easily define your custom metrics
[2015-06-30T22:23:40.445Z] <5425a933163965c9bc206e53> Yes, I've done so. I just wondered if it would be generally useful and worth pushing upstream.
[2015-06-30T22:24:39.111Z] <54e07d6515522ed4b3dc0858> If you want you can prepare a PR
[2015-06-30T22:25:37.015Z] <54e07d6515522ed4b3dc0858> Of course it would need tests and docs (with references) and maybe a motivating example.
[2015-06-30T22:26:19.585Z] <5425a933163965c9bc206e53> Okay. That's reasonable. Not sure I can provide a motivating reason to use it, other than it's the metric for the competition I'm working on
[2015-06-30T22:27:16.505Z] <54e07d6515522ed4b3dc0858> I don't know whether it belongs in scikit-learn by default. But I'm pessimistic because I personally never heard of this metric before. I'm rather clueless though. It also may be the case that it's been around under a different name
[2015-06-30T23:07:57.064Z] <54e07d6515522ed4b3dc0858> Ugh. I just noticed that the CVIterator, when given a class that implements _iter_test_indices, converts the indices to masks and then back into indices.
[2015-06-30T23:36:22.109Z] <54e07d6515522ed4b3dc0858> I mean PartitionIterator, not CVIterator
[2015-07-01T04:42:25.706Z] <53135b495e986b0712efc453> seq of seq support for `LabelBinarizer` is [earmarked for removal in 0.17](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/multiclass.py#L195)... should we remove it??
[2015-07-01T04:54:08.544Z] <53135b495e986b0712efc453> @vene Thanks heaps for the patient reviews!!! I'll address them and push before tomorrow along with the documentation and examples... with that #4294 is done!!! (except for further rounds of reviews, ofcourse!!)
[2015-07-01T04:54:21.033Z] <53135b495e986b0712efc453> tomorrow (in NYC time)
[2015-07-01T05:11:09.803Z] <54e07d6515522ed4b3dc0858> I still have, like, half of the PR to go through.  it's a big one! :)
[2015-07-01T05:12:06.108Z] <53135b495e986b0712efc453> Yeaa :/ Thanks anyway :) After addressing your comments I'll split it into one commit per file... this should make it marginally easy to review?
[2015-07-01T05:12:22.389Z] <54e07d6515522ed4b3dc0858> Don't worry about label binarizer right now. Probably yes, it should be removed.
[2015-07-01T05:13:33.886Z] <54e07d6515522ed4b3dc0858> I use  git diff to compare to the old files, so I don't really care how the commits are grouped. I just look at the head
[2015-07-01T05:13:51.570Z] <53135b495e986b0712efc453> Ah okay then :)
[2015-07-01T05:15:58.041Z] <54e07d6515522ed4b3dc0858> Anyway, before I go to bed, I'm not sold on using labels for the predefined split. It shouldn't stray too much from the old api
[2015-07-01T05:16:59.029Z] <54e07d6515522ed4b3dc0858> I'll think about it some more tomorrow
[2015-07-01T05:17:18.037Z] <54e07d6515522ed4b3dc0858> Happy hacking!
[2015-07-01T05:17:19.577Z] <53135b495e986b0712efc453> Okay!! I'll leave it as such :) Good night!!
[2015-07-01T13:49:24.607Z] <54d4a1d6db8155e6700f853b> @zacsteward  I never heard of that metric before either. which community is it from? Google told me it is used in a couple of kaggle competitions, but it doesn't have a wikipedia entry
[2015-07-01T13:49:49.788Z] <5425a933163965c9bc206e53> Kaggle is the only place I've seen it as well
[2015-07-01T13:51:21.807Z] <54d4a1d6db8155e6700f853b> i guess it is for exponential regression tasks. Basically you log the target and then to rmse? For most models it would probably be better to log the target before training as regression models are more likely to minimize rmse
[2015-07-01T13:53:14.148Z] <5425a933163965c9bc206e53> I agree. I will probably try that in my model, but unfortunately I can't change the evaluation metric that this competition uses
[2015-07-01T13:53:21.042Z] <54d4a1d6db8155e6700f853b> alternatively you could create your own scorer for this, but I don't think it belongs in sklearn. The problem is that if you do your own scorer, you probably also want a meta-estimator that logs the target before fitting / predicting with your model and then transform back.
[2015-07-01T13:53:42.827Z] <54d4a1d6db8155e6700f853b> you don't need to change the evaluation metric. just apply log to y. then do grid-search with rmse on your ridge regression
[2015-07-01T13:53:47.995Z] <54d4a1d6db8155e6700f853b> the error will be the "right" one\
[2015-07-01T13:54:13.684Z] <54d4a1d6db8155e6700f853b> and it will perform much better than using ridge on the original target with rmsle
[2015-07-01T13:54:36.705Z] <5425a933163965c9bc206e53> Hm, I suppose then I would just have to exp my predictions for submission
[2015-07-01T13:54:45.670Z] <54d4a1d6db8155e6700f853b> yes
[2015-07-01T13:55:09.053Z] <54d4a1d6db8155e6700f853b> (log(y + 1) and exp(y - 1) that is to not get nans)
[2015-07-01T13:56:20.639Z] <5425a933163965c9bc206e53> Not sure if they have internal optimizations to save you the extra op
[2015-07-01T13:56:24.545Z] <5425a933163965c9bc206e53> or use numpy's log1p and expm1
[2015-07-01T13:57:17.602Z] <5425a933163965c9bc206e53> Anyway, I didn't want to solicit free advice on how to win a Kaggle competition. Just wanted to find out of this evaluation metric was noteworthy enough to merit a PR
[2015-07-01T13:57:29.600Z] <5425a933163965c9bc206e53> Thanks for the discussion
[2015-07-01T13:59:30.220Z] <54d4a1d6db8155e6700f853b> np. I wouldn't worry about optimizing this, though using log1p and expm1 are probably a good idea
[2015-07-01T14:00:23.203Z] <54e07d6515522ed4b3dc0858> For stability yes. For speed, this is just pre and post processing, so I doubt it matters
[2015-07-01T14:03:11.309Z] <54e07d6515522ed4b3dc0858> http://www.johndcook.com/blog/2010/06/07/math-library-functions-that-seem-unnecessary/
[2015-07-01T15:29:11.458Z] <54e07d6515522ed4b3dc0858> if curious, here's the numpy implementation of log1p if the math.h one is not available https://github.com/numpy/numpy/blob/master/numpy/core/src/npymath/npy_math.c.src#L86
[2015-07-02T14:45:29.777Z] <54e07d6515522ed4b3dc0858> @amueller did you see this notebook ~~re~~implementing the google blog post from earlier? https://github.com/google/deepdream/blob/master/dream.ipynb
[2015-07-02T14:49:34.185Z] <53135b495e986b0712efc453> wow! :O
[2015-07-02T14:50:17.708Z] <54e07d6515522ed4b3dc0858> it generates things that look like this https://slack-files.com/files-tmb/T04T7B1ST-F074J6EDD-5630fb79d2/frames_360.png
[2015-07-02T14:51:08.162Z] <53135b495e986b0712efc453> too awsome!
[2015-07-02T14:56:15.863Z] <53135b495e986b0712efc453> @vene Do you have any suggestions for a practical example for nested cv using LOLO... ? :) Any dataset / public domain problem (like iris classification)?
[2015-07-02T14:57:37.631Z] <54e07d6515522ed4b3dc0858> I can't think of any datasets with meaningful groups
[2015-07-02T14:57:50.618Z] <54e07d6515522ed4b3dc0858> you could generate one yourself
[2015-07-02T14:58:06.555Z] <53135b495e986b0712efc453> Okay!!
[2015-07-02T15:00:58.468Z] <54e07d6515522ed4b3dc0858> like a regression problem with multiple noisy observations per subject
[2015-07-02T15:02:15.623Z] <54e07d6515522ed4b3dc0858> if you accidentally leave observations of the same subject in both train and test folds, you'll get overly optimistic results
[2015-07-02T15:11:41.719Z] <54e07d6515522ed4b3dc0858> (I'm just thinking out loud, this might not be right) say you have 2 features and the target is `y = w_1 + w_2 + noise` but `w1` is very correlated within the same subject and w2 is essentially independent. 
[2015-07-02T15:12:43.231Z] <54e07d6515522ed4b3dc0858> like if `w1` is essentialy the label of the subject + noise, and `w2` is just noise
[2015-07-02T15:13:54.890Z] <54e07d6515522ed4b3dc0858> say maybe `w_1`is the person's weight (fluctuates slightly but not a lot) and `w_2` is how many minutes the person walked outside today
[2015-07-02T15:22:02.839Z] <54d4a1d6db8155e6700f853b> @vene yeah saw the blog post. pretty cool
[2015-07-02T15:22:13.329Z] <54d4a1d6db8155e6700f853b> I have to work on the scipy tutorial today, sorry
[2015-07-02T20:37:07.519Z] <5425a933163965c9bc206e53> Is there a good way to use an LabelEncoder to encode several columns of categorical variables?
[2015-07-02T20:38:00.167Z] <54d4a1d6db8155e6700f853b> you probably want OneHotEncoder
[2015-07-02T20:38:09.992Z] <54d4a1d6db8155e6700f853b> (only it doesn't do strings at the moment which makes me sad)
[2015-07-02T20:38:45.192Z] <5425a933163965c9bc206e53> This is exactly what I want. But I need to encode those string categorical values to integers so I can use it :)
[2015-07-02T20:39:13.311Z] <54d4a1d6db8155e6700f853b> you could make it a dict and use dict vectorizer... or use pandas?
[2015-07-02T20:39:38.689Z] <54d4a1d6db8155e6700f853b> I was really surprised when I recently realized that there is no good way to do this in sklearn. you can open an issue if you like
[2015-07-02T20:39:59.454Z] <5425a933163965c9bc206e53> I am actually using pandas. I've done this various hacky ways in the past
[2015-07-02T20:40:05.371Z] <5425a933163965c9bc206e53> Would making the OneHotEncoder accept strings be relatively straight forward or are there design problems blocking it? I'd love to issue a PR for that
[2015-07-02T20:55:18.570Z] <54d4a1d6db8155e6700f853b> it seemed slightly non-trivial but didn't look blocking. maybe open an issue and ping @jnothman what he thinks of it
[2015-07-02T20:55:33.883Z] <5425a933163965c9bc206e53> :+1:
[2015-07-02T20:57:09.413Z] <54d4a1d6db8155e6700f853b> sweet thanks
[2015-07-04T02:08:24.970Z] <54c084dbdb8155e6700eed4c> [![download (1).jpg](https://files.gitter.im/scikit-learn/scikit-learn/6cOi/thumb/download-_1_.jpg)](https://files.gitter.im/scikit-learn/scikit-learn/6cOi/download-_1_.jpg)
[2015-07-04T02:08:26.818Z] <54c084dbdb8155e6700eed4c> Deep dreaming on sklearn... 
[2015-07-04T02:10:42.178Z] <54c084dbdb8155e6700eed4c> My assessment: blue blob is pure machine, and orange blob is learning.
[2015-07-04T02:11:17.548Z] <54c084dbdb8155e6700eed4c> FWIW, the crazy stuff in the background was imagined from a blank white canvas 
[2015-07-04T08:11:50.178Z] <53135b495e986b0712efc453> Cool!! How
[2015-07-04T08:12:38.465Z] <53135b495e986b0712efc453> *how'd u do that??
[2015-07-04T08:13:10.373Z] <53135b495e986b0712efc453> BTW andyy happy birthday!! :)
[2015-07-04T15:39:24.983Z] <54c084dbdb8155e6700eed4c> @rvraghav93 I spent several hours trying to get caffe installed :smiley: and then played with a few of the params at https://github.com/google/deepdream
[2015-07-04T17:17:06.897Z] <54c084dbdb8155e6700eed4c> And then, things got weird... http://i.imgur.com/5QA87gU.gif
[2015-07-05T13:27:05.837Z] <53135b495e986b0712efc453> if there were no eyes this would probably look even better! eyes pop out almost everywhere... :anguished: 
[2015-07-06T15:06:01.188Z] <53135b495e986b0712efc453> @trevorstephens  you might want to take a took at this :laughing: 
[2015-07-06T15:07:01.229Z] <53135b495e986b0712efc453> http://i.imgur.com/OPbPA4M.gif
[2015-07-07T20:10:27.713Z] <54c084dbdb8155e6700eed4c> that's terrifying 
[2015-07-08T14:18:14.054Z] <54d4a1d6db8155e6700f853b> @xuewei4d I think you should have a look at https://bitbucket.org/michaelchughes/bnpy/
[2015-07-08T14:18:33.956Z] <54d4a1d6db8155e6700f853b> It looks like it might be a good reference for the dp gmm
[2015-07-08T14:50:32.910Z] <550f53e215522ed4b3dda5f6> Thanks. I am looking into it.
[2015-07-08T20:30:39.968Z] <550f53e215522ed4b3dda5f6> Hi I have a question about git/github. How can I create a branch from a branch of other's forked repository?
[2015-07-08T21:15:33.444Z] <54e07d6515522ed4b3dc0858> You can add the fork as a remote with git remote add <name> <uri> 
[2015-07-08T21:22:30.966Z] <550f53e215522ed4b3dda5f6> I just tried, but there are too many conflicts. What should I do?
[2015-07-08T22:11:24.911Z] <54e07d6515522ed4b3dc0858> I don't see how "git remote add" could trigger conflicts, what exactly is the problem?
[2015-07-08T22:13:11.977Z] <54e07d6515522ed4b3dc0858> the way I'd do it is:  ``` git remote add xuewei4d https://github.com/xuewei4d/scikit-learn.git git fetch xuewei4d git checkout xuewei4d/<whatever-branch> git checkout -b <my-new-local-branch> ```
[2015-07-08T22:14:27.415Z] <54e07d6515522ed4b3dc0858> if the branch you want is a PR you can also use [this trick](https://gist.github.com/piscisaureus/3342247)
[2015-07-08T22:14:59.975Z] <54e07d6515522ed4b3dc0858> HTH
[2015-07-10T11:58:33.795Z] <54e07d6515522ed4b3dc0858> @rvraghav93 there was a question on the mailing list very relevant to what you are working on
[2015-07-10T12:16:05.063Z] <53135b495e986b0712efc453> Thanks for pinging me!! I'll look into it and reply :)
[2015-07-10T12:17:16.132Z] <53135b495e986b0712efc453> Also if you could spare a few mins could you let me know if there is anything left to be done for the #4294 :) I wish to get started on the next goal (sample props) asap :) 
[2015-07-10T12:30:07.508Z] <54e07d6515522ed4b3dc0858> I need to review it, it will take a bit more than a few minutes
[2015-07-10T12:30:19.623Z] <54e07d6515522ed4b3dc0858> I hope I can do it today
[2015-07-10T12:43:21.817Z] <53135b495e986b0712efc453> Thanks :)) also do you feel it is an apt time to send a mail on the mailing list requesting for the comments on sample props? (ML instead of issue since it will reach a wider audience)
[2015-07-10T12:51:09.084Z] <54e07d6515522ed4b3dc0858> I'd discuss in the issue first
[2015-07-10T12:57:06.644Z] <53135b495e986b0712efc453> Okay! Thanks!
[2015-07-10T12:58:26.040Z] <54e07d6515522ed4b3dc0858> There is already discussion in progress there
[2015-07-10T12:58:44.901Z] <54e07d6515522ed4b3dc0858> It seems like the appropriate place
[2015-07-10T13:00:03.618Z] <54e07d6515522ed4b3dc0858> That's just my 2c
[2015-07-10T13:00:08.144Z] <54e07d6515522ed4b3dc0858> After polling dev opinion, you can summarize and post on the ML too
[2015-07-10T13:02:35.095Z] <54e07d6515522ed4b3dc0858> As for Luca's question, you could advertise how that sort of thing is possible with your branch, introduce the new API and see whether it suits his needs. It's good to get the users' point of view.
[2015-07-10T13:03:14.183Z] <54e07d6515522ed4b3dc0858> Also it might attract another round of review, which would be great
[2015-07-10T14:33:59.751Z] <550f53e215522ed4b3dda5f6> Thanks @vene. I had an internet connection problem.
[2015-07-10T14:34:49.944Z] <550f53e215522ed4b3dda5f6> I cannot login gitter yesterday.
[2015-07-10T15:12:56.662Z] <53135b495e986b0712efc453> @vene okay :) thanks!!
[2015-07-10T19:34:05.154Z] <550f53e215522ed4b3dda5f6> Hi, when I am using %timeit on one function, how to disable caching intermediate results?
[2015-07-11T15:56:41.471Z] <54d4a1d6db8155e6700f853b> good morning everyone! sprints are starting now!
[2015-07-11T16:06:52.545Z] <53135b495e986b0712efc453> Good morning!! Scipy sprints??
[2015-07-11T16:33:14.590Z] <54d4a1d6db8155e6700f853b> yes!
[2015-07-11T16:35:19.174Z] <53135b495e986b0712efc453> Awesome! good luck with that! :)
[2015-07-11T19:21:55.586Z] <54e07d6515522ed4b3dc0858> Hi @amueller, sprint still going?
[2015-07-11T21:11:33.806Z] <54d4a1d6db8155e6700f853b> yeahg
[2015-07-11T21:12:03.779Z] <54d4a1d6db8155e6700f853b> @rvraghav93 @vene so what do we want to tackle next? I feel the sample_props is not clear enough to go ahead
[2015-07-11T21:12:15.317Z] <54d4a1d6db8155e6700f853b> Another possibility would be the multiple metrics grid-search
[2015-07-11T21:12:23.549Z] <54d4a1d6db8155e6700f853b> or nesting GridSearchCV and EstimatorCV
[2015-07-11T21:14:31.228Z] <54e07d6515522ed4b3dc0858> is #1626 where I should read about the second suggestion?
[2015-07-11T21:16:03.699Z] <54e07d6515522ed4b3dc0858> multiple metrics seems more straightforward to me right now
[2015-07-11T21:16:12.875Z] <54e07d6515522ed4b3dc0858> I agree sample_props is not ripe yet
[2015-07-11T23:17:07.922Z] <53135b495e986b0712efc453> Okay!! multiple metric it is! BTW the reason I suggested sample props to be done next was because it seemed more framework-ish... 
[2015-07-11T23:18:19.268Z] <54e07d6515522ed4b3dc0858> @rvraghav93 it would have been a great thing to work on next, but the solution isn't clear enough, as @amueller noted
[2015-07-11T23:19:50.161Z] <53135b495e986b0712efc453> yes indeed!! BTW I heard from Joel that he wouldn't be available for the next few weeks... too bad since he vouched for multiple metric support very much!
[2015-07-11T23:20:58.895Z] <53135b495e986b0712efc453> My reply to Luca was brief... will expand it as a blog post and reply to that mail like you had suggested... 
[2015-07-11T23:21:55.591Z] <54e07d6515522ed4b3dc0858> it was a good reply
[2015-07-11T23:22:47.289Z] <53135b495e986b0712efc453> Also I scoured through the notification email and found bits and pieces of the lost conversation on `classifier` param... have commented it there!!
[2015-07-11T23:33:55.776Z] <54e07d6515522ed4b3dc0858> I'm finally resuming my review! sorry for the delay
[2015-07-11T23:34:13.621Z] <54e07d6515522ed4b3dc0858> thanks for finding the e-mails, I thought there had been more discussion that I missed
[2015-07-12T00:38:56.672Z] <54e07d6515522ed4b3dc0858> @rvraghav93: didn't we agree to not duplicate the code that doesn't need to be duplicated? eg the old gridsearch, can't it be just imported from the new path?
[2015-07-12T01:02:25.599Z] <54e07d6515522ed4b3dc0858> basically we'll have duplicated functionality in the old and new CV classes for a while, but the rest of the things that were moved should just be imported from the new place, assuming their behavior with old-style CV classes doesn't change.
[2015-07-12T16:45:41.245Z] <54d4a1d6db8155e6700f853b> +1
[2015-07-12T16:47:43.137Z] <54e07d6515522ed4b3dc0858> @amueller what do you think about the placement on the `labels` argument in `cross_val_score` and the like?
[2015-07-12T16:49:45.372Z] <54e07d6515522ed4b3dc0858> If we leave it at the end, we don't need to duplicate that code either, right?
[2015-07-12T16:54:42.285Z] <53135b495e986b0712efc453> (About reducing duplicates) already done at https://github.com/rvraghav93/scikit-learn/pull/2 :)
[2015-07-12T16:55:44.979Z] <53135b495e986b0712efc453> I also reused a few docstrings... That is a bit hacky not sure if that's correct!!
[2015-07-12T16:58:15.516Z] <53135b495e986b0712efc453> @amueller discussion abt the labels arg here - https://github.com/scikit-learn/scikit-learn/pull/4294#discussion_r34417412
[2015-07-12T21:23:06.819Z] <55a13e9b5e0d51bd787b0bb6> I'm curious about the [MRG] convention I see being used on pull requests. Does that just indicate that the author believes it's ready to merge?
[2015-07-12T21:23:42.954Z] <55a13e9b5e0d51bd787b0bb6> I think I wrote a good test for PR #4961. I hesitated before because I thought it would be weird to test something that should be somewhere around 0.5. But then I taught myself about assert_almost_equal.
[2015-07-12T21:24:24.988Z] <55a13e9b5e0d51bd787b0bb6> It was fun sprinting with some of you, I'll be back on later today or this week to hopefully finish that k-means example.
[2015-07-12T21:52:41.145Z] <54e07d6515522ed4b3dc0858> @mrphilroth exactly! It's a way for reviewers to tell at a glance what state a PR is in.
[2015-07-15T21:22:54.895Z] <550f53e215522ed4b3dda5f6> https://cloud.githubusercontent.com/assets/1180956/8710149/a6437600-2b15-11e5-9524-d503200f01a5.gif
[2015-07-15T21:23:16.949Z] <550f53e215522ed4b3dda5f6> Hi all. Here is a ```BayesianGaussianMixture``` demo on rescaled old faith data.
[2015-07-16T12:28:28.837Z] <54bd1809db8155e6700ed1e4> Hey, I was wondering whether there was a way to see the output of the transformers in the `sklearn.pipeline.Pipeline`, i.e. to obtain the result of the fit_transform steps
[2015-07-16T12:30:41.925Z] <5425a933163965c9bc206e53> @HolgerPeters: you mean you want to look at the transformers and models contained in the pipeline?
[2015-07-16T12:31:03.781Z] <5425a933163965c9bc206e53> Or you want to transform some data with one of them to see how it's working?
[2015-07-16T12:31:25.282Z] <54bd1809db8155e6700ed1e4> essentialy yes, see the data before it is passed to the estimator
[2015-07-16T12:31:36.363Z] <5425a933163965c9bc206e53> Either way, you can get a handle to them via Pipeline.steps
[2015-07-16T12:31:41.764Z] <5425a933163965c9bc206e53> You
[2015-07-16T12:32:27.462Z] <5425a933163965c9bc206e53> 'll have to manually run fit_transform through each step though
[2015-07-16T12:33:12.125Z] <5425a933163965c9bc206e53> Either that, or you could roll your own DebugTransformer that just opens a debugger session within `transform`
[2015-07-16T12:54:46.011Z] <54bd1809db8155e6700ed1e4> ok, thanks
[2015-07-16T14:03:12.271Z] <55a13e9b5e0d51bd787b0bb6> Hello. I want to bug people to look at my PRs and merge or discuss them. But I want to bug people in the least annoying way possible. Is that maybe mentioning them here? Take a look at PR #4961 and then PR #4965.
[2015-07-16T14:59:02.090Z] <555b8aa615522ed4b3e0a160> @xuewei4d  nice !
[2015-07-16T15:07:51.463Z] <550f53e215522ed4b3dda5f6> Thanks. It is based on my PR #4802. Any feedback is welcome.
[2015-07-16T15:55:38.940Z] <5576063e15522ed4b3e19cc3> cant access scikit-learns website today?
[2015-07-16T16:03:08.317Z] <5576063e15522ed4b3e19cc3> now it works :)
[2015-07-16T18:42:08.134Z] <55a7fad98a7b72f55c3f9de8> Any idea if the sci-kit learn website is down ?
[2015-07-16T18:54:45.666Z] <55a7fdd18a7b72f55c3f9e4a> Hi, is the sci-kit learn site down? Have tried to open on Internet Explorer,Chrome, and Firefox
[2015-07-16T18:56:46.734Z] <550f53e215522ed4b3dda5f6> Me too...
[2015-07-17T16:44:09.365Z] <54a2cde7db8155e6700e4190> Andy uploaded the docs here: http://scikit-learn.github.io/dev/
[2015-07-20T09:28:22.673Z] <54d4a1d6db8155e6700f853b> please everybody check scikit-learn.github.io/ and stable and dev and 0.16 subfolders
[2015-07-20T09:28:25.226Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/issues/4993
[2015-07-20T09:28:29.791Z] <54d4a1d6db8155e6700f853b> report issues there
[2015-07-20T09:58:11.649Z] <54d4a1d6db8155e6700f853b> added 0.15
[2015-07-20T11:56:52.765Z] <54d4a1d6db8155e6700f853b> ok looking good now.
[2015-07-20T11:56:57.708Z] <54d4a1d6db8155e6700f853b> waiting for the dns move
[2015-07-20T15:17:08.690Z] <54e07d6515522ed4b3dc0858> dns is up over here, thanks @amueller!
[2015-07-20T15:25:54.720Z] <54e07d6515522ed4b3dc0858> hi @rvraghav93 
[2015-07-20T19:27:06.543Z] <54d4a1d6db8155e6700f853b> @xuewei4d sorry for the lack of feedback, but would you have time to look at this: https://github.com/scikit-learn/scikit-learn/pull/1292#issuecomment-122038677 ?
[2015-07-20T19:28:11.741Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I'll have more time on wednesday to look at your code
[2015-07-20T19:40:45.432Z] <550f53e215522ed4b3dda5f6> Yes. He is right. I have fixed this problem in https://github.com/scikit-learn/scikit-learn/pull/4802/files#diff-a498a8ef6ad37ebc525591d722e0a7ceR220
[2015-07-20T19:43:35.212Z] <550f53e215522ed4b3dda5f6> The kmeans initialization in GMM is not good. It only initializes the means_. My PR will initialize the responsibilities first, then all parameters including means, weights, covars.
[2015-07-21T13:02:26.824Z] <555b8aa615522ed4b3e0a160> @ogrisel AppVeyor is blocked on a build
[2015-07-21T22:10:27.931Z] <5583486615522ed4b3e220e5> Hi, I'm fairly new to machine learning/deep learning, but I'm currently working on a project where I want to classify some biological images. I want to initially run an unsupervised clustering of similar images that don't have  labels. Later on I want to take a set of labeled images and run some type of deep learning algorithm to aid in classifying the images. What are some ways i can get started? Any help would be really appreciated, thank you!
[2015-07-21T22:42:38.487Z] <53135b495e986b0712efc453> Hi @vene @amueller sorry! Got a bit busy :/ will resume work in a few hours!! :)
[2015-07-23T00:18:06.644Z] <54e07d6515522ed4b3dc0858> Hi @rvraghav93. Do you have a draft of your next blog post?
[2015-07-23T00:18:44.469Z] <54e07d6515522ed4b3dc0858> I will be on a 16h flight tomorrow, maybe I can make myself useful.
[2015-07-25T09:16:18.529Z] <53135b495e986b0712efc453> Hey! I'll add one tonight! :)
[2015-07-25T14:29:01.085Z] <53135b495e986b0712efc453> Vlad is choosing k in KNN a good example for LOLO? (About labeled data I was thinking like some N samples from M patients and we leave one patient out for validation to make sure we are able to generalise to other patients too)
[2015-07-25T14:29:05.503Z] <53135b495e986b0712efc453> Sounds good?
[2015-07-25T14:29:36.928Z] <53135b495e986b0712efc453> I am unable to find a nice example for LOLO otherwise :/
[2015-07-25T14:29:44.346Z] <53135b495e986b0712efc453> any suggestions?
[2015-07-25T15:47:22.043Z] <53135b495e986b0712efc453> Also if you find time could you take a look at #4826
[2015-07-28T03:29:47.476Z] <5395efa3a9176b500d1cd7fb> just to let u know, cluster.DBSCAN (and I guess lots more) is not working with scipy 0.16.0 on OSX, at least not with a conda install (maybe the library is missing in the conda binary?) https://github.com/scipy/scipy/issues/5092
[2015-07-28T14:08:44.598Z] <54d4a1d6db8155e6700f853b> @rvraghav93 sorry for my proonged abscense. I am back from my travels and will catch up with all your activity
[2015-07-28T14:09:18.606Z] <54d4a1d6db8155e6700f853b> michaelaye: what is the error you get?
[2015-07-28T14:09:35.800Z] <54d4a1d6db8155e6700f853b> @michaelaye what is the error? I'm pretty sure that is working for other people.
[2015-07-28T20:38:27.883Z] <54d4a1d6db8155e6700f853b> master is failing?
[2015-07-28T20:38:31.403Z] <54d4a1d6db8155e6700f853b> was that me?!
[2015-07-28T20:41:00.573Z] <54d4a1d6db8155e6700f853b> is there a way to see when master started failing?
[2015-07-28T20:44:24.957Z] <54a2cde7db8155e6700e4190> https://travis-ci.org/scikit-learn/scikit-learn/builds
[2015-07-28T20:44:31.943Z] <54a2cde7db8155e6700e4190> May not just be master
[2015-07-28T20:44:35.078Z] <5395efa3a9176b500d1cd7fb> @amueller i was not alone, e.g. https://github.com/ContinuumIO/anaconda-issues/issues/392 but its all fixed now.
[2015-07-28T20:45:36.063Z] <54d4a1d6db8155e6700f853b> @michaelaye glad you worked it out :)
[2015-07-28T20:46:02.233Z] <54d4a1d6db8155e6700f853b> @TomAugspurger which makes it very hard to find out which are actual master commits and which are not
[2015-07-28T20:46:10.066Z] <5395efa3a9176b500d1cd7fb> well, others worked it, im just happy it does work again. ;) Its really scary if scipy doesnt work... ;)
[2015-07-28T20:46:38.110Z] <5395efa3a9176b500d1cd7fb> but thankfully, its so easy to quickly downgrade with conda: `conda install scipy=0.15`
[2015-07-28T20:46:41.156Z] <54d4a1d6db8155e6700f853b> kinda ;) well np.dot "doesn't work" so ....
[2015-07-28T22:25:12.208Z] <54d4a1d6db8155e6700f853b> great, the error was first here: 24e962cfe1c348d0c1de95f546b2091fe75a2c06
[2015-07-28T22:25:36.115Z] <54d4a1d6db8155e6700f853b> failure: https://travis-ci.org/scikit-learn/scikit-learn/jobs/72957365 success: https://travis-ci.org/scikit-learn/scikit-learn/jobs/72439348
[2015-07-28T22:25:41.743Z] <54d4a1d6db8155e6700f853b> and all the versions seem to be  the same
[2015-07-28T22:42:14.261Z] <54d4a1d6db8155e6700f853b> ah, new scipy
[2015-07-29T01:49:37.132Z] <54e07d6515522ed4b3dc0858> @rvraghav93 you should have pinged me using my username, I didn't see your message. I'm behind the Great Firewall so my connectivity is poor until the 31st
[2015-07-29T01:51:15.179Z] <54e07d6515522ed4b3dc0858> To answer, I don't see why knn would be better or worse than anything else. The gist of the problem is the estimation of the score. If you use kfold instead of lolo you will overestimate.
[2015-07-29T01:53:40.557Z] <54e07d6515522ed4b3dc0858> The idea of validation is to estimate how your model would do in a realistic setting. If your observations are grouped and they arrive in groups, it's not realistic to assume that you can be able to train on some samples from the same groups that you will run it on.
[2015-07-29T01:55:37.233Z] <54e07d6515522ed4b3dc0858> I guess knn is likely to overestimate. But it's not a question of cchoosing k. It's one of methodology
[2015-07-29T01:57:07.190Z] <54e07d6515522ed4b3dc0858> Think of search queries. If real life users would look for exactly the same queries you have in your training set, 1nn can return perfect results. But that's not a realistic of interesting case.
[2015-07-29T01:59:03.001Z] <54e07d6515522ed4b3dc0858> If you "contaminate" your evaluation with this kind of data you can think your system generalizes much better than it really does.
[2015-07-29T02:00:18.461Z] <54e07d6515522ed4b3dc0858> Because the model can implicitly learn to recognize the latent group label, and then get some of the test points predicted really well
[2015-07-29T02:00:40.504Z] <54e07d6515522ed4b3dc0858> I hope this makes sense. I gtg
[2015-07-29T15:06:20.100Z] <550f53e215522ed4b3dda5f6> Excuse me, what kind of test cases should I write for some computation functions? 
[2015-07-29T15:32:25.918Z] <54d4a1d6db8155e6700f853b> which functions?
[2015-07-29T15:40:09.300Z] <550f53e215522ed4b3dda5f6> like update functions...
[2015-07-29T15:43:25.175Z] <550f53e215522ed4b3dda5f6> https://github.com/scikit-learn/scikit-learn/pull/4802/files#diff-47bf98f4dd63f89baa089da3ffe28652R650
[2015-07-29T15:46:52.184Z] <550f53e215522ed4b3dda5f6> https://github.com/scikit-learn/scikit-learn/pull/4802/files#diff-47bf98f4dd63f89baa089da3ffe28652R197
[2015-07-29T16:47:31.288Z] <54d4a1d6db8155e6700f853b> not easily ;)
[2015-07-29T16:47:44.658Z] <54d4a1d6db8155e6700f853b> you could test it against simple cases that you worked out on paper and that are easy to check?
[2015-07-29T16:48:15.394Z] <54d4a1d6db8155e6700f853b> though that is rarely the case with formulas involving digamma functions :-/
[2015-07-29T16:50:20.144Z] <54d4a1d6db8155e6700f853b> Honestly I don't know. unit-testing variational inference ....
[2015-07-29T18:07:26.513Z] <550f53e215522ed4b3dda5f6> OK.. I will try it against simple cases.
[2015-07-29T19:01:15.913Z] <54d4a1d6db8155e6700f853b> reviews for #5049 and #5047 would be very welcome so we can fix travis
[2015-07-30T15:19:14.713Z] <54d4a1d6db8155e6700f853b> do we have a way to check if a regressor or classifier supports multi-output / multi-label? cc @arjoly 
[2015-07-31T16:18:39.275Z] <54d4a1d6db8155e6700f853b> not a lot happening here at the moment ^^
[2015-07-31T16:20:32.883Z] <54e07d6515522ed4b3dc0858> I just got out from behind the Great Firewall. But I'm coming after a 35h trip. It'll be a little while before I can be of any help :(
[2015-07-31T16:24:48.850Z] <54d4a1d6db8155e6700f853b> haha yeah have a nap ;)
[2015-08-01T20:56:12.801Z] <550f53e215522ed4b3dda5f6> According to the emails from Prof.  Azzalini and Prof. Bowman, I think, we cannot use old-faithful data set without the permission of Royal Statistical Society. We cannot use data from R either, right?
[2015-08-01T20:56:35.345Z] <550f53e215522ed4b3dda5f6> @amueller @ogrisel 
[2015-08-02T15:29:40.556Z] <54e07d6515522ed4b3dc0858> @xuewei4d It probably depends, what dataset do you mean in particular?
[2015-08-02T21:23:41.656Z] <54d4a1d6db8155e6700f853b> I think based on their mails we shouldn't worry too much about including it.
[2015-08-02T21:27:55.881Z] <53135b495e986b0712efc453> could someone merge #5077? :)
[2015-08-02T22:32:22.702Z] <54d4a1d6db8155e6700f853b> why is that imporant?
[2015-08-02T22:32:23.944Z] <54d4a1d6db8155e6700f853b> but sure
[2015-08-02T23:18:04.011Z] <53135b495e986b0712efc453> When attempting to import from the old `cross_validation` module which is deprecated... I noticed a weird behaviour in ipython... simply tabcompleting brings up the deprecation warning... is that normal...?  ``` from sklearn.cross_validation import KF/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:40: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. Refer model_selection.split for more info.   "Refer model_selection.split for more info.", DeprecationWarning) ```
[2015-08-02T23:18:54.492Z] <53135b495e986b0712efc453> notice the warning start after `KF<tab>`
[2015-08-02T23:19:25.367Z] <53135b495e986b0712efc453> @amueller That was failing #4294 ;) Thanks for the merge!
[2015-08-02T23:59:12.833Z] <54e07d6515522ed4b3dc0858> That's expected if the deprecation warning is at module level AFAIK
[2015-08-02T23:59:30.904Z] <53135b495e986b0712efc453> okay! Thanks :)
[2015-08-03T01:42:25.160Z] <53135b495e986b0712efc453> Just realised we crossed 7k stars!! :beers:
[2015-08-03T11:58:54.971Z] <550f53e215522ed4b3dda5f6> It is old-faithful data set. @vene 
[2015-08-03T14:36:36.270Z] <54d4a1d6db8155e6700f853b> wb @ogrisel :)
[2015-08-03T16:37:23.392Z] <54d4a1d6db8155e6700f853b> @vene can you have a look at the discussion topics at the top of #4294 ?
[2015-08-03T18:33:20.960Z] <54e07d6515522ed4b3dc0858> sure thing
[2015-08-03T20:00:47.933Z] <54e07d6515522ed4b3dc0858> I'm slightly confused by the PR that to @rvraghav93 's branch that removes the code reuse.
[2015-08-03T20:01:19.156Z] <54e07d6515522ed4b3dc0858> Is only the newest commit relevant? That commit seems to have some extra things squashed in it.
[2015-08-03T20:15:42.398Z] <54d4a1d6db8155e6700f853b> I haven't really looked at that recently
[2015-08-03T20:15:59.466Z] <54d4a1d6db8155e6700f853b> I think we should first get the one with all the duplication merged
[2015-08-03T20:16:08.297Z] <54d4a1d6db8155e6700f853b> what do you think about making the submodules private?
[2015-08-03T20:30:32.567Z] <54e07d6515522ed4b3dc0858> with underscores?
[2015-08-03T20:31:21.454Z] <54e07d6515522ed4b3dc0858> I think it's a good idea
[2015-08-03T20:32:00.460Z] <54d4a1d6db8155e6700f853b> yes, with underscores.
[2015-08-03T20:32:20.178Z] <54d4a1d6db8155e6700f853b> ok please say in the PR, then he can do that. apart from the docs /examples that is the only major thing left.
[2015-08-05T18:26:27.957Z] <54d4a1d6db8155e6700f853b> @rvraghav93 how are things looking?
[2015-08-05T18:32:25.720Z] <53135b495e986b0712efc453> Hey thanks a lot for the reviews!! Ive fixed most... Ill fix the rest (mostly trivial) and We are merging  that pr this weekend ;) u guys will be available right?? So we could have last minute reviews?? Also do u feel that or should have +3 since its a major refactpr??
[2015-08-05T18:32:39.466Z] <53135b495e986b0712efc453> Pr*
[2015-08-05T18:33:06.173Z] <53135b495e986b0712efc453> (Apologies for typo - using my mobile :( )
[2015-08-05T23:36:53.432Z] <550f53e215522ed4b3dda5f6> Hey @amueller @ogrisel , I got some medical issues, and probably cannot work for GSoC project in the recent few days. Sorry. :worried: 
[2015-08-05T23:57:54.324Z] <54e07d6515522ed4b3dc0858> @xuewei4d sorry to hear that, get well soon!
[2015-08-06T00:00:27.176Z] <54e07d6515522ed4b3dc0858> @rvraghav93 I will be around this week. I agree a 4th person would be nice, maybe @jnothman can take a look. PS: Don't forget about the blog!
[2015-08-06T02:30:32.068Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I'll be around but I'll also have to work on some other things. When are you going to Paris.
[2015-08-06T02:30:39.239Z] <54d4a1d6db8155e6700f853b> @xuewei4d get well soon!
[2015-08-06T16:40:24.564Z] <54d4a1d6db8155e6700f853b> @ogrisel are you project owner on appveyor? we need to do something: http://help.appveyor.com/discussions/problems/2721-getting-message-error-creating-build-entry-please-contact-appveyor-support-in-every-build  otherwise all PRs have failing tests.
[2015-08-06T17:14:48.992Z] <54d4a1d6db8155e6700f853b> That was easy: https://github.com/scikit-learn/scikit-learn/pull/5093
[2015-08-06T17:24:52.840Z] <54d4a1d6db8155e6700f853b> ah, I found the appveyor integration stuff ^^ @ogrisel sent me that at some point
[2015-08-06T17:29:22.126Z] <54d4a1d6db8155e6700f853b> so the appveyor builds are running again and I'm excited to see what happens with #5093 ^^
[2015-08-06T17:42:21.919Z] <54d4a1d6db8155e6700f853b> hum.. @ogrisel I still need help :-/ https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.1490/job/26vknwf7qa70r868
[2015-08-07T11:24:55.824Z] <5478876cdb8155e6700d907b> @amueller is waiting the thing to do or is there something missing from #5037 that I can do to get it towards MRG+n's?
[2015-08-07T16:22:10.638Z] <555b8aa615522ed4b3e0a160> @betatim you can change the name of the PR with [MRG], to show you ask for some review
[2015-08-09T09:06:16.791Z] <53135b495e986b0712efc453> I feel we could add more to the doc string of the dataset loaders... (perhaps a description or at least a link?)  For example in the diabetes documentation no domain related info is given...
[2015-08-09T09:07:34.380Z] <53135b495e986b0712efc453> domain related as in no info as to what the targets represent or what the various attributes are?
[2015-08-09T09:09:06.381Z] <53135b495e986b0712efc453> @amueller @agramforte said there were delays in the visa process ;( I've tried pestering him too :P I really hope I'd be there by September at the least :|
[2015-08-09T13:02:37.328Z] <54e07d6515522ed4b3dc0858> Most of them have readmes after loading, I guess.
[2015-08-09T18:14:11.427Z] <54d4a1d6db8155e6700f853b> wasn't the diabetes fixed recently?
[2015-08-09T18:14:36.308Z] <54d4a1d6db8155e6700f853b> @rvraghav93 last time I checked there were still unresolved comments on the model selection PR.
[2015-08-09T18:19:34.900Z] <53135b495e986b0712efc453> No it is still the same AFAIK... Yes a few... I'm working on them :) I'm actually finishing up on my blog post! Will publish the same in a few mins... Would you be around? If so I'll trouble you for a review!
[2015-08-09T18:20:28.380Z] <54d4a1d6db8155e6700f853b> I can try. I'm pretty busy at the moment but I'll have a look
[2015-08-09T18:20:47.504Z] <54d4a1d6db8155e6700f853b> Does anyone know where @ogrisel is? Holidays?
[2015-08-09T18:22:55.758Z] <53135b495e986b0712efc453> `/ogrisel` ;)
[2015-08-09T18:28:08.244Z] <54d4a1d6db8155e6700f853b> ?
[2015-08-09T18:29:11.441Z] <53135b495e986b0712efc453> Performing a vim search for @ogrisel ;)
[2015-08-09T18:31:51.112Z] <54d4a1d6db8155e6700f853b> ah ^^
[2015-08-09T21:43:08.695Z] <53135b495e986b0712efc453> @amueller @vene This is my new blog post... could you check it and let me know if it looks okay?
[2015-08-09T21:43:09.792Z] <53135b495e986b0712efc453> http://rvraghav93.blogspot.in/2015/08/gsoc-2015-new-cross-validation.html
[2015-08-09T22:45:37.354Z] <54d4a1d6db8155e6700f853b> I'll check it tomorrow
[2015-08-09T22:55:47.024Z] <54d4a1d6db8155e6700f853b> Can this get another review: https://github.com/scikit-learn/scikit-learn/pull/4924 so we can merge it before  https://github.com/scikit-learn/scikit-learn/pull/4421 ?
[2015-08-09T22:55:52.914Z] <54d4a1d6db8155e6700f853b> also we should really work on https://github.com/scikit-learn/scikit-learn/pull/4421
[2015-08-10T14:03:48.000Z] <550f53e215522ed4b3dda5f6> @o
[2015-08-10T14:09:57.754Z] <550f53e215522ed4b3dda5f6> Sorry for the interruption. I am back, although not fully recovered. 
[2015-08-10T18:34:19.841Z] <550f53e215522ed4b3dda5f6> Hi @amueller @ogrisel , I just finished test cases for DP. Where should I update the mixture documentation and the mixture examples?
[2015-08-10T18:35:46.697Z] <54d4a1d6db8155e6700f853b> @xuewei4d great :) yeah, that sounds like a plan. 
[2015-08-10T18:37:02.299Z] <550f53e215522ed4b3dda5f6> I think I finished what I must do.  @ogrisel mentioned the "mixture documentation" and "mixture examples" several days ago, but I don't know where should I put.
[2015-08-10T18:38:39.607Z] <54d4a1d6db8155e6700f853b> doc/modules/mixture.rst ?
[2015-08-10T18:40:38.773Z] <550f53e215522ed4b3dda5f6> OK. Would it be better to add the animation? :wink:  
[2015-08-10T18:41:26.146Z] <54d4a1d6db8155e6700f853b> I don't think this is a priority but it would be kinda nice. The actual implementation and tests are much more important obviously. sorry for the slow reviews :-/
[2015-08-10T18:43:46.588Z] <550f53e215522ed4b3dda5f6> I agree. I think I could do the examples after the soft pencil down deadline. What else should I begin right now before next Monday?
[2015-08-10T18:44:39.999Z] <550f53e215522ed4b3dda5f6> Never mind. :sweat_smile: The equations for BGMM are really cumbersome. 
[2015-08-10T18:46:30.400Z] <54d4a1d6db8155e6700f853b> I know ;)
[2015-08-10T19:36:37.717Z] <54e07d6515522ed4b3dc0858> @rvraghav93  "in the year 2010" I'd just say "in 2010"
[2015-08-10T19:40:32.290Z] <54e07d6515522ed4b3dc0858> I think there's a methodological issue with the set up in your blog post. If you do plain Kfold in the outer loop, you can still have the same group label in the outer train and test. Why not use leave-one-label-out in both inner and outer?
[2015-08-10T19:42:10.845Z] <54e07d6515522ed4b3dc0858> So at a "big picture" level I don't see the point of the final section that looks at the folds.  I think that's common practice anyway, doesn't seem specific to nested or group-aware CV.
[2015-08-10T19:43:12.722Z] <54e07d6515522ed4b3dc0858> I would prefer if you showed an actual example of overfitting without LOLO. Your explanation of why it can happen is good, but it would be much better to illustrate it.
[2015-08-10T19:44:20.356Z] <54e07d6515522ed4b3dc0858> You suggested earlier using KNN and generating some data based on the patient id.
[2015-08-10T20:00:03.995Z] <54d4a1d6db8155e6700f853b> @xuewei4d btw were you aware that semantics of np.diag are changing? in new versions, np.diag returns a view. Not sure that is relevant, I haven't reviewed this parts in detail
[2015-08-10T21:43:04.873Z] <54e07d6515522ed4b3dc0858> also I cann't load kernelsvm.tripod.com
[2015-08-11T01:16:24.295Z] <554e8cf715522ed4b3e02ab6> '
[2015-08-11T14:16:28.796Z] <550f53e215522ed4b3dda5f6> @amueller I checked np.diag usages in my code, I think it is OK. I didn't write sth into the diagonal elements of an array.
[2015-08-11T16:08:25.505Z] <550f53e215522ed4b3dda5f6> I just added the verbose flag back into mixture modules. What else should I do before soft pencil down? @amueller @ogrisel 
[2015-08-11T17:08:38.306Z] <53135b495e986b0712efc453> @vene Thanks for the review!! I couldn't find a nice dataset to illustrate LOLO :/ There is one dataset inside the proprietary `perClass` package (small_medical... I'll have to mail them and ask if it can be used in a blog post... moreover it is a matlab package so I'll have to convert it to a csv file)   Do you have any suggestions?? Earlier I recall yourself suggesting search query... could you expand a bit on that pl??
[2015-08-11T17:10:50.540Z] <53135b495e986b0712efc453> And I can load kernelsvm.tripod.com :O That seems to be a pretty famous reference for SVR...
[2015-08-11T17:18:23.115Z] <5478876cdb8155e6700d907b> does someone know how to "restart" a appveyor build? The build for a PR failed with some weird errors that I am pretty confident have nothing to do with the contents of the PR #5037.
[2015-08-11T17:25:51.785Z] <53135b495e986b0712efc453> simplest way would be to push a commit / make some amends to your previous comment, squash and force push it...
[2015-08-11T17:30:48.363Z] <54e07d6515522ed4b3dc0858> @rvraghav93 you can always create a syntethic dataset
[2015-08-11T18:11:29.536Z] <53135b495e986b0712efc453> Okay! I'll look on how to create one... Any tips?? :)
[2015-08-11T18:11:45.709Z] <53135b495e986b0712efc453> Also could you take a look at #4919 ?
[2015-08-11T18:50:53.246Z] <5478876cdb8155e6700d907b> thanks, appveyor is doing its thing :)
[2015-08-11T18:51:16.537Z] <53135b495e986b0712efc453> :)
[2015-08-11T18:59:22.475Z] <53135b495e986b0712efc453> Appveyor doesn't seem to test the model selection module :/ Do I have to add something somewhere?
[2015-08-11T18:59:31.164Z] <53135b495e986b0712efc453> @amueller @ogrisel 
[2015-08-11T23:56:11.880Z] <54e07d6515522ed4b3dc0858> @rvraghav93 regarding the dataset: you can take the diabetes dataset and invent arbitrary group ids (as you already have), but generate a new `y` based on a formula you come up with (a function of one or two features and also of the group_id)
[2015-08-11T23:57:56.602Z] <54e07d6515522ed4b3dc0858> or you could just use `make_blobs` with a large number of blobs and arbitrarily assign half of them to the positive and half to the negative class. Then the blob assignment is the group_id.  Imagine if half a blob is in training and half in testing, a classifier like KNN will predict really well. 
[2015-08-11T23:58:15.983Z] <54e07d6515522ed4b3dc0858> Makes sense?
[2015-08-12T14:31:57.158Z] <53135b495e986b0712efc453> @amueller @vene Could you confirm if [this](https://github.com/scikit-learn/scikit-learn/pull/4294/files#r35808353) can be left untouched??
[2015-08-12T14:32:59.265Z] <53135b495e986b0712efc453> @vene Thanks!!! And yes it helps! I'll modify the example that way!! Using `make_blobs`, I will also be able to illustrate it graphically :)
[2015-08-12T14:45:14.809Z] <53135b495e986b0712efc453> Also could anyone help me with [this](https://travis-ci.org/scikit-learn/scikit-learn/jobs/75260268#L1509) failure :/ I am unable to comprehend why this test should fail :| 
[2015-08-12T15:58:01.919Z] <54e07d6515522ed4b3dc0858> @rvraghav93 regarding the failure: maybe the doctest should have the random seed fixed?
[2015-08-12T17:03:34.082Z] <54d4a1d6db8155e6700f853b> @xuewei4d btw were you aware that semantics of np.diag are changing? in new versions, np.diag returns a view. Not sure that is relevant, I haven't reviewed this parts in detail
[2015-08-12T17:03:49.986Z] <54d4a1d6db8155e6700f853b> (hm sorry sent that before)
[2015-08-12T17:05:55.030Z] <54d4a1d6db8155e6700f853b> @xuewei4d I'm sorry, I don't think I'll be able to review before the pencil down. I'm pretty busy and have to look at @rvraghav93's work. I'm not sure where @ogrisel is.
[2015-08-12T17:06:45.158Z] <54d4a1d6db8155e6700f853b> Where is loic btw?
[2015-08-12T19:24:13.673Z] <53135b495e986b0712efc453> @vene No it passes in master... it used to pass in my branch too... since I squashed a few commits I am unable to get the exact point at which it broke :sob: 
[2015-08-12T20:42:02.812Z] <54e07d6515522ed4b3dc0858> you can always git bisect
[2015-08-12T20:42:36.179Z] <54e07d6515522ed4b3dc0858> but have you tried that piece of code locally in ipython with random_state to None vs other fixed values?
[2015-08-13T10:46:17.607Z] <53135b495e986b0712efc453> Thanks!! git bisect is cool... This seems to happen after the OnlinLDA pr.. (#3659)  I'll send a PR to fix the random state... 
[2015-08-13T10:55:17.578Z] <53135b495e986b0712efc453> Wait thats not right... Fixing random_state fixes this but I am unable to figure out why master doesn't fail..
[2015-08-13T13:15:33.012Z] <54d4a1d6db8155e6700f853b> where is the random state not fixed?
[2015-08-13T13:46:24.399Z] <53135b495e986b0712efc453> https://github.com/rvraghav93/scikit-learn/commit/97d4f3eaba284c07406b82a5d75d9da8196e95e7
[2015-08-13T16:42:43.329Z] <54d4a1d6db8155e6700f853b> That's not in the LDA branch..
[2015-08-13T16:46:38.733Z] <54d4a1d6db8155e6700f853b> did you sent a PR, I didn't see it.
[2015-08-13T16:54:20.134Z] <53135b495e986b0712efc453> No... I just added it as a commit to #4294.. and yea it has nothing to do with LDA... sorry I misread git bisect output...
[2015-08-13T16:54:49.685Z] <53135b495e986b0712efc453> Also appveyor is not testing model selection... why is that?? 
[2015-08-13T17:10:32.298Z] <5478876cdb8155e6700d907b> 
[2015-08-13T17:10:35.014Z] <5478876cdb8155e6700d907b> 
[2015-08-13T17:36:00.318Z] <54d4a1d6db8155e6700f853b> ah, but the commit is not in the addition to the examples. I'm not entirely certain but maybe it's better to merge these two so they are self-contained
[2015-08-13T17:36:26.261Z] <54d4a1d6db8155e6700f853b>  s/tests/examples/
[2015-08-13T17:45:09.590Z] <53135b495e986b0712efc453> `E486: Pattern not found: tests` :p 
[2015-08-13T17:46:13.019Z] <53135b495e986b0712efc453> Ok so you mean we can merge https://github.com/rvraghav93/scikit-learn/pull/3 into #4294 right?
[2015-08-13T17:46:14.272Z] <54d4a1d6db8155e6700f853b>  s/examples/tests I mean
[2015-08-13T17:46:20.681Z] <54d4a1d6db8155e6700f853b> yes
[2015-08-13T17:46:37.643Z] <53135b495e986b0712efc453> okay I'll do it now... https://github.com/rvraghav93/scikit-learn/pull/3 is just one commit..
[2015-08-13T17:46:41.004Z] <54d4a1d6db8155e6700f853b> ok
[2015-08-13T17:46:52.139Z] <54d4a1d6db8155e6700f853b> why do you think appveyor is not testing model selection?
[2015-08-13T17:48:27.395Z] <53135b495e986b0712efc453> For the last few failures... Only travis seemed to be unhappy... appveyor didn't raise any errors... I'll confirm with a dummy failing test in a moment...
[2015-08-13T17:49:26.348Z] <53135b495e986b0712efc453> merged...
[2015-08-13T17:52:29.696Z] <53135b495e986b0712efc453> Is there a way to make travis build the documentation automatically and host it at a temporary place somewhere? (maybe using pythonanywhere.com + additional travis build just for docs)? 
[2015-08-13T17:56:51.259Z] <54d4a1d6db8155e6700f853b> we have a setup hosted on rackspace but it is non-trivial and you don't have access, sorry
[2015-08-13T17:56:54.096Z] <54d4a1d6db8155e6700f853b> we should improve that.
[2015-08-13T18:02:30.658Z] <53135b495e986b0712efc453> Could you review [this commit](https://github.com/rvraghav93/scikit-learn/commit/b5077d2f817b7c78782da3703c7cf4847809092a) which tests `_CVIterableWrapper` alone? Its a minor one... (And I did this since you said that there were no tests covering it.. (your comment got hidden..)...)
[2015-08-13T18:04:58.434Z] <54d4a1d6db8155e6700f853b> It looks ok
[2015-08-13T22:46:11.629Z] <53135b495e986b0712efc453> This is the documentation - http://rvraghav93.github.io/scikit-learn/ Once this gets an OK I think #4294 is finally done :D
[2015-08-13T22:48:27.813Z] <54e07d6515522ed4b3dc0858> @rvraghav93 that 404s for me
[2015-08-13T22:53:47.098Z] <53135b495e986b0712efc453> Sorry :/
[2015-08-13T22:54:07.119Z] <53135b495e986b0712efc453> http://rvraghav93.github.io/scikit-learn/doc/_build/html/stable/
[2015-08-14T13:53:46.469Z] <54d4a1d6db8155e6700f853b> I'll give it a (hopefully) final review this afternoon :)
[2015-08-14T15:03:56.386Z] <550f53e215522ed4b3dda5f6> Hi, how could I preview the html generated by rst file ?
[2015-08-14T15:34:24.887Z] <53135b495e986b0712efc453> Open doc/_build/html/stable/index.html in your browser :)
[2015-08-14T15:34:35.476Z] <53135b495e986b0712efc453> @amueller thanks!!
[2015-08-14T15:43:39.700Z] <550f53e215522ed4b3dda5f6> Thanks @rvraghav93 
[2015-08-14T15:44:43.911Z] <550f53e215522ed4b3dda5f6> after ```make```?
[2015-08-14T15:51:15.892Z] <550f53e215522ed4b3dda5f6> Thanks. I got it.
[2015-08-14T15:54:16.910Z] <54d4a1d6db8155e6700f853b> after make in the doc folder
[2015-08-14T17:38:47.533Z] <54d4a1d6db8155e6700f853b> @rvraghav93 there are no changes to doc/ or examples/ in #4294. did you forget to push or something?
[2015-08-14T17:41:12.351Z] <54d4a1d6db8155e6700f853b> oh, wait, I thought you merged https://github.com/rvraghav93/scikit-learn/pull/3 and https://github.com/rvraghav93/scikit-learn/pull/4 but you didn't?
[2015-08-14T17:45:36.368Z] <54d4a1d6db8155e6700f853b> the built at http://rvraghav93.github.io/scikit-learn/doc/_build/html/stable/modules/grid_search.html doesn't seem to be using the documentation change branch?
[2015-08-14T17:54:54.254Z] <54d4a1d6db8155e6700f853b> I'll review rvraghav93/scikit-learn#4 now, but it would be good to have a built of it
[2015-08-14T17:58:54.135Z] <53135b495e986b0712efc453> 2 mins! :)
[2015-08-14T18:02:54.313Z] <54d4a1d6db8155e6700f853b> sure :)
[2015-08-14T18:05:04.594Z] <53135b495e986b0712efc453> It should be updated now!! How did you detect it was not updated? (asking so I could check that part of doc and see if it reflects the change :) )
[2015-08-14T18:10:07.074Z] <54d4a1d6db8155e6700f853b> well there were no changes in the grid-search part?
[2015-08-14T18:10:25.613Z] <54d4a1d6db8155e6700f853b> it still had the header grid-search and was referencing grid_search.*
[2015-08-14T18:10:38.840Z] <53135b495e986b0712efc453> ohh okay! Now its fixed :)
[2015-08-14T18:12:43.605Z] <53135b495e986b0712efc453> And yes I didn't merge https://github.com/rvraghav93/scikit-learn/pull/4... I only merged https://github.com/rvraghav93/scikit-learn/pull/3 since I got a +1 from yourself and Vlad... Do you suggest that I merge https://github.com/rvraghav93/scikit-learn/pull/4 too?
[2015-08-14T18:21:11.354Z] <54d4a1d6db8155e6700f853b> well I wanted to give it a final pass as a whole. but I'll review the 4 now on its own
[2015-08-14T18:27:39.243Z] <54e07d6515522ed4b3dc0858> I can help
[2015-08-14T18:50:46.817Z] <54d4a1d6db8155e6700f853b> thanks @vene. I think the main question on rvraghav93/scikit-learn#4 is whether to keep the old stuff in the references
[2015-08-14T18:51:11.159Z] <54d4a1d6db8155e6700f853b> and whether to "fix" the references in the whatsnew (loads of non-links otherwise?)
[2015-08-14T18:58:03.529Z] <53135b495e986b0712efc453> @vene thanks!! yayy with all 3 of us online... its getting merged by today I suppose ;) :D
[2015-08-14T18:59:40.241Z] <54d4a1d6db8155e6700f853b> I'd actually like at least one more feedback on keeping the old methods in the references or not.
[2015-08-14T19:07:52.336Z] <54d4a1d6db8155e6700f853b> @rvraghav93 did you do "make html" in the doc folder to run all the examples? That shouldn't give any deprecation warnings wrt the move
[2015-08-14T19:08:09.305Z] <54d4a1d6db8155e6700f853b> same goes for running the tests. the old classes should be tested, but all deprecations should be caught.
[2015-08-14T19:32:40.963Z] <54d4a1d6db8155e6700f853b> @rvraghav93 does rvraghav93/scikit-learn#4  include the example fixes?
[2015-08-14T19:50:41.612Z] <54d4a1d6db8155e6700f853b> @rvraghav93 are you around?
[2015-08-14T19:51:08.448Z] <53135b495e986b0712efc453> 2 mins... the make html takes a looooong time :(
[2015-08-14T19:51:17.586Z] <54d4a1d6db8155e6700f853b> I know ;)
[2015-08-14T19:51:22.550Z] <54d4a1d6db8155e6700f853b> did you fix the other examples, though?
[2015-08-14T19:51:27.242Z] <54d4a1d6db8155e6700f853b> if so, you should push...
[2015-08-14T19:51:58.776Z] <53135b495e986b0712efc453> Example fixes were merged into #4294
[2015-08-14T19:52:33.087Z] <54d4a1d6db8155e6700f853b> cool
[2015-08-14T19:53:13.783Z] <54d4a1d6db8155e6700f853b> and the doc pr was rebased on top?
[2015-08-14T19:53:22.328Z] <53135b495e986b0712efc453> yea :)
[2015-08-14T19:53:47.490Z] <53135b495e986b0712efc453> of `model_selection` branch which includes example fixes.. yes :)
[2015-08-14T19:54:17.697Z] <54d4a1d6db8155e6700f853b> the model_selection branch doesn't include the fixes yet.
[2015-08-14T19:54:20.632Z] <54d4a1d6db8155e6700f853b> they are not in the PR
[2015-08-14T20:18:28.578Z] <53135b495e986b0712efc453> something got screwed up :sob: now I deleted the merged branch too :/ will have to redo the work... give me a few mins... its quite trivial only...
[2015-08-14T20:20:19.773Z] <53135b495e986b0712efc453> yay I was able to recover it as a patch from [here](https://github.com/rvraghav93/scikit-learn/commit/beec231002e722ea19a494dfc411140ac6327842) :D
[2015-08-14T20:24:10.643Z] <54e07d6515522ed4b3dc0858> with git, things are rarely truly lost
[2015-08-14T21:15:02.361Z] <54d4a1d6db8155e6700f853b> :)
[2015-08-14T21:15:08.770Z] <54d4a1d6db8155e6700f853b> also, have a look at the reflog command
[2015-08-14T22:40:32.223Z] <54d4a1d6db8155e6700f853b> @rvraghav93 sorry I gotta run. I'll continue reviewing tomorrow
[2015-08-18T10:26:12.853Z] <555e110715522ed4b3e0bd50> Anyone interested in giving some feedback on https://github.com/scikit-learn/scikit-learn/pull/5123 ? 
[2015-08-18T14:15:41.941Z] <54d4a1d6db8155e6700f853b> @basveeling sorry, feedback often takes some time. It sounds like a good idea to me, though I'm not the authority on this subject.
[2015-08-18T14:16:26.245Z] <54d4a1d6db8155e6700f853b> When designing the classifiers, we didn't have "most entries are zero all the time" in mind, which is the case for hashing.
[2015-08-18T16:36:44.300Z] <555e110715522ed4b3e0bd50> @amueller no worries, thanks for the feedback! I'll spend some more time on benchmarking the sparse structure
[2015-08-18T19:06:59.806Z] <54e07d6515522ed4b3dc0858> @rvraghav93: gentle reminder that Friday is the firm GSoC pencils-down date.
[2015-08-19T13:04:36.842Z] <53135b495e986b0712efc453> Apologies for the delay!! I got my French work permit and am shopping some stuff and also applying for the visa :D I'll finish the documentation comments by today!!
[2015-08-19T15:40:38.215Z] <54d4a1d6db8155e6700f853b> sweet @rvraghav93 ! congratulations!
[2015-08-25T17:34:06.424Z] <54d4a1d6db8155e6700f853b> ping @vighneshbirodkar we often hang out here for discussions, too [though the more we stay on github the better]
[2015-08-25T18:15:10.806Z] <53810862048862e761fa2887> Cool
[2015-08-25T18:50:01.367Z] <54d4a1d6db8155e6700f853b> @ogrisel btw I didn't have time to look into the doc build server. do you think you'll find time?
[2015-09-01T15:21:59.524Z] <54d4a1d6db8155e6700f853b> @rvraghav93 how are things? I haven't heard from you in a while...
[2015-09-04T18:42:51.519Z] <53135b495e986b0712efc453> Hey!! Looking for apartments in Paris ;( Looks like I'll get the Visa only after I confirm the accom... and I won't be getting accom from univ... Hoping to be there atleast by Sept end/Oct 1st
[2015-09-04T18:43:53.516Z] <53135b495e986b0712efc453> I'll have to finish up the documentation no? Sorry It won't be delayed anymore... I'll do this in a day or two... Only a very few comments to be fixed up...
[2015-09-08T14:49:30.945Z] <54d4a1d6db8155e6700f853b> @ogrisel are you around?
[2015-09-09T20:49:17.593Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar I think this would be interesting to work on: https://github.com/scikit-learn/scikit-learn/issues/4920
[2015-09-09T21:14:01.865Z] <54d4a1d6db8155e6700f853b> does anyone have opinions about including issue numbers into whatsnew?
[2015-09-09T22:33:05.883Z] <54e07d6515522ed4b3dc0858> Just that sklearn will outlive github
[2015-09-09T22:33:11.924Z] <54e07d6515522ed4b3dc0858> :)
[2015-09-09T22:33:43.060Z] <54d4a1d6db8155e6700f853b> well we can stop using them then ;) Also, outlive the existence of github or the use?
[2015-09-09T22:34:02.057Z] <54d4a1d6db8155e6700f853b> As long as the links still work it might be useful, even if we transition to the next version control system ;)
[2015-09-09T22:41:51.406Z] <54e07d6515522ed4b3dc0858> Possibly the existence. But we could always save a copy of the issue text.
[2015-09-09T22:42:20.946Z] <54e07d6515522ed4b3dc0858> It seems useful to have the numbers. 
[2015-09-10T00:27:51.023Z] <53135b495e986b0712efc453> I just got a stop gap accommodation till Dec 31 thanks to Mainak Jas and Airbnb... I am back... @amueller is there anything I need to worry about w.r.t this comment? (https://github.com/scikit-learn/scikit-learn/pull/4270#issuecomment-136450796) 
[2015-09-10T00:37:36.921Z] <54d4a1d6db8155e6700f853b> @rvraghav93 Great to have you back!
[2015-09-10T00:37:53.714Z] <54d4a1d6db8155e6700f853b> No, it's just that we won't include the model selection changes in the upcoming release.
[2015-09-10T00:38:00.198Z] <54d4a1d6db8155e6700f853b> Still it would be great to get them done soon
[2015-09-10T00:38:21.536Z] <53135b495e986b0712efc453> Okay!! :D and thanks :)
[2015-09-10T13:27:27.356Z] <541a528b163965c9bc2053de> @amueller I have rebased the LDA deprecation in #5245. Let's wait for CI to check that I did not break anything in the process.
[2015-09-10T13:40:06.826Z] <54d4a1d6db8155e6700f853b> thanks cool :)
[2015-09-10T13:41:27.237Z] <54d4a1d6db8155e6700f853b> Do you maybe want to have a look at #4924 ?
[2015-09-10T14:11:22.273Z] <54d4a1d6db8155e6700f853b> also #5236
[2015-09-10T14:15:12.805Z] <541a528b163965c9bc2053de> For #4924, it will need to be updated to work on top of #5245.
[2015-09-10T14:17:22.035Z] <54d4a1d6db8155e6700f853b> yeah but that should be a quick change that either of us can do if it has two reviews
[2015-09-10T14:18:06.017Z] <54d4a1d6db8155e6700f853b> do you have any opinion on adding PR links to whatsnew?
[2015-09-10T14:29:15.588Z] <541a528b163965c9bc2053de> I gave my +1
[2015-09-10T14:31:23.142Z] <541a528b163965c9bc2053de> > do you have any opinion on adding PR links to whatsnew? I am fine with it. It would be great to add the PR numbers on all of the items but that sounds tedious to do :)
[2015-09-10T14:32:33.985Z] <541a528b163965c9bc2053de> I will have to run soon to take my shuttle. I will be busy tonight so I don't think will be able to work on the release much more today. I should be able to focus on that tomorrow though.
[2015-09-10T14:36:24.409Z] <541a528b163965c9bc2053de> You might want to have a look at #5104 as well.
[2015-09-10T14:59:13.992Z] <54d4a1d6db8155e6700f853b> cool. have fun tonight :)
[2015-09-10T18:54:26.096Z] <53810862048862e761fa2887> `LabelEncoder` right now is doing a binary search using `np.searchsorted`. Can't we speed that up by using a dictionary ?
[2015-09-11T02:10:02.535Z] <53135b495e986b0712efc453> @amueller @vene Do we need `LabelKFold` in #4294? Why can't we just pass the labels in `split(X, y, labels)` instead of having a new class? (Same for `LabelShuffleSplit`)
[2015-09-11T02:38:01.695Z] <53135b495e986b0712efc453> @ogrisel appveyor doesn't test model selection
[2015-09-11T02:39:52.206Z] <53135b495e986b0712efc453> [![appveyor.png](https://files.gitter.im/scikit-learn/scikit-learn/x9Q7/thumb/appveyor.png)](https://files.gitter.im/scikit-learn/scikit-learn/x9Q7/appveyor.png)
[2015-09-11T02:41:11.602Z] <53135b495e986b0712efc453> [![appveyor2.png](https://files.gitter.im/scikit-learn/scikit-learn/gKbL/thumb/appveyor2.png)](https://files.gitter.im/scikit-learn/scikit-learn/gKbL/appveyor2.png)
[2015-09-11T02:41:53.060Z] <53135b495e986b0712efc453> 1st image you can see one of appveyor builds passing successfully despite a failing test in model_selection, in the 2nd you can see travis working correctly...
[2015-09-11T02:43:24.157Z] <53135b495e986b0712efc453> https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.2085/job/qd27oykpd2ubc1yr#L3734 - After `sklearn.mixture` `sklearn.model_selection` should have been tested...
[2015-09-11T02:43:30.999Z] <53135b495e986b0712efc453> Any clues to debug this?
[2015-09-11T05:27:37.442Z] <53135b495e986b0712efc453> [![appveyorfinal.png](https://files.gitter.im/scikit-learn/scikit-learn/KW30/thumb/appveyorfinal.png)](https://files.gitter.im/scikit-learn/scikit-learn/KW30/appveyorfinal.png)
[2015-09-11T14:13:30.655Z] <55901c1b15522ed4b3e2f949> The newest merge seems to have modified _tree.c
[2015-09-11T14:13:55.090Z] <541a528b163965c9bc2053de> which merge?
[2015-09-11T14:14:17.182Z] <55901c1b15522ed4b3e2f949> "ENH add sag solver in LinearRegression and Ridge"
[2015-09-11T14:14:38.132Z] <541a528b163965c9bc2053de> indeed
[2015-09-11T14:14:45.580Z] <541a528b163965c9bc2053de> git log sklearn/tree/_tree.c
[2015-09-11T14:14:58.897Z] <541a528b163965c9bc2053de> I will recythonize it from the current _tree.pyx
[2015-09-11T14:15:25.431Z] <55901c1b15522ed4b3e2f949> coolios. Weird that it got changed
[2015-09-11T14:15:53.618Z] <541a528b163965c9bc2053de> running the tests locally to check that I did no break anything.
[2015-09-11T14:15:58.435Z] <541a528b163965c9bc2053de> yeah
[2015-09-11T14:27:36.667Z] <541a528b163965c9bc2053de> pushed the cythonized tree code to master directly
[2015-09-11T14:28:13.395Z] <55901c1b15522ed4b3e2f949> appveyor is failing?
[2015-09-11T14:28:23.138Z] <55901c1b15522ed4b3e2f949> or is that from the previous tree code
[2015-09-11T14:28:54.955Z] <55901c1b15522ed4b3e2f949> ah, appveyor is really behind
[2015-09-11T14:29:25.916Z] <541a528b163965c9bc2053de> here is the state of the queue: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/history
[2015-09-11T14:29:51.032Z] <55901c1b15522ed4b3e2f949> okay, cool
[2015-09-11T14:30:25.790Z] <541a528b163965c9bc2053de> @rvraghav93 which PR is that?
[2015-09-11T14:30:41.759Z] <541a528b163965c9bc2053de> appveyor does not run the doctests, maybe a doctest is failing?
[2015-09-11T15:06:09.829Z] <54d4a1d6db8155e6700f853b> @ogrisel I'm in ;)
[2015-09-11T15:06:13.774Z] <54d4a1d6db8155e6700f853b> sorry meetings stuff
[2015-09-11T15:07:28.156Z] <541a528b163965c9bc2053de> no pbm
[2015-09-11T15:09:22.033Z] <54d4a1d6db8155e6700f853b> I'll do #5104 and then the tsne example
[2015-09-11T15:09:37.336Z] <54d4a1d6db8155e6700f853b> the mlp is starting to look good btw #5214
[2015-09-11T15:09:47.881Z] <541a528b163965c9bc2053de> #5245 should be good to go (it's just appveyor that is slow as a dog today)
[2015-09-11T15:12:47.258Z] <54d4a1d6db8155e6700f853b> have you seen this: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.2086/job/drvmlx86c9swelx4 ?
[2015-09-11T15:13:27.437Z] <54d4a1d6db8155e6700f853b> #5206 should also be ok, but could be made shorter
[2015-09-11T15:14:16.805Z] <541a528b163965c9bc2053de> > have you seen this: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.2086/job/drvmlx86c9swelx4 ?  Hum that's bad
[2015-09-11T15:18:48.331Z] <54d4a1d6db8155e6700f853b> yeah
[2015-09-11T15:18:52.791Z] <54d4a1d6db8155e6700f853b> this is also new to me: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.2090/job/toaww87ohll9pxv9
[2015-09-11T15:19:31.848Z] <54d4a1d6db8155e6700f853b> wait that is the same
[2015-09-11T15:19:35.419Z] <54d4a1d6db8155e6700f853b> sorry
[2015-09-11T15:19:55.591Z] <541a528b163965c9bc2053de> That's weird that it only fails on 32 bit Python, both 2 and 3. It's seems completely unrelated to the architecture.
[2015-09-11T15:20:32.764Z] <541a528b163965c9bc2053de> maybe it's just random?
[2015-09-11T15:21:43.634Z] <541a528b163965c9bc2053de> the fact that we get it with Python 2 is really weird: it means that it cannot be caused by the use of the multiprocessing context /  start method in  joblib because this does not exist under Python 2.
[2015-09-11T15:22:31.137Z] <54d4a1d6db8155e6700f853b> here the failing pattern is different: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.2090
[2015-09-11T15:23:00.089Z] <53135b495e986b0712efc453> @ogrisel #4294 And no it was not a doctest... I specifically made a failing test inside model selection to confirm my observation... :)
[2015-09-11T15:24:53.052Z] <541a528b163965c9bc2053de> maybe this is caused by a change in the way nose run the tests.
[2015-09-11T15:25:21.808Z] <541a528b163965c9bc2053de> I will open an issue to track this problem
[2015-09-11T15:25:48.932Z] <53135b495e986b0712efc453> ~~Okay but this is localized to model_selection right? maybe I am doing something incorrectly?~~
[2015-09-11T15:27:16.962Z] <53135b495e986b0712efc453> Also @amueller @vene do we need the new `LabelKFold` and `LabelShuffleSplit` as separate classes or can we specify the labels in `split(X, y, labels)` in the (new) `KFold` class itself?
[2015-09-11T15:27:26.492Z] <541a528b163965c9bc2053de> #5254
[2015-09-11T15:28:09.533Z] <541a528b163965c9bc2053de> @rvraghav93 your issue is probably not related to the appveyor problem we are discussing (which has to do with multiprocessing #5254)
[2015-09-11T15:28:32.955Z] <53135b495e986b0712efc453> Oh sorry I thought it was a reply to my comment... :D Any ideas on how to debug mine?
[2015-09-11T15:30:22.220Z] <541a528b163965c9bc2053de> @rvraghav93 do you have a windows machine at hand? you can try to replicate it locally by following the install stepts in appveyor.yml
[2015-09-11T15:35:15.664Z] <54d4a1d6db8155e6700f853b> @rvraghav93 they do somewhat different things. What is the benefit of putting them in the same class?
[2015-09-11T15:42:41.884Z] <53135b495e986b0712efc453> `LabelKFold` is `KFold` with `labels` (somewhat like group labels) specifying  that the points in the same label should not be used for both testing and training right? Would it benefit from grouping together?
[2015-09-11T16:39:49.267Z] <541a528b163965c9bc2053de> @amueller unfortunately I will have to leave soon and won't be able to work on the release this WE. I think we should fix the appveyor issue before cutting the branch. I have opened a PR there #5255 to try a quickfix even though I don't understand the problem.
[2015-09-11T16:40:04.977Z] <541a528b163965c9bc2053de> I can work on that on monday if that does not work
[2015-09-11T16:40:53.924Z] <541a528b163965c9bc2053de> I added some quick benchmark in the comments of #5253.
[2015-09-11T16:47:45.723Z] <541a528b163965c9bc2053de> appveyor has a network problem on the fast infra and so the queue is running on the old Azure based infra
[2015-09-11T16:47:57.040Z] <541a528b163965c9bc2053de> this is why the build are slower than usual
[2015-09-11T16:48:19.881Z] <541a528b163965c9bc2053de> I don't know if that explains the weird multiprocessing issue though (it seems unlikely)
[2015-09-11T16:48:28.069Z] <541a528b163965c9bc2053de> ok I have to go
[2015-09-11T16:48:30.997Z] <541a528b163965c9bc2053de> see you later
[2015-09-11T17:27:52.999Z] <54d4a1d6db8155e6700f853b> ok ttyl. Can you work on the release next week?
[2015-09-11T17:50:13.074Z] <53135b495e986b0712efc453> @amueller @vene Actually that won't make sense especially when we want to group `Stratified{KFold|ShuffleSplit}` and `{KFold|ShuffleSplit}` together making stratify an option as suggested by Joel! Sorry for the noise... I'll add it as such :)
[2015-09-12T17:54:30.696Z] <55901c1b15522ed4b3e2f949> AppVeyor tweeted about slow performance recently; I guess that's what is holding up all the tests
[2015-09-13T00:58:34.071Z] <54d4a1d6db8155e6700f853b> @ogrisel the MLP is good to go, too, I think. do you want to merge it after release or before? I don't really see a reason not to merge now.
[2015-09-13T14:02:57.353Z] <553e8e1015522ed4b3df97f7> Hey guys, can we merge this? https://github.com/scikit-learn/scikit-learn/pull/4525
[2015-09-13T15:25:31.002Z] <54d4a1d6db8155e6700f853b> I think so. You have my +!
[2015-09-13T15:25:32.435Z] <54d4a1d6db8155e6700f853b> +1
[2015-09-13T15:28:37.346Z] <55901c1b15522ed4b3e2f949> I'm taking a quick look as well
[2015-09-13T15:30:47.800Z] <55901c1b15522ed4b3e2f949> Looks great, thanks for the work!
[2015-09-13T15:32:05.683Z] <55901c1b15522ed4b3e2f949> @rvraghav93 what is the status of your issue? I have a windows machine, I can take a quick look.
[2015-09-13T15:40:27.709Z] <54d4a1d6db8155e6700f853b> which issue is that?
[2015-09-13T15:43:06.584Z] <55901c1b15522ed4b3e2f949> I'm not sure, I just saw Olivier asked if he had a windows machine to reproduce an Appveyor issue,.
[2015-09-13T15:46:59.889Z] <54d4a1d6db8155e6700f853b> ah that is the joblib one that keeps appveyor from failing
[2015-09-13T15:47:06.402Z] <54d4a1d6db8155e6700f853b> just run the test suite
[2015-09-13T15:47:51.932Z] <55901c1b15522ed4b3e2f949> no, the joblib issue is a separate issue
[2015-09-13T15:48:05.179Z] <54d4a1d6db8155e6700f853b> ok then I don't know which one we are talking about
[2015-09-13T15:48:51.708Z] <55901c1b15522ed4b3e2f949> > [![appveyor2.png](https://files.gitter.im/scikit-learn/scikit-learn/gKbL/thumb/appveyor2.png)](https://files.gitter.im/scikit-learn/scikit-learn/gKbL/appveyor2.png)
[2015-09-13T16:01:27.728Z] <53135b495e986b0712efc453> @jmschrei thanks a lot!! In my PR #4294 the tests in the new module `model_selection` are not being run in appveyor... Any help would be really awesome!! :) I could use virtual box... but earlier I had little success doing so :(
[2015-09-13T16:03:45.840Z] <55901c1b15522ed4b3e2f949> That is a lot of files changed.
[2015-09-13T16:04:28.272Z] <53135b495e986b0712efc453> Yea :grin: 
[2015-09-13T16:06:16.238Z] <55901c1b15522ed4b3e2f949> You'll squash all these commits soon?
[2015-09-13T16:06:20.166Z] <53135b495e986b0712efc453> You can replicate that by simply creating a foo folder and a tests directory with a simple failing test :)
[2015-09-13T16:06:49.172Z] <53135b495e986b0712efc453> Yes that's a whole lot of commits ;) I'll probably squash it to less than 5
[2015-09-13T16:07:07.689Z] <53135b495e986b0712efc453> It will help tracking things easier.... 
[2015-09-13T16:09:47.349Z] <55901c1b15522ed4b3e2f949> I don't understand, is this a PR meant to refactor CV or reorganize the modules?
[2015-09-13T16:10:33.246Z] <53135b495e986b0712efc453> Both :p
[2015-09-13T16:11:17.804Z] <53135b495e986b0712efc453> Refractor as in making then data dependent... and reorganise into `model_selection` folder
[2015-09-13T16:11:35.995Z] <53135b495e986b0712efc453> *independent
[2015-09-13T16:13:07.632Z] <55901c1b15522ed4b3e2f949> Alright, I'm just going to look for bugs, this conversation is too long for me.
[2015-09-13T16:13:53.735Z] <53135b495e986b0712efc453> Haha okay :)
[2015-09-13T16:30:35.997Z] <55901c1b15522ed4b3e2f949> After months of developing in Ubuntu, I am remembering why Windows is such a pain.
[2015-09-13T16:34:42.478Z] <53135b495e986b0712efc453> ^_^
[2015-09-13T16:43:40.778Z] <54e07d6515522ed4b3dc0858> @rvraghav93 could you clarify what about the labels param I should comment on?
[2015-09-13T16:48:24.346Z] <55901c1b15522ed4b3e2f949> I am getting 12 failures
[2015-09-13T16:48:28.911Z] <55901c1b15522ed4b3e2f949> Mostly related to string format
[2015-09-13T16:48:57.739Z] <55901c1b15522ed4b3e2f949> Is this what you are getting, @rvraghav93 
[2015-09-13T17:15:13.949Z] <55901c1b15522ed4b3e2f949> These errors seem to stem from getting longs instead of ints
[2015-09-13T17:15:34.467Z] <55901c1b15522ed4b3e2f949> This manifests as getting (10L, 2L) instead of (10, 2)
[2015-09-13T17:37:07.206Z] <54d4a1d6db8155e6700f853b> I think we should fix these. @ogrisel didn't want to fix them I think.
[2015-09-13T17:37:31.269Z] <54d4a1d6db8155e6700f853b> I mean it does add clutter to the docstrings, but it is not rendered on the webpage
[2015-09-13T18:19:38.537Z] <55901c1b15522ed4b3e2f949> Is there any way to force numpy to use ints? I'm not finding anything, unfortunately.
[2015-09-13T18:19:47.731Z] <55901c1b15522ed4b3e2f949> In the shape, I mean.
[2015-09-14T00:32:16.156Z] <53135b495e986b0712efc453> @jmschrei No my concern is that the model_selection tests are not at all run by appveyor... only travis seems to detect the module and run the tests... 
[2015-09-14T00:38:37.521Z] <53135b495e986b0712efc453> Is that because there are no public python sources in `model_selection`? (all three are private)
[2015-09-14T05:17:12.453Z] <53135b495e986b0712efc453> @vene You had earlier said that the doc for labels param was not apt... Does `" Class labels to be assigned to the samples and used while splitting the dataset into test/train set."` sound like a good doc for `labels` param?
[2015-09-14T05:17:25.178Z] <53135b495e986b0712efc453> (of `split(X, y, labels)`?)
[2015-09-14T07:16:31.680Z] <55901c1b15522ed4b3e2f949> The unit tests are failing on my machine. raise self.failureException("ImportError('No module named sag_fast'm) != None")
[2015-09-14T07:16:52.394Z] <55901c1b15522ed4b3e2f949> Ubuntu 64 bit, they were all running fine on Friday.
[2015-09-14T07:34:11.768Z] <55e5c37d0fc9f982beaf4d61> did you miss a make in ?
[2015-09-14T07:37:14.458Z] <55901c1b15522ed4b3e2f949> Yep
[2015-09-14T13:19:10.150Z] <54d4a1d6db8155e6700f853b> @rvraghav93 it shouldn't be "class labels" they are not class labels. maybe group labeles?
[2015-09-14T13:19:23.344Z] <54d4a1d6db8155e6700f853b> also not really assigned to the samples?
[2015-09-14T16:25:44.499Z] <553e8e1015522ed4b3df97f7> Guys, I opened this PR https://github.com/scikit-learn/scikit-learn/pull/5271 to fix a minor typo in doc/modules/neighbors.rst L470
[2015-09-14T16:28:36.178Z] <553e8e1015522ed4b3df97f7> I'll do a git grep to check for more typos, if there are any
[2015-09-14T16:31:20.223Z] <553e8e1015522ed4b3df97f7> :sweat_smile: 
[2015-09-19T13:03:30.429Z] <53135b495e986b0712efc453> how about `"Group labels for the samples used while splitting the dataset into test/train set."`?
[2015-09-19T13:03:35.907Z] <53135b495e986b0712efc453> @amueller @vene 
[2015-09-19T13:06:38.071Z] <53135b495e986b0712efc453> This would be for all the `labels` parameter in `.*Label.*` classes...
[2015-09-19T18:07:06.951Z] <54d4a1d6db8155e6700f853b> yes that sounds good
[2015-09-20T06:59:00.077Z] <53135b495e986b0712efc453> @amueller @vene I've fixed the documentation and the `labels` param... I've hosted the doc (with examples and all the new changes but without plots) [here](http://rvraghav93.github.io/doc_builds)
[2015-09-20T07:00:04.427Z] <53135b495e986b0712efc453> The doc with plots is building... It will hopefully get over in a few hours and I'll host it once its done...
[2015-09-20T07:01:36.220Z] <53135b495e986b0712efc453> Ah one more thing... the appveyor not testing the `model_selection` is not yet fixed... :/ I suspect its because that module has not public python files? That would be the only thing left to investigate apart from your final reviews on rvraghav93/scikit-learn#4
[2015-09-20T07:02:04.615Z] <53135b495e986b0712efc453> And moving `grid_search.rst` to `search.rst` once the review is over :)
[2015-09-21T15:44:19.780Z] <54d4a1d6db8155e6700f853b> Thanks @rvraghav93. I'll try to review soon. I have a couple of hundred emails I need to read, and we want to release this week, though
[2015-09-21T15:44:55.276Z] <54d4a1d6db8155e6700f853b> @ogrisel (or anyone else) do you remember the recent blog post that explained tree-based models as linear combinations ?
[2015-09-21T17:01:29.671Z] <55901c1b15522ed4b3e2f949> @amueller do you mean Tianqis?
[2015-09-21T17:02:03.048Z] <55901c1b15522ed4b3e2f949> https://github.com/scikit-learn/scikit-learn/pull/5222
[2015-09-21T23:07:57.665Z] <54d4a1d6db8155e6700f853b> I don't think that was it. there was a way to explain the prediction made for a single point as a simple function of the features somehow
[2015-09-22T00:43:19.128Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/5293 reviews for 0.17?
[2015-09-22T16:20:23.384Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar This one would be good to fix: https://github.com/scikit-learn/scikit-learn/issues/5089
[2015-09-22T16:22:59.489Z] <53810862048862e761fa2887> Can @amueller or someone else OK this ? https://github.com/scikit-learn/scikit-learn/pull/5234
[2015-09-22T16:23:16.539Z] <53810862048862e761fa2887> It is a minor change and can be easily included in the upcoming release
[2015-09-22T16:35:09.919Z] <53810862048862e761fa2887> @amueller There are some warnings due to PIL not being there. I can either install PIL on travis or skip those tests like this https://github.com/scikit-image/scikit-image/blob/master/skimage/future/graph/tests/test_rag.py#L51
[2015-09-22T17:59:14.245Z] <54d4a1d6db8155e6700f853b>  scikit-learn/scikit-learn#5234 already has my +1
[2015-09-26T20:48:46.596Z] <53135b495e986b0712efc453> @vene would you be coming for the sprint?? :) - https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events
[2015-09-26T20:49:31.546Z] <54e07d6515522ed4b3dc0858> Unfortunately not :(
[2015-09-26T20:49:47.650Z] <53135b495e986b0712efc453> ;(
[2015-09-26T20:50:04.548Z] <53135b495e986b0712efc453> May I ask - funding or busy?? :)
[2015-09-26T20:52:04.294Z] <54e07d6515522ed4b3dc0858> Both... I'm in a slightly awkward position in my PhD
[2015-09-26T20:52:37.702Z] <54e07d6515522ed4b3dc0858> I might visit Paris in the winter though
[2015-09-26T20:54:24.657Z] <53135b495e986b0712efc453> Thats great!! when??
[2015-09-26T20:54:55.957Z] <54e07d6515522ed4b3dc0858> No clue, it's just hope for now.
[2015-09-26T20:56:00.181Z] <53135b495e986b0712efc453> Okay!! See you there ;) 
[2015-09-27T00:38:45.245Z] <53135b495e986b0712efc453> @amueller reviews for  rvraghav93/scikit-learn#4 please? :grin:
[2015-09-27T00:39:05.892Z] <53135b495e986b0712efc453> (2 comments of Joel are yet  to be addressed there)
[2015-09-27T17:21:38.746Z] <54d4a1d6db8155e6700f853b> Sorry I'm still quite sick and stressed. I'll get to it asap
[2015-09-28T18:12:10.911Z] <53135b495e986b0712efc453> Oh!! Okay get well soon :)
[2015-10-02T21:45:11.197Z] <54c084dbdb8155e6700eed4c> I'm toying with the idea of doing a PyData NYC pilgrimage next month. Anyone planning on being there? Chance for a sklearn sprint perhaps?
[2015-10-02T21:51:37.232Z] <53810862048862e761fa2887> Count me in
[2015-10-05T14:30:22.321Z] <53135b495e986b0712efc453> Do we need to have the notifications for test failures in gitter activity bar... wouldn't notifications on PR activity suffice?
[2015-10-05T14:30:34.379Z] <53135b495e986b0712efc453> @ogrisel 
[2015-10-05T14:33:52.466Z] <541a528b163965c9bc2053de> @rvraghav93 we can try adding them in gitter. If it's too noisy, we can remove it.
[2015-10-06T14:06:38.406Z] <53135b495e986b0712efc453> Okay :)
[2015-10-06T14:22:00.025Z] <53135b495e986b0712efc453> BTW from discussions at #4254 I don't think #4225 will be in soon... Should it still be tagged 1.7?
[2015-10-06T17:00:25.584Z] <541a528b163965c9bc2053de> I agree, re-tagged.
[2015-10-06T19:59:41.589Z] <5612e60ad33f749381a8600b> Where is the best place to find help on deprecation issues for scikit?  I'm having trouble using Multilabelbinarizer and neither stackoverflow nor googling are helping.
[2015-10-06T20:01:59.342Z] <53135b495e986b0712efc453> What kind of issue?
[2015-10-06T20:05:19.917Z] <5612e60ad33f749381a8600b> I'm trying to use the accuracy_score function (or even the Confusion matrix function) and I've transformed my Ytest using an multilabel binarizer so it's type is "multilabel-indicator" but the predicted values are in the form of binary.
[2015-10-06T20:06:10.781Z] <5612e60ad33f749381a8600b> so I get a "ValueError: Can't handle mix of multilabel-indicator and binary" error, but multilabel-indicator seems to be supported according to line 93 in classification.py
[2015-10-07T09:11:07.514Z] <541a528b163965c9bc2053de> @TracyMRohlin please write this a small reproduction code snippet on small random data (e.g. using `np.random.randn` and such) and post it as a question on stackoverflow. If you think this is a bug, post it as an issue on the scikit-learn issue tracker instead.
[2015-10-07T14:37:34.432Z] <53135b495e986b0712efc453> #3123 can be closed!
[2015-10-07T14:44:51.800Z] <53135b495e986b0712efc453> @ogrisel Manoj wants you to review his #4242 if possible :P 
[2015-10-07T14:45:50.040Z] <541a528b163965c9bc2053de> I would like to focus on bug fixing for the release this week...
[2015-10-07T14:54:05.914Z] <53135b495e986b0712efc453> Okay :)
[2015-10-07T16:24:28.516Z] <53135b495e986b0712efc453> @TomDLT Can I take #4523 up?
[2015-10-07T16:47:11.771Z] <555b8aa615522ed4b3e0a160> yes sure!
[2015-10-09T14:56:35.066Z] <53135b495e986b0712efc453> @ogrisel I feel #4826 can be included in 0.17?? It was already [reviewed by Andy](https://github.com/scikit-learn/scikit-learn/pull/4826#issuecomment-125715318) a second review should make it merge-able? 
[2015-10-09T16:43:23.374Z] <54d4a1d6db8155e6700f853b> opening my sklearn inbox now
[2015-10-09T16:45:10.903Z] <54d4a1d6db8155e6700f853b> everybody brace themselves for spam
[2015-10-09T16:45:16.411Z] <54d4a1d6db8155e6700f853b> (by me)
[2015-10-09T16:54:01.548Z] <53135b495e986b0712efc453> I'm eagerly waiting ;)
[2015-10-09T16:58:31.411Z] <54d4a1d6db8155e6700f853b> did https://github.com/scikit-learn/scikit-learn/pull/4826
[2015-10-09T17:13:32.821Z] <530c03e25e986b0712efafb8> What is the right way to get a nice unique and consistent hash value for an estimator?
[2015-10-09T17:13:47.657Z] <530c03e25e986b0712efafb8> can I hash something like `type(est), est.get_params(), ...`?
[2015-10-09T18:10:55.105Z] <54d4a1d6db8155e6700f853b> with or without the part that is estimated from data? Without that should cover it.
[2015-10-09T18:11:16.255Z] <530c03e25e986b0712efafb8> lets say *with*
[2015-10-09T18:11:18.654Z] <54d4a1d6db8155e6700f853b> If est.get_params() contains a random state, we probably need to fix it to something?
[2015-10-09T18:11:21.849Z] <530c03e25e986b0712efafb8> or rather, optionally with
[2015-10-09T19:59:14.747Z] <54d4a1d6db8155e6700f853b> well with is harder. I think we opted for storing the data along, right? I think storing the class, get_params, and the data is enough. With a fixed random_state that is.
[2015-10-09T20:00:13.383Z] <54d4a1d6db8155e6700f853b> actually, what is the definition of unique consistent hash?
[2015-10-09T20:02:31.613Z] <54d4a1d6db8155e6700f853b> should they be the same if a) they are the same object [probably not] b) they behave the same way? c) they are the same in memory? I guess the answer is c)?
[2015-10-09T20:15:55.488Z] <530c03e25e986b0712efafb8> I'm trying to solve this more generally and in isolation from the dasklearn project.  Is there a consistent set of attributes on a BaseEstimator that define it?  After I call `estimator.fit(X)`is there a set of attributes on the object that I can consistently check?  Or does this vary estimator-to-estimator?
[2015-10-09T20:38:45.113Z] <53135b495e986b0712efc453> If I understand you correctly, What you require is partly similar to the model similarity checking problem at #4841 AFAIK you can only have a relative equality check and not a(n) (absolute) hash value that can uniquely identify a fit-model...
[2015-10-09T22:17:53.430Z] <541a528b163965c9bc2053de> @mrocklin beware of `est.get_params(deep=True)` that includes both the subestimator instances and their params
[2015-10-09T22:18:59.261Z] <541a528b163965c9bc2053de> e.g.: ```python >>> from sklearn.svm import SVC >>> from sklearn.decomposition import PCA >>> from sklearn.pipeline import make_pipeline >>> p = make_pipeline(PCA(3), SVC()) >>> p.get_params(deep=True) {'svc__probability': False, 'svc__decision_function_shape': None, 'svc__degree': 3, 'pca__copy': True, 'svc__tol': 0.001, 'svc': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,   decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',   max_iter=-1, probability=False, random_state=None, shrinking=True,   tol=0.001, verbose=False), 'steps': [('pca', PCA(copy=True, n_components=3, whiten=False)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,   decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',   max_iter=-1, probability=False, random_state=None, shrinking=True,   tol=0.001, verbose=False))], 'svc__cache_size': 200, 'svc__max_iter': -1, 'pca__n_components': 3, 'svc__coef0': 0.0, 'pca__whiten': False, 'svc__shrinking': True, 'pca': PCA(copy=True, n_components=3, whiten=False), 'svc__gamma': 'auto', 'svc__verbose': False, 'svc__C': 1.0, 'svc__kernel': 'rbf', 'svc__class_weight': None, 'svc__random_state': None} ```
[2015-10-09T22:20:22.821Z] <541a528b163965c9bc2053de> > After I call estimator.fit(X)is there a set of attributes on the object that I can consistently check? Or does this vary estimator-to-estimator?  It varies on an per-estimator basis.
[2015-10-09T22:20:49.161Z] <541a528b163965c9bc2053de> Attributes learned from data (by the call to fit) ends in `_`.
[2015-10-09T22:21:40.834Z] <541a528b163965c9bc2053de> `get_params` only returns constructor parameters (aka hyperparameters) not the fitted parameters
[2015-10-09T22:22:06.271Z] <541a528b163965c9bc2053de> we don't have a good abstraction to introspect / serialize / deserialize fitted models.
[2015-10-09T22:22:34.093Z] <530c03e25e986b0712efafb8> is there a way to check if a model is fitted?
[2015-10-09T22:22:42.975Z] <530c03e25e986b0712efafb8> or to revert it to a non-fitted state?
[2015-10-09T22:23:25.804Z] <541a528b163965c9bc2053de> to revert to a non-fitted state you can use:  ```python >>> from sklearn.base import clone >>> unfitted_est = clone(fitted_est) ```
[2015-10-09T22:23:42.000Z] <541a528b163965c9bc2053de> the `clone`  name is not necessarily a good name...
[2015-10-09T22:36:13.175Z] <530c03e25e986b0712efafb8> Is there an equivalent for to ask if it is fitted?
[2015-10-10T01:59:46.779Z] <54c084dbdb8155e6700eed4c> Have not read any history on this, but https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py#L636 might help? Need to know what attributes get set when fitted for a given est though I think. I think if you grep'd the repo you could find an exhaustive list of those being used to check.
[2015-10-12T17:37:57.277Z] <54d4a1d6db8155e6700f853b> @mrocklin there is no way currently to know if something has been fitted. The "idiomatic" way is to try and predict. If it hasn't been fitted, it will raise an appropriate error. But you need to know the number of features is might have been fitted with.
[2015-10-12T21:07:51.849Z] <54d4a1d6db8155e6700f853b> @ogrisel did you have time to set up the doc build server yet?
[2015-10-13T00:04:10.194Z] <54d4a1d6db8155e6700f853b> wow this is the worst: https://github.com/scikit-learn/scikit-learn/issues/5267
[2015-10-13T09:19:51.462Z] <53135b495e986b0712efc453> Is having an issue for splitting the current utils into private/public worth it?
[2015-10-13T19:33:00.275Z] <54d4a1d6db8155e6700f853b> not sure. we should get the model_selection stuff done first.
[2015-10-13T19:33:02.789Z] <54d4a1d6db8155e6700f853b> I'm catching up right now
[2015-10-13T19:33:08.122Z] <54d4a1d6db8155e6700f853b> ping @GaelVaroquaux are you here?
[2015-10-13T19:33:19.190Z] <54d4a1d6db8155e6700f853b> also ping @ogrisel 
[2015-10-13T19:33:31.361Z] <54d4a1d6db8155e6700f853b> I might be able to help with releasing this week. should we? Or wait for the sprint?
[2015-10-13T19:56:34.840Z] <53135b495e986b0712efc453> If we have the model selection merged by this week I can work on the multiple metric thing during sprint :)
[2015-10-13T19:56:49.397Z] <53135b495e986b0712efc453> You are coming right?
[2015-10-13T19:57:23.441Z] <53135b495e986b0712efc453> Gael is not in gitter ;)
[2015-10-13T22:45:33.538Z] <54d4a1d6db8155e6700f853b> we cam
[2015-10-13T22:45:41.266Z] <54d4a1d6db8155e6700f853b> we can't really merge model selection before releasing
[2015-10-13T22:46:14.787Z] <54d4a1d6db8155e6700f853b> I just updated to numpy 1.10.1 and now I get a lot of test failures. Anyone else?
[2015-10-13T22:46:32.108Z] <54d4a1d6db8155e6700f853b> TypeError: Cannot cast ufunc subtract output from dtype('float64') to dtype('int64') with casting rule 'same_kind' 
[2015-10-13T22:46:36.813Z] <54d4a1d6db8155e6700f853b> running conda
[2015-10-14T08:48:06.350Z] <53135b495e986b0712efc453> I can confirm that! (numpy pip installed)
[2015-10-14T08:59:59.775Z] <53135b495e986b0712efc453> http://stackoverflow.com/a/14270230/3109769
[2015-10-14T09:08:10.956Z] <53135b495e986b0712efc453> `np.cancast(np.float64, np.int64)` is `False` from `numpy 1.10.1`
[2015-10-14T10:53:22.967Z] <53135b495e986b0712efc453> Setting the `dtype` at `check_array` stage fixes these failures... Do we need a travis build for 1.10 or should we update one to check for numpy 1.10.1? (@ogrisel?) - PR at #5398 
[2015-10-14T11:05:24.368Z] <53135b495e986b0712efc453> @vene la multi ani!! :P
[2015-10-14T12:19:13.685Z] <541a528b163965c9bc2053de> I finally took the time to fix the docbuilder machine to update the dev/ website.
[2015-10-14T12:19:46.816Z] <541a528b163965c9bc2053de> It seems to work correctly but let me know if you spot problems. There is a couple of broken example in master.
[2015-10-14T12:28:11.910Z] <541a528b163965c9bc2053de> @amueller I would like to release the beta tomorrow. @lesteve is working on the joblib 0.9.0 release right now.
[2015-10-14T12:38:04.305Z] <54e07d6515522ed4b3dc0858> Thanks @rvraghav93 :)
[2015-10-14T14:46:12.517Z] <54d4a1d6db8155e6700f853b> @ogrisel cool. Anything I should look at in partticular?
[2015-10-14T14:46:24.618Z] <54d4a1d6db8155e6700f853b> @ogrisel the numpy 1.10.1 looks bad. can you confirm?
[2015-10-14T14:55:34.029Z] <54d4a1d6db8155e6700f853b> @ogrisel I'm still catching up with github notifications and my health sucks :-/
[2015-10-14T17:04:32.849Z] <541a528b163965c9bc2053de> numpy 1.10.1 need fixes but seemingly not too complicated
[2015-10-14T17:04:53.870Z] <541a528b163965c9bc2053de> I have not checked the LogisticRegressionCV issue
[2015-10-14T18:09:04.956Z] <54d4a1d6db8155e6700f853b> Ok. just got to sklearn notification inbox zero. I'll have a celebratory dirty chai latte and then look at LogisticRegressionCV and other issues that we enthusiastically tagged for 0.17
[2015-10-14T18:10:41.159Z] <54d4a1d6db8155e6700f853b> the doc build seems to be working. pushed 30 seconds ago! Awesomeness!! Thanks @ogrisel !
[2015-10-14T18:10:49.504Z] <54d4a1d6db8155e6700f853b> (and sorry for the constant nagging about it )
[2015-10-14T18:11:09.521Z] <541a528b163965c9bc2053de> > the doc build seems to be working. pushed 30 seconds ago:  I just did a fix :)
[2015-10-14T18:11:54.052Z] <54d4a1d6db8155e6700f853b> http://scikit-learn.org/dev/auto_examples/model_selection/plot_roc.html is not rendered
[2015-10-14T18:11:56.244Z] <54d4a1d6db8155e6700f853b> meh
[2015-10-14T18:12:13.706Z] <54d4a1d6db8155e6700f853b> and scikit-learn.org/dev/auto_examples/preprocessing/plot_function_transformer.html
[2015-10-14T18:12:29.179Z] <541a528b163965c9bc2053de> there are errors in some examples
[2015-10-14T18:12:55.102Z] <541a528b163965c9bc2053de> I need to deploy an HTTP server to publish the doc build log.
[2015-10-14T18:13:02.414Z] <541a528b163965c9bc2053de> +1 a DNS
[2015-10-14T18:13:10.934Z] <541a528b163965c9bc2053de> don't have time to do that tonight though
[2015-10-14T18:13:14.767Z] <54d4a1d6db8155e6700f853b> that would be sweet. sure
[2015-10-14T18:13:30.637Z] <54d4a1d6db8155e6700f853b> @rvraghav93 do you want to build the docs and see if you find the errors?
[2015-10-14T18:13:38.247Z] <54d4a1d6db8155e6700f853b> or I'll do it.
[2015-10-14T18:13:52.672Z] <54d4a1d6db8155e6700f853b> I haven't checked doc build errors or testing errors recently
[2015-10-14T18:14:16.146Z] <541a528b163965c9bc2053de> +1 for the dirty chai latte :)
[2015-10-14T18:15:07.115Z] <541a528b163965c9bc2053de> I'll go and get some dinner now, see you later.
[2015-10-14T18:38:46.048Z] <54d4a1d6db8155e6700f853b> sure :) It would be good to get https://github.com/scikit-learn/scikit-learn/pull/4478 merged. I'll add a whatsnew now
[2015-10-14T18:41:07.304Z] <54d4a1d6db8155e6700f853b> also https://github.com/scikit-learn/scikit-learn/pull/5395
[2015-10-15T12:19:02.285Z] <53135b495e986b0712efc453> @amueller Sorry I saw the chat just now! I'll build the docs and look for errors  :)
[2015-10-15T12:50:48.604Z] <5571fe1015522ed4b3e17d90> @rvraghav93 I was planning to look at the broken examples too. Let me know if we can split the work between the two of us.
[2015-10-15T12:53:02.424Z] <53135b495e986b0712efc453> Yes sure! I'm looking at http://scikit-learn.org/dev/auto_examples/model_selection/plot_roc.html
[2015-10-15T12:53:24.491Z] <53135b495e986b0712efc453> Let me know if you want to take over...
[2015-10-15T12:55:25.930Z] <5571fe1015522ed4b3e17d90> Do you have a list of all the broken examples? I am generating the doc right now but if you already have the full list I could look at another broken example.
[2015-10-15T12:58:01.708Z] <53135b495e986b0712efc453> Wait Andy posted one more broken link right? - [scikit-learn.org/dev/auto_examples/preprocessing/plot_function_transformer.html](scikit-learn.org/dev/auto_examples/preprocessing/plot_function_transformer.html) Unless you are more than 20% done with the doc generation I'll generate the list and let you know shortly :) I need to generate the docs with plots for the one of my PRs anyway...so I could save you the trouble... If you want please take over the http://scikit-learn.org/dev/auto_examples/model_selection/plot_roc.html too... that seems to be due to a problem in importing (`from scipy import stats` seems to fail(?))
[2015-10-15T13:01:51.982Z] <53135b495e986b0712efc453> Is there a way to work with 2 branches at once? :P
[2015-10-15T13:11:11.080Z] <5571fe1015522ed4b3e17d90> OK I'll take a look at http://scikit-learn.org/dev/auto_examples/model_selection/plot_roc.html
[2015-10-15T13:16:48.602Z] <541a528b163965c9bc2053de> > Is there a way to work with 2 branches at once?  clone the scikit-learn repo twice, create 2 conda env or 2 virtualenvs and `pip install -e .` each repo in each env.
[2015-10-15T13:17:28.746Z] <53135b495e986b0712efc453> Okay!! thanks :)
[2015-10-15T13:22:28.256Z] <541a528b163965c9bc2053de> @amueller any review for the joblib sync #5399? It reverts a broken experimental change in the pickle format that was in introduced in joblib 0.9.0b2 (hence not part of scikit-learn 0.16.1). See:  https://github.com/joblib/joblib/blob/master/CHANGES.rst#release-092
[2015-10-15T14:03:14.000Z] <5571fe1015522ed4b3e17d90> I generated the doc locally so I am going to create one ticket by broken example. FWIW I found 5 broken examples: examples/applications/plot_tomography_l1_reconstruction.py examples/ensemble/plot_random_forest_embedding.py examples/manifold/plot_lle_digits.py examples/model_selection/plot_roc.py examples/svm/plot_rbf_parameters.py
[2015-10-15T14:03:44.274Z] <5571fe1015522ed4b3e17d90> Note the tomography one is broken only for numpy 1.10
[2015-10-15T14:05:25.563Z] <53135b495e986b0712efc453> you did doc with plots right? How did it get over so fast? It takes forever on my machine :/ Anyway let me know if you want me to look into any of those while you work on other things...
[2015-10-15T14:09:32.799Z] <5571fe1015522ed4b3e17d90> yeah make html. Too ~25 minutes on my machine.
[2015-10-15T14:13:57.268Z] <541a528b163965c9bc2053de> Let's split the work on fixing the examples.
[2015-10-15T14:14:24.338Z] <53135b495e986b0712efc453> I'll take the last 2 if no one else is working on it?
[2015-10-15T14:14:55.721Z] <541a528b163965c9bc2053de> plot_roc and plot_rbf_parameters? sure I have a look at something else.
[2015-10-15T14:15:04.145Z] <53135b495e986b0712efc453> yea!
[2015-10-15T14:15:12.666Z] <541a528b163965c9bc2053de> I will have a look at plot_random_forest_embedding.py
[2015-10-15T14:15:12.681Z] <5571fe1015522ed4b3e17d90> I can take plot_lle_digits should be trivial
[2015-10-15T14:17:15.632Z] <5571fe1015522ed4b3e17d90> @rvraghav93 the plot_roc one is due to the roc_curves not all having the same shape, not sure why ...
[2015-10-15T14:24:56.464Z] <541a528b163965c9bc2053de> RandomTreesEmbedding looks like a real regression :(
[2015-10-15T14:35:31.338Z] <54d4a1d6db8155e6700f853b> I'm back
[2015-10-15T14:39:09.706Z] <5571fe1015522ed4b3e17d90> I did the plot_tomography_l1_reconstruction fix while I was at it.
[2015-10-15T14:39:42.798Z] <54d4a1d6db8155e6700f853b> @ogrisel are you planning on uploading the website for the rc? No, right?
[2015-10-15T14:49:10.679Z] <54d4a1d6db8155e6700f853b> I think it would be nice to fix https://github.com/scikit-learn/scikit-learn/issues/5324
[2015-10-15T14:49:16.092Z] <54d4a1d6db8155e6700f853b> should I go for that?
[2015-10-15T14:50:31.032Z] <54d4a1d6db8155e6700f853b> oh right there is https://github.com/scikit-learn/scikit-learn/pull/5402
[2015-10-15T15:10:52.728Z] <53135b495e986b0712efc453> Is there a reason why we don't have the `requirements.txt` in our repo?
[2015-10-15T15:17:19.455Z] <54d4a1d6db8155e6700f853b> yeah because it would need to include numpy and scipy and we don't want people to install this via pip on linux
[2015-10-15T15:17:23.199Z] <54d4a1d6db8155e6700f853b> is anyone doing #5407 ?
[2015-10-15T15:19:19.042Z] <53135b495e986b0712efc453> Okay.. and yes I am...
[2015-10-15T15:26:17.202Z] <54d4a1d6db8155e6700f853b> http://scikit-learn.org/dev/modules/classes.html is entirely broken
[2015-10-15T15:26:24.437Z] <54d4a1d6db8155e6700f853b> it's the sphinx version with the fun
[2015-10-15T15:38:35.728Z] <54d4a1d6db8155e6700f853b> btw, do we want to fix the "FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison" ?
[2015-10-15T15:39:11.356Z] <54d4a1d6db8155e6700f853b> @ogrisel which version of sphinx is on the doc build bot?
[2015-10-15T16:52:22.685Z] <54d4a1d6db8155e6700f853b> @ogrisel I mean it is not really release related but for the build bot we need to fix the sphinx version to 1.2.3 not sure how to do that with a salt state
[2015-10-15T16:52:59.589Z] <54d4a1d6db8155e6700f853b> oh wait, just  name = sphinx == 1.2.3
[2015-10-15T17:03:06.394Z] <541a528b163965c9bc2053de> > @ogrisel are you planning on uploading the website for the rc? No, right?  Updating the /stable/ part? No I don't think we should do it for the beta.
[2015-10-15T17:05:41.868Z] <54d4a1d6db8155e6700f853b> I agree.
[2015-10-15T17:05:58.017Z] <54d4a1d6db8155e6700f853b> so the plotting examples are "not that critical" for the release. Though it would be nice to fix them
[2015-10-15T17:06:06.285Z] <541a528b163965c9bc2053de> for the final they are
[2015-10-15T17:07:05.862Z] <54d4a1d6db8155e6700f853b> yeah but not for the rc.
[2015-10-15T17:07:21.710Z] <54d4a1d6db8155e6700f853b> I thought you wanted to do an RC/beta today? Or the full release?
[2015-10-15T17:07:54.532Z] <541a528b163965c9bc2053de> @amueller  >  which version of sphinx is on the doc build bot?  It using the latest stable version installed by pip: https://github.com/scikit-learn/sklearn-docbuilder/blob/master/srv/salt/sklearn-docbuilder.sls#L107
[2015-10-15T17:08:18.740Z] <541a528b163965c9bc2053de> It's not updated as long as the machine does not crash and we restart it though (which is very rare).
[2015-10-15T17:08:27.706Z] <54d4a1d6db8155e6700f853b> yeah that is no good. I just sent you a PR to fix it to 1.2.3
[2015-10-15T17:08:35.597Z] <54d4a1d6db8155e6700f853b> current stable doesn't build the api docs
[2015-10-15T17:08:46.959Z] <541a528b163965c9bc2053de> ok
[2015-10-15T17:09:35.976Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/sklearn-docbuilder/pull/6
[2015-10-15T17:15:51.114Z] <541a528b163965c9bc2053de> I just put some instructions to let you try to run it. If it fails, tell me and I will do it.
[2015-10-15T17:20:33.646Z] <54d4a1d6db8155e6700f853b> ok. gotta grab some lunch now
[2015-10-15T17:20:46.143Z] <54d4a1d6db8155e6700f853b> @rvraghav93 if you're bored you can try to bisect https://github.com/scikit-learn/scikit-learn/issues/5267
[2015-10-15T17:20:54.781Z] <541a528b163965c9bc2053de> do you want me to do the sklearn-docbuilder stuff?
[2015-10-15T17:21:04.051Z] <541a528b163965c9bc2053de> you can always give it a try later
[2015-10-15T17:21:50.256Z] <541a528b163965c9bc2053de> guten Appetit!
[2015-10-15T17:23:09.818Z] <54d4a1d6db8155e6700f853b> merci
[2015-10-15T17:23:18.458Z] <54d4a1d6db8155e6700f853b> I can try it later
[2015-10-15T17:23:35.835Z] <54d4a1d6db8155e6700f853b> I don't see any fires at the moment
[2015-10-15T17:23:41.843Z] <541a528b163965c9bc2053de> ok
[2015-10-15T17:24:01.968Z] <54d4a1d6db8155e6700f853b> fixing more warnings in master and fixing the doc-build would be nice
[2015-10-15T17:24:10.207Z] <541a528b163965c9bc2053de> ok
[2015-10-15T17:24:20.781Z] <54d4a1d6db8155e6700f853b> how about the "FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison" ? from numpy?
[2015-10-15T17:24:29.573Z] <54d4a1d6db8155e6700f853b> anyhow, my stomach demands attention
[2015-10-15T19:10:34.489Z] <54d4a1d6db8155e6700f853b> website build is fixed. Thanks @ogrisel 
[2015-10-15T19:12:40.370Z] <541a528b163965c9bc2053de> good
[2015-10-15T19:13:35.296Z] <54d4a1d6db8155e6700f853b> what is the timeline? how long will you be around today?
[2015-10-15T19:30:10.657Z] <54d4a1d6db8155e6700f853b> many of the the "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison"  are due to us comparing parameters that might be arrays to strings. like ``if init == "something"``
[2015-10-15T19:36:02.640Z] <541a528b163965c9bc2053de> I will soon logout. I wanted to do the RandomTreeEmbedding example fix but we can do that after the cut of the 0.17.X branch.
[2015-10-15T19:36:25.115Z] <541a528b163965c9bc2053de> Do you want to cut it today? Otherwise I can do it tomorrow morning (Paris time).
[2015-10-15T19:37:14.973Z] <541a528b163965c9bc2053de> I just merged the joblib upgrade
[2015-10-15T19:52:07.723Z] <54d4a1d6db8155e6700f853b> cool.
[2015-10-15T19:52:34.711Z] <54d4a1d6db8155e6700f853b> I'll fix "FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison" in a couple of minutes. I'd like to include that in the RC. Then you can cut it tomorrow morning?
[2015-10-15T20:10:12.832Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/5413
[2015-10-16T13:08:56.084Z] <53135b495e986b0712efc453> @lesteve Are you working on #5415? I have a fix for it... can I send a PR?
[2015-10-16T13:33:12.866Z] <5571fe1015522ed4b3e17d90> @rvraghav93 Sorry didn't see that, I am not working on it so yeah be my guest and send a PR !
[2015-10-16T13:35:16.657Z] <53135b495e986b0712efc453> #5420 :)
[2015-10-16T14:59:23.385Z] <54d4a1d6db8155e6700f853b> @ogrisel you around?
[2015-10-16T15:06:27.436Z] <541a528b163965c9bc2053de> @amueller yes back online
[2015-10-16T15:07:16.770Z] <541a528b163965c9bc2053de> shall we cut the 0.17.X branch now? or do you have quick PRs you would like to merge now?
[2015-10-16T15:07:55.429Z] <54d4a1d6db8155e6700f853b> I'm fine with doing it now.
[2015-10-16T15:08:01.141Z] <54d4a1d6db8155e6700f853b> We can always backport bugfixes
[2015-10-16T15:09:02.822Z] <54d4a1d6db8155e6700f853b> the LogisticCV seems broken with non-sag solvers (maybe)
[2015-10-16T15:09:09.224Z] <541a528b163965c9bc2053de> argl
[2015-10-16T15:09:14.331Z] <541a528b163965c9bc2053de> which number?
[2015-10-16T15:09:42.197Z] <54d4a1d6db8155e6700f853b> ah never mind
[2015-10-16T15:09:49.771Z] <54d4a1d6db8155e6700f853b> I didn't read the thread to the end
[2015-10-16T15:10:00.076Z] <541a528b163965c9bc2053de> Ok :)
[2015-10-16T15:10:06.626Z] <54d4a1d6db8155e6700f853b> all good
[2015-10-16T15:10:12.133Z] <541a528b163965c9bc2053de> Maybe #5420 if appveyor is quick enough?
[2015-10-16T15:11:00.837Z] <541a528b163965c9bc2053de> Not a big deal we can backport. Let me cut the 0.17.X branch now.
[2015-10-16T15:13:26.418Z] <541a528b163965c9bc2053de> pushed the 0.17.X branch and the 0.17-branching tag
[2015-10-16T15:13:38.451Z] <541a528b163965c9bc2053de> I will update the version to 0.18.dev0 in master
[2015-10-16T15:15:00.309Z] <54d4a1d6db8155e6700f853b> thanks
[2015-10-16T15:15:08.989Z] <54d4a1d6db8155e6700f853b> #5408 needs to be backported, too
[2015-10-16T15:19:05.019Z] <541a528b163965c9bc2053de> I pushed the version change in master.
[2015-10-16T15:19:20.273Z] <53135b495e986b0712efc453> :beers:
[2015-10-16T15:23:07.025Z] <54d4a1d6db8155e6700f853b> hurray.
[2015-10-16T15:23:46.845Z] <54d4a1d6db8155e6700f853b> are you pushing to pipy now?
[2015-10-16T15:27:04.211Z] <541a528b163965c9bc2053de> I a have not yet made the 0.17.0b1 release in the 0.17.X branch
[2015-10-16T15:27:28.850Z] <541a528b163965c9bc2053de> Shall we merge and backport #5416 before?
[2015-10-16T15:35:07.642Z] <541a528b163965c9bc2053de> @amueller do you want to merge #5416 and backport to 0.17.X before the 0.17.0b1 release or not?
[2015-10-16T15:35:52.085Z] <53135b495e986b0712efc453> And #5420 too? ;)
[2015-10-16T15:36:19.001Z] <53135b495e986b0712efc453> Oh you were waiting for appveyor.... Okay :)
[2015-10-16T15:36:49.077Z] <54d4a1d6db8155e6700f853b> @ogrisel yeah I think so. I'll remove the "resets" sentence though.
[2015-10-16T15:37:29.533Z] <54d4a1d6db8155e6700f853b> Let's wait for travis on  #5416 ok?
[2015-10-16T15:44:37.127Z] <541a528b163965c9bc2053de> ok
[2015-10-16T15:45:29.525Z] <541a528b163965c9bc2053de> I have slides to work on in the mean time. Ping me once you merge #5416 and I will do the 0.17.0b1 release.
[2015-10-16T15:49:43.506Z] <54d4a1d6db8155e6700f853b> @ogrisel done :)
[2015-10-16T15:49:57.836Z] <54d4a1d6db8155e6700f853b> I did the cherry picking
[2015-10-16T15:51:02.874Z] <541a528b163965c9bc2053de> Great, thanks
[2015-10-16T15:53:16.330Z] <541a528b163965c9bc2053de> git pull is very slow for some reason #hotelwifi
[2015-10-16T15:55:29.085Z] <541a528b163965c9bc2053de> I will actually name it 0.17b1 to respect the convention of the last release cycle.
[2015-10-16T15:55:47.681Z] <54d4a1d6db8155e6700f853b> ok. Should I merge / cherry-pick #5420  ?
[2015-10-16T15:55:50.000Z] <54d4a1d6db8155e6700f853b> it looks good
[2015-10-16T15:59:31.725Z] <541a528b163965c9bc2053de> We can do that after the beta :)
[2015-10-16T16:00:54.860Z] <541a528b163965c9bc2053de> I forgot to update doc/conf.py in master, can you do it?
[2015-10-16T16:01:45.414Z] <541a528b163965c9bc2053de> ah non need anymore... sorry for the noise
[2015-10-16T16:01:51.256Z] <541a528b163965c9bc2053de> the wiki is not up to date
[2015-10-16T16:04:20.917Z] <53135b495e986b0712efc453> #5423?
[2015-10-16T16:05:36.002Z] <54d4a1d6db8155e6700f853b> we should remove the wiki and point to the release docs in the doc folder
[2015-10-16T16:05:44.915Z] <54d4a1d6db8155e6700f853b> I think gael or joel started them
[2015-10-16T16:17:53.610Z] <54d4a1d6db8155e6700f853b> @ogrisel are you updating the website related stuff in the docs, that is the links to the older / newer docs?
[2015-10-16T16:17:57.686Z] <54d4a1d6db8155e6700f853b> or should I?
[2015-10-16T16:18:57.317Z] <541a528b163965c9bc2053de> I don't update the website for beta in the 0.17.X branch
[2015-10-16T16:19:27.160Z] <541a528b163965c9bc2053de> I updated the website for 0.18.0.dev0 version in the master branch for the `/dev/` website.
[2015-10-16T16:23:19.961Z] <54d4a1d6db8155e6700f853b> Ah, because we don't upload we can't change the links yet, never mind.
[2015-10-16T16:23:48.836Z] <54d4a1d6db8155e6700f853b> we need to make sure to update the links later to point to "stable" in the release and update the links to the different versions.
[2015-10-16T16:24:09.964Z] <54d4a1d6db8155e6700f853b> Do we want to merge the GP now and remove the deprecated stuff?
[2015-10-16T16:25:31.667Z] <54d4a1d6db8155e6700f853b> I guess better now than during the sprint
[2015-10-16T16:26:40.816Z] <53135b495e986b0712efc453> I'm removing deprecated stuff (and finishing off my old PRs)!
[2015-10-16T16:27:11.637Z] <541a528b163965c9bc2053de> As you wish, I have not reviewed the GP stuff but I trust the other reviewers
[2015-10-16T16:27:34.314Z] <541a528b163965c9bc2053de> remove deprecated stuff can be done now or during the sprint
[2015-10-16T16:27:49.981Z] <541a528b163965c9bc2053de> I am testing the sdist on my local machine before push
[2015-10-16T16:27:57.548Z] <541a528b163965c9bc2053de> internet is so slow...
[2015-10-16T16:28:15.942Z] <53135b495e986b0712efc453> Since Andy will be there I plan to work on the multiple metric support during sprint... so finishing off minor stuff now :)
[2015-10-16T16:29:26.772Z] <53135b495e986b0712efc453> BTW will merging GP mean I'll have to fix it as per #4294 :sob: 
[2015-10-16T16:30:18.806Z] <54d4a1d6db8155e6700f853b> I probably won't be at the sprint, sorry
[2015-10-16T16:30:43.841Z] <54d4a1d6db8155e6700f853b> what does the GP have to do with #4294?
[2015-10-16T16:30:52.469Z] <53135b495e986b0712efc453> Oh thats bad... :/ remotely? 
[2015-10-16T16:32:05.749Z] <54d4a1d6db8155e6700f853b> probably
[2015-10-16T16:32:34.672Z] <54d4a1d6db8155e6700f853b> @rvraghav93 can you finish of #5420 before doing the deprecations?
[2015-10-16T16:34:21.442Z] <53135b495e986b0712efc453> Oh wait... I didn't notice your comments there....
[2015-10-16T16:41:05.503Z] <54d4a1d6db8155e6700f853b> @ogrisel are you waiting for the wheels before announce?
[2015-10-16T16:42:08.561Z] <541a528b163965c9bc2053de> probably not
[2015-10-16T16:42:28.024Z] <541a528b163965c9bc2053de> but I am currently configuring the MacPython repo to generate the mac wheels
[2015-10-16T16:44:10.230Z] <54d4a1d6db8155e6700f853b> ok
[2015-10-16T17:11:46.035Z] <541a528b163965c9bc2053de> Ok the tests pass with sklearn installed from the sdist on a newly built venv
[2015-10-16T17:12:07.565Z] <541a528b163965c9bc2053de> I think I am getting the MacPython config right
[2015-10-16T17:16:07.604Z] <541a528b163965c9bc2053de> uploading the 0.17b1 release now
[2015-10-16T17:19:21.200Z] <541a528b163965c9bc2053de> The windows wheels will take some time. They should be built by: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.2792 but the queue is long: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/history
[2015-10-16T17:48:36.305Z] <541a528b163965c9bc2053de> ok the sdist is uploaded
[2015-10-16T17:49:15.098Z] <541a528b163965c9bc2053de> will the mac wheels are getting built, will upload them tomorrow with the windows wheels as my internet is too shitty to do it now
[2015-10-16T17:52:50.518Z] <54d4a1d6db8155e6700f853b> sweet! Great, thanks!
[2015-10-16T17:53:10.544Z] <54d4a1d6db8155e6700f853b> you wanna tweet?
[2015-10-16T17:53:29.328Z] <541a528b163965c9bc2053de> I sent an email to the mailing list
[2015-10-16T17:56:52.041Z] <54d4a1d6db8155e6700f853b> I saw
[2015-10-16T17:56:55.536Z] <54d4a1d6db8155e6700f853b> ok I tweeted.
[2015-10-16T17:57:10.722Z] <54d4a1d6db8155e6700f853b> Did you purposefully not include the pip line because people might have anaconda?
[2015-10-16T17:57:59.734Z] <541a528b163965c9bc2053de> We have issues under OSX:   https://travis-ci.org/MacPython/scikit-learn-wheels/builds/85779066 
[2015-10-16T17:58:06.884Z] <541a528b163965c9bc2053de> it was good to make it a beta...
[2015-10-16T17:58:28.775Z] <541a528b163965c9bc2053de> I have to go, now. Will do the windows upload tomorrow.
[2015-10-16T17:59:16.573Z] <541a528b163965c9bc2053de> For the pip line we can do it for the official announcement once all the wheels are on PyPI.
[2015-10-16T17:59:46.615Z] <541a528b163965c9bc2053de> We can also coordinate with continnum to have them build from the tag before we do the PyPI upload.
[2015-10-16T17:59:53.689Z] <541a528b163965c9bc2053de> and do a sync release
[2015-10-16T18:00:02.879Z] <541a528b163965c9bc2053de> and enthought as well
[2015-10-16T18:00:07.062Z] <54d4a1d6db8155e6700f853b> for the final release that would be good
[2015-10-16T18:00:30.368Z] <54d4a1d6db8155e6700f853b> one of the os X issues is the log getting to long because of compiler warnings on cython code.
[2015-10-16T18:00:50.681Z] <54d4a1d6db8155e6700f853b> I'll look into it.
[2015-10-16T18:00:54.057Z] <541a528b163965c9bc2053de> thanks
[2015-10-16T18:01:10.421Z] <541a528b163965c9bc2053de> see you later. I will be at PyConFR tomorrow
[2015-10-16T18:01:21.302Z] <541a528b163965c9bc2053de> will be online intermittently
[2015-10-16T18:01:23.588Z] <54d4a1d6db8155e6700f853b> cool. have fun!
[2015-10-16T18:01:35.549Z] <54d4a1d6db8155e6700f853b> wait os X builds on python 3.3 ? we don't support that, do we?
[2015-10-16T18:02:01.728Z] <541a528b163965c9bc2053de> I thought we did, we can drop it if it's too painful to maintain
[2015-10-16T18:02:13.493Z] <54d4a1d6db8155e6700f853b> ah. but then we should test it on travis, right?
[2015-10-16T18:02:13.955Z] <541a528b163965c9bc2053de> nobody cares (under OSX) I guess
[2015-10-16T18:02:22.480Z] <541a528b163965c9bc2053de> as long as 3.4 and 3.5 work
[2015-10-16T18:02:23.413Z] <54d4a1d6db8155e6700f853b> it's not os X related
[2015-10-16T18:02:29.769Z] <54d4a1d6db8155e6700f853b> it's just 3.3
[2015-10-16T18:02:35.806Z] <54d4a1d6db8155e6700f853b> it's not hard to fix though
[2015-10-16T18:02:36.538Z] <541a528b163965c9bc2053de> ah ok
[2015-10-16T18:02:56.146Z] <54d4a1d6db8155e6700f853b> I'll fix it.
[2015-10-16T18:03:03.736Z] <541a528b163965c9bc2053de> thanks
[2015-10-16T18:03:47.751Z] <54d4a1d6db8155e6700f853b> the readme says "scikit-learn is tested to work under Python 2.6, Python 2.7, and Python 3.4. It should also work with Python 3.3" glorious
[2015-10-16T18:03:53.007Z] <54d4a1d6db8155e6700f853b> anyhow see ya
[2015-10-16T18:06:12.843Z] <541a528b163965c9bc2053de> see ya :)
[2015-10-16T18:09:57.934Z] <541a528b163965c9bc2053de> I just uploaded the first 2 OSX wheels that work
[2015-10-16T18:10:26.832Z] <541a528b163965c9bc2053de> I am really going offline now :)
[2015-10-16T18:10:30.677Z] <541a528b163965c9bc2053de> see ya
[2015-10-16T19:15:14.334Z] <54d4a1d6db8155e6700f853b> thank you so much olivier!
[2015-10-16T23:31:29.729Z] <54d4a1d6db8155e6700f853b> does anyone know how setuptools (or numpy.distutils?) assembles the gcc options?
[2015-10-17T00:37:30.098Z] <54d4a1d6db8155e6700f853b> @ogrisel do you understand this https://travis-ci.org/MacPython/scikit-learn-wheels/jobs/85847030 ?
[2015-10-17T00:37:53.830Z] <54d4a1d6db8155e6700f853b> install_scripts failed
[2015-10-17T08:51:24.228Z] <541a528b163965c9bc2053de> @amueller it's weird I just did it (bdist_wheel) on my mac and I don't get the error.
[2015-10-17T08:51:35.726Z] <541a528b163965c9bc2053de> python 3.5.0 as well.
[2015-10-17T08:55:24.898Z] <541a528b163965c9bc2053de> Maybe the version of the `wheel` project pre-installed on the travis host is too old for Python 3.5.0. Will change the config to make it upgrade it.
[2015-10-17T08:55:27.462Z] <541a528b163965c9bc2053de> > Requirement already satisfied (use --upgrade to upgrade): wheel in ./venv/lib/python3.5/site-packages
[2015-10-17T16:42:29.677Z] <54d4a1d6db8155e6700f853b> @ogrisel I saw you commited something. did it fix it?
[2015-10-17T16:43:04.326Z] <54d4a1d6db8155e6700f853b> the weird gcc flags were... weird but I didn't see it come up again after I added the flags
[2015-10-17T16:43:30.468Z] <54d4a1d6db8155e6700f853b> ah, wheels work. we only need to sync master for the 3.3 fix
[2015-10-17T16:48:05.822Z] <541a528b163965c9bc2053de> For 3.5 on the OSX  wheel builder, yes it's fixed (just ugraded the `wheel` package on travis).
[2015-10-17T16:48:39.536Z] <541a528b163965c9bc2053de> For your 3.3 fix that I merged I plan to only include it for the next release.
[2015-10-17T16:49:06.733Z] <541a528b163965c9bc2053de> I would like to have the tag match the content of the archive.
[2015-10-17T17:57:52.318Z] <54d4a1d6db8155e6700f853b> What do you mean by that? that the version tag in the sklearn repo is the same as the wheel with the same name? makes sense.
[2015-10-17T17:58:36.875Z] <54d4a1d6db8155e6700f853b> I have to work on other stuff today. You are busy with Pycon FR right? it looks like #5008 would be good to have / review
[2015-10-17T20:55:37.077Z] <560731310fc9f982beb1f438> I'd like to start contributing and work on #5089, so I was wondering if it's better to submit one PR with a lot of warning fixes or PRs in chunks that deal with one specific type of warning?
[2015-10-18T07:56:31.840Z] <541a528b163965c9bc2053de> @oolongtea  Start with one that fix related stuff if it's your first PR. It's easier to give you feedback to get started.
[2015-10-18T19:23:30.580Z] <54d4a1d6db8155e6700f853b> does anyone know a good "real world" dataset for regression on which regularization helps? In diabetes and boston linear regression does as well as any other linear model, which is sad. the only examples for regularization we have are using ``make_regression``
[2015-10-18T19:32:40.989Z] <54d4a1d6db8155e6700f853b> so diabetes is from the lars paper, but lars doesn't actually make better predictions than ols on diabetes.....
[2015-10-18T20:00:46.624Z] <54e07d6515522ed4b3dc0858> How about high dim. data, say movie review stars from text
[2015-10-18T20:06:45.332Z] <54d4a1d6db8155e6700f853b> yeah that would work. but I don't want to go too high dim. I settled for polynomial features on boston, which works well
[2015-10-18T20:07:15.616Z] <54d4a1d6db8155e6700f853b> It's for the book, and I don't want to explain bag of words at this point. Not sure I want to explain polynomial features, but it's a little easier.
[2015-10-18T20:07:24.683Z] <54d4a1d6db8155e6700f853b> might be an interesting example for non-synthetic data
[2015-10-18T20:07:33.364Z] <54d4a1d6db8155e6700f853b> (for the examples folder I mean)
[2015-10-19T08:15:08.755Z] <541a528b163965c9bc2053de> for fMRI data I know they need regularization a lot (typical shape ~100 samples, 50k features with a lot of local correlations)
[2015-10-19T08:40:44.923Z] <53135b495e986b0712efc453> @ogrisel Can I remove all the deprecated stuff? or list them in an issue and ping you for tagging them easy?
[2015-10-19T08:40:53.639Z] <53135b495e986b0712efc453> There are quite a few!!
[2015-10-19T08:41:39.349Z] <541a528b163965c9bc2053de> @rvraghav93 go for both! Maybe start with reviewing issues.
[2015-10-19T08:53:16.951Z] <54bd0a4fdb8155e6700ed136> Hey there. How is the sprint going on? Things you need help from remote?
[2015-10-19T09:28:27.978Z] <541a528b163965c9bc2053de> Hi @glouppe, the sprint has started with 21 people in the room so far. If you can help triage issues to identify bugs that are easyfix for newcomers that would be great.
[2015-10-19T09:29:51.191Z] <54bd0a4fdb8155e6700ed136> yup okay
[2015-10-19T09:48:37.408Z] <54b4f2d1db8155e6700e99c0> Hey Folks, is anyone working on issue #5185?
[2015-10-19T09:50:09.166Z] <54b4f2d1db8155e6700e99c0> @amueller maybe?
[2015-10-19T09:52:53.167Z] <54bd0a4fdb8155e6700ed136> @fabianp is working on it
[2015-10-19T09:53:52.532Z] <54b4f2d1db8155e6700e99c0> OK thx @glouppe 
[2015-10-19T09:57:13.290Z] <541a528b163965c9bc2053de> @amueller must be sleeping at the moment :)
[2015-10-19T10:41:02.935Z] <54d4a1d6db8155e6700f853b> I am
[2015-10-19T10:41:09.585Z] <54d4a1d6db8155e6700f853b> should be at least ;)
[2015-10-19T10:43:46.661Z] <54d4a1d6db8155e6700f853b> I thought sprint started tomorrow? When did the dates change? hm
[2015-10-19T10:45:14.103Z] <54d4a1d6db8155e6700f853b> Was the same last time, was scheduled to start on Tuesday but started on Monday ^^
[2015-10-19T11:18:48.912Z] <541a528b163965c9bc2053de> I think this time it was always supposed to start today, no?
[2015-10-19T11:38:58.935Z] <55e5c37d0fc9f982beaf4d61> @amueller I think the PLS fix is ready and does not affect performance
[2015-10-19T11:41:16.892Z] <54e07d9515522ed4b3dc085e> Does somebody need a review?
[2015-10-19T11:42:01.603Z] <54bd0a4fdb8155e6700ed136> Salut Arnaud :)
[2015-10-19T11:42:13.000Z] <54bd0a4fdb8155e6700ed136> the isolation forest PR would be nice to review 
[2015-10-19T11:42:32.867Z] <54bd0a4fdb8155e6700ed136> the code is not perfect, but it has been reviewed several times already
[2015-10-19T11:42:40.280Z] <54bd0a4fdb8155e6700ed136> I think it is good enough to be merged
[2015-10-19T11:42:45.978Z] <54e07d9515522ed4b3dc085e> Ok je vais regarder cela. 
[2015-10-19T11:42:53.702Z] <54bd0a4fdb8155e6700ed136> (considering improvements will come later)
[2015-10-19T11:43:06.462Z] <54bd0a4fdb8155e6700ed136> tu es au sprint?
[2015-10-19T11:43:10.501Z] <54e07d9515522ed4b3dc085e> oui :-)
[2015-10-19T11:43:33.479Z] <54bd0a4fdb8155e6700ed136> j'aurais bien voulu venir mais j'ai epuise mon stock de conges -.-
[2015-10-19T11:43:53.852Z] <54bd0a4fdb8155e6700ed136> ca aurait ete un mois plus tard, je serais venu
[2015-10-19T11:44:04.715Z] <54e07d9515522ed4b3dc085e> :-/ By chance, have you check https://github.com/tsdalton/Isolation-Forest/blob/master/iforest.py which looks like a scikit-learn compatible isolation forest.
[2015-10-19T11:44:28.971Z] <54bd0a4fdb8155e6700ed136> nope
[2015-10-19T11:44:36.798Z] <54bd0a4fdb8155e6700ed136> it looks very clean though
[2015-10-19T11:44:55.826Z] <54e07d9515522ed4b3dc085e> it looks like an extracted version of the pr.
[2015-10-19T11:44:59.714Z] <54e07d9515522ed4b3dc085e> given the author name.
[2015-10-19T11:45:07.444Z] <54bd0a4fdb8155e6700ed136> yeah, strange
[2015-10-19T12:28:49.056Z] <54bd0a4fdb8155e6700ed136> well maybe the isolation forest was not in a so good state after all :s 
[2015-10-19T12:31:57.181Z] <53135b495e986b0712efc453> @ogrisel Any ideas on why travis isn't running at #5451?
[2015-10-19T12:32:50.256Z] <555b8aa615522ed4b3e0a160> not running on #5008 too
[2015-10-19T12:34:27.757Z] <54bd0a4fdb8155e6700ed136> Too many running instances for scikit-learn maybe?
[2015-10-19T12:34:37.339Z] <54bd0a4fdb8155e6700ed136> See https://github.com/scikit-learn/scikit-learn/pulls 
[2015-10-19T12:34:43.998Z] <54bd0a4fdb8155e6700ed136> 10 travis instances are running
[2015-10-19T13:13:11.712Z] <5624b76416b6c7089cb77abb> I'm looking for the wee-wee pass!
[2015-10-19T13:13:50.190Z] <541a528b163965c9bc2053de> @rvraghav93 no idea...
[2015-10-19T13:30:20.887Z] <541a528b163965c9bc2053de> @rvraghav93 it works now, did you do anything on your side?
[2015-10-19T14:10:50.613Z] <53135b495e986b0712efc453> No I think like @glouppe said it must have been overwhelmed by our enthusiasm today ;)
[2015-10-19T14:33:58.738Z] <54bd0a4fdb8155e6700ed136> Yeah, see https://travis-ci.org/scikit-learn/scikit-learn/pull_requests
[2015-10-19T14:40:04.792Z] <541a528b163965c9bc2053de> indeed
[2015-10-19T14:43:33.229Z] <53135b495e986b0712efc453> awesome!!
[2015-10-19T14:56:04.760Z] <53135b495e986b0712efc453> (@ogrisel These deprecations seem a little bit tricky and fail a lot of tests, is there  anyone who would like to take them or should I do these or should I raise a separate issue and leave till end of sprint?) - [ ] Remove support for uppercase values for loss in sv* (test in file `svm/tests/test_svm.py`, uppercase support in `_fit_liblinear` function in `svm/base.py`, Refer #4261 and #4260 also svm/classes.py L192) - [ ] Remove support for `gamma==0.0` (`svm/base.py`) - [ ] Change the default value of `decision_function_shape` to `'ovr'` (`svm/base.py`) 
[2015-10-19T14:57:26.529Z] <53135b495e986b0712efc453> And is setting `gamma` to `1 / n_features` the correct thing to do [here](https://github.com/scikit-learn/scikit-learn/issues/5434#issuecomment-149223797)?
[2015-10-19T15:03:18.813Z] <54d4a1d6db8155e6700f853b> @ogrisel no, was announced as Oct. 20 to 25 Isn't kyle also coming tomorrow? 
[2015-10-19T15:03:53.905Z] <54d4a1d6db8155e6700f853b> @arjoly you are in paris? Awesome :)
[2015-10-19T15:10:28.729Z] <53135b495e986b0712efc453> Kyle is here ;)
[2015-10-19T15:11:13.735Z] <53135b495e986b0712efc453> And in the wiki its 19th - https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events ;) :P 
[2015-10-19T15:17:06.076Z] <541a528b163965c9bc2053de> There must have been an error in the announcement email, I read the date from wiki...
[2015-10-19T15:22:07.871Z] <54d4a1d6db8155e6700f853b> hm ok. Kyle and I asked Nelle and Alexandre like 10 times "will this be the dates" ^^ Is kyle there already?
[2015-10-19T15:22:26.117Z] <54d4a1d6db8155e6700f853b> well doesn't matter ^^
[2015-10-19T15:22:32.051Z] <54d4a1d6db8155e6700f853b> I'll review from here
[2015-10-19T15:33:06.710Z] <541a528b163965c9bc2053de> yes Kyle is here
[2015-10-19T15:49:51.486Z] <54e07d9515522ed4b3dc085e> > @arjoly you are in paris? Awesome  rvraghav93 17:10 
[2015-10-19T15:49:59.503Z] <54e07d9515522ed4b3dc085e> Yeah I am in paris :-)
[2015-10-19T15:50:10.017Z] <54e07d9515522ed4b3dc085e> will you be here?
[2015-10-19T15:51:18.604Z] <54d4a1d6db8155e6700f853b> cool
[2015-10-19T15:51:35.912Z] <54d4a1d6db8155e6700f853b> it would be great if anyone could work on the docs building more error-free ^^
[2015-10-19T15:53:35.574Z] <53135b495e986b0712efc453> Can someone remove the "Need contributors" tag from #5441
[2015-10-19T15:54:22.272Z] <54bd0a4fdb8155e6700ed136> done
[2015-10-19T15:54:26.055Z] <54bd0a4fdb8155e6700ed136> and assigned arnaud
[2015-10-19T15:54:33.705Z] <53135b495e986b0712efc453> Thanks :)
[2015-10-19T15:54:40.501Z] <541a528b163965c9bc2053de> The new circle CI job will build the doc on a post-merge to master basis and raise errors if there is a "Traceback" in the report.
[2015-10-19T15:55:56.793Z] <53135b495e986b0712efc453> Is setting `gamma` to `1 / n_features` the correct thing to do for `gamma = 'auto'`? (https://github.com/scikit-learn/scikit-learn/issues/5434#issuecomment-149223797)
[2015-10-19T15:56:13.695Z] <541a528b163965c9bc2053de> I enabled it a bit too early and PRs that don't have the `circle.yml` file yield a spurious failure. That should no longer happen on rebased PRs though.
[2015-10-19T16:08:52.259Z] <54d4a1d6db8155e6700f853b> @ogrisel stupid question: what is our default deprecation strategy? We want something to be deprecated in two releases or in one?
[2015-10-19T16:09:59.429Z] <541a528b163965c9bc2053de> 2
[2015-10-19T16:10:16.512Z] <54d4a1d6db8155e6700f853b> because https://github.com/scikit-learn/scikit-learn/pull/5451/files#diff-65dc1c804f310acfd90f5ea83286065cL440 was only deprecated in 0.17
[2015-10-19T16:10:25.151Z] <541a528b163965c9bc2053de> deprecated in n and will be removed in n + 2
[2015-10-19T16:10:38.873Z] <54d4a1d6db8155e6700f853b> and I think the same is true for the default multi-output averaging, but I can't find a whatsnew entry for that
[2015-10-19T16:13:12.456Z] <541a528b163965c9bc2053de> Oh that's bad. We must have missed in the review process. This is why I always ask to explicitly state the explicit deprecation message "this feature is deprecated in n and will be removed in n + 2".
[2015-10-19T16:13:20.982Z] <54d4a1d6db8155e6700f853b> @ogrisel should I backport https://github.com/scikit-learn/scikit-learn/commit/49e8fd33e8be83c016e61f866d3505387ba423af or do you want to?
[2015-10-19T16:14:31.567Z] <541a528b163965c9bc2053de> thanks for the heads up, let me do the backport
[2015-10-19T16:20:43.553Z] <541a528b163965c9bc2053de> done
[2015-10-19T16:24:11.475Z] <54bd0a4fdb8155e6700ed136> GPs are merged!!
[2015-10-19T16:26:31.995Z] <541a528b163965c9bc2053de> @amueller what is your thought about https://github.com/scikit-learn/scikit-learn/pull/5451/files#diff-65dc1c804f310acfd90f5ea83286065cL440? Shall we extend the deprecation period to 0.19 to be inline with our general policy or shall we remove the code and respect the original deprecation message?
[2015-10-19T16:28:57.274Z] <541a528b163965c9bc2053de> @glouppe \o/
[2015-10-19T16:29:07.789Z] <541a528b163965c9bc2053de> MLPs are next :)
[2015-10-19T16:34:07.576Z] <541a528b163965c9bc2053de> @amueller @glouppe we should get out of the sprint room before 7pm (Paris time) and people are actually starting to leave
[2015-10-19T16:34:57.508Z] <54bd0a4fdb8155e6700ed136> I just added the entry in the what's new
[2015-10-19T16:35:00.303Z] <54bd0a4fdb8155e6700ed136> OK no problem
[2015-10-19T16:36:57.016Z] <54bd0a4fdb8155e6700ed136> we should now make some cleanup regarding open issues for GPs
[2015-10-19T16:37:04.659Z] <54bd0a4fdb8155e6700ed136> I guess most of them are irrelevant now
[2015-10-19T16:37:48.200Z] <541a528b163965c9bc2053de> good point
[2015-10-19T16:40:46.572Z] <541a528b163965c9bc2053de> ok I am off for tonight, see you tomorrow
[2015-10-19T16:41:12.312Z] <54bd0a4fdb8155e6700ed136> same
[2015-10-19T16:41:14.958Z] <54bd0a4fdb8155e6700ed136> have fun
[2015-10-19T16:41:24.367Z] <54bd0a4fdb8155e6700ed136> bonjour a tous de ma part  :)
[2015-10-19T17:58:41.750Z] <54d4a1d6db8155e6700f853b> Looks like I'm coming over, doc says I'll be fine
[2015-10-19T18:04:10.941Z] <53135b495e986b0712efc453> Yay!!! Thanks :)
[2015-10-19T18:15:14.683Z] <54d4a1d6db8155e6700f853b> @ogrisel the cron job on the doc builder doesn't seem to have triggered this morning. I guess it should trigger tomorrow morning before you see this message.
[2015-10-19T19:11:30.593Z] <54d0b7eadb8155e6700f63f9> great news @amueller !
[2015-10-19T20:15:16.785Z] <54d4a1d6db8155e6700f853b> I'll be with you tomorrow after lunch, unless I get lost. I don't have a phone aka google map
[2015-10-19T20:16:26.928Z] <541a528b163965c9bc2053de> great !
[2015-10-20T07:21:39.567Z] <54bd0a4fdb8155e6700ed136> 
[2015-10-20T07:21:55.668Z] <54bd0a4fdb8155e6700ed136> 
[2015-10-20T07:22:09.026Z] <54bd0a4fdb8155e6700ed136> 
[2015-10-20T07:23:32.624Z] <54bd0a4fdb8155e6700ed136> 
[2015-10-20T07:24:00.124Z] <54bd0a4fdb8155e6700ed136> 
[2015-10-20T07:25:44.560Z] <54bd0a4fdb8155e6700ed136> 
[2015-10-20T08:37:30.737Z] <53135b495e986b0712efc453> should there be need contrib tag in #4687?
[2015-10-20T08:58:24.109Z] <53135b495e986b0712efc453> @zermelozf #3846 ? There are like 90 odd examples to be added ;) (@ogrisel and others - Do you feel this one would be useful or should he pick something else from the recently tagged pool of issues to work on?)
[2015-10-20T09:09:48.657Z] <53135b495e986b0712efc453> here too (need contrib to be removed) - #5322
[2015-10-20T09:44:08.989Z] <53135b495e986b0712efc453> @glouppe Could you please remove the "Need Contributor" tag from #5474, #4687, #5455, #5447, #5432, #5380 ?
[2015-10-20T09:46:09.849Z] <54bd0a4fdb8155e6700ed136> all done
[2015-10-20T09:46:20.018Z] <53135b495e986b0712efc453> Thanks :beers:
[2015-10-20T10:04:20.439Z] <53135b495e986b0712efc453> @glouppe also from this one - 5290 and maybe assign it to Arthur? (sorry for repeatedly pinging you ;) )
[2015-10-20T11:07:55.721Z] <54bd0a4fdb8155e6700ed136> done
[2015-10-20T11:08:07.868Z] <54bd0a4fdb8155e6700ed136> unfortunately, I cannot assign to people outside of the scikit-learn team
[2015-10-20T11:08:11.050Z] <54bd0a4fdb8155e6700ed136> dunno why
[2015-10-20T11:32:42.964Z] <53135b495e986b0712efc453> This one can be closed - #5060
[2015-10-20T11:33:15.445Z] <53135b495e986b0712efc453> (It was fixed by #5084)
[2015-10-20T11:37:24.054Z] <555b8aa615522ed4b3e0a160> @ogrisel in sklearn.metrics.pairwise._parallel_pairwise, the joblib Parallel loop is slowed by thread locking, which is weird with the multiprocessing backend
[2015-10-20T11:41:33.207Z] <55e5c37d0fc9f982beaf4d61> issue #5481 is actually a batch of small issues on estimators that fails on read only memory map data once check_array process memory map without copying their content unnecessarily. I guess it could be labelled as easy as it could be addressed by new contributors 
[2015-10-20T11:46:47.450Z] <53135b495e986b0712efc453> @glouppe If you are able to find time could you review #4294 ? ;)
[2015-10-20T11:47:52.167Z] <54bd0a4fdb8155e6700ed136> wow, this is poisoned gift you are giving me there
[2015-10-20T11:47:59.772Z] <53135b495e986b0712efc453> :P :P
[2015-10-20T11:48:22.018Z] <54bd0a4fdb8155e6700ed136> I never touched these modules though
[2015-10-20T11:48:44.026Z] <53135b495e986b0712efc453> Lol okay :D I am eagerly waiting for Andy ;)
[2015-10-20T12:25:28.160Z] <54d4ae8cdb8155e6700f858d> hi guys, not sure if that's the place to ask but I'm looking for a way to use a function-call instead of already having the target value next to the features. So I'd like to put in the features as usual but don't know the results yet. This is because I don't know them and also don't want to run them since it would take to long to do this with a grid-brute. I'm hoping to save time by using a more advanced search mechanism instead that I can feed a function that then puts out the results. I've only found examples so far where the target values are already known. Any help on what to look for?
[2015-10-20T12:27:52.737Z] <54d4a1d6db8155e6700f853b> can anyone get me? I'm in the lobby
[2015-10-20T12:28:33.841Z] <54d4ae8cdb8155e6700f858d> another thing I'm looking for is a function that I can give a sample of numbers, let's say a np array of 1000 numbers and then have that function create a sample of N numbers with the same distribution characteristics as the input numbers...
[2015-10-20T12:28:35.906Z] <53135b495e986b0712efc453> 
[2015-10-20T12:29:08.957Z] <53135b495e986b0712efc453> Olivier is coming!
[2015-10-20T13:10:41.021Z] <54d4a1d6db8155e6700f853b> wohoo wifi
[2015-10-20T13:18:00.265Z] <541a528b163965c9bc2053de> \o/
[2015-10-20T13:43:44.006Z] <54d4a1d6db8155e6700f853b> @ogrisel can we trigger circleci on https://github.com/scikit-learn/scikit-learn/pull/5451 again?
[2015-10-20T16:21:44.197Z] <54d4a1d6db8155e6700f853b> Btw, if you add an entry to whatsnew.rst, please include a link to the github issue / pull request!
[2015-10-20T17:38:42.651Z] <53810862048862e761fa2887> Hello, I am trying to understand the current Gradient Boosting code
[2015-10-20T17:39:25.040Z] <53810862048862e761fa2887> Can someone point out where step 3 is being performed ? According to the this https://en.wikipedia.org/wiki/Gradient_boosting#Algorithm
[2015-10-21T06:11:00.850Z] <54bd0a4fdb8155e6700ed136> @rvraghav93 In addition to finding issues to fix at the sprint (which is great!), could you also try to promote reviewing :) You can tell people to look for PRs with the [MRG] tag, these are the ones ready for review
[2015-10-21T06:56:13.378Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar you mean 2.3,  right?
[2015-10-21T07:31:53.709Z] <54e07d4015522ed4b3dc0856> if anyone has a PR that needs review that is what I am focusing on - though some stuff may be outside my wheelhouse
[2015-10-21T07:41:59.668Z] <54bd0a4fdb8155e6700ed136> @kastnerkyle #4294 would need some love, but this is huge
[2015-10-21T07:42:32.573Z] <54bd0a4fdb8155e6700ed136> (though both arnaud and andy have been reviewing it)
[2015-10-21T07:43:06.114Z] <54bd0a4fdb8155e6700ed136> #5291 maybe?
[2015-10-21T07:44:43.966Z] <54bd0a4fdb8155e6700ed136> or any help with all the mrg+1 PRs is welcome, so that we can have some of those merged 
[2015-10-21T07:52:50.701Z] <54d4a1d6db8155e6700f853b> @kastnerkyle https://github.com/scikit-learn/scikit-learn/pull/5358 ;)
[2015-10-21T07:58:46.426Z] <54d4a1d6db8155e6700f853b> Anyone wanna weigh in on #5319 (adding k modes to related projects)
[2015-10-21T08:02:45.066Z] <54d4a1d6db8155e6700f853b> Anything anyone want's me to have a look at?
[2015-10-21T08:16:29.690Z] <53135b495e986b0712efc453> I have an urgent bank work :( I'll be coming in the afternoon. Apologies :grin: 
[2015-10-21T08:16:47.846Z] <53135b495e986b0712efc453> @glouppe sure!! Will do :)
[2015-10-21T08:17:05.529Z] <541a528b163965c9bc2053de> @rvraghav93 no problem.
[2015-10-21T08:18:00.932Z] <541a528b163965c9bc2053de> @rvraghav93 hopefully by then I will have finished reviewing your CV PR ;)
[2015-10-21T08:18:27.394Z] <54d4a1d6db8155e6700f853b> can we discuss #5023
[2015-10-21T08:18:28.542Z] <54e07d4015522ed4b3dc0856> @amueller #5358 looks like a +2 now with @ogrisel 
[2015-10-21T08:18:54.799Z] <541a528b163965c9bc2053de> @arthurmensch needs to rebase it first
[2015-10-21T08:19:23.346Z] <541a528b163965c9bc2053de> I mean #5358
[2015-10-21T08:19:37.096Z] <54d4a1d6db8155e6700f853b> @ogrisel opinions on #5023 ?
[2015-10-21T08:19:48.869Z] <54d4a1d6db8155e6700f853b> I wanna ask gael and arnaud, too
[2015-10-21T08:20:26.381Z] <54d4a1d6db8155e6700f853b> lol https://github.com/scikit-learn/scikit-learn/pull/5498/files#r42594166
[2015-10-21T08:20:35.282Z] <54d4a1d6db8155e6700f853b> I think this is a first, Gael telling me to be more pragmatic
[2015-10-21T08:26:28.669Z] <54d4a1d6db8155e6700f853b> not sure I should screenshot
[2015-10-21T08:50:08.778Z] <54d4a1d6db8155e6700f853b> @ogrisel you agree that GaussianProcesses should be removed in 0.20, right?
[2015-10-21T08:50:21.970Z] <54d4a1d6db8155e6700f853b> then we need to fix and backport
[2015-10-21T08:54:30.012Z] <541a528b163965c9bc2053de> old GP is deprecated in 0.18, removed in 0.20
[2015-10-21T08:54:38.612Z] <541a528b163965c9bc2053de> indeed
[2015-10-21T08:56:07.392Z] <54bd0a4fdb8155e6700ed136> ok my bad then
[2015-10-21T08:56:10.298Z] <54bd0a4fdb8155e6700ed136> i'll fix that
[2015-10-21T08:59:26.822Z] <54bd0a4fdb8155e6700ed136> done
[2015-10-21T09:14:34.528Z] <541a528b163965c9bc2053de> #5504 and #5505 need contributors: those are documentation related issues. @rvraghav93: @amueller told me to tell you to leave those issues for others ;)
[2015-10-21T09:15:53.253Z] <54d4a1d6db8155e6700f853b> thanks @glouppe 
[2015-10-21T09:16:55.842Z] <54d4a1d6db8155e6700f853b> hm similarly here: #5452 we should change the version. or backport the deprecation to 0.17
[2015-10-21T09:17:34.961Z] <54e07d4015522ed4b3dc0856> #5500 as well
[2015-10-21T09:17:42.181Z] <54e07d4015522ed4b3dc0856> documentation fixes
[2015-10-21T09:21:15.002Z] <54d4a1d6db8155e6700f853b> ah needs contributor as well...
[2015-10-21T09:39:49.603Z] <54d4a1d6db8155e6700f853b> @kastnerkyle if you are bored, maybe look at #5008 (needs reviews)
[2015-10-21T10:21:33.858Z] <54d4a1d6db8155e6700f853b> I though #5141 was merged, whoops (randomized_svd default parameters and normalization)
[2015-10-21T10:21:40.858Z] <54d4a1d6db8155e6700f853b> reviews appreciated
[2015-10-21T10:33:41.318Z] <54e07d4015522ed4b3dc0856> I am +1 on 5141
[2015-10-21T10:35:06.341Z] <54e07d4015522ed4b3dc0856> so it is +2 now - if tests pass you can go ahead and hit the button @amueller 
[2015-10-21T10:40:20.193Z] <54bd0a4fdb8155e6700ed136> you can go ahead and merge Kyle :)
[2015-10-21T10:40:59.640Z] <53810862048862e761fa2887> Yes @amueller , I mean 2.3
[2015-10-21T10:46:08.260Z] <54e07d4015522ed4b3dc0856> @glouppe traaaaaaaaaaaaavis. so slow. it needs to hurry up before andy stops eating... he is faster than me :D
[2015-10-21T10:46:17.426Z] <54e07d4015522ed4b3dc0856> I'll never win the "merge button shootout"
[2015-10-21T10:47:49.918Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar in ``update_terminal_region`` I think. not sure though
[2015-10-21T10:48:20.912Z] <54d4a1d6db8155e6700f853b> @ogrisel had some thoughts about doing only two power iterations, I think
[2015-10-21T10:51:11.185Z] <54e07d4015522ed4b3dc0856> I thought those were addressed, but we can let him hit the button instead
[2015-10-21T10:56:11.212Z] <54d4a1d6db8155e6700f853b> does anyone at the sprint have ibuprofene?
[2015-10-21T11:24:33.059Z] <54d4a1d6db8155e6700f853b> can people still look at travis logs? https://travis-ci.org/scikit-learn/scikit-learn/builds/86595504 for example?
[2015-10-21T11:24:53.439Z] <54d4a1d6db8155e6700f853b> I think travis just throttled our IP
[2015-10-21T11:25:35.574Z] <54bd0a4fdb8155e6700ed136> keeps "loading" here
[2015-10-21T11:27:01.849Z] <54d4a1d6db8155e6700f853b> so it is not our IP
[2015-10-21T11:27:04.521Z] <54bd0a4fdb8155e6700ed136> https://www.traviscistatus.com/
[2015-10-21T11:32:09.531Z] <541a528b163965c9bc2053de> H99 errors
[2015-10-21T11:32:26.972Z] <541a528b163965c9bc2053de> https://devcenter.heroku.com/articles/error-codes#h99-platform-error
[2015-10-21T11:32:33.376Z] <541a528b163965c9bc2053de> could be anything
[2015-10-21T11:49:11.293Z] <53135b495e986b0712efc453> @ogrisel Lol okay ;) and thanks a lot for the reviews :)
[2015-10-21T11:49:24.050Z] <541a528b163965c9bc2053de> I still need to finish that one.
[2015-10-21T12:19:56.623Z] <54d4a1d6db8155e6700f853b> I remember there was a discussion about how to call a function that gives uncertainty estimates on regression values. Where was that? I can't find it any more
[2015-10-21T12:26:39.212Z] <54d4a1d6db8155e6700f853b> We need reviews on #4490 and want to backport it.
[2015-10-21T12:28:22.281Z] <54d4a1d6db8155e6700f853b> I'm going to lie on the couch in front of the room if anyone is looking for me. I'm beginning to question my decision to take a flight yesterday ^^
[2015-10-21T12:51:13.272Z] <541a528b163965c9bc2053de> > I remember there was a discussion about how to call a function that gives uncertainty estimates on regression values. Where was that? I can't find it any more  `return_std` on the `predict` method of old GPs
[2015-10-21T12:52:28.720Z] <541a528b163965c9bc2053de> I thought we discussed the use of the same parameter for another non-GP regressor (I checked RidgeCV but it's not it apparently).
[2015-10-21T13:56:02.605Z] <54d4a1d6db8155e6700f853b> That is doing interval predictions. that is slightly different. sometimes you want to evaluate the density at a certain point
[2015-10-21T14:11:27.646Z] <53810862048862e761fa2887> @amueller While you are there, can you have a discussion with the other about the `OneHotEncoder` issue and in general how we can handle strings with it ? 
[2015-10-21T14:12:41.282Z] <53810862048862e761fa2887> others*
[2015-10-21T14:13:06.442Z] <54d4a1d6db8155e6700f853b> the joblib fun on windows is back: https://ci.appveyor.com/project/amueller/scikit-learn/build/1.0.1408/job/7sldjuplbqf2t31u
[2015-10-21T14:13:51.738Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar what was the open questions? if there are  columns with mixed strings and numbers?
[2015-10-21T14:15:51.004Z] <53810862048862e761fa2887> Yes, specially an array with `1` and `"1"` in the same column
[2015-10-21T14:16:51.647Z] <53810862048862e761fa2887> @amueller What is your definition of "fun" ? :D
[2015-10-21T14:17:10.739Z] <541a528b163965c9bc2053de> something that you cannot reproduce on your dev environment
[2015-10-21T14:17:44.815Z] <541a528b163965c9bc2053de> Maybe @TomDLT can give it a try.
[2015-10-21T14:22:49.497Z] <53810862048862e761fa2887> I have faced similar issues before somewhere else.
[2015-10-21T14:29:51.855Z] <541a528b163965c9bc2053de> Yes: it used to be very frequent in the past and at some point it stopped appearing. But now it's back. I am not sure whether it reveals a true problem in the way we use multiprocessing under windows or is caused by a problem on the appveyor CI infrastructure.
[2015-10-21T14:30:54.171Z] <53810862048862e761fa2887> I have windows on dual-boot, but I have to setup scikit-learn over there before I can run tests. Does anyone else over there have it ?
[2015-10-21T14:31:38.685Z] <541a528b163965c9bc2053de> I have a windows VM in the cloud that I use for such debugging. I can give it another try.
[2015-10-21T15:02:46.247Z] <55e5c37d0fc9f982beaf4d61> PR #5492 is ready for review. Caching + removal of .c file seems to be working
[2015-10-21T15:03:03.521Z] <55e5c37d0fc9f982beaf4d61> It's a bit hackish though, waiting for some proper build system...
[2015-10-21T15:18:03.198Z] <53810862048862e761fa2887> @amueller In `2.3` when they say "argmin" I assume there will be some sort of a loop ? I can't seem to find that anywhere
[2015-10-21T15:40:07.186Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar there doesn't necessarily be a loop
[2015-10-21T15:42:54.040Z] <54d4a1d6db8155e6700f853b> @ogrisel I can not reproduce the issue with conda locally
[2015-10-21T15:43:15.113Z] <53810862048862e761fa2887> @amueller You mean it could be computed by some function in `scipy.optimize` or similar ?
[2015-10-21T15:46:25.218Z] <541a528b163965c9bc2053de> FYI the https://ci.appveyor.com/project/amueller/scikit-learn/build/1.0.1408/job/7sldjuplbqf2t31u failure might be caused by the fact that this was deployed on @amueller's appveyor account which runs of a different infra than the one we should usually run on (that is using the @sklearn-ci account). I reconfigured the appveyor webhook on the scikit-learn repo and hopefully the future appveyor builds will run on the correct infra and not fail this way anymore. If this is not the case we will have to investigate.
[2015-10-21T15:46:50.482Z] <541a528b163965c9bc2053de> > @ogrisel I can not reproduce the issue with conda locally  So it might be a consequence of the past travis outage
[2015-10-21T15:47:34.690Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar  or there could be a closed form solution
[2015-10-21T15:47:51.057Z] <54d4a1d6db8155e6700f853b> @ogrisel yeah I think it was a fluke
[2015-10-21T16:03:40.598Z] <53810862048862e761fa2887> If you see this https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/gradient_boosting.py#L254 for example,  only the learning late is multiplied.
[2015-10-21T16:15:54.636Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar I'm not sure. Maybe ping @pprett ?
[2015-10-21T16:19:59.664Z] <54d4a1d6db8155e6700f853b> @ogrisel can we talk about handling strings in OneHotEncoder ?
[2015-10-21T16:29:25.404Z] <54d4a1d6db8155e6700f853b> @ogrisel have you asked arnaud about the greater is better issue?
[2015-10-21T16:46:12.827Z] <541a528b163965c9bc2053de> no have have not asked him, and yes we can talk about strings in ohe
[2015-10-21T16:51:39.269Z] <54d4a1d6db8155e6700f853b> @vig
[2015-10-21T16:51:51.924Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar about the one hot encoder: we are fine if dtype=object, right?
[2015-10-21T16:52:18.591Z] <53810862048862e761fa2887> Yes
[2015-10-21T16:53:14.200Z] <54d4a1d6db8155e6700f853b> so the problem is only if you pass a list?
[2015-10-21T16:55:01.127Z] <53810862048862e761fa2887> Yes, and I am assuming based on the dtype of the input, we will have 2 different pieces of code to process them (object and dtype)
[2015-10-21T16:55:51.679Z] <54d4a1d6db8155e6700f853b> why?
[2015-10-21T16:56:32.441Z] <53810862048862e761fa2887> Because the current code only works for integers
[2015-10-21T16:56:46.367Z] <54d4a1d6db8155e6700f853b> right.
[2015-10-21T16:57:09.116Z] <54d4a1d6db8155e6700f853b> but maybe the new code based on unique would work for both integers and objects? well ok that is not that important
[2015-10-21T17:00:01.739Z] <54d4a1d6db8155e6700f853b> maybe we do ``check_array`` and if we get back a string dtype, we do the conversion again with dtype object. Does that solve all problems?
[2015-10-21T17:00:05.222Z] <53810862048862e761fa2887> Even with #5270 the code cannot support non-integer types
[2015-10-21T17:03:09.902Z] <53810862048862e761fa2887> the problem is if converting something like `[1, '1', 2 , 3 , 4]` to an integer, casting to integer works and gives wrong results
[2015-10-21T17:36:41.485Z] <53810862048862e761fa2887> Now that I think about it, since the `LabelEncoder` has a lot of the functionality needed, instead have a subclass of `Pipeline` called `OneHotObjectEncoder`
[2015-10-21T19:09:56.889Z] <54e07d6515522ed4b3dc0858> So the KNN docstrings mention from place to place the idea that `metric` can be `"precomputed"`, but I can't get that to work, the current code doesn't seem to implement it.
[2015-10-21T19:12:19.208Z] <54e07d6515522ed4b3dc0858> I can't seem to find any documentation or any open issues about this. 
[2015-10-21T19:17:40.274Z] <54e07d6515522ed4b3dc0858> hmm I think it's fixed in master actually, sorry about the noise
[2015-10-22T07:26:07.396Z] <54d4a1d6db8155e6700f853b> good morning :)
[2015-10-22T07:27:22.243Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar For the one hot encoder: that
[2015-10-22T07:27:49.353Z] <54d4a1d6db8155e6700f853b> that's why I said try to do check_array, and if we get a string type back, instead make it an object type.
[2015-10-22T07:28:02.974Z] <54d4a1d6db8155e6700f853b> your example will give a string type
[2015-10-22T07:28:15.822Z] <54d4a1d6db8155e6700f853b> if we detect that and instead convert with an explicit object dtype, it'll work
[2015-10-22T07:44:01.752Z] <54bd0a4fdb8155e6700ed136> good morning
[2015-10-22T07:44:14.852Z] <541a528b163965c9bc2053de> good morning
[2015-10-22T07:44:52.744Z] <54bd0a4fdb8155e6700ed136> hey, by any chance, what would you recommend for a good introduction to linear models? (to be recommended as reading materials for a workshop with an audience of physicists)
[2015-10-22T07:45:16.864Z] <54bd0a4fdb8155e6700ed136> (covering linear regression, lasso, svm, etc)
[2015-10-22T08:18:07.745Z] <54e07d4015522ed4b3dc0856> good morning - @ogrisel might comment more but I would probably say elements of statistical learning
[2015-10-22T08:18:22.782Z] <54e07d4015522ed4b3dc0856> or the intro version of that (can't remember the name)
[2015-10-22T08:19:07.668Z] <54e07d4015522ed4b3dc0856> "Introduction to Statistical Learning"
[2015-10-22T08:21:34.222Z] <54bd0a4fdb8155e6700ed136> okay, thanks Kyle
[2015-10-22T08:22:15.719Z] <541a528b163965c9bc2053de> I don't have a better suggestion
[2015-10-22T08:56:31.059Z] <54bd0a4fdb8155e6700ed136> is it me or github is very slow at the moment?
[2015-10-22T10:29:13.529Z] <541a528b163965c9bc2053de> it seems fine now
[2015-10-22T10:40:22.472Z] <54d4a1d6db8155e6700f853b> @glouppe you just missed the introduction of the scikit-learn advancement proposal
[2015-10-22T11:11:06.867Z] <54bd0a4fdb8155e6700ed136> =(
[2015-10-22T11:17:41.832Z] <54bd0a4fdb8155e6700ed136> Given my +1 and partial reviews from @amueller, @ngoix and @jmschrei, can we merge #5487?
[2015-10-22T11:38:09.268Z] <54bd0a4fdb8155e6700ed136> thanks alex :)
[2015-10-22T12:48:56.826Z] <54e07d4015522ed4b3dc0856> @glouppe I think it is important to note that SLAP is our new acronym...
[2015-10-22T13:13:01.750Z] <54d4a1d6db8155e6700f853b> @kastnerkyle @GaelVaroquaux called the repo "enhancement" :-/ https://github.com/scikit-learn/enhancement_proposals
[2015-10-22T13:13:45.780Z] <54d4a1d6db8155e6700f853b> stupid git question: how to I update a local branch that is a pr/1234 branch?
[2015-10-22T13:13:55.539Z] <54d4a1d6db8155e6700f853b> i.e. that comes from a pull request
[2015-10-22T14:36:26.418Z] <54e07d4015522ed4b3dc0856> does anyone know if CircleCI is pushing the doc to github? Or just creating an artifact that some other thing can get
[2015-10-22T14:36:44.764Z] <54e07d4015522ed4b3dc0856> I am trying to make CircleCI push a doc (for another project) after succesful build
[2015-10-22T15:02:26.665Z] <54d4a1d6db8155e6700f853b> https://skll.readthedocs.org/en/latest/run_experiment.html#param-grids-optional
[2015-10-22T15:04:18.629Z] <54d4a1d6db8155e6700f853b> https://github.com/EducationalTestingService/skll/blob/5ea61b8dfc23570e661468457a262b6c2242daa9/skll/learner.py#L62
[2015-10-22T16:36:19.210Z] <54d4a1d6db8155e6700f853b> I think I'll have to head out soon
[2015-10-22T16:36:38.946Z] <54d4a1d6db8155e6700f853b> @kastnerkyle that is not working yet, there is a PR
[2015-10-22T16:55:22.519Z] <54e07d4015522ed4b3dc0856> ok - I got the build part working on sklearn-theano pretty easily, and I think Fred will take a look at it for Theano as well. This is a lot better than a cron job...
[2015-10-22T19:32:20.834Z] <54d4a1d6db8155e6700f853b> indeed
[2015-10-22T19:32:30.423Z] <54d4a1d6db8155e6700f853b> lol I don't think I wrote a line of code this week
[2015-10-23T02:59:54.172Z] <54c084dbdb8155e6700eed4c> @amueller ... http://opendatascicon.com/scikit-learn-code-sprint/ ... Looking forward to it!
[2015-10-23T07:13:19.823Z] <54d4a1d6db8155e6700f853b> @trevorstephens cool :) glad to have you there!
[2015-10-23T07:28:18.998Z] <54bd0a4fdb8155e6700ed136> will we have MLP by today? :)
[2015-10-23T07:28:23.073Z] <54bd0a4fdb8155e6700ed136> and isolation forest?
[2015-10-23T07:28:28.687Z] <54bd0a4fdb8155e6700ed136> that would be very nice
[2015-10-23T07:40:48.687Z] <54e07d4015522ed4b3dc0856> sadly mlp seems unlikely IMO - lots of hard choices but it is getting closer. if there are other things to be reviewed I can take a look - I am also hopeful the PCA fixes by Giorgio will go today (if they didn't last night!)
[2015-10-23T07:53:19.830Z] <54bd0a4fdb8155e6700ed136> it's been more than a year since the MLP PRs have started :/
[2015-10-23T07:53:45.103Z] <54bd0a4fdb8155e6700ed136> if these decisions are only about internals, we should try to be pragmatic at some point
[2015-10-23T08:41:34.725Z] <54e07d4015522ed4b3dc0856> yes it is mostly logical - some of the core logic is spread over several classes which makes it hard to reason about its behavior especially w.r.t to stopping criterion. But Andy has a student on it full-time (ish) who is quite good so I don't think it will be much longer
[2015-10-23T08:41:47.138Z] <54e07d4015522ed4b3dc0856> and the documentation is basically done IMO - which was a huge chunk of the work
[2015-10-23T13:22:19.034Z] <54d4a1d6db8155e6700f853b> anyone wants to review #5540 ?
[2015-10-23T13:23:31.095Z] <54d4a1d6db8155e6700f853b> @kastnerkyle but if it's only refactoring, we don't really need to do that for merging if it's not public API, right?
[2015-10-23T13:58:55.903Z] <54e07d4015522ed4b3dc0856> @glouppe things are looking positive for the MLP - you might get your wish :D
[2015-10-23T14:07:52.638Z] <54bd0a4fdb8155e6700ed136> \o/
[2015-10-23T14:23:18.498Z] <54e07d4015522ed4b3dc0856> #5299 is very close if anyone wants to review
[2015-10-23T14:34:20.084Z] <54d4a1d6db8155e6700f853b> we need to do ##5502 if anyone is looking for an issue to pick up
[2015-10-23T14:34:28.488Z] <54d4a1d6db8155e6700f853b> it's needed for 0.17
[2015-10-23T15:33:45.190Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/5274#discussion-diff-42377195
[2015-10-23T15:33:51.281Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/5565#issuecomment-150609391
[2015-10-23T16:52:30.591Z] <54e07d4015522ed4b3dc0856> @glouppe it's gonna happen. If Travis ever runs
[2015-10-26T09:21:08.778Z] <5615bee3d33f749381a8a4f5> I have a stupid general question here: What are possible ways to do key words/sentenses extraction from a large text corpora?
[2015-10-26T10:40:21.580Z] <553e8e1015522ed4b3df97f7> @bawongfai have you tried textrank?
[2015-10-26T11:39:25.408Z] <5615bee3d33f749381a8a4f5> @vortex-ape not really. How does it compare to document vectorisation?
[2015-10-26T11:41:11.687Z] <53810862048862e761fa2887> Text rank tries to order sentences by their importance 
[2015-10-26T11:42:35.206Z] <53810862048862e761fa2887> A sentence is of more importance  if it talks about a large number of things and thus gets a higher score. 
[2015-10-26T11:43:56.744Z] <5615bee3d33f749381a8a4f5> Then is it good bad for a short sentence that contains potential keyword?
[2015-10-26T11:44:02.433Z] <5615bee3d33f749381a8a4f5> bad i meant
[2015-10-26T11:44:43.514Z] <53810862048862e761fa2887> From what I've used it, bad
[2015-10-26T11:45:08.457Z] <5615bee3d33f749381a8a4f5> So what do you suggest as an alternative?
[2015-10-26T11:45:15.511Z] <53810862048862e761fa2887> It generally gives a long sentence talking about lots kf things 
[2015-10-26T11:45:59.031Z] <53810862048862e761fa2887> Can you give me an example of an output you would expect? 
[2015-10-26T11:48:15.145Z] <53810862048862e761fa2887> You can give this a try, but I have no idea what kind of output to expect. 
[2015-10-26T11:48:18.437Z] <53810862048862e761fa2887> http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf.html
[2015-10-26T11:48:30.525Z] <5615bee3d33f749381a8a4f5> @vighneshbirodkar I would like to have a summarisation of conversation
[2015-10-26T11:48:38.690Z] <5615bee3d33f749381a8a4f5> conversation, by nature, could be short
[2015-10-26T11:49:08.749Z] <53810862048862e761fa2887> For example we are having one, what would you expect the summary to be ?
[2015-10-26T11:49:42.128Z] <5615bee3d33f749381a8a4f5> I guess the summary would be about text summarisation and keyword extraction
[2015-10-26T11:52:16.007Z] <53810862048862e761fa2887> You can try the nmf example I posted. 
[2015-10-26T11:52:38.155Z] <553e8e1015522ed4b3df97f7> would you want an abstractive summary or an extractive one? I used textrank once to get extractive summaries of a conversation and it seemed to work well, though I didn't compare it with other methods
[2015-10-26T11:53:27.121Z] <53810862048862e761fa2887> I don't know of any such technique. Since I had worked with text rank I thought I'd give my 2 cents 
[2015-10-26T11:54:38.039Z] <5615bee3d33f749381a8a4f5> extractive is fine for me
[2015-10-26T11:54:58.311Z] <5615bee3d33f749381a8a4f5> Just pick 2 most important sentences and display
[2015-10-26T11:58:07.758Z] <553e8e1015522ed4b3df97f7> You could experiment with both these methods and explore about other ones too, and see which one gives you the desired results, I used textrank as a quick hack in a hackathon so I'm no expert in this regard 
[2015-10-26T11:59:26.235Z] <553e8e1015522ed4b3df97f7> :smile: 
[2015-10-26T12:01:31.278Z] <5615bee3d33f749381a8a4f5> @vortex-ape thanks, i will try textrank first
[2015-10-26T12:01:47.392Z] <5615bee3d33f749381a8a4f5> I would like to go into deep learning approach later
[2015-10-26T15:26:43.865Z] <5615bee3d33f749381a8a4f5> @vortex-ape tried textrank, not too bad
[2015-10-29T23:18:48.018Z] <54d4a1d6db8155e6700f853b> @ogrisel you think we can release weekend or Monday? Should we talk to conda folks?
[2015-10-29T23:21:21.446Z] <54d4a1d6db8155e6700f853b> hm was about to reach out to asmeurer but I guess he is not the right contact any more ^^ http://asmeurer.github.io/blog/
[2015-10-29T23:23:29.855Z] <54d4a1d6db8155e6700f853b> trying ilanschnell now
[2015-10-29T23:27:27.943Z] <53810862048862e761fa2887> @amueller are you back ?
[2015-10-29T23:31:55.103Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar https://www.youtube.com/watch?v=Q2J9F2sJMT4
[2015-10-29T23:32:38.670Z] <54d4a1d6db8155e6700f853b> sweet I didn't realize gitter embedded youtube videos. really important for github collaborations.
[2015-10-29T23:33:24.793Z] <53810862048862e761fa2887> https://youtu.be/FJbmB9k2Y88
[2015-10-29T23:43:02.967Z] <54d4a1d6db8155e6700f853b> :D
[2015-10-30T05:02:55.847Z] <54c084dbdb8155e6700eed4c> hahaha
[2015-10-30T13:20:41.966Z] <541a528b163965c9bc2053de> @amueller I am reverting the use of the forkserver method by default in joblib as it causes crash in interactive sessions see #5623.
[2015-10-30T13:22:06.762Z] <541a528b163965c9bc2053de> When we have `dill` integrated with joblib then we can re examine that choice.
[2015-10-30T15:35:43.867Z] <54d4a1d6db8155e6700f853b> @ogrisel cool
[2015-10-30T15:35:57.988Z] <54d4a1d6db8155e6700f853b> I'll try to finish the install documentation rewrite today and see what else is up
[2015-10-30T15:36:22.373Z] <541a528b163965c9bc2053de> I am breaking tests under appveyor on Python 2.7 on the 0.17.X branch
[2015-10-30T15:36:48.141Z] <541a528b163965c9bc2053de> https://ci.appveyor.com/project/ogrisel/scikit-learn/build/job/5x1jj8tdg7w30ay2
[2015-10-30T15:37:09.647Z] <541a528b163965c9bc2053de> it does not come from the joblib forkserver mode as it does not exist on Python 2.
[2015-10-30T15:38:00.378Z] <541a528b163965c9bc2053de> on master appveyor tests are broken somewhere else: #5598, @TomDLT is on it apparently.
[2015-10-30T15:38:06.426Z] <541a528b163965c9bc2053de> but this is unrelated.
[2015-10-30T15:42:26.474Z] <541a528b163965c9bc2053de> There is also the problem on the decision trees that are not sample-weight-scale invariant under Linux / Python 32 bit. 
[2015-10-30T15:42:54.213Z] <541a528b163965c9bc2053de> Although the code seems to use `double` typed variable everywhere.
[2015-10-30T15:44:07.824Z] <53135b495e986b0712efc453> (Just leaving a silent note while you guys are online  - Travis now passes on #5566 which is ready for merge ;) )
[2015-10-30T15:45:02.527Z] <541a528b163965c9bc2053de> Please wait for appveyor to catch up and check that this PR does not introduce any new failure under windows.
[2015-10-30T15:45:52.796Z] <541a528b163965c9bc2053de> I have changed the appveyor config to skip redundant builds (option named "Rolling builds" in the appveyor UI) so that it should be able to catch up hopefully.
[2015-10-30T15:47:06.573Z] <541a528b163965c9bc2053de> Both master and 0.17.X  are broken under windows and I would like not to merge any new feature / refactoring that might cause new regressions under windows.
[2015-10-30T15:47:51.675Z] <53135b495e986b0712efc453> Oh!! BTW aren't there any other CI like travis for windows?
[2015-10-30T15:48:17.964Z] <53135b495e986b0712efc453> travis guys are still yet to support windows I think...
[2015-10-30T18:21:03.381Z] <541a528b163965c9bc2053de> @amueller I merged the joblib 0.9.3 fix with a backport. We now run fork mode as in past releases.
[2015-10-30T18:21:30.058Z] <541a528b163965c9bc2053de> @amueller I have been fighting with the 32 bit python tree code but still don't understand the issue.
[2015-10-30T18:22:24.935Z] <541a528b163965c9bc2053de> I will leave have to go offline soon and tomorrow I will go on vacation to Japan and will not have time to help you do the release...
[2015-10-30T18:22:43.714Z] <541a528b163965c9bc2053de> I am sorry to leave you with such a mess, we still have 2 blockers:
[2015-10-30T18:22:53.260Z] <541a528b163965c9bc2053de> https://github.com/scikit-learn/scikit-learn/labels/Blocker
[2015-10-30T18:23:17.431Z] <541a528b163965c9bc2053de> + the install doc to finish and the release itself.
[2015-10-30T18:24:08.236Z] <541a528b163965c9bc2053de> I build the examples on 0.17.X yesterday and they all pass but I am not sure we have backported all the PRs for bugs we marked with the 0.17 milestone.
[2015-10-30T18:30:42.854Z] <541a528b163965c9bc2053de> Also tests are much slower than they used to be. I think we were not careful during the sprint and we merged some PR that contributed very slow tests. I haven't taken the time to investigate yet.
[2015-10-30T18:38:05.831Z] <54d4a1d6db8155e6700f853b> @ogrisel thanks for the wrap up. I have time next week and over the weekend I think.
[2015-10-30T18:38:22.576Z] <54d4a1d6db8155e6700f853b> Is 0.17 fixed on windows?
[2015-10-30T18:38:28.630Z] <541a528b163965c9bc2053de> yes
[2015-10-30T18:39:08.963Z] <54d4a1d6db8155e6700f853b> ah the tests being slow is an issue for master, not the release, right?
[2015-10-30T18:39:52.520Z] <541a528b163965c9bc2053de> @TomDLT is making progress on the appveyor build on master #5636
[2015-10-30T18:40:35.027Z] <541a528b163965c9bc2053de> In the comments of that issue I mention that I ended up disabling the "Rolling builds" option on appveyor. I don't think it does what I think it says it does.
[2015-10-30T18:41:06.516Z] <541a528b163965c9bc2053de> @amueller I have not timed the tests on 0.17.X but it's possible that we backported some slow tests as well.
[2015-10-30T18:50:36.860Z] <54d4a1d6db8155e6700f853b> @ogrisel ok got it.
[2015-10-30T18:51:12.410Z] <541a528b163965c9bc2053de> I need to go now. I might check back later tonight or maybe tomorrow morning but I am not sure I will be able to help any further
[2015-10-30T18:53:59.910Z] <541a528b163965c9bc2053de> bye
[2015-10-30T19:16:54.509Z] <54d4a1d6db8155e6700f853b> bye. have a great trip!
[2015-10-30T19:17:02.843Z] <54d4a1d6db8155e6700f853b> and don't worry too much about it ;)
[2015-10-30T19:31:06.015Z] <54d4a1d6db8155e6700f853b> @trevorstephens are you around?
[2015-10-30T19:31:58.952Z] <54d4a1d6db8155e6700f853b> or maybe someone else has some time to investigate #5164 ? @rvraghav93 or @MechCoder maybe?
[2015-10-30T19:41:35.121Z] <54d4a1d6db8155e6700f853b> is @sieben here? Also: was he at the sprint? 
[2015-10-30T19:54:46.948Z] <53135b495e986b0712efc453> Could someone restart this build - https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.3567
[2015-10-30T19:54:53.735Z] <53135b495e986b0712efc453> seems to have been cancelled ;(
[2015-10-30T19:55:07.358Z] <53135b495e986b0712efc453> And yes I'll look into that now :)
[2015-10-30T20:13:39.496Z] <54d4a1d6db8155e6700f853b> thanks @rvraghav93 :)
[2015-10-30T20:14:29.260Z] <54c084dbdb8155e6700eed4c> @amueller can you give any guidance on doing tests on 32 bit on a 64 bit host? re #5164
[2015-10-30T20:15:28.762Z] <54d4a1d6db8155e6700f853b> @rvraghav93 is on it, I think. If you'd also like to investigate: vagrant or docker
[2015-10-30T20:16:43.090Z] <54d4a1d6db8155e6700f853b> @trevorstephens the last message was for you ;) Vagrant is usually relatively simple and there are ubuntu images that you can just point to
[2015-10-30T20:16:53.547Z] <54c084dbdb8155e6700eed4c> thx
[2015-10-30T20:18:53.107Z] <53135b495e986b0712efc453> BTW someone on our ML asked if we can do nested cv using LabelKFold... we can... I totally forgot to reply him back :/ 
[2015-10-30T20:18:59.395Z] <54d4a1d6db8155e6700f853b> I did
[2015-10-30T20:56:23.056Z] <54c084dbdb8155e6700eed4c> @rvraghav93 are you working on #5164 ? I am almost done building sklearn on vagrant. i am guessing that the problem either exists within the tree building itself, or the homebrew hex encoder in export_graphviz ... py3 discontinued the built-in byte encoding function
[2015-10-30T20:58:17.236Z] <54d4a1d6db8155e6700f853b> hm our appveyor build now takes 4 hours per branch.. meh
[2015-10-30T21:02:07.168Z] <54d4a1d6db8155e6700f853b> does any one remember the old issue for speeding up tests that had a benchmark script?
[2015-10-30T21:25:24.035Z] <54c084dbdb8155e6700eed4c> ive got a fix
[2015-10-30T21:26:41.768Z] <54c084dbdb8155e6700eed4c> https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/export.py#L161 appears to go through a rounding difference in calculating the byte representation of alpha
[2015-10-30T21:26:51.730Z] <54c084dbdb8155e6700eed4c> np.round fixes in ad-hoc tests
[2015-10-30T21:27:11.084Z] <54c084dbdb8155e6700eed4c> will push a pr after i test a tad more
[2015-10-30T21:33:41.068Z] <54c084dbdb8155e6700eed4c> though im not sure if the underlying problem is with the tree impurity numbers, or the alpha calculation
[2015-10-30T21:33:52.472Z] <54c084dbdb8155e6700eed4c> is passing the test sufficient here @amueller  ?
[2015-10-30T21:34:21.449Z] <54c084dbdb8155e6700eed4c> i will have to modify some of the test's correct results to the superior 32 bit numbers :-D
[2015-10-30T21:50:51.031Z] <54d4a1d6db8155e6700f853b> I think passing the test is ok for now. Hm, is colors and value always float? because there is a "/"
[2015-10-30T21:54:59.548Z] <54c084dbdb8155e6700eed4c> bounds are float, so the "/" should make no difference
[2015-10-30T21:56:31.110Z] <54c084dbdb8155e6700eed4c> value is either plucked from impurity or value from the tree itself, depending on regression/classification/multioutput
[2015-10-30T21:56:42.202Z] <54c084dbdb8155e6700eed4c> so should be guaranteed float
[2015-10-30T21:59:06.778Z] <54d4a1d6db8155e6700f853b> ok, just checking ;)
[2015-10-30T21:59:09.880Z] <54c084dbdb8155e6700eed4c> passed on py2.7.10 64bit
[2015-10-30T21:59:15.757Z] <54c084dbdb8155e6700eed4c> trying on vagrant now
[2015-10-30T21:59:27.101Z] <54c084dbdb8155e6700eed4c> will throw to travis if it passes too
[2015-10-30T21:59:55.577Z] <54c084dbdb8155e6700eed4c> what do you take me for @amueller ;-) 
[2015-10-30T22:00:54.318Z] <54d4a1d6db8155e6700f853b> well we all miss details sometimes ;)
[2015-10-30T22:01:49.061Z] <54c084dbdb8155e6700eed4c> haha. well i missed that one. the problem was that i wrote too many tests to bump up my coverage percentage. should never do that.
[2015-10-30T22:02:06.741Z] <54c084dbdb8155e6700eed4c> :-)
[2015-10-30T22:10:06.217Z] <54c084dbdb8155e6700eed4c> well this is annoying. im now getting a fail on 32bit due to the splitting in the tree, not the colours. random state is set on the tree too
[2015-10-30T23:23:18.360Z] <54c084dbdb8155e6700eed4c> @amueller #5644 should fix #5164 , if you happen to have a spare 32 bit box to test on, be a good idea. Fingers crossed on travis, but this passed on my local install and the 32bit vagrant
[2015-10-31T14:42:48.403Z] <541a528b163965c9bc2053de> @amueller some appveyor builds seems to be fast again, especially on 64 bit for some reason: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.3621
[2015-10-31T14:43:09.956Z] <541a528b163965c9bc2053de> maybe there is some variability in the platform
[2015-11-01T21:36:29.714Z] <54d4a1d6db8155e6700f853b> thanks @trevorstephens sorry I'm a bit behind on things.
[2015-11-01T21:41:23.967Z] <54c084dbdb8155e6700eed4c> np
[2015-11-01T23:38:06.842Z] <54c084dbdb8155e6700eed4c> @amueller should https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events be updated to show ODSC?
[2015-11-01T23:39:46.766Z] <54d4a1d6db8155e6700f853b> If you can edit it, feel free ;)
[2015-11-01T23:39:52.714Z] <54d4a1d6db8155e6700f853b> I should probably announce it on the ML
[2015-11-01T23:40:09.889Z] <54c084dbdb8155e6700eed4c> k will do. is it open to non odsc attendees?
[2015-11-01T23:41:22.070Z] <54d4a1d6db8155e6700f853b> yes it is
[2015-11-01T23:41:29.636Z] <54d4a1d6db8155e6700f853b> there was a separate announcement mail, right?
[2015-11-01T23:41:38.928Z] <54d4a1d6db8155e6700f853b> anyone wanna review https://github.com/scikit-learn/scikit-learn/pull/5658 ?
[2015-11-01T23:41:48.912Z] <54d4a1d6db8155e6700f853b> @trevorstephens just setting up a 32bit linux btw ;)
[2015-11-01T23:42:17.130Z] <54c084dbdb8155e6700eed4c> haha. what a pain.
[2015-11-01T23:42:31.096Z] <54c084dbdb8155e6700eed4c> the mail i got was just a link to the odsc landing page
[2015-11-01T23:42:37.074Z] <54c084dbdb8155e6700eed4c> http://opendatascicon.com/scikit-learn-code-sprint/
[2015-11-01T23:42:45.004Z] <54c084dbdb8155e6700eed4c> they never followed up with registration ingo
[2015-11-01T23:42:48.225Z] <54c084dbdb8155e6700eed4c> info
[2015-11-01T23:42:52.984Z] <54c084dbdb8155e6700eed4c> which is on meetup
[2015-11-01T23:42:57.573Z] <54d4a1d6db8155e6700f853b> hm ok
[2015-11-01T23:43:39.430Z] <54d4a1d6db8155e6700f853b> feel free to announce to the ML including any links that might be helpful. At meetup it is announced as a free open meetup, right?
[2015-11-01T23:43:47.315Z] <54d4a1d6db8155e6700f853b> I'm trying to get the 0.17 release rolling ;)
[2015-11-01T23:44:27.668Z] <54d4a1d6db8155e6700f853b> (if you have better things to do I'll do it lateR)
[2015-11-01T23:45:10.295Z] <54c084dbdb8155e6700eed4c> understandable, doing wiki now. will send a note to the ML after
[2015-11-01T23:45:29.795Z] <54c084dbdb8155e6700eed4c> there are no notes on the meetup page about limitations that i see
[2015-11-01T23:47:18.921Z] <54c084dbdb8155e6700eed4c> or on the odsc landing page
[2015-11-01T23:50:32.844Z] <54d4a1d6db8155e6700f853b> yeah there should be none, but people should register (using meetup, I guess)
[2015-11-01T23:50:36.944Z] <54d4a1d6db8155e6700f853b> thanks :)
[2015-11-01T23:54:06.882Z] <54c084dbdb8155e6700eed4c> np. if you want to glance at the wiki ... https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events
[2015-11-02T00:34:35.655Z] <54c084dbdb8155e6700eed4c> @amueller #5164 re-opened by accident? 
[2015-11-02T00:35:52.475Z] <54d4a1d6db8155e6700f853b> @trevorstephens thanks for the mail. #5164 reports more issues
[2015-11-02T00:37:34.049Z] <54c084dbdb8155e6700eed4c> np
[2015-11-02T00:37:43.561Z] <54c084dbdb8155e6700eed4c> i thought that one was limited to graphviz?
[2015-11-02T00:37:58.228Z] <54c084dbdb8155e6700eed4c> there are a couple of other issues with other 32-bit fails\
[2015-11-02T00:38:09.386Z] <54d4a1d6db8155e6700f853b> yeah
[2015-11-02T00:38:54.097Z] <54d4a1d6db8155e6700f853b> I never thought about the fact that anyone can edit the wiki and there is no tracking... hum
[2015-11-02T00:39:22.241Z] <54c084dbdb8155e6700eed4c> there's tracking
[2015-11-02T00:39:27.999Z] <54c084dbdb8155e6700eed4c> click 'edits'
[2015-11-02T00:39:47.722Z] <54c084dbdb8155e6700eed4c> sorry 'revisions'
[2015-11-02T00:39:51.740Z] <54c084dbdb8155e6700eed4c> under the title
[2015-11-02T00:41:31.830Z] <54c084dbdb8155e6700eed4c> i moved the recent paris sprint info to 'past sprints' 
[2015-11-02T00:42:30.688Z] <54c084dbdb8155e6700eed4c> do core contribs get notified of the changes to wiki?
[2015-11-02T00:44:23.869Z] <54d4a1d6db8155e6700f853b> not that I know of.  maybe I could subscribe
[2015-11-02T00:44:29.212Z] <54d4a1d6db8155e6700f853b> yeah I saw, looks good :)
[2015-11-02T00:47:18.152Z] <54d4a1d6db8155e6700f853b> reviews for https://github.com/scikit-learn/scikit-learn/pull/5661 would also be welcome
[2015-11-02T00:48:08.535Z] <54d4a1d6db8155e6700f853b> @trevorstephens the review suggestions are not explicitly for you, I just like to spam the channel ;)
[2015-11-02T00:59:11.276Z] <54c084dbdb8155e6700eed4c> haha ok. i have no familiarity with tsne anyhow :-/ but int64? i didn't even know that existed! number of ants to stack to get to the moon?
[2015-11-02T01:01:02.055Z] <54d4a1d6db8155e6700f853b> damn, I confused #5534 and #5164
[2015-11-02T01:01:16.328Z] <54d4a1d6db8155e6700f853b> you were right, #5164 should have been closed
[2015-11-02T01:01:33.972Z] <54c084dbdb8155e6700eed4c> thought so. just the one failure
[2015-11-02T01:03:55.363Z] <54c084dbdb8155e6700eed4c> anyone who has a spare cycle and cares about package organization, comments about the location of `partial_dependence` in #5653 welcome :-)
[2015-11-02T03:50:14.051Z] <54d4a1d6db8155e6700f853b> anyone who as spare cycles, I just opened 7 pull requests, 4 of which are release blockers ^^
[2015-11-02T03:52:25.892Z] <53810862048862e761fa2887> @amueller Where did you see the `OneHotEncoder` warnings ?
[2015-11-02T03:52:40.440Z] <54d4a1d6db8155e6700f853b> I just commented
[2015-11-02T03:52:49.417Z] <54d4a1d6db8155e6700f853b> also, don't worry about it tonight ;)
[2015-11-02T03:54:29.676Z] <53810862048862e761fa2887> No warnings on python 2.7.6 and numpy 1.8.2
[2015-11-02T03:57:39.361Z] <54d4a1d6db8155e6700f853b> yeah you need numpy 1.10
[2015-11-02T03:57:45.273Z] <54d4a1d6db8155e6700f853b> I think
[2015-11-02T04:42:47.679Z] <53810862048862e761fa2887> Reproduced it, but yeah, I am better of looking at this tomorrow :D
[2015-11-02T18:04:55.931Z] <54d4a1d6db8155e6700f853b> I would really like to get some feedback on how to treat the 32bit test failures
[2015-11-02T18:09:27.106Z] <53810862048862e761fa2887> Could you tell me more about them ?
[2015-11-02T18:18:12.332Z] <54d4a1d6db8155e6700f853b> the 32bit failures? They are precision issues and I don't know whether to reduce the precision or ignore the tests or what else to do.
[2015-11-02T18:21:14.178Z] <53810862048862e761fa2887> Do you have some logs somwhere ?
[2015-11-02T18:21:20.079Z] <53810862048862e761fa2887> somewhere*
[2015-11-02T18:40:41.908Z] <54c084dbdb8155e6700eed4c> @amueller , on #5682, would a test to ensure an index error is not thrown for the second example i gave be sufficient?
[2015-11-02T18:41:15.506Z] <54c084dbdb8155e6700eed4c> or test the value error string ?
[2015-11-02T18:43:05.391Z] <54d4a1d6db8155e6700f853b> Testing the value error string would be good
[2015-11-02T18:43:31.886Z] <54d4a1d6db8155e6700f853b>  @vighneshbirodkar logs are here: https://github.com/scikit-learn/scikit-learn/issues/5534 but it is more a question to the other core devs on how we handle this.
[2015-11-02T18:50:40.192Z] <53810862048862e761fa2887> Ok
[2015-11-03T17:29:39.254Z] <54d4a1d6db8155e6700f853b> hm... anyone have an idea why github stopped notifying me for comments on pull requests I created?
[2015-11-03T17:30:39.155Z] <54d4a1d6db8155e6700f853b> ok I was just hallucinating, never mind
[2015-11-03T20:01:35.116Z] <53135b495e986b0712efc453> .
[2015-11-03T20:14:21.855Z] <54d4a1d6db8155e6700f853b> ?
[2015-11-03T20:14:38.500Z] <54d4a1d6db8155e6700f853b> I'm trying to check if we missed anything in whatsnew for 0.17 by running a diff against 0.16
[2015-11-03T20:14:57.791Z] <54d4a1d6db8155e6700f853b> some idiot changed the docstrings of all the classes so all files are changed
[2015-11-03T20:21:55.856Z] <53135b495e986b0712efc453> sorry that . was a typo.. (gitter android app sucks... :/) and lol `*`silently hopes I don't show up in the git blame`*` :p
[2015-11-03T20:50:34.632Z] <54d4a1d6db8155e6700f853b> there is an android gitter app? hm...
[2015-11-03T20:51:41.140Z] <53135b495e986b0712efc453> yea its just the mobile site wrapped as an app... too slow and buggy... :/
[2015-11-03T20:52:05.414Z] <54d4a1d6db8155e6700f853b> meh
[2015-11-03T20:54:46.944Z] <53810862048862e761fa2887> They updated it
[2015-11-03T21:27:59.591Z] <54d4a1d6db8155e6700f853b> anyone want to make the pdf docs build on 0.17.X ? ^^
[2015-11-04T06:09:51.490Z] <53810862048862e761fa2887> http://cs.nyu.edu/~vnb222/temp/user_guide.pdf
[2015-11-04T06:10:05.661Z] <53810862048862e761fa2887> I can see figures overflowing in some pages ?
[2015-11-04T18:50:19.988Z] <54d4a1d6db8155e6700f853b> thanks for having a look
[2015-11-04T18:51:07.666Z] <54d4a1d6db8155e6700f853b> when I called "make dist" there were latex errors and the build didn't finish
[2015-11-04T21:05:40.802Z] <54d4a1d6db8155e6700f853b> does anyone have matplotlib 1.5 to test the examples?
[2015-11-04T21:06:15.271Z] <54d4a1d6db8155e6700f853b> I'm trying to pip install it in my conda env. I'm sure that's going to go great
[2015-11-04T21:21:43.697Z] <54d4a1d6db8155e6700f853b> @MechCoder if you're bored, you can have a look at https://github.com/scikit-learn/scikit-learn/pull/5721
[2015-11-04T21:52:41.561Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/issues/5724 is also fun
[2015-11-04T22:35:15.032Z] <54d4a1d6db8155e6700f853b> if anyone wants to help me find out why "clustering" isn't properly linked on the website, that would also be sweet ^^
[2015-11-05T00:27:01.711Z] <54d4a1d6db8155e6700f853b> wohoo down to only one issue https://github.com/scikit-learn/scikit-learn/pull/5692
[2015-11-05T00:34:29.805Z] <54d4a1d6db8155e6700f853b> apart from a segfaulting example that prevents me from building the docs... great. https://github.com/scikit-learn/scikit-learn/issues/5724
[2015-11-05T00:42:56.182Z] <562aa0c916b6c7089cb80cd7> Hi, I'm a newbie, want to start contributing, can someone guide me how to start.
[2015-11-05T01:01:20.786Z] <54d4a1d6db8155e6700f853b> hi @manipalsingh013 
[2015-11-05T01:01:30.585Z] <54d4a1d6db8155e6700f853b> have you had a look at the contribution guidelines?
[2015-11-05T01:01:47.394Z] <54d4a1d6db8155e6700f853b> http://scikit-learn.org/dev/developers/index.html
[2015-11-05T01:02:26.095Z] <54d4a1d6db8155e6700f853b> pick an easy issue: http://scikit-learn.org/dev/developers/contributing.html#easy-issues best one that has the "needs contributor" tag
[2015-11-05T01:49:05.517Z] <562aa0c916b6c7089cb80cd7> Thanks @amueller 
[2015-11-05T01:49:56.093Z] <562aa0c916b6c7089cb80cd7> I am starting with contribution guideline.
[2015-11-05T03:52:54.194Z] <54c084dbdb8155e6700eed4c> hey all... MLPClassifier, anyone familiar? I'm trying to understand the output of predict_proba. It seems inconsistent with all other estimators
[2015-11-05T03:53:25.200Z] <54c084dbdb8155e6700eed4c> (in terms of output shape)
[2015-11-05T03:53:50.771Z] <54c084dbdb8155e6700eed4c> is it assuming a 2d `y` is already one-hot encoded?
[2015-11-05T03:55:01.764Z] <54c084dbdb8155e6700eed4c> because it can learn on a multi-output type `y` so long as its binary and the results appear to be.. strange
[2015-11-05T03:56:00.992Z] <54c084dbdb8155e6700eed4c> im mainly asking as im trying to determine from the predict_proba shape what the input y was (multioutput or otherwise) and this single classifier is throwing a spanner in the works
[2015-11-05T03:59:46.371Z] <54c084dbdb8155e6700eed4c> plus, the `n_outputs_' attribute seems to indicate it can do multi, but im not anywhere familiar with the estimator to know if thats true
[2015-11-05T04:00:06.342Z] <54c084dbdb8155e6700eed4c> `n_outputs_` that is
[2015-11-05T04:05:43.531Z] <54c084dbdb8155e6700eed4c> this is for the partial dependence enhancement. im trying to support all estimators as input without knowing what `y` was
[2015-11-05T04:06:37.568Z] <54c084dbdb8155e6700eed4c> multi-output, as usual, the thorny one
[2015-11-05T15:28:42.890Z] <54d4a1d6db8155e6700f853b> @trevorstephens gimme a sec
[2015-11-05T15:28:52.273Z] <54d4a1d6db8155e6700f853b> Anyone want to review https://github.com/scikit-learn/scikit-learn/pull/5692 ?
[2015-11-05T15:29:25.551Z] <54d4a1d6db8155e6700f853b> oh never mind, has two +1 already
[2015-11-05T15:29:53.929Z] <54d4a1d6db8155e6700f853b> @trevorstephens it can to multi-class and multi-label. Only there is a bug in predict_proba for multi-label that is fixed in a new PR
[2015-11-05T15:30:10.355Z] <54d4a1d6db8155e6700f853b> @trevorstephens is there unexpected output in the multi-class case, too?
[2015-11-05T15:30:21.296Z] <54c084dbdb8155e6700eed4c> thanks @amueller ... this is where it turned up btw
[2015-11-05T15:30:24.151Z] <54c084dbdb8155e6700eed4c>     from sklearn.utils.testing import all_estimators     cancer = load_breast_cancer()     cancer_multi = np.vstack((cancer.target, cancer.target, cancer.target)).T     string = ""     for name, Estimator in all_estimators():         clf = Estimator()         if hasattr(clf, '_estimator_type'):             if hasattr(clf, 'predict_proba'):                 if clf._estimator_type == 'classifier':                     try:                         clf.fit(cancer.data, cancer_multi)                     except:                         continue                     preds = clf.predict_proba(cancer.data)                     if type(preds) == list:                         string += "%30s, %25s: %s\n" % (name, type(preds), str([p.shape for p in preds]))                     else:                         string += "%30s, %25s: %s\n" % (name, type(preds), preds.shape)     print "BINARY MULTIx3"     print string
[2015-11-05T15:31:01.251Z] <54c084dbdb8155e6700eed4c>     BINARY MULTIx3             DecisionTreeClassifier,             <type 'list'>: [(569, 2), (569, 2), (569, 2)]                ExtraTreeClassifier,             <type 'list'>: [(569, 2), (569, 2), (569, 2)]               ExtraTreesClassifier,             <type 'list'>: [(569, 2), (569, 2), (569, 2)]               KNeighborsClassifier,             <type 'list'>: [(569, 2), (569, 2), (569, 2)]                      MLPClassifier,    <type 'numpy.ndarray'>: (569, 3)             RandomForestClassifier,             <type 'list'>: [(569, 2), (569, 2), (569, 2)] 
[2015-11-05T15:31:21.246Z] <54c084dbdb8155e6700eed4c> rows add to one. i think it believes its doing multi-label then
[2015-11-05T15:31:23.434Z] <54d4a1d6db8155e6700f853b> well it hast the format that is currently produced by OneVsRestClassifier
[2015-11-05T15:31:41.563Z] <54d4a1d6db8155e6700f853b> there is inconsistency in how multi-label is currently encoded.
[2015-11-05T15:31:52.480Z] <54d4a1d6db8155e6700f853b> because the trees to multi-label multi-output, they have a more complex format
[2015-11-05T15:32:02.712Z] <54d4a1d6db8155e6700f853b> we need to unify those
[2015-11-05T15:32:29.792Z] <54c084dbdb8155e6700eed4c> ok. so im principally interested in multi-output handling. so it seems checking if pred_proba gives a list i should be good on the classification side
[2015-11-05T15:32:37.450Z] <54d4a1d6db8155e6700f853b> rows add to one because of a bug. it's doing multi-label
[2015-11-05T15:32:59.819Z] <54d4a1d6db8155e6700f853b> yeah if it gives a list (tree based and nearest neighbor ones) it does multi-output multi-label
[2015-11-05T15:33:05.361Z] <54d4a1d6db8155e6700f853b> err multi-output multi-class
[2015-11-05T15:33:06.832Z] <54d4a1d6db8155e6700f853b> I mena
[2015-11-05T15:33:07.833Z] <54d4a1d6db8155e6700f853b> mean
[2015-11-05T15:33:16.097Z] <54c084dbdb8155e6700eed4c> cool
[2015-11-05T15:33:18.828Z] <54c084dbdb8155e6700eed4c> thanks
[2015-11-05T15:33:22.368Z] <54d4a1d6db8155e6700f853b> there is a list of what supports what in the multiclass docs
[2015-11-05T15:33:34.227Z] <54c084dbdb8155e6700eed4c> the n_outputs~ attr threw me off in mlp
[2015-11-05T15:37:43.274Z] <54d4a1d6db8155e6700f853b> n_outputs means it allows multi-label
[2015-11-05T15:38:07.315Z] <54d4a1d6db8155e6700f853b> (stupid question but you are familiar with the nomenclature of multilabel vs multiclass vs multioutput multi-label)?
[2015-11-05T15:40:45.530Z] <54d4a1d6db8155e6700f853b> multiclass means a prediction is one of k classes, multi-label means it is a subset of the k classes (or k zero-one decisions) and multi-ouput multi-class means k separate classification problems with possible different numbers of classes each
[2015-11-05T15:41:05.357Z] <54d4a1d6db8155e6700f853b> and maybe that should be said in a more clear way in the docs, not sure how it is described there
[2015-11-05T15:41:20.679Z] <54d4a1d6db8155e6700f853b> only #5257 to go and I can release!
[2015-11-05T15:43:33.319Z] <54c084dbdb8155e6700eed4c> niiicee!
[2015-11-05T15:43:45.982Z] <54c084dbdb8155e6700eed4c> seems to have been a long road through beta this time
[2015-11-05T15:49:04.733Z] <54c084dbdb8155e6700eed4c> yep, im familiar with the differences, but `n_ouputs_` in d-trees specifies number of multi-class output cols in y, whereas here i guess it means number of labels. 
[2015-11-05T15:51:28.247Z] <54c084dbdb8155e6700eed4c> ie printing clf.n_outputs_ for that cancer_multi example above gives "3". Same result for running on a 1D multi-class, ie iris
[2015-11-05T15:53:25.797Z] <54c084dbdb8155e6700eed4c> whereas `n_outputs_` for RandForCls only gives "3" for cancer_multi, not iris
[2015-11-05T16:48:22.030Z] <54d4a1d6db8155e6700f853b> sorry what did you mean by 1d multi-class?
[2015-11-05T16:48:53.230Z] <54d4a1d6db8155e6700f853b> oh... hm... that is probably an inconsistent use of ``n_outputs_`` if it is >1 for multi-class
[2015-11-05T16:49:34.475Z] <54d4a1d6db8155e6700f853b> yeah actually the issue was not so much that people found bugs in the beta, but that I was unhappy with deprecated features in the tests and stuff that got deprecated in numpy 1.10 and matplotlib 1.5
[2015-11-05T16:49:50.738Z] <54d4a1d6db8155e6700f853b> I just saw there is still so many typos in the whatsnew and dead links. well whatever
[2015-11-05T16:50:20.754Z] <54d4a1d6db8155e6700f853b> There is no point in delaying much more
[2015-11-05T16:50:32.525Z] <54d4a1d6db8155e6700f853b> I just like the docs to look relatively clean and the tests to run clean on a release
[2015-11-05T16:51:15.846Z] <54d4a1d6db8155e6700f853b> Now I only need to wait for the wheels to build and the conda people to build their binaries
[2015-11-05T16:51:44.635Z] <54d4a1d6db8155e6700f853b> FUCK
[2015-11-05T16:53:43.319Z] <54d4a1d6db8155e6700f853b> One of my fixes that I did a month ago had a mistake
[2015-11-05T20:39:15.022Z] <54d4a1d6db8155e6700f853b> anyone wanna try the new website?
[2015-11-05T20:39:15.540Z] <54d4a1d6db8155e6700f853b> http://scikit-learn.org/0.17/
[2015-11-05T20:39:25.640Z] <54d4a1d6db8155e6700f853b> and tell me that there is absolutely nothing wrong with it
[2015-11-05T20:50:23.971Z] <54d4a1d6db8155e6700f853b> great, the link to the pdf doc is broken
[2015-11-05T20:50:25.315Z] <54d4a1d6db8155e6700f853b> as in master
[2015-11-05T21:03:00.203Z] <54d4a1d6db8155e6700f853b> I actually need to "make clean && make html" for this...
[2015-11-05T21:03:03.615Z] <54d4a1d6db8155e6700f853b> see you in an hour
[2015-11-05T22:13:41.491Z] <54d4a1d6db8155e6700f853b> cool pypi seems to have serious trouble https://pypi.python.org/pypi?%3Aaction=pkg_edit&name=scikit-learn
[2015-11-05T22:32:16.261Z] <54d4a1d6db8155e6700f853b> ok wheels and source dist is up. it would be cool if people could try the wheels but please don't announce it yet
[2015-11-06T00:06:46.507Z] <562aa0c916b6c7089cb80cd7> Do I need to have great knowledge about machine learning and AI to start with.
[2015-11-06T00:07:09.088Z] <562aa0c916b6c7089cb80cd7> or knowing some basic about it will help.
[2015-11-06T00:07:50.017Z] <562aa0c916b6c7089cb80cd7> I'm confused as of now I know python and some basic of machine learning and AI
[2015-11-06T00:47:26.092Z] <54d4a1d6db8155e6700f853b> @manipalsingh013 knowing some basics is good but even that is not necessary to get started
[2015-11-06T00:49:30.059Z] <562aa0c916b6c7089cb80cd7> all right @amueller . Thanks
[2015-11-06T03:42:49.858Z] <54c084dbdb8155e6700eed4c> Thanks for all your work @amueller, congrats on the release! :beers: 
[2015-11-06T03:47:40.085Z] <54c084dbdb8155e6700eed4c> btw sorry I missed your responses, I'll have a bit more of a tinker with MLP at some point 
[2015-11-08T20:07:03.804Z] <54b4f2d1db8155e6700e99c0> Hey Folks, congrats for the release! Awesome work!
[2015-11-08T20:07:34.721Z] <54b4f2d1db8155e6700e99c0> Quick question, why does KMeans accept y in its fit() ?
[2015-11-08T20:12:58.888Z] <53135b495e986b0712efc453> For API compatibility with other supervised learning algorithms... (and to safely pass y through kmeans in a pipeline)
[2015-11-08T20:13:38.462Z] <54b4f2d1db8155e6700e99c0> Thanks a lot @rvraghav93 :)
[2015-11-10T16:23:31.229Z] <53135b495e986b0712efc453> Firefox users might find this handy ;) - https://addons.mozilla.org/en-US/firefox/addon/git-done/?src=search
[2015-11-12T08:46:56.166Z] <5571fe1015522ed4b3e17d90> @rvraghav93 out of interest what does it look like in the PR, does it just add a "Done" comment when you click on the "Done" button? Not sure how useful this is to be honest. Generally when you do something following a comment, it gets hidden into an "outdated diff" section anyway.
[2015-11-12T09:14:03.719Z] <53135b495e986b0712efc453> for some reason it doesn't work for me ;( It might be useful for those comments that aren't hidden after the change I think... ;) Apart from that you are right... its not really that useful since the comment gets hidden anyways...
[2015-11-12T10:30:20.591Z] <5571fe1015522ed4b3e17d90> I'd love if someone did a firefox extension which shows "outdated diff" comments. I know there are some bookmarklets on the internet but it never worked for me somehow, I always end up having to copy and paste the code in the Javascript console, not great.
[2015-11-12T10:39:30.506Z] <53135b495e986b0712efc453> as as in does not hide them by default u mean huh?
[2015-11-12T10:43:59.431Z] <5571fe1015522ed4b3e17d90> see for example https://coderwall.com/p/akdgoq/expand-all-outdated-diff-comments-in-a-github-pull-request
[2015-11-12T10:53:01.822Z] <53135b495e986b0712efc453> Install [greasemonkey](https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/) and add this script to it, (you can enable or disable greasemonkey if you aren't using it for anything else) to enable/disable expanding the diff comments... ``` // ==UserScript== // @name        github expand outdated diff comments // @namespace   rvraghav93@gmail.com // @include     https://github.com/scikit-learn/scikit-learn/pull/* // @version     1 // @grant       none // ==/UserScript== $(".outdated-diff-comment-container").addClass('open') ```
[2015-11-12T10:57:08.307Z] <53135b495e986b0712efc453> One thing I wish the github PR page to show is a list of all the referred links and PRs or Issues in a neat side bar like stackoverflow has at the right, next to the question area... I am planning to write a greasemonkey script for that... I think it will be super useful to have all the links at the right instead of searching through the PR...
[2015-11-12T12:02:15.072Z] <5571fe1015522ed4b3e17d90> Looks interesting, I'll give it a shot, thanks !
[2015-11-13T19:49:32.907Z] <54c084dbdb8155e6700eed4c> Hey @amueller , I'm trying to decide between heckling the presenter at the scikit-learn tutorial @ ODSC or learning some d3.js ... Do you have a strong opinion on the matter? :smile: 
[2015-11-14T10:59:11.831Z] <553e8e1015522ed4b3df97f7> I hope all of you in Paris are safe :worried:
[2015-11-14T21:42:37.981Z] <5395efa3a9176b500d1cd7fb> master does not compile on py35 for me:
[2015-11-14T21:43:07.318Z] <5395efa3a9176b500d1cd7fb> ```bash --------------------------------------------------------------------------- ImportError                               Traceback (most recent call last) <ipython-input-3-fa7b5efcaf90> in <module>() ----> 1 from planet4.clustering import ClusteringManager       2 from planet4 import p4io as io       3 from IPython.display import display       4 from ipywidgets import FloatText       5 from pathlib import Path  /Users/klay6683/Dropbox/src/planet4/planet4/clustering.py in <module>()      11 from ipywidgets import FloatText      12 from pathlib import Path ---> 13 from sklearn.cluster import DBSCAN      14       15 from . import markings, p4io  /Users/klay6683/miniconda3/envs/py35/lib/python3.5/site-packages/sklearn/cluster/__init__.py in <module>()       8                           estimate_bandwidth, get_bin_seeds)       9 from .affinity_propagation_ import affinity_propagation, AffinityPropagation ---> 10 from .hierarchical import (ward_tree, Ward, WardAgglomeration,      11                            AgglomerativeClustering, linkage_tree,      12                            FeatureAgglomeration)  ImportError: cannot import name 'Ward' ``` Did `python setup.py clean` beforehand.
[2015-11-14T21:48:31.316Z] <5395efa3a9176b500d1cd7fb> This also did not go away by checking out `0.17`.
[2015-11-14T22:03:30.476Z] <53135b495e986b0712efc453> Could you try "make clean" then make...
[2015-11-15T06:51:09.201Z] <5395efa3a9176b500d1cd7fb> `make clean; make` finishes fine, but then? should i `make install` as usual for C-progs?
[2015-11-15T11:53:35.609Z] <53135b495e986b0712efc453> yes.. does that succeed now?
[2015-11-15T16:46:48.259Z] <5395efa3a9176b500d1cd7fb> ```bash $ make install make: *** No rule to make target `install'.  Stop. ```
[2015-11-15T19:34:20.059Z] <54d4a1d6db8155e6700f853b> do you want to globally install? or user install or build in the folder?
[2015-11-15T19:35:03.496Z] <54d4a1d6db8155e6700f853b> python setup.py install or python setup.py develop or python setup.py build_ext -i do some of these
[2015-11-15T21:41:56.684Z] <5395efa3a9176b500d1cd7fb> yes, but i have been advised above not to use that.
[2015-11-15T21:43:21.129Z] <5395efa3a9176b500d1cd7fb> i want to just install for my user account, what is the advised sequence of commands (as written above, `python setup.py install` failed).
[2015-11-15T21:49:36.754Z] <5634e8e116b6c7089cb8fa99> @michaelaye it would be
[2015-11-15T21:49:56.912Z] <5634e8e116b6c7089cb8fa99> python setup.py install --user
[2015-11-15T21:51:04.430Z] <5395efa3a9176b500d1cd7fb> hah, after the full run of make clean; make the `python setup.py install` actually worked now. thanks for your help.
[2015-11-15T21:52:07.924Z] <5395efa3a9176b500d1cd7fb> in case u wonder, i still need to self-compile even so im a conda user,  b/c i have pinned my numpy to 1.9.* b/c numpy 1.10 has performance probs with character arrays.
[2015-11-15T21:52:31.007Z] <5395efa3a9176b500d1cd7fb> and theres no scikit-learn for conda py3.5 numpy  1.9 on offer in conda.
[2015-11-16T17:11:19.664Z] <54d4a1d6db8155e6700f853b> welcome everybody to the sprint!
[2015-11-16T17:19:31.891Z] <54c084dbdb8155e6700eed4c>  hey all!
[2015-11-16T17:43:28.850Z] <564a144c16b6c7089cbaebe3> Hello folks! I'm having an issue building sklearn from source. I've included my full logs here (http://pastebin.com/13LKxi55). I'm using pyenv with anaconda. Has anyone seen any issues with sklearn/cluster/_k_means.c failing to compile?  This looks a lot like my error https://github.com/scikit-learn/scikit-learn/issues/3114, but I don't understand the resolution.
[2015-11-16T17:44:28.347Z] <564a0e2916b6c7089cbaead6> Which version of python are you using?
[2015-11-16T17:45:15.065Z] <564a144c16b6c7089cbaebe3> ``` (root) <unconvertable>  scikit-learn git:(master) pyenv version anaconda3-2.4.0 (set by /Users/maxlikely/src/scikit-learn/.python-version) ```
[2015-11-16T17:45:33.326Z] <564a144c16b6c7089cbaebe3> which is 3.5
[2015-11-16T17:49:11.780Z] <564a0e2916b6c7089cbaead6> I think that might be your issue
[2015-11-16T17:49:21.060Z] <564a0e2916b6c7089cbaead6> Possible to build against an 3.4?
[2015-11-16T17:49:25.090Z] <564a0dc816b6c7089cbaeacd> suppose I've found an Easy issue to address, having a Needs Contributor label. how do I claim this as my own?
[2015-11-16T17:49:33.066Z] <564a0e2916b6c7089cbaead6> comment on it
[2015-11-16T17:52:39.452Z] <564a144c16b6c7089cbaebe3> @joshuacook I tried building against 3.4.3, I had the same issue. I can try 3.4.0.
[2015-11-16T17:57:49.033Z] <54c084dbdb8155e6700eed4c> http://scikit-learn.org/stable/developers/contributing.html
[2015-11-16T17:57:50.869Z] <564a18f416b6c7089cbaec93> Here is the documentation on contributing code, for the person who just asked: http://scikit-learn.org/dev/developers/contributing.html#contributing-code
[2015-11-16T17:58:22.312Z] <564a0e2916b6c7089cbaead6> @maxlikely I had issues with required libs being built against different versions. But I'm not using `conda`
[2015-11-16T18:02:19.527Z] <564a185916b6c7089cbaec66> When I run `make` on a forked branch of master, I get 1 error and 1 failure.  Here is the traceback for the error http://pastebin.com/C8EpQT75 It involves reading a jpeg with PIL, which hasn't been working for me the past few weeks.  I have Pillow 3.0.0 installed
[2015-11-16T18:07:33.564Z] <564a0d8116b6c7089cbaeabf> Looking at https://github.com/scikit-learn/scikit-learn/issues/5686
[2015-11-16T18:10:46.211Z] <564a0dc816b6c7089cbaeacd> looking at 5581, and need to reconcile the built path mentioned in the bug with the path in the source. bug mentions file:///home/andy/checkout/scikit-learn/doc/_build/html/stable/modules/neural_networks_supervised.html#more-control-with-warm-start, but the source path is actually doc/modules/neural_networks_supervised.rst. After updating such a doc, what is to be done to verify all is well before submitting a PR?
[2015-11-16T18:19:59.005Z] <564a18f416b6c7089cbaec93> When I run '''make''' on my branch, the build fails. Here is the traceback: http://pastebin.com/VgHFvhPF# Any help appreciated.
[2015-11-16T18:30:49.982Z] <5648fd3216b6c7089cbad1e3> I got the same error as @hallr   Any ideas why it doesn't "make"?
[2015-11-16T18:34:20.958Z] <564a116816b6c7089cbaeb95> Me too I have the same problem @hallr  @lazarillo 
[2015-11-16T18:38:38.882Z] <564a0e2916b6c7089cbaead6> any restructured text gurus?
[2015-11-16T18:46:07.467Z] <564a0dc816b6c7089cbaeacd> answering my own question, `make doc` builds html docs under doc/_build/html/stable  
[2015-11-16T18:50:47.081Z] <564a0d8116b6c7089cbaeabf> Any traction on that make test error with the infinite value?
[2015-11-16T18:55:16.570Z] <564a264d16b6c7089cbaee0f> hi all, if anybody would like to review my pull request for 'adding cython to requirements' in documentation, it is here: 
[2015-11-16T18:55:17.690Z] <564a264d16b6c7089cbaee0f> https://github.com/scikit-learn/scikit-learn/pull/5834
[2015-11-16T18:57:16.669Z] <5648fd3216b6c7089cbad1e3> Hi @joshuacook  I don't know if I'd say guru, but I understand it fairly well.
[2015-11-16T19:00:00.856Z] <564a144c16b6c7089cbaebe3> I'm going to take a stab at https://github.com/scikit-learn/scikit-learn/issues/5606.
[2015-11-16T19:00:21.381Z] <564a0d8116b6c7089cbaeabf> I have a PR for an error that happens in the tests: https://github.com/scikit-learn/scikit-learn/pull/5836
[2015-11-16T19:00:33.760Z] <564a144c16b6c7089cbaebe3> FWIW: I bypassed the build issue with `pyenv` by installing anaconda directly.
[2015-11-16T19:00:49.962Z] <53135b495e986b0712efc453> @amueller #4533 can be closed...
[2015-11-16T19:01:06.231Z] <564a0e2916b6c7089cbaead6> @lazarillo where can I find you? I am red head in red flannel
[2015-11-16T19:12:45.985Z] <564a11fc16b6c7089cbaeb9e> Has anyone found an issue that they are working on that is simple and would enjoy more collaboration?
[2015-11-16T19:22:52.442Z] <564a176d16b6c7089cbaec44> Is there a norm against implementing visualization methods directly within an sklearn module?
[2015-11-16T19:24:09.469Z] <564a11fc16b6c7089cbaeb9e> @hallr @NTBlok Can i work on issue #5827 with you? 
[2015-11-16T19:25:24.586Z] <53135b495e986b0712efc453> What kind of visualisation methods do you mean? @jonoleson
[2015-11-16T19:31:20.000Z] <564a176d16b6c7089cbaec44> @rvraghav93 Like I was considering adding a plotting method to the RFECV module that would graph the cross-validation scores for each subset of features. Just a simple line graph with num_features on the x-axis and cv_score on the y-axis. 
[2015-11-16T19:34:30.014Z] <564a11fc16b6c7089cbaeb9e> I am going to work on issue #5656
[2015-11-16T19:35:46.238Z] <564a264d16b6c7089cbaee0f> edited pull request and ready to merge #5834 
[2015-11-16T19:39:58.037Z] <564a27c016b6c7089cbaee48> I'm looking into #5364
[2015-11-16T19:42:02.450Z] <564a183f16b6c7089cbaec5b> we're looking into #5804
[2015-11-16T19:42:44.044Z] <54d4a1d6db8155e6700f853b> for someone interested in figuring out a segfault, you can take a stab at https://github.com/scikit-learn/scikit-learn/issues/5724
[2015-11-16T19:43:24.711Z] <54d4a1d6db8155e6700f853b> btw, fixing any errors in the build of the documentation (running make or make html in the doc folder) or fixing any warnings in the tests is also very welcome
[2015-11-16T20:05:26.118Z] <564a18f416b6c7089cbaec93> @NTBlok @fluxtransport and I submitted PR for #5827 - add contributors for 0.16 and 0.17 to docs
[2015-11-16T20:12:18.462Z] <564a11fc16b6c7089cbaeb9e> @lazarillo and I are taking a stab at #4920
[2015-11-16T20:40:04.737Z] <564a0d8116b6c7089cbaeabf> Is the problem with the news group downloads b/c the underlying data has moved to a new web site? https://github.com/scikit-learn/scikit-learn/issues/4711
[2015-11-16T21:00:00.801Z] <564a0d8116b6c7089cbaeabf> I had a look at the segfault -- I cannot reproduce when using %run inside an ipython notebook. Using either of the new matplotlib methods to fetch the yahoo data.
[2015-11-16T21:03:47.391Z] <564a0e2916b6c7089cbaead6> Pull request for the single dead link: https://github.com/scikit-learn/scikit-learn/pull/5829#partial-pull-merging
[2015-11-16T21:08:57.505Z] <564a11fc16b6c7089cbaeb9e> @amueller Is issue Meta-estimators for multi-output learning #5824 still available? 
[2015-11-16T21:13:11.014Z] <54d4a1d6db8155e6700f853b> @MrChristophRivera @hugobowne just asked me about it.
[2015-11-16T21:13:29.663Z] <54d4a1d6db8155e6700f853b> it is probably not as easy as the other issues. please check with him if he is working on it
[2015-11-16T21:18:15.305Z] <564a264d16b6c7089cbaee0f> @MrChristophRivera i'm just looking into it now -- not sure whether i'll attack it . are you at the code sprint. thanks @amueller 
[2015-11-16T21:31:56.504Z] <54d4a1d6db8155e6700f853b> @MrChristophRivera probably is ;) you can also use the physical audio channel
[2015-11-16T21:52:22.159Z] <564a4d2b16b6c7089cbaf2ee> @amueller made changes you requested: https://github.com/scikit-learn/scikit-learn/pull/5841
[2015-11-16T22:02:23.072Z] <564a144c16b6c7089cbaebe3> Hey, I just wanted to check if anyone has claimed https://github.com/scikit-learn/scikit-learn/issues/5851 yet?
[2015-11-16T22:48:36.378Z] <564a183f16b6c7089cbaec5b> git@github.com:RubyW/scikit-learn.git
[2015-11-16T22:48:45.394Z] <564a183f16b6c7089cbaec5b> oops
[2015-11-16T22:49:26.606Z] <564a0d8116b6c7089cbaeabf> can someone review my change here: https://github.com/scikit-learn/scikit-learn/pull/5858
[2015-11-16T23:18:20.277Z] <564a0dc816b6c7089cbaeacd> coupla PRs here: https://github.com/scikit-learn/scikit-learn/pull/5833 https://github.com/scikit-learn/scikit-learn/pull/5856
[2015-11-16T23:31:48.407Z] <54d4a1d6db8155e6700f853b> is @maxlikely in SF at the sprint?
[2015-11-16T23:32:35.743Z] <564a144c16b6c7089cbaebe3> yes
[2015-11-16T23:34:28.070Z] <564a0dc816b6c7089cbaeacd> probably
[2015-11-17T06:46:08.458Z] <5395efa3a9176b500d1cd7fb> looks like the dataset for the scipy2015 tutorial sessions is not coming down? http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip download does not start.
[2015-11-17T06:46:37.623Z] <5395efa3a9176b500d1cd7fb> im using the fetch_data script in your github repo.
[2015-11-17T06:49:51.186Z] <5395efa3a9176b500d1cd7fb> ah worked now, just took ages for the 81 MB with no bytes flowing for minutes...
[2015-11-17T13:24:52.196Z] <53135b495e986b0712efc453> @jonoleson I am unable to gauge how useful that usecase is... Once you convince @amueller it is useful enough (:P) you can add a plotting function similar to the `plot_partial_dependence` (in `ensemble/partial_dependence.py`)...  (But IMHO that particular usecase seems simple enough to not warrant a plotting helper function!)
[2015-11-18T11:31:51.001Z] <564789be16b6c7089cbab8b7> Just wanted to say how much I admire the way scikit learn development is managed. Sorry if this is OT :)
[2015-11-18T11:39:18.148Z] <53135b495e986b0712efc453> :)
[2015-11-18T11:41:24.256Z] <564789be16b6c7089cbab8b7> I could go on to explain why....
[2015-11-18T16:01:06.894Z] <54d4a1d6db8155e6700f853b> @michaelaye sorry, that's odd. But it is not on hour server.  I guess we could put it up somewhere else if the problems persist
[2015-11-18T16:01:28.393Z] <54d4a1d6db8155e6700f853b> @lesshaste I'd be interested to hear.
[2015-11-18T16:02:34.160Z] <54d4a1d6db8155e6700f853b> @rvraghav93 what was @jonoleson's question?
[2015-11-18T16:02:48.069Z] <54d4a1d6db8155e6700f853b> Btw, I'll be in NYC for a whole week of catching up ^^
[2015-11-18T18:55:04.407Z] <564789be16b6c7089cbab8b7> Am I right that there is no "top n" encoder for categorical data currently?
[2015-11-18T18:55:23.512Z] <54d4a1d6db8155e6700f853b> @lesshaste what do you mean by that?
[2015-11-18T18:55:29.748Z] <564789be16b6c7089cbab8b7> Consider some categorical feature that can take 100,000 categorical values.. you only want to one hot encode the most common 30  of those categories say
[2015-11-18T18:55:44.417Z] <564789be16b6c7089cbab8b7> and the others just get one binary variable indicating it isn't one of the most frequent 30
[2015-11-18T18:57:07.364Z] <564789be16b6c7089cbab8b7> This may be a sensible way to deal with such data
[2015-11-18T18:59:07.177Z] <564789be16b6c7089cbab8b7> I am not sure what other options there are in scikit learn for this sort of data, apart from feature hasher maybe
[2015-11-18T18:59:36.191Z] <564789be16b6c7089cbab8b7> @amueller  Does that make more sense?
[2015-11-18T19:02:16.777Z] <564789be16b6c7089cbab8b7> @amueller oh ... reasons why I admire scikit learn... OK... a) I find the documentation very impressive in its effort to be genuinely useful and usable by non-experts. This is not such a common thing to see.  b) I love that developers who say "How about we include feature X from paper Y" are told "Sure. Find us a public data set where this method does better than something we already have and give us code that we can test on it."  It's a great attitude.  c) I love that everything is being continually improved. Things that work, e.g. decision trees, random forests are not just left as "good enough" but are being made better all the time
[2015-11-18T19:04:36.813Z] <564789be16b6c7089cbab8b7> d) I even love that developers regularly look to R and see what they are doing that we aren't or are doing better than we are. So many other projects are boastful amd full of pride and can't see where they can learn from others.
[2015-11-18T19:05:40.336Z] <564789be16b6c7089cbab8b7> (I'll pause here.. :) )
[2015-11-18T19:07:13.285Z] <564789be16b6c7089cbab8b7> actually.. I also think the way deep learning has been handled is great. It makes sense not to just include deep learning at this point but it is particularly awesome that rather than just rejecting it and forgetting about it scikit learn is starting from the bottom with MLP and then MLP + dropout and presumably one day deep learning itself.
[2015-11-18T19:08:27.007Z] <564789be16b6c7089cbab8b7> ( at least I think I saw some dev mention a plan to implement dropout)
[2015-11-18T19:11:41.855Z] <54d4a1d6db8155e6700f853b> @lesshaste there is no feature for doing the top k hone-hot in scikit-learn. Clearly you could easily do that with some custom code. Btw, is the data public? A very good approach when having that many categories might be target frequency encoding. There was a discussion about that on the mailing list, and maybe there is a PR. Look at a talk by Owen Zhang for an explanation
[2015-11-18T19:12:00.735Z] <54d4a1d6db8155e6700f853b> basically you represent each category using n_classes many floats that encode the class distribution for this category
[2015-11-18T19:12:44.206Z] <54d4a1d6db8155e6700f853b> " I even love that developers regularly look to R and see what they are doing that we aren't or are doing better than we are." I hate that I don't really know R. I'd love to learn more from that community :-/
[2015-11-18T19:52:33.382Z] <564789be16b6c7089cbab8b7> @amueller   thanks I will check out target frequency encoding. Sadly this data isn't public
[2015-11-18T19:53:31.610Z] <564789be16b6c7089cbab8b7> @amueller  one of the key features of the R community is that every (not quite literally but close enough) PhD in stats still to this day has a part where they explain they have made a new R package.
[2015-11-18T20:00:17.161Z] <564789be16b6c7089cbab8b7> googling "target frequency encoding" doesn't work although I did find http://nycdatascience.com/featured-talk-1-kaggle-data-scientist-owen-zhang/
[2015-11-18T20:01:37.450Z] <53135b495e986b0712efc453> @amueller He wanted to know if adding a plotting function for [this](https://gitter.im/scikit-learn/scikit-learn?at=564a2f086296df7f6efed2fa) use case would be a good idea... Could you please guide him?  BTW I think you would be getting approx 1 e-mail / 5minutes... I am just curious how you, with your vigilant email checking routine, would be to catch up with everything :P 
[2015-11-18T20:02:47.786Z] <54d4a1d6db8155e6700f853b> @lesshaste yeah I don't know what the thing is called. If you find the name in his talk, let me know. I had trouble finding the discussion on the mailing list because I didn't know what it is called
[2015-11-18T20:03:07.605Z] <54d4a1d6db8155e6700f853b> @lesshaste I was at that talk ^^
[2015-11-18T20:03:51.668Z] <564789be16b6c7089cbab8b7> will do.. he refers to "High cardinality features" in the notes attached to the talk
[2015-11-18T20:04:31.321Z] <54d4a1d6db8155e6700f853b> @lesshaste yeah around 19:30
[2015-11-18T20:04:36.848Z] <564789be16b6c7089cbab8b7> on another note.. I was hoping to play with some of the methods in scikit learn for clustering when you don't know the number of clusters
[2015-11-18T20:05:18.268Z] <564789be16b6c7089cbab8b7> but I have 10^8 data points and it seems they need a lot of manual tuning which I don't really understand to get to work
[2015-11-18T20:05:20.303Z] <54d4a1d6db8155e6700f853b> "out of fold average counts"
[2015-11-18T20:05:32.106Z] <564789be16b6c7089cbab8b7> are there any PRs that you know of related to this?
[2015-11-18T20:05:39.345Z] <564789be16b6c7089cbab8b7> @amueller thanks!
[2015-11-18T20:05:41.142Z] <54d4a1d6db8155e6700f853b> for clustering? 
[2015-11-18T20:05:53.834Z] <564789be16b6c7089cbab8b7> yes.. to help you cluster large data sets when you don't know the number of clusters in advance
[2015-11-18T20:06:21.122Z] <54d4a1d6db8155e6700f853b> birch and dbscan
[2015-11-18T20:06:40.938Z] <54d4a1d6db8155e6700f853b> I still don't find the discussion / PR on the categorical stuff
[2015-11-18T20:07:06.011Z] <564789be16b6c7089cbab8b7> I have very little expertise in this but it seems that vbgmm  has a bandwidth parameter that you need to set separately
[2015-11-18T20:07:24.200Z] <564789be16b6c7089cbab8b7> and there is some "standard" way to guess the right number of clusters by repeatedly doing PCA with different parameters
[2015-11-18T20:07:50.756Z] <564789be16b6c7089cbab8b7> I will look at birch and dbscan again though , thanks
[2015-11-18T20:08:47.181Z] <54d4a1d6db8155e6700f853b> @lesshaste don't use vbgmm
[2015-11-18T20:08:56.122Z] <54d4a1d6db8155e6700f853b> the one in master is likely broken. and will be much too slow
[2015-11-18T20:09:01.432Z] <54d4a1d6db8155e6700f853b> https://github.com/CoAxLab/DeBaCl
[2015-11-18T20:09:04.087Z] <54d4a1d6db8155e6700f853b> could also be interesting
[2015-11-18T20:09:21.603Z] <564789be16b6c7089cbab8b7> ah thanks for the vbgmm tip! You need to update your online guide :)
[2015-11-18T20:09:30.193Z] <53135b495e986b0712efc453> [I am not sure if this is relevant to your discussions... but we are planning to introduce categorical variable support for trees here at #4899...]
[2015-11-18T20:10:00.818Z] <564789be16b6c7089cbab8b7> @rvraghav93 I am already following that PR with great excitement :) Thanks!
[2015-11-18T20:10:05.030Z] <54d4a1d6db8155e6700f853b> @lesshaste https://github.com/scikit-learn/scikit-learn/pull/4301
[2015-11-18T20:10:25.537Z] <54d4a1d6db8155e6700f853b> @lesshaste if you find the out of fold frequency discussion on the ML or issue tracker let me know
[2015-11-18T20:10:55.369Z] <54d4a1d6db8155e6700f853b> does anyone remember the alternative to theano that that was recently announced and that starts with a c? (not tensorflow)
[2015-11-18T20:11:15.613Z] <564789be16b6c7089cbab8b7> @amueller Thanks! The discussion seems to stop on 13 August. Does that typically mean people lost interest?
[2015-11-18T20:11:22.600Z] <5576063e15522ed4b3e19cc3> mxnet?
[2015-11-18T20:11:29.389Z] <53135b495e986b0712efc453> @lesshaste Ah you have commented on it... awesome thanks... your inputs will be great to have from time to time there as I will be working on it for the time being... :)
[2015-11-18T20:12:15.980Z] <54d4a1d6db8155e6700f853b> @lesshaste for #4301? It means core devs prioritized other things. I couldn't judge it / didn't have time to read the papers. It's probably a high quality addition and you should try it
[2015-11-18T20:12:31.031Z] <54d4a1d6db8155e6700f853b> @tw991 thanks but I think I was thinking of a different one
[2015-11-18T20:12:50.186Z] <564789be16b6c7089cbab8b7> @amueller Will do (can you tell which comment I am replying to? It's "if you find the out of fold frequency discussion on the ML or issue tracker let me know")
[2015-11-18T20:13:09.921Z] <54d4a1d6db8155e6700f853b> @tw991 though that also looks cool. I haven't looked at that either
[2015-11-18T20:13:26.843Z] <564789be16b6c7089cbab8b7> ok one last question... consider the following not so rare situation
[2015-11-18T20:13:28.516Z] <54d4a1d6db8155e6700f853b> @lesshaste hehe with clarification I can
[2015-11-18T20:13:49.962Z] <564789be16b6c7089cbab8b7> I have 10^9 labelled data points and I want to build classifier
[2015-11-18T20:14:05.898Z] <564789be16b6c7089cbab8b7> so I want to do CV.. but it's much too slow to do that with 10^9 data points
[2015-11-18T20:14:42.641Z] <564789be16b6c7089cbab8b7> so I want to sample 10^6 say at random and split it 60/40, train and test. Then for the next fold sample another 10^6 at random and repeat
[2015-11-18T20:15:00.139Z] <564789be16b6c7089cbab8b7> Am I right that this isn't supported currently by any of the CV code in scikit-learn?
[2015-11-18T20:15:03.612Z] <54d4a1d6db8155e6700f853b> @tw991 CGT is the one I meant
[2015-11-18T20:15:13.579Z] <5576063e15522ed4b3e19cc3> @amueller I havent got time to read mxnet either, but have heard some good things about it. 
[2015-11-18T20:15:59.392Z] <564789be16b6c7089cbab8b7> I believe this is a better form of cross-validation than just sampling 10^6 points and running CV within that set
[2015-11-18T20:17:13.214Z] <54d4a1d6db8155e6700f853b> @lesshaste ShuffleSplit and StratifiedShuffleSplit implement that
[2015-11-18T20:21:50.665Z] <564789be16b6c7089cbab8b7> @amueller  Oh I didn't realise that. I don't quite get it yet. I start with this matrix of 10^9 rows. The first thing I need to do is just randomly sample 10^6 of them.  Which of ShuffleSplit and StratifiedShuffleSplit  does that?
[2015-11-18T20:23:10.490Z] <564789be16b6c7089cbab8b7> @rvraghav93  The Internet claims that gradient boosted trees gracefully handle missing values. I can't say I know how but is that also part of the plan?
[2015-11-18T20:23:11.645Z] <54d4a1d6db8155e6700f853b> well what you want is sample 6 * 10^5 samples for training set and 4 * 10^5 disjoint samples for the test set, right?
[2015-11-18T20:23:27.499Z] <54d4a1d6db8155e6700f853b> @lesshaste re gradient boosting: at some point ;)
[2015-11-18T20:23:34.812Z] <564789be16b6c7089cbab8b7> @amueller  yes
[2015-11-18T20:24:05.334Z] <54d4a1d6db8155e6700f853b> well both ShuffleSplit and StratifiedShuffleSplit allow you to give training and test size either in absolute terms or percentages.
[2015-11-18T20:25:57.902Z] <564789be16b6c7089cbab8b7> I am reading http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html Is that what you mean?
[2015-11-18T20:26:55.230Z] <53135b495e986b0712efc453> [small noise: I would be a little happy if you instead read http://scikit-learn.org/dev/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html]
[2015-11-18T20:27:32.173Z] <564789be16b6c7089cbab8b7> oh I see
[2015-11-18T20:27:46.731Z] <564789be16b6c7089cbab8b7> thanks @amueller  I didn't really understand it before
[2015-11-18T20:27:56.799Z] <53135b495e986b0712efc453> That is just our new API for the cross validators :)
[2015-11-18T20:28:07.350Z] <564789be16b6c7089cbab8b7> @rvraghav93  thanks
[2015-11-18T20:29:57.262Z] <564789be16b6c7089cbab8b7> another thing I love is https://github.com/scikit-learn/scikit-learn/issues/5212  .. the long term check list at the top is awesome
[2015-11-18T20:30:03.470Z] <564789be16b6c7089cbab8b7> and I hope will be much copied
[2015-11-18T20:30:42.999Z] <564789be16b6c7089cbab8b7> is there a PR for MLP plus dropout or did I dream it?
[2015-11-18T20:32:14.768Z] <564789be16b6c7089cbab8b7> I feel that scikit-learn/all machine libraries will have to embrace neural nets/deep buzzword sooner than they might like
[2015-11-18T20:32:56.497Z] <564789be16b6c7089cbab8b7> although I often wish there were a separate "not using deep learning" prize on kaggle just so we could see what the difference would be
[2015-11-18T20:37:43.244Z] <54d4a1d6db8155e6700f853b> @glennq is working on dropout, but I think he is waiting for https://github.com/scikit-learn/scikit-learn/pull/5718 to get merged
[2015-11-18T20:38:11.030Z] <54d4a1d6db8155e6700f853b> @lesshaste probably quite big a difference ;) look at the forums?
[2015-11-18T21:41:16.351Z] <53810862048862e761fa2887> @amueller `np.argpartition` is kind of defined here argpartition
[2015-11-18T21:41:27.333Z] <53810862048862e761fa2887> https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/fixes.py#L193
[2015-11-18T21:41:45.577Z] <53810862048862e761fa2887> Although  it is as inefficient as `np.sort`
[2015-11-18T21:42:36.461Z] <53810862048862e761fa2887> I was thinking if I could do a similar wrapper for `np.partition` and at least make sure that everyone using `numpy 1.8` and above would get speedups
[2015-11-18T22:01:27.127Z] <564789be16b6c7089cbab8b7> @amueller Thanks. Re: "not using deep learning" it's not clear because the best teams with the best ideas choose to you use it. So maybe they would have done well if they hadn't. Who knows?
[2015-11-18T22:03:52.931Z] <564789be16b6c7089cbab8b7> I am not sure I know where the line is drawn between MLP and deep learning to be honest
[2015-11-18T23:18:06.973Z] <54c084dbdb8155e6700eed4c> https://github.com/scikit-learn/scikit-learn/graphs/contributors ... Top 3 contributors within 4 commits of each other? I wonder if you were all equal recently?
[2015-11-18T23:22:14.570Z] <53135b495e986b0712efc453> @rvraghav93 is happy that there is only 3 more commits to reach his hundredth commit!!!
[2015-11-19T10:47:17.184Z] <564789be16b6c7089cbab8b7> I have data with a mix of categorical and numerical values. It classifies very well using one-hot encoding + random forests but terribly using any non-tree method I have tried. I am looking for a clustering method that might work on this sort of data.  What might be suitable?
[2015-11-19T10:47:39.424Z] <564789be16b6c7089cbab8b7> I tried some standard methods that rely on euclidean distance but they are a disaster it seems
[2015-11-19T10:48:25.456Z] <564789be16b6c7089cbab8b7> I noticed that http://labs.genetics.ucla.edu/horvath/RFclustering/RFclustering.htm exists 
[2015-11-19T12:27:40.612Z] <53135b495e986b0712efc453> #5765 can be closed...
[2015-11-19T12:28:17.003Z] <564789be16b6c7089cbab8b7> hi @rvraghav93 
[2015-11-19T12:28:26.363Z] <53135b495e986b0712efc453> Hi @lesshaste :)
[2015-11-19T12:28:48.912Z] <564789be16b6c7089cbab8b7> Are you interested in random forests by any chance?
[2015-11-19T12:29:22.812Z] <564789be16b6c7089cbab8b7> I think there are some interesting directions to take the scikit-learn work
[2015-11-19T12:29:28.101Z] <53135b495e986b0712efc453> Yes I will be working on Trees and RFs :)
[2015-11-19T12:29:45.501Z] <564789be16b6c7089cbab8b7> great!
[2015-11-19T12:30:03.837Z] <53135b495e986b0712efc453> For me the priority is https://github.com/scikit-learn/scikit-learn/issues/5212#issuecomment-155387289 :)
[2015-11-19T12:30:14.624Z] <53135b495e986b0712efc453> Do you have any suggestions in mind?
[2015-11-19T12:30:43.374Z] <564789be16b6c7089cbab8b7> not for that sorry.... I was going to make longer term suggestions for when that is all done..which I hope is ok
[2015-11-19T12:31:15.836Z] <564789be16b6c7089cbab8b7> but first I should say a huge thank you for the work you are doing
[2015-11-19T12:31:58.817Z] <564789be16b6c7089cbab8b7> adding to your TODO may not be a great way of saying thank you :)
[2015-11-19T12:32:48.786Z] <564789be16b6c7089cbab8b7> but actually.. before I get to that. Does scikit learn have any equivalent of the R package randomGLM ?
[2015-11-19T12:34:04.937Z] <564789be16b6c7089cbab8b7> It is described at http://labs.genetics.ucla.edu/horvath/RGLM/. I couldn't quite tell from the scikit-learn docs. There are lots of things that look similar but maybe not the same
[2015-11-19T12:35:19.103Z] <53135b495e986b0712efc453> Thanks :D and no I'd be happy TODO :) You can actually raise an issue and add your suggestions of features which you feel are worthy of adding and why you think they should be added... That way you will get a larger participation of people  in discussions... :)
[2015-11-19T12:35:52.095Z] <564789be16b6c7089cbab8b7> good point.. because there is a risk my ideas are already done or just plain stupid, do you mind being a first stage filter?
[2015-11-19T12:35:52.844Z] <53135b495e986b0712efc453> And about GLM what does it do? Generalized Linear Models? translates roughly to our `linear_model` module?
[2015-11-19T12:37:26.120Z] <53135b495e986b0712efc453> Oh sure a stupidity filter... I'm in ;)
[2015-11-19T12:38:49.169Z] <564789be16b6c7089cbab8b7> the full title of the randomGLM talk is "Random generalized linear model:  a highly accurate and interpretable  ensemble predictor" . http://labs.genetics.ucla.edu/horvath/RGLM/TalkRGLM.pdf   In more detail it is an ensemble predictor based on  bootstrap  aggregation (bagging) of  generalized linear models  whose  covariates are selected using  forward regression  according to  AIC criteria.
[2015-11-19T12:39:04.728Z] <564789be16b6c7089cbab8b7> maybe we already have something that is equivalent to that?
[2015-11-19T12:41:55.903Z] <564789be16b6c7089cbab8b7> @rvraghav93  https://followthedata.wordpress.com/2013/10/10/random-generalized-linear-models/ has an explanation of randomglm too
[2015-11-19T12:43:03.818Z] <53135b495e986b0712efc453> We got `bagging` and `boosting` in the `ensemble` module! (Is that what randomGLM does?)... I will read the links in a moment...
[2015-11-19T12:43:11.300Z] <564789be16b6c7089cbab8b7> thanks
[2015-11-19T12:46:10.358Z] <53135b495e986b0712efc453> Ah that was interesting... we don't have it... 
[2015-11-19T12:50:25.041Z] <53135b495e986b0712efc453> But the paper - http://www.ncbi.nlm.nih.gov/pubmed/23323760 - has only 12 citations... I am not sure the core devs might want to take this into scikit learn, since this is not popular/old/academically established enough... See [this FAQ](http://scikit-learn.org/stable/faq.html#can-i-add-this-new-algorithm-that-i-or-someone-else-just-published) :)
[2015-11-19T12:53:26.811Z] <564789be16b6c7089cbab8b7> I like that rule
[2015-11-19T12:53:39.995Z] <53135b495e986b0712efc453> :)
[2015-11-19T13:09:07.247Z] <564789be16b6c7089cbab8b7> ok back to my real suggestions :)
[2015-11-19T13:12:07.792Z] <564789be16b6c7089cbab8b7> for random forests, it would be great if we had a method to make a small interpretable versions.  One of the main drawbacks of random forests is that they end up like a black box. Can you read http://link.springer.com/chapter/10.1007/978-3-319-18356-5_20 ?  
[2015-11-19T13:13:16.756Z] <564789be16b6c7089cbab8b7> or even to infer a single decision tree
[2015-11-19T13:14:56.813Z] <564789be16b6c7089cbab8b7> http://scikit-learn.org/stable/faq.html doesn't mention neural networks!
[2015-11-19T13:15:24.109Z] <564789be16b6c7089cbab8b7> @rvraghav93  see above 
[2015-11-19T13:18:24.017Z] <564789be16b6c7089cbab8b7> ah..200 references.. I will work on that :)
[2015-11-19T13:18:26.918Z] <564789be16b6c7089cbab8b7> it's not a bad rule
[2015-11-19T13:23:11.127Z] <564789be16b6c7089cbab8b7> @rvraghav93  under the 200+ citations rule I withdraw all my suggestions :)
[2015-11-19T13:43:37.633Z] <564a264d16b6c7089cbaee0f> #5834 ready for merge. minor changes to documentation. straightforward.
[2015-11-19T13:54:03.746Z] <53135b495e986b0712efc453> 200+ citations is not a hard and fast rule... if the suggestion is for an improvement/technique that is not fundamentally different from a well established algorithm and gives a very significant performance improvement, it would be worthwhile to implement the same... Basically, the idea is that we don't want code that might rot over time without a substantial userbase or maintainers to support or both... Essentially u can compress that rule to this --  `((Will a lot of people who already use sklearn benefit from this?) || (Will it help bring *a lot* of new people to sklearn?, if its a completely new feature)) && (Does it fit well within our API?) && !(Will it make life tougher for the existing users)` ;)
[2015-11-19T13:55:11.246Z] <564789be16b6c7089cbab8b7> @rvraghav93  I think these are really sensible rules and I completely agree with them :)
[2015-11-19T13:55:21.156Z] <53135b495e986b0712efc453> :D 
[2015-11-19T13:57:14.684Z] <564789be16b6c7089cbab8b7> @rvraghav93  I realise it's a little cheeky to ask here but.. do you have a view on my earlier question? That is ... I have data with a mix of categorical and numerical values. It classifies very well using one-hot encoding + random forests but terribly using any non-tree method I have tried. I am looking for a clustering/unsupervised method that might work on this sort of data. What might be suitable? I tried some standard methods that rely on euclidean distance but they are a disaster it seems
[2015-11-19T13:58:34.188Z] <564789be16b6c7089cbab8b7> That is what took me to the unsupervised random forest method
[2015-11-19T14:23:19.537Z] <564789be16b6c7089cbab8b7> Another suggestion, this one I hope uncontroversial. We seem not to have the Gower distance implemented. As in http://stats.stackexchange.com/a/15313/53128
[2015-11-19T15:00:56.589Z] <53135b495e986b0712efc453> That one seems useful... Please raise an issue!! I'll try to implement if possible :)
[2015-11-19T15:05:10.955Z] <53135b495e986b0712efc453> Nevermind I raised an issue (#5884)... Lets see how it is received... Thanks for the suggestion! :)
[2015-11-19T15:06:59.089Z] <53135b495e986b0712efc453> Could someone review #5823 please? @amueller ?
[2015-11-19T15:10:04.336Z] <564789be16b6c7089cbab8b7> @rvraghav93  Thanks! I am impressed again :)
[2015-11-19T15:10:16.125Z] <53135b495e986b0712efc453> @amueller Also #5834 
[2015-11-19T15:12:35.339Z] <53135b495e986b0712efc453> And #5703... (sorry :P)
[2015-11-19T15:14:27.145Z] <564789be16b6c7089cbab8b7> @rvraghav93  is daisy https://stat.ethz.ch/R-manual/R-devel/library/cluster/html/daisy.html something that been discussed (this is relevant to the Gower coefficient). I have  a very vague memory of seeing it in some scikit learn discussion but I may well have that wrong
[2015-11-19T15:17:02.715Z] <564789be16b6c7089cbab8b7> ah no.. I think I was remembering http://stackoverflow.com/a/26387936/2179021
[2015-11-19T16:04:13.628Z] <564789be16b6c7089cbab8b7> I just realised that scikit learn has no support at all for ordinals currently.. is that right?
[2015-11-19T16:14:35.953Z] <53135b495e986b0712efc453> I think so... By ordinals you mean something like `{"small", "medium", "large"}` correct?
[2015-11-19T16:16:09.698Z] <53135b495e986b0712efc453> @glouppe Your PhD thesis is awesome! Thanks... I am loving it...
[2015-11-19T16:17:08.555Z] <564789be16b6c7089cbab8b7> @rvraghav93  more 1,2,3,4,5,6,7 where all you know is that 1<2<3<4<5<6<7 
[2015-11-19T16:17:12.466Z] <564789be16b6c7089cbab8b7> that is you just know the order
[2015-11-19T16:17:21.697Z] <564789be16b6c7089cbab8b7> but you can't do 1+3 = 4
[2015-11-19T16:17:39.608Z] <564789be16b6c7089cbab8b7> we could call them ranks
[2015-11-19T16:26:13.616Z] <53135b495e986b0712efc453> yes we don't support them...
[2015-11-19T16:27:51.758Z] <564789be16b6c7089cbab8b7> OK thanks. Something for the future maybe :)
[2015-11-19T16:28:02.086Z] <53135b495e986b0712efc453> Probably ;)
[2015-11-19T16:28:36.919Z] <564789be16b6c7089cbab8b7> Although there is a very interesting and related PR about LambdaMART I see where the conclusion of the discussion seems to be that we are better off using GBRT
[2015-11-19T16:38:49.048Z] <53135b495e986b0712efc453> @amueller If you come online I have a list of minor PRs for you to review/merge ;) BTW was #5883 discussed during the sprint??
[2015-11-19T16:50:11.327Z] <54d4a1d6db8155e6700f853b> @lesshaste scikit-learn doesn't really have any support for categorical variables at the moment.
[2015-11-19T16:50:48.764Z] <54d4a1d6db8155e6700f853b> #5883 wasn't discusses during the sprint afaik
[2015-11-19T16:50:57.611Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I have a loooot to review at the moment. Trying to catch up
[2015-11-19T16:51:13.044Z] <53135b495e986b0712efc453> @lesshaste Oh!! Sorry I haven't followed that PR... :(
[2015-11-19T16:52:31.346Z] <53135b495e986b0712efc453> @amueller Do you have anything in mind that I could be of help (in reviewing)?
[2015-11-19T16:54:52.401Z] <54d4a1d6db8155e6700f853b> things by tw991, the neural network improvements, the huber regressor. Anything by vignesh, tian or manoj (I'm supervising them). Your stuff is after that ;)
[2015-11-19T16:56:39.938Z] <53135b495e986b0712efc453> Do you mean to say I can review any of these or are u just listing ur todo list? :P
[2015-11-19T17:00:03.033Z] <564789be16b6c7089cbab8b7> @amueller right.. well I suppose the tree improvements will be  the first major support for categorical variables.. ? I am referring to https://github.com/scikit-learn/scikit-learn/pull/4899
[2015-11-19T17:00:59.028Z] <564789be16b6c7089cbab8b7> @amueller and my suggestion for the Gower coefficient gives an easy way for mixed types including categorical variables if all you need is a distance. This could really help for clustering I suspect.
[2015-11-19T17:17:34.499Z] <564789be16b6c7089cbab8b7> @amueller  in relation to our previous conversation about using shufflesplit to subsample for CV, I realised the use case I really had in mind is doing this out of core
[2015-11-19T17:19:10.163Z] <564789be16b6c7089cbab8b7> so the 10^9 feature vectors stay out of core and shufflesplit samples 6 10^5 feature vectors for training and 4 10^5 feature vectors for testing from the large out of core data set.  This may all be better done by bespoke code however rather than something built into scikit learn
[2015-11-19T18:36:07.752Z] <54d4a1d6db8155e6700f853b> I was listing my todo list ;)
[2015-11-19T18:36:51.112Z] <54d4a1d6db8155e6700f853b> @lesshaste you could possibly use memory mapped arrays to do this out of core. Not sure though
[2015-11-19T19:02:30.909Z] <564789be16b6c7089cbab8b7> @amueller  That sounds like a good idea to me
[2015-11-19T19:05:26.727Z] <564789be16b6c7089cbab8b7> @amueller  maybe http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html or https://docs.python.org/2/library/mmap.html ?
[2015-11-19T19:05:59.072Z] <564789be16b6c7089cbab8b7> Is it worth opening an issue? I see that some support for out of core processing is entering into scikit-learn
[2015-11-19T19:07:29.043Z] <564789be16b6c7089cbab8b7> or are you thinking the mmap'ing can happen in the user code and shufflesplit will just use it efficiently as is?
[2015-11-19T19:54:56.459Z] <54d4a1d6db8155e6700f853b> yes
[2015-11-19T19:55:01.099Z] <54d4a1d6db8155e6700f853b> that might be possible
[2015-11-19T20:37:07.594Z] <5395efa3a9176b500d1cd7fb> Why would the PCA fit methods accept target vectors `y` if they dont do anything with it? Just for API exchange-a-bility ?
[2015-11-19T21:36:06.738Z] <54d4a1d6db8155e6700f853b> yes
[2015-11-19T21:36:11.558Z] <54d4a1d6db8155e6700f853b> all fit methods do
[2015-11-19T21:36:23.342Z] <54d4a1d6db8155e6700f853b> in particular to make pipelines easier to understand
[2015-11-19T22:27:50.241Z] <5395efa3a9176b500d1cd7fb> Thanks. So, if I may ask one more: Im a bit confused how to reduce dimensionality for a regression task? It is clear to me that some features are more related to variance in the target vector than others, so I believe to understand that applying a PCA should make sense in general, but I dont understand how to apply `sklearn` for this. Should I make the target vector part of the X-matrix before handing it to the PCA? I want to learn which of my features are related to variability in the target vector, and how much. All your examples and very nice tutorials only ever mention how to apply PCA to classification but never a case for regression, it seems.
[2015-11-19T22:43:03.952Z] <54a2cde7db8155e6700e4190> Youre probably better of with something like Lasso or RidgeRegression if youre interested in knowing which features are related to your target vector.
[2015-11-19T22:43:52.559Z] <54a2cde7db8155e6700e4190> PCA will mix together your inputs, meaning your regression coefficients wont have a direct interpretation.
[2015-11-19T22:45:54.819Z] <54a2cde7db8155e6700e4190> But if you do want to use PCA, then making a pipeline something like `pipeline.make_pipeline(PCA(n_components=N), LinearRegression()).fit(X, y)` ought to work (untested code)
[2015-11-19T22:55:37.917Z] <54d4a1d6db8155e6700f853b> reviews for #5728 would be cool
[2015-11-19T22:58:17.961Z] <5395efa3a9176b500d1cd7fb> I thought PCA might be the right tool, as it provided this percentage-wise composition of the feature vectors for the resulting decomposition which I find very neat, also the way the explained variance results tells you how many new components are needed to explain variety. Your pipeline code will not consider the target vector in the PCA so I wonder how the PCA can be helpful that way.
[2015-11-19T22:59:22.557Z] <5395efa3a9176b500d1cd7fb> Ill have a look at how Lasso/Ridge Regressions work, thanks.
[2015-11-19T23:17:01.775Z] <564e507e16b6c7089cbb6551> Is fuzzy c-means clustering implemented in scikit-learn?
[2015-11-19T23:28:29.843Z] <54d4a1d6db8155e6700f853b> @h4k1m0u currently not. Why do you want that and not GMMs?
[2015-11-19T23:29:07.482Z] <54d4a1d6db8155e6700f853b> It is just optimizing GMMs with spherical covariance and optimized using hard EM, right?
[2015-11-19T23:29:39.425Z] <54d4a1d6db8155e6700f853b> @michaelaye PCA never uses y, it is an unsupervised method. Therefor it is likely not a good choice for your application.
[2015-11-19T23:38:30.662Z] <5395efa3a9176b500d1cd7fb> ok, gotcha, thks.
[2015-11-20T02:15:33.163Z] <564e507e16b6c7089cbb6551> @amueller because I'm trying to cluster an image and for that I've found in the literature that it's possible to take into account the spatial context (neighbourhood) when using fuzzy c-means. But, I would be really interested to know if GMM offer this possibility as well in image clustering (considering the spatial dimension besides the intensity), although I had issues with the GMM on matlab when operating on a multi-dimensional data (multivariate gaussians).
[2015-11-20T09:08:32.446Z] <53135b495e986b0712efc453> The number of open PRs are slowly increasing... From 300 to 368 :O
[2015-11-20T09:09:09.329Z] <53135b495e986b0712efc453> We should have one sprint just for reviewing ;) That would be awesome!
[2015-11-20T09:18:30.687Z] <53135b495e986b0712efc453> BTW github's new repo layout is good! ;)
[2015-11-20T09:18:40.948Z] <53135b495e986b0712efc453> everything on top...
[2015-11-20T11:08:56.622Z] <564789be16b6c7089cbab8b7> @rvraghav93 That's a great idea!
[2015-11-20T13:14:21.249Z] <564e507e16b6c7089cbb6551> When clustering an image (distribution of pixel intensities), is it possible using GMM (implemented in scikit-learn) to include the spatial context besides the pixel brightness during the clustering (GMM using multivariate gaussian distribution)?
[2015-11-20T13:15:50.974Z] <564789be16b6c7089cbab8b7> @h4k1m0u  That's quite a tricky question (I am not an expert).  I suspect your best bet for getting a high quality answer would be actually implement a solution using GMM on some publicly available data and show the problem. Can you do that?
[2015-11-20T13:16:17.553Z] <564789be16b6c7089cbab8b7> even better if you can find another system that does exactly what you want and compare them
[2015-11-20T13:16:45.038Z] <564789be16b6c7089cbab8b7> There is nothing as compelling to a developer as a worked example :)
[2015-11-20T14:04:19.755Z] <564e507e16b6c7089cbb6551> @lesshaste I know that what I'm trying to do has already been achieved with fuzzy c-means (including the neighborhood context) to the clustering (see [Zhang and Chen 2004] A novel kernelized fuzzy C-means algorithm with application in medical image segmentation). But, since the fuzzy c-means is not implemented in scikit-learn, I'm looking for something similar but with GMM.
[2015-11-20T14:13:32.317Z] <564789be16b6c7089cbab8b7> is there code in some other language for fuzzy c-means?
[2015-11-20T14:39:28.322Z] <564e507e16b6c7089cbb6551> @lesshaste yes in python (https://github.com/scikit-fuzzy/scikit-fuzzy)
[2015-11-20T15:58:34.225Z] <564789be16b6c7089cbab8b7> @h4k1m0u  It's very useful you have code that does it. Your question is good but I wonder if this the right place for it. If you are not asking for a new feature or asking about an existing one maybe a stackexchange site would work better
[2015-11-20T18:09:38.067Z] <564e507e16b6c7089cbb6551> @lesshaste ok I will try to test the GMM implemented in scikit-learn, to cluster images (taking into account the spatial context). Otherwise, I will ask my question in stackoverflow... thanks..
[2015-11-20T19:01:53.727Z] <564789be16b6c7089cbab8b7> @h4k1m0u  sorry I wasn't very helpful!
[2015-11-20T19:02:09.219Z] <564789be16b6c7089cbab8b7> please feel free to post the url to the question here
[2015-11-20T20:12:57.592Z] <564e507e16b6c7089cbb6551> @lesshaste it's okay, my issue is not really related to machine learning (clustering). just an image processing issue (maybe I should ask to the scikit-image community): http://stackoverflow.com/questions/33834883/include-the-spatial-context-of-pixels-during-image-clustering
[2015-11-20T21:08:19.586Z] <54d4a1d6db8155e6700f853b> @h4k1m0u the standard is to also include the x and y coordinates. slic for example is just k-means on x,y,lab
[2015-11-20T21:08:25.120Z] <54d4a1d6db8155e6700f853b> same for quickshift
[2015-11-20T21:08:37.628Z] <54d4a1d6db8155e6700f853b> look at the image segmentation module in scikit-image. it does what you want.
[2015-11-20T21:14:02.740Z] <54d4a1d6db8155e6700f853b> @h4k1m0u answert on SO, too
[2015-11-20T21:14:22.892Z] <54d4a1d6db8155e6700f853b> @MechCoder starting to review your HuberEstimator. Teaches you to be careful what you wish for ;)
[2015-11-20T21:33:18.744Z] <54d4a1d6db8155e6700f853b> @rvraghav93 please don't ping joel, he is offline at the moment.
[2015-11-20T21:39:26.479Z] <53135b495e986b0712efc453> Yes I heard about him... Thats so sad... :/ Hope he stays strong!! And yes sure I won't... (BTW are you telling me in the context of any particular comment where I accidentally pinged him or are you just letting me know?)
[2015-11-20T22:01:53.366Z] <53135b495e986b0712efc453> BTW I just realized you are down to your last but one task in your TODO... That means I am next :smiling_imp:
[2015-11-20T22:01:59.559Z] <53135b495e986b0712efc453> (Don't worry I've a very small list - #5823 #5703 #5568 #4115)
[2015-11-20T22:02:05.201Z] <53135b495e986b0712efc453> :P
[2015-11-20T22:23:47.263Z] <54d4a1d6db8155e6700f853b> No, there is like three more tasks :P Still on Huber, then Vighnes and Tian
[2015-11-20T22:24:21.822Z] <54d4a1d6db8155e6700f853b> you pinged Joel 5 days ago somewhere. How did you hear. He did not post publicly, so I think we should not make it overtly public.
[2015-11-20T22:34:01.938Z] <53135b495e986b0712efc453> Check PM :)
[2015-11-20T22:37:39.287Z] <53135b495e986b0712efc453> well then `amueller._todo_queue.put_nowait([5823, 5703, 5568, 4115])` ^_^
[2015-11-20T22:42:07.316Z] <54d4a1d6db8155e6700f853b> http://i.imgur.com/aOChOa2.png
[2015-11-20T22:42:16.995Z] <54d4a1d6db8155e6700f853b> (note the last line)
[2015-11-20T22:46:03.571Z] <53135b495e986b0712efc453> In my defence `put_no wait` fails when the thread is busy... so u dont have to worry about it :p I'll work on something else at the moment :grin: 
[2015-11-21T01:12:49.301Z] <55e8e8690fc9f982beaf992f> Hey guys! What's the best way to perform Kernel Logistic Regression or Import Vector Machine (or anything that will do binary classification + output probabilities) with SkLearn or some other python package? I can't seem to find anything. Does no one ever use KLR or IVM ?
[2015-11-21T01:13:19.791Z] <54d4a1d6db8155e6700f853b> I have not heard of IVM. and yes, no-one ever uses KernelLogisticRegression because it scales even worse than SVMs ;)
[2015-11-21T01:14:03.181Z] <55e8e8690fc9f982beaf992f> Thanks, but I don't have that much data, so I wanted to use it since I really need probabilistic outputs. I don't care about scaling for now.
[2015-11-21T01:14:05.939Z] <54d4a1d6db8155e6700f853b> @AAnoosheh you can use SVM(probabilities=True) which will use Platt's method for calibration of the decision function. Or you can use CallibratedClassifierCV to use Isotonic REgression to calibrate an SVM
[2015-11-21T01:14:30.470Z] <54d4a1d6db8155e6700f853b> you can use Nystrom together with LogisticRegression
[2015-11-21T01:14:50.456Z] <54d4a1d6db8155e6700f853b> just set n_components in Nystroem to n_samples and it will give you exact kernel logistic regression
[2015-11-21T01:15:01.510Z] <55e8e8690fc9f982beaf992f> @amueller  Isn't the Platt's method really expensive? Or is SVM+Platt's similar expense to KLR?
[2015-11-21T01:15:31.884Z] <54d4a1d6db8155e6700f853b> make_pipe(Nystroem(n_components=n_samples), LogisticRegression())
[2015-11-21T01:15:40.174Z] <54d4a1d6db8155e6700f853b> does kernel logistic regression
[2015-11-21T01:16:49.180Z] <54d4a1d6db8155e6700f853b> platt's method in libsvm does 5-fold cross-validation, so it is 5 times as expensive at one SVM.
[2015-11-21T01:17:04.139Z] <54d4a1d6db8155e6700f853b> I don't even know how one would implement KLR in any efficient way, as the dual is dense
[2015-11-21T01:17:29.727Z] <54d4a1d6db8155e6700f853b> I guess you could do SMO or a similar coordinate descent solver?
[2015-11-21T01:18:12.600Z] <54d4a1d6db8155e6700f853b> anyhow, I would expect SVM+Platt do be much faster than KLR, unless you set the parameters such that all samples are support vectors
[2015-11-21T01:19:18.117Z] <55e8e8690fc9f982beaf992f> Interesting, thanks.  Also this is the IVM; just heard of it recently: http://www.ipb.uni-bonn.de/ivm/?L=1
[2015-11-21T01:21:17.225Z] <54d4a1d6db8155e6700f853b> interesting. that's my almer mater but I haven't heard of that professor
[2015-11-21T01:21:24.866Z] <54d4a1d6db8155e6700f853b> paper is here: http://papers.nips.cc/paper/2059-kernel-logistic-regression-and-the-import-vector-machine.pdf
[2015-11-21T01:21:44.983Z] <54d4a1d6db8155e6700f853b> you can set n_components to a smaller number in Nystroem for an approximation of kernel logistic regression
[2015-11-21T01:22:18.844Z] <54d4a1d6db8155e6700f853b> ah the improved paper is foerstner
[2015-11-21T01:22:21.110Z] <54d4a1d6db8155e6700f853b> makes sense
[2015-11-21T01:23:16.878Z] <54d4a1d6db8155e6700f853b> if you have benchmarks that show IVM is superior to svm + platt let me know ;)
[2015-11-21T01:25:49.947Z] <54d4a1d6db8155e6700f853b> ah IVM is kernel logistic regression with one-step look-ahead greedy selection of the non-zero dual coefficients.
[2015-11-21T01:29:03.881Z] <54d4a1d6db8155e6700f853b> I think people are just not so excited about kernels any more, so people don't really care for practical implementations of kernels
[2015-11-21T01:39:07.132Z] <55e8e8690fc9f982beaf992f> Perfect, thanks @amueller 
[2015-11-21T07:00:12.903Z] <564789be16b6c7089cbab8b7> @amueller I didn't realise people don't really care about kernels any more. Is this because everyone has moved on to random forests and deep learning?
[2015-11-22T04:03:45.651Z] <5576063e15522ed4b3e19cc3> This looks interesting :) https://github.com/google/skflow
[2015-11-22T05:16:04.615Z] <55901c1b15522ed4b3e2f949> People certainly do care about kernels, @lesshaste 
[2015-11-22T05:17:04.728Z] <55901c1b15522ed4b3e2f949> "Random forests and deep learning" are certainly not the solution to everything.
[2015-11-22T07:07:42.502Z] <564789be16b6c7089cbab8b7> @tw991  Thanks!
[2015-11-22T07:08:06.345Z] <564789be16b6c7089cbab8b7> @jmschrei  It would lovely to see a blog post investigating that question more deeply.
[2015-11-22T08:51:55.662Z] <55901c1b15522ed4b3e2f949> Investigating what question?
[2015-11-22T08:52:07.024Z] <55901c1b15522ed4b3e2f949> If people use other methods than RF and deep learning?
[2015-11-22T11:08:05.034Z] <564789be16b6c7089cbab8b7> @jmschrei  I didn't quite mean that :) If you look at kaggle winners their main tools are quite consistent  (GBRT and/or deep learning).  I was thinking of a blog post titled "Where kernels methods still rule" explaining with examples where they are still the best approach
[2015-11-22T20:47:59.558Z] <55901c1b15522ed4b3e2f949> My understanding is high frequency trading uses kernel methods pretty extensively, because they need speed and tree based approaches are rather slow
[2015-11-22T20:48:14.265Z] <55901c1b15522ed4b3e2f949> So they'll usually use some form of logistic kernel regression
[2015-11-22T20:48:38.413Z] <55901c1b15522ed4b3e2f949> "Rather slow" in the HFT sense, not in the normal person sense, at making predictions
[2015-11-22T20:50:00.348Z] <55901c1b15522ed4b3e2f949> Kernel methods are also pretty good for variable length sequences. For example in bioinformatics, the 'spectrum kernel SVM' is frequently used to compare protein sequences to each other to do domain classification or such.
[2015-11-22T20:50:41.645Z] <55901c1b15522ed4b3e2f949> I mean, kernels extend far past just matrices of data. There are kernels to compare tree based structures, or graphs, to each other.
[2015-11-22T20:50:43.723Z] <564789be16b6c7089cbab8b7> @jmschrei  that's very interesting... although I am a little surprised by the trees being slow
[2015-11-22T20:50:49.906Z] <55901c1b15522ed4b3e2f949> Why?
[2015-11-22T20:51:06.518Z] <55901c1b15522ed4b3e2f949> Doing an inner product is super fast, compared to traversing n binary trees.
[2015-11-22T20:51:58.444Z] <55901c1b15522ed4b3e2f949> I'm not trying to demean either RF or deep learning, which are super powerful, but kaggle competitions are a small subset of ML problems out there.
[2015-11-22T20:52:14.051Z] <564789be16b6c7089cbab8b7> @jmschrei  only because there is a line of research on producing minimum and forests or even a single decision tree with similar performance to a random forest and all you are doing is comparisons. 1000 comparisons is very fast
[2015-11-22T20:52:15.797Z] <55901c1b15522ed4b3e2f949> You haven't even touched my favorite models, probabilistic graphical models. People use Bayes nets, HMMs, GMMs all the time.
[2015-11-22T20:52:50.507Z] <55901c1b15522ed4b3e2f949> Very fast for a normal person, but it's still orders of magnitude slower than an inner product using BLAS, and in the HFT sense, microseconds count.
[2015-11-22T20:54:03.195Z] <55901c1b15522ed4b3e2f949> I also imagine you can put a logistic kernel machine on a GPU, but can't put trees on a gpu easily.
[2015-11-22T20:54:11.750Z] <564789be16b6c7089cbab8b7> @jmschrei I think you would be a great person to write a blog post on this. It's very interesting and not universally understood
[2015-11-22T20:54:34.191Z] <55901c1b15522ed4b3e2f949> What do you think it should cover?
[2015-11-22T20:59:22.839Z] <564789be16b6c7089cbab8b7> I am trying and failing to find some papers on inferring a singe decision tree from a random forest currently
[2015-11-22T21:03:33.283Z] <564789be16b6c7089cbab8b7> I can't seem to find the papers now... :(
[2015-11-22T21:04:32.307Z] <564789be16b6c7089cbab8b7> @jmschrei  Well... that would be up to the author :)  But how about a set of topics intersecting with... timings for prediction using random forests versus kernel methods, spectrum kernel SVM and how it is applied to variable length sequences. This would be even cooler if there were a test dataset and we could see how well a straightforward application of GBRT does in comparison,  practical examples with real data for kernels to compare tree based structures, or graphs and a comparison with what one would have to do using GBRT
[2015-11-22T21:06:33.994Z] <564789be16b6c7089cbab8b7> that sort of thing :)
[2015-11-22T21:07:15.370Z] <564789be16b6c7089cbab8b7> Basically, concrete classification or regression tasks where there is  a clearly understandable objective function and we can see how kernel methods are easier or just do better
[2015-11-22T21:16:31.942Z] <55901c1b15522ed4b3e2f949> I don't think it's possible to infer a single tree from an entire random forest, except in special circumstances
[2015-11-22T21:18:25.650Z] <564789be16b6c7089cbab8b7> @jmschrei  there is work on this. I am just struggling to find the papers again!
[2015-11-22T21:18:55.956Z] <55901c1b15522ed4b3e2f949> I'd love to se it
[2015-11-22T21:19:26.394Z] <564789be16b6c7089cbab8b7> @jmschrei  can you read http://link.springer.com/chapter/10.1007/978-3-319-18356-5_20 ?
[2015-11-22T21:19:57.345Z] <55901c1b15522ed4b3e2f949> The abtract
[2015-11-22T21:20:14.271Z] <564789be16b6c7089cbab8b7> not the whole paper?
[2015-11-22T21:20:19.853Z] <55901c1b15522ed4b3e2f949> No :(
[2015-11-22T21:20:43.961Z] <564789be16b6c7089cbab8b7> ok.. let me try harder.. the papers I am referring to are in the "related work" section of that paper
[2015-11-22T21:20:44.254Z] <55901c1b15522ed4b3e2f949> That also doesn't look exactly the same as turning a RF into a single decision tree
[2015-11-22T21:21:02.150Z] <55901c1b15522ed4b3e2f949> I thought you meant turn a RF into a single tree which mimiced it identically
[2015-11-22T21:21:31.855Z] <564789be16b6c7089cbab8b7> 2 seconds :)
[2015-11-22T21:23:42.767Z] <564789be16b6c7089cbab8b7> @jmschrei  here is one https://www.researchgate.net/profile/Ulf_Johansson5/publication/221008645_One_tree_to_explain_them_all/links/0deec52ff78d51398e000000.pdf
[2015-11-22T21:24:15.873Z] <564789be16b6c7089cbab8b7> @jmschrei  here is another http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.6595&rep=rep1&type=pdf
[2015-11-22T21:24:54.093Z] <564789be16b6c7089cbab8b7> @jmschrei  this is a copy and paste of the related work section https://bpaste.net/show/54f0d4433bca
[2015-11-22T21:25:02.471Z] <564789be16b6c7089cbab8b7> let me know if you want any of the papers
[2015-11-22T21:30:33.257Z] <55901c1b15522ed4b3e2f949> That's pretty interesting, I didn't know that was a thing.
[2015-11-22T21:56:08.584Z] <564789be16b6c7089cbab8b7> I don't know how well known it is.. or how useful  :) 
[2015-11-22T21:58:40.978Z] <564789be16b6c7089cbab8b7> It would be great to understand how practically important http://jmlr.org/proceedings/papers/v37/beygelzimer15.pdf is too!
[2015-11-22T21:59:48.784Z] <564789be16b6c7089cbab8b7> section 5 claims it does better than vowpal wabbit
[2015-11-23T03:16:55.242Z] <53810862048862e761fa2887> Hello  I have been trying a lot of stuff to get #5689 to pass the tests. I am not able to reproduce the failures locally using `conda`.  I have narrowed the failure down to one line Any ideas why this commit https://github.com/vighneshbirodkar/scikit-learn/commit/02bf4df3ccd9f2eec5f1c0519caff7fbe7257969 causes this test https://travis-ci.org/scikit-learn/scikit-learn/builds/92637403 to fail ?
[2015-11-23T15:12:21.154Z] <5653208916b6c7089cbbd390> Hi anyone know word2vec ?
[2015-11-23T15:13:07.874Z] <5653208916b6c7089cbbd390> I cant import Word2vec in python. Am facing error File "/usr/local/lib/python2.7/dist-packages/gensim-0.12.3-py2.7-linux-x86_64.egg/gensim/models/word2vec.py", line 690, in train     raise RuntimeError("you must first build vocabulary before training the model") RuntimeError: you must first build vocabulary before training the model
[2015-11-23T15:13:17.011Z] <5653208916b6c7089cbbd390> Kindly any one help me
[2015-11-23T15:13:30.168Z] <53135b495e986b0712efc453> Could you post a full code snippet?
[2015-11-23T15:13:47.069Z] <5653208916b6c7089cbbd390> ya sure 
[2015-11-23T15:14:07.357Z] <53135b495e986b0712efc453> If its too long (>10 lines) use pastebin... :)
[2015-11-23T15:16:33.966Z] <5653208916b6c7089cbbd390> Traceback (most recent call last):   File "<pyshell#0>", line 1, in <module>     import word2vec   File "word2vec.py", line 14, in <module>     model = word2vec.Word2Vec(sentences, size=100, window=4, min_count=1, workers=4)   File "/usr/local/lib/python2.7/dist-packages/gensim-0.12.3-py2.7-linux-x86_64.egg/gensim/models/word2vec.py", line 432, in __init__     self.train(sentences)
[2015-11-23T15:16:40.446Z] <5653208916b6c7089cbbd390> File "/usr/local/lib/python2.7/dist-packages/gensim-0.12.3-py2.7-linux-x86_64.egg/gensim/models/word2vec.py", line 690, in train     raise RuntimeError("you must first build vocabulary before training the model") RuntimeError: you must first build vocabulary before training the model
[2015-11-23T15:22:22.994Z] <53135b495e986b0712efc453> Oh I am sorry I didn't realize that you were asking about the library `word2vec`... This chat room is about scikit-learn :) This is not the correct place to ask... You would probably be better off, asking them at their mailing list... sorry :)
[2015-11-23T15:23:51.457Z] <5653208916b6c7089cbbd390> okay :+1: 
[2015-11-23T15:24:21.918Z] <5653208916b6c7089cbbd390> i searched there is no room for Word2vec and gensim :(
[2015-11-23T15:25:25.252Z] <53135b495e986b0712efc453> You could try - here - https://groups.google.com/forum/#!forum/gensim or here - https://radimrehurek.com/gensim/support.html :)
[2015-11-23T15:26:00.142Z] <5653208916b6c7089cbbd390> Thank you so much :+1:  :)
[2015-11-23T15:26:05.452Z] <53135b495e986b0712efc453> :)
[2015-11-23T15:33:55.772Z] <54e07d6515522ed4b3dc0858> @Rahulvks if you follow the directions in this blog post it should work: http://rare-technologies.com/word2vec-tutorial/
[2015-11-23T15:34:54.492Z] <54e07d6515522ed4b3dc0858> in particular, I suspect you are missing the middle step here: ``` >>> model = gensim.models.Word2Vec() # an empty model, no training >>> model.build_vocab(some_sentences)  # can be a non-repeatable, 1-pass generator >>> model.train(other_sentences)  # can be a non-repeatable, 1-pass generator ```
[2015-11-23T19:34:30.589Z] <53135b495e986b0712efc453> @vigneshbirodkar  did u try pdb?? Its good sometimes to debug frame by frame... Its a bit irritating to get started with but its worth it... (Just a humble suggestion ;) )
[2015-11-23T20:12:25.613Z] <53810862048862e761fa2887> @rvraghav93 I would have done that, but the tests don't fail on my system. 
[2015-11-23T20:16:25.489Z] <53135b495e986b0712efc453> Ah that's a drat... Only otherway is to skip all other tests temporarily and also skip 2.6, 2.7 tests and ram Travis till u figure it out :p (if u run only this one... u can run it in a minute I think) 
[2015-11-23T20:17:48.347Z] <53810862048862e761fa2887> I have narrowed down the failure to one line so far, but I still don't know why that line causes those tests to fail
[2015-11-23T20:19:28.916Z] <53135b495e986b0712efc453> The fit line right? Wait I'm bored... I'll try pulling ur branch... 
[2015-11-23T20:21:02.634Z] <53810862048862e761fa2887> Ok. Thanks. Make sure you go to that commit the last 2 or 3 commits I have been trying other stuff
[2015-11-25T17:59:06.217Z] <564789be16b6c7089cbab8b7> I am wondering if I have misunderstood https://github.com/scikit-learn/scikit-learn/issues/5870#issuecomment-159511717 .  Is the question if isnan() is fast in C ?
[2015-11-25T18:08:02.752Z] <53135b495e986b0712efc453> The thing is NaN in IEEE std has two possible representations (qNaN, which is the quiet NaN where we explicitly specify values to be NaN and sNaN where NaN is a signal NaN and is a (possibly unexpected) result of  numeric computation, like in Gael's comment...) So Gael was wondering if that would make `is_nan` computation in python/cython less efficient... Your pandas point was correct in that pandas does use a consistent NaN representation for both q/sNaN (atleast that is what I understood from that link), whereas numpy doesn't have one... I think it won't really affect the speed... but I am not sure... I am currently working on benchmarking that...
[2015-11-25T18:14:24.518Z] <564789be16b6c7089cbab8b7> @rvraghav93 interesting! In C you really just have to do x!=x which is true iff x = NaN. This is exactly one comparison
[2015-11-25T18:16:36.721Z] <564789be16b6c7089cbab8b7> @rvraghav93  I also looked at the assembly that you get from isnan() from gcc which is quite interesting too :)
[2015-11-25T18:18:41.642Z] <53135b495e986b0712efc453> Could you share?
[2015-11-25T18:19:57.622Z] <564789be16b6c7089cbab8b7> @rvraghav93  sure.. using math.h,  isnan() compiles to  jmp __isnanf  .  However return x != x compiles to xor eax, eax ucomiss xmm0, xmm0 setp    al ret
[2015-11-25T18:25:29.713Z] <564789be16b6c7089cbab8b7> @rvraghav93  however it turns out gcc had a performance bug and bleeding edge isnan()  compiles to something closer to the latter assembly.. Does this make sense?
[2015-11-25T18:33:45.558Z] <53135b495e986b0712efc453> I am not sure if the latter x!=x will work in all compilers... but that is the most effective way to check for nan AFAIK... In general, IIRC `ucomiss` will handle the nan(s) effectively (i.e not distinguish between multiple nan representations)
[2015-11-25T19:05:50.592Z] <564789be16b6c7089cbab8b7> @rvraghav93  I think you are right C99 mandates the use of a macro for this.  x!=x certainly works in gcc however and I assume all sensible compilers
[2015-11-25T19:07:08.257Z] <564789be16b6c7089cbab8b7> @rvraghav93  if you are interesting.. this was the gcc performance bug https://sourceware.org/bugzilla/show_bug.cgi?id=17441 . Fixed on 2015-09-18
[2015-11-25T19:34:15.735Z] <564789be16b6c7089cbab8b7> @rvraghav93  I looked it up.. it seems any C99 compliant C compiler is guaranteed to do x!=x correctly That is x!=x iff x is NaN
[2015-11-25T19:38:57.727Z] <564789be16b6c7089cbab8b7> @rvraghav93  it is specified in http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf#page=525&zoom=auto,-193,767 section F.9.3 Relational operators
[2015-11-25T19:43:52.297Z] <564789be16b6c7089cbab8b7> but in any case...isnan() is much easier to read and gcc will compile it properly soon :) (I don't really understand the math.h versus cmath.h point in any case)
[2015-11-27T09:57:50.486Z] <561a58f7d33f749381a8ff2f> I always wonder what is the best way to apply transformers to a dataset
[2015-11-27T09:58:09.240Z] <561a58f7d33f749381a8ff2f> e.g. I want to OneHotEncode only certain variables
[2015-11-27T09:58:54.595Z] <561a58f7d33f749381a8ff2f> X = [categorical_column, continuous_column, continuous_column]
[2015-11-27T09:59:00.377Z] <561a58f7d33f749381a8ff2f> then throw it in a pipeline
[2015-11-27T09:59:14.057Z] <561a58f7d33f749381a8ff2f> where a onehotencoder would only apply to the categorical column
[2015-11-27T09:59:29.452Z] <561a58f7d33f749381a8ff2f> (similar with a standardscaler, only to columns where it "makes sense")
[2015-11-27T09:59:36.293Z] <561a58f7d33f749381a8ff2f> how do you guys solve this issue?
[2015-11-27T12:27:10.538Z] <53135b495e986b0712efc453> @ogrisel @amueller Why does sorceforge not show 0.17 as the latest version??
[2015-11-27T12:27:12.923Z] <53135b495e986b0712efc453> http://sourceforge.net/projects/scikit-learn/files/
[2015-11-27T17:31:40.859Z] <564789be16b6c7089cbab8b7> @rvraghav93  hi
[2015-11-27T17:32:22.696Z] <564789be16b6c7089cbab8b7> I was attempting to read http://arxiv.org/abs/1504.04595 . There is still a big gap between stats and machine learning!
[2015-11-27T17:32:48.597Z] <564789be16b6c7089cbab8b7> This part in particular where they explain which classifiers they will compare with: "For comparison, we also present results for several state-of-the-art methods for high-dimensional classification, namely Penalized LDA (Witten and Tibshirani, 2011), Nearest Shrunken Centroids (Tibshirani et al., 2003), Shrunken Centroids Regularized Discriminant Analysis (Guo, Hastie and Tibshirani, 2007), and Independence Rules (IR) (Bickel and Levina, 2004), as well as for the base classi- fier applied in the original space"
[2015-11-27T17:33:03.327Z] <564789be16b6c7089cbab8b7> does scikit-learn have any of those?
[2015-11-27T17:34:49.297Z] <564789be16b6c7089cbab8b7> oh..maybe shrunken centroids are here? http://scikit-learn.org/stable/modules/neighbors.html#nearest-shrunken-centroid
[2015-11-27T17:35:19.770Z] <564789be16b6c7089cbab8b7> is our LDA implementation the same as  Penalized LDA (Witten and Tibshirani, 2011) ?
[2015-11-27T17:37:10.887Z] <564789be16b6c7089cbab8b7> on another note.. the two images at http://scikit-learn.org/stable/auto_examples/neighbors/plot_nearest_centroid.html#example-neighbors-plot-nearest-centroid-py look identical to me
[2015-11-27T17:37:15.479Z] <564789be16b6c7089cbab8b7> are they meant to be different?
[2015-11-27T22:13:43.570Z] <53135b495e986b0712efc453> we also have LDA ^^
[2015-11-27T23:15:33.666Z] <564789be16b6c7089cbab8b7> @rvraghav93  thanks.. I don't even know what  Shrunken Centroids Regularized Discriminant Analysis and Independence Rules are
[2015-11-27T23:16:02.792Z] <564789be16b6c7089cbab8b7> but the author of the paper is absolutely at the top of his field so I assume the new method is important
[2015-11-27T23:17:04.328Z] <564789be16b6c7089cbab8b7> @rvraghav93  do we have *penalized* LDA as in https://faculty.washington.edu/dwitten/Papers/JRSSBPenLDA.pdf ?
[2015-11-27T23:26:07.193Z] <53135b495e986b0712efc453> Ah no... I am not sure how useful that is?
[2015-11-27T23:29:55.616Z] <53135b495e986b0712efc453> And there is something wrong with the example that you had posted... Mind raising it as an issue for someone else to look into it...? `shrinkage` is supposed to have an effect... ping @robertlayton and @MechCoder in your issue... 
[2015-11-27T23:37:10.492Z] <53135b495e986b0712efc453> And lol no I don't either... I am hoping it gets named to LDA on steroids... must be easier to rememeber... on a serious note it seems to be a combination of regular LDA with shrunken centroids method (thought you must have figured that out already ;))
[2015-11-28T08:23:30.746Z] <564789be16b6c7089cbab8b7> @rvraghav93  thanks. I opened an issue. It would be very interesting to know what exactly scikit-learn is missing from that list and if the things that are missing are worthwhile. 
[2015-11-28T12:19:27.045Z] <561a58f7d33f749381a8ff2f> Guys what about adding an interface to OneHotEncoder and other transformers that can take a matrix and only operate on certain columns? E.g. if max_unique_values < 5 per column or whatever.... 
[2015-11-28T12:19:43.301Z] <561a58f7d33f749381a8ff2f> I'm not sure how to use this encoder directly on a matrix mixed of continuous variables and categorical variables.
[2015-11-28T12:19:48.542Z] <561a58f7d33f749381a8ff2f> Some others must have battled this?
[2015-11-28T12:20:03.135Z] <561a58f7d33f749381a8ff2f> Also, is pd.get_dummies a solution here? I don't see though how it would work with train + test together....
[2015-11-28T20:59:29.464Z] <53135b495e986b0712efc453> @kootenpv I don't think we have a workaround for this ATM ;( We are working on making the pipeline objects more flexible... 
[2015-11-28T23:39:28.600Z] <561a58f7d33f749381a8ff2f> @rvraghav93  How are you solving that situation then? I understand if there is no solution, but there must be some way to "work around" it, no? Just a list of transformers for each variable or something?
[2015-11-29T17:20:11.701Z] <565b339a16b6c7089cbc9958> Hey guys!
[2015-11-29T17:20:54.920Z] <565b339a16b6c7089cbc9958> I was trying to work on an easy bug regarding RobustScaler under sklearn.preprocessing 
[2015-11-29T17:21:50.863Z] <565b339a16b6c7089cbc9958> when i checked the data.py file in the given file hierarchy, the robust scaler class does exist and i'm not able to figure out why is it giving me an import error
[2015-11-29T17:23:50.383Z] <565b339a16b6c7089cbc9958> I've even tried to run the plot_robust_scaling.py in the examples folder but then again I end up with the same import error.
[2015-11-30T14:18:59.378Z] <554c47fe15522ed4b3e01823> Hey Guys, I want to contribute to this project, How do i start?
[2015-11-30T14:23:29.214Z] <553e8e1015522ed4b3df97f7> Hi @chinmoysam, just dive into the issue tracker and see issues that are tagged Easy and Need Contributor.
[2015-11-30T14:24:24.517Z] <553e8e1015522ed4b3df97f7> take a look at the developer guide too: http://scikit-learn.org/stable/developers/
[2015-11-30T14:25:17.681Z] <554c47fe15522ed4b3e01823> @vortex-ape Thanks is this issue tracker in the github page?? and i have just started learning scikit i have some knowledge of programming in python, Can i directly go to issue tracker and try to solve something??
[2015-11-30T14:25:47.824Z] <553e8e1015522ed4b3df97f7> https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+is%3Aissue+label%3AEasy
[2015-11-30T14:27:03.560Z] <553e8e1015522ed4b3df97f7> go through the easy issues, you should be able to solve most with a basic knowledge of python
[2015-11-30T16:03:21.593Z] <554c47fe15522ed4b3e01823> thanks a lot  @vortex-ape 
[2015-11-30T16:30:13.959Z] <5653208916b6c7089cbbd390> Hi, Anyone having sample svm text classification code in sklearn ?
[2015-12-01T07:06:06.678Z] <54d4a1d6db8155e6700f853b> @Rahulvks have you looked at the text classification tutorial? http://scikit-learn.org/dev/tutorial/text_analytics/working_with_text_data.html
[2015-12-01T07:06:36.403Z] <54d4a1d6db8155e6700f853b> you can also find several examples in the examples gallery: http://scikit-learn.org/dev/auto_examples/index.html
[2015-12-01T13:39:26.291Z] <565b339a16b6c7089cbc9958> @amueller, can you please help me out with this issue??
[2015-12-01T13:39:28.634Z] <565b339a16b6c7089cbc9958> I was trying to work on an easy bug regarding RobustScaler under sklearn.preprocessing  when i checked the data.py file in the given file hierarchy, the robust scaler class does exist and i'm not able to figure out why is it giving me an import error I've even tried to run the plot_robust_scaling.py in the examples folder but then again I end up with the same import error.
[2015-12-01T13:40:51.730Z] <565b339a16b6c7089cbc9958> I currently use a mac operating on OS X 10.11
[2015-12-01T13:41:38.614Z] <565b339a16b6c7089cbc9958> and tried importing the code on python3
[2015-12-01T13:45:07.806Z] <565b339a16b6c7089cbc9958> [![Screen Shot 2015-12-01 at 7.13.59 PM.png](https://files.gitter.im/scikit-learn/scikit-learn/KIc6/thumb/Screen-Shot-2015-12-01-at-7.13.59-PM.png)](https://files.gitter.im/scikit-learn/scikit-learn/KIc6/Screen-Shot-2015-12-01-at-7.13.59-PM.png)
[2015-12-01T15:23:30.886Z] <561a58f7d33f749381a8ff2f> @SumedhArani  Old version, it is really new
[2015-12-01T18:42:45.060Z] <561a58f7d33f749381a8ff2f> @SumedhArani  What I meant was... you're importing an old version of scikit, while you might be looking at some other source code. Try to see the path of sklearn.preprocessing module after importing sklearn.preprocessing
[2015-12-01T18:42:54.788Z] <561a58f7d33f749381a8ff2f>     import sklearn.preprocessing
[2015-12-01T18:43:03.115Z] <561a58f7d33f749381a8ff2f>     sklearn.preprocessing
[2015-12-02T05:33:26.921Z] <565b339a16b6c7089cbc9958> @kootenpv Thanks for the reply!!
[2015-12-02T05:33:33.796Z] <565b339a16b6c7089cbc9958> <module 'sklearn.preprocessing' from '/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/preprocessing/__init__.py'>
[2015-12-02T05:33:56.403Z] <565b339a16b6c7089cbc9958> This is the output that I got on trying out what you told me!
[2015-12-02T05:35:03.426Z] <565b339a16b6c7089cbc9958> I've recently upgraded my scikit version and prior to which I had installed 0.16 version whose source code I have been referring to.
[2015-12-02T05:35:10.241Z] <565b339a16b6c7089cbc9958> I'll check out once again.
[2015-12-02T05:37:07.559Z] <565b339a16b6c7089cbc9958> I used pip install -U scikit-learn and it says the requirement is up to date.
[2015-12-02T18:53:11.599Z] <541d52b1163965c9bc205cf3> hi anyone up here
[2015-12-02T19:01:15.809Z] <53135b495e986b0712efc453> Yes?
[2015-12-02T19:06:24.939Z] <541d52b1163965c9bc205cf3> https://github.com/scikit-learn/scikit-learn/issues/5947
[2015-12-02T19:07:37.717Z] <541d52b1163965c9bc205cf3> i would like to implement this  if it is not already implemented (I couldnt find this in scikit library )
[2015-12-02T19:08:01.214Z] <541d52b1163965c9bc205cf3> The closest was  spectral embedding
[2015-12-02T19:08:54.993Z] <541d52b1163965c9bc205cf3> I havent explained the idea of the algorithm in the issue  but i can do that 
[2015-12-02T19:09:34.746Z] <541d52b1163965c9bc205cf3> and the applications of the same too , as in recent years its gainig some popularity
[2015-12-02T19:18:58.635Z] <53135b495e986b0712efc453> How popular is it?
[2015-12-02T19:21:21.586Z] <53135b495e986b0712efc453> Also what kind of problems does it solve? You may want to include the answer to the prev questions in your issue :)
[2015-12-02T19:22:06.192Z] <53135b495e986b0712efc453> I haven't looked into it exactly... will do so and let you know my view :)
[2015-12-02T19:30:33.676Z] <541d52b1163965c9bc205cf3> as already mentioned some very popular uses are web graph minning , page ranking algorithms 
[2015-12-02T19:31:06.642Z] <541d52b1163965c9bc205cf3> let me include some application based papers in the area
[2015-12-02T19:31:07.092Z] <541d52b1163965c9bc205cf3> http://cseweb.ucsd.edu/~atsiatas/pr_diffusion.pdf
[2015-12-02T19:31:17.725Z] <541d52b1163965c9bc205cf3> http://ictactjournals.in/paper/IJSC_Vol3_Iss3_P5_544_548.pdf
[2015-12-02T19:33:27.933Z] <53135b495e986b0712efc453> I'll let you know my views after I look into it. You may have to wait for core devs to respond to you in that issue before you can proceed. You can also make a detailed email to our mailing list linking your issue to attract more comments.
[2015-12-02T19:35:59.679Z] <541d52b1163965c9bc205cf3> fot the other part of the questions :: it is used   in  a semi-supervised setup  and can be used at problems requiring local and global scales of information using some sort of  label transfer but not limited to this
[2015-12-02T19:37:25.177Z] <53135b495e986b0712efc453> Could you also add these questions and answers to the issue? (So that this discussion could reach a larger audience)
[2015-12-02T19:40:28.734Z] <55f2a92f0fc9f982beb05d85> Hey Scikiters,
[2015-12-02T19:41:06.176Z] <55f2a92f0fc9f982beb05d85> I would like to know if someone has a parallel implementation of DBSCAN .. or Knows how to use it on top of Apache Spark .. Thanks in Advance
[2015-12-02T19:45:09.168Z] <53135b495e986b0712efc453> I may be wrong but isn't our implementation parallel?
[2015-12-02T19:48:06.693Z] <55f2a92f0fc9f982beb05d85> No, the base one in Scikit learn is serial one .. I am trying now to use pySpark to paralleize it, but its really difficult as I am not aware of scikit learn, and I dont have plenty of time :) .. would appreciate if someone can help
[2015-12-02T19:49:19.883Z] <53135b495e986b0712efc453> Afaik parallelization in scikit-learn is mostly done using joblib... maybe you should take a look at that?
[2015-12-02T19:54:33.495Z] <55f2a92f0fc9f982beb05d85> Do u mean, i should try to edit the scikit implementation to utilize Joblib, or u already using Joblib ?
[2015-12-02T19:59:55.246Z] <541d52b1163965c9bc205cf3> i will do that
[2015-12-02T20:02:02.324Z] <55f2a92f0fc9f982beb05d85> @halwai  .. if u mean DBSCAN, would u please let me know then ?
[2015-12-02T20:11:15.968Z] <541d52b1163965c9bc205cf3> @Elbehery   i am sorry  i was not reffering to DBSCAN
[2015-12-02T20:27:13.646Z] <55f2a92f0fc9f982beb05d85> no problem
[2015-12-03T01:13:59.886Z] <53135b495e986b0712efc453> Could someone remove the need contrib tags from issues which have a PR open? @amueller @ogrisel @glouppe ?
[2015-12-03T01:15:17.366Z] <53135b495e986b0712efc453> #5943 #4639 #4808 #4883 #5029 #5298 #5318 #5952 
[2015-12-03T01:19:00.352Z] <53135b495e986b0712efc453> Also since there was sufficient interest in mailing list (by sufficient interest I mean the +1 from Joel and +0(?) from Andy ;)), could some one add the "Need Review" tag pl? Once added I have a list of PRs to be tagged ;)
[2015-12-04T10:19:42.257Z] <561a58f7d33f749381a8ff2f> I'm really wondering if there would be ways to "cache" things in the Pipeline
[2015-12-04T10:20:17.387Z] <561a58f7d33f749381a8ff2f> I mean... when you're doing a grid search... if you use some kind of static transformation in it
[2015-12-04T10:21:33.034Z] <561a58f7d33f749381a8ff2f> E.g. you use a CountVectorizer that has no variation in parameters and it is put in the pipeline, I suspect that if you have some alpha values changing in a Ridge() in the pipeline, it still does the static CountVectorizer endlessly?
[2015-12-04T10:22:56.682Z] <561a58f7d33f749381a8ff2f>     Pipeline({       'countvectorizer': CountVectorizer,       'ridge': Ridge})          grid = {'ridge__alpha': [0.1, 1, 10]}
[2015-12-07T19:10:49.769Z] <54d4a1d6db8155e6700f853b> @kootenpv not currently unfortunately https://github.com/scikit-learn/scikit-learn/pull/3951
[2015-12-07T19:11:09.080Z] <54d4a1d6db8155e6700f853b> dask-sklearn tries to get rid of that, but that's more of a prototype
[2015-12-07T19:11:22.377Z] <54d4a1d6db8155e6700f853b> see http://blaze.pydata.org/blog/2015/10/19/dask-learn/
[2015-12-08T00:43:31.819Z] <561a58f7d33f749381a8ff2f> @amueller nice catch
[2015-12-08T10:55:44.951Z] <564789be16b6c7089cbab8b7> hi.. I was wondering if http://arxiv.org/pdf/1109.0887.pdf "Learning Nonlinear Functions Using Regularized Greedy Forest" is of interest? It was the method that came second in the kaggle higgs boson competition
[2015-12-08T11:01:59.728Z] <564789be16b6c7089cbab8b7> hmm.. I see that despite this it hasn't been cited many times
[2015-12-08T17:46:24.808Z] <54d4a1d6db8155e6700f853b> @kootenpv well it is a known longstanding issue
[2015-12-09T00:05:26.390Z] <54d4a1d6db8155e6700f853b> man @agramfort is killing it on the issue tracker
[2015-12-09T00:09:44.623Z] <53135b495e986b0712efc453> xD
[2015-12-09T01:28:08.836Z] <53135b495e986b0712efc453> Btw can u create the "Need Review" Tag??
[2015-12-09T09:03:05.493Z] <565b49ee16b6c7089cbc9b44> Hey! I've found that http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html#sklearn.cross_validation.StratifiedKFold if called under `print` shows first argument as named `labels`, but you actually cannot pass it this way. Is it intentional?
[2015-12-09T12:57:43.259Z] <53135b495e986b0712efc453> A lot of issues need the `"Need Contributor"` tag removed - https://github.com/scikit-learn/scikit-learn/labels/Need%20Contributor
[2015-12-09T14:57:32.694Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar maybe ping @ogrisel or @lesteve about the joblib thing
[2015-12-09T15:00:34.850Z] <54d4a1d6db8155e6700f853b> rvraghav93: can you list the issues that need the "need contributor" removed?
[2015-12-09T15:06:04.152Z] <53810862048862e761fa2887> Hello @ogrisel , @lesteve , I can see a fix for #5956 by setting `copy_cov=True` on this line https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/dict_learning.py#L296
[2015-12-09T15:17:18.021Z] <53810862048862e761fa2887> Also, passing `mmap_mode=readwrite' to `joblib.Parallel` gives a file descriptor error, but passing `mmap_mode=c' works, 
[2015-12-09T15:17:39.188Z] <53810862048862e761fa2887> I am yet to find out what 'c' means for it,  I wasn't able to find any documentation
[2015-12-09T15:21:01.732Z] <53810862048862e761fa2887> Ok, see stands for Copy on write, is passing that ok ?
[2015-12-09T16:41:34.027Z] <54d4a1d6db8155e6700f853b> added the needs review tag
[2015-12-09T16:43:14.971Z] <53135b495e986b0712efc453> Yay yay :p I'll just send u a list for both (removal of need cont and addtn of need rev) 
[2015-12-09T17:10:02.172Z] <54d4a1d6db8155e6700f853b> sent where?
[2015-12-09T17:10:06.152Z] <54d4a1d6db8155e6700f853b> ah sorry future
[2015-12-09T17:36:37.167Z] <54d4a1d6db8155e6700f853b> @rvraghav93 sorry I'm a bit out of touch with what is happening at the moment. Have you worked on the multiple metrics stuff yet?
[2015-12-09T17:42:56.188Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar would you be fine with a non-ml project? I think doing the website build would be cool #5578 #4986
[2015-12-09T17:43:41.367Z] <54d4a1d6db8155e6700f853b> Otherwise the multiple metrics would be very high priority to me unless @rvraghav93 worked on it. It might be that we need to first merge ragav's improvements / code deletions though
[2015-12-09T17:44:10.621Z] <53135b495e986b0712efc453> Hey no I am breaking my head over tree code ;(
[2015-12-09T17:44:45.638Z] <53135b495e986b0712efc453> Sorry I will try my best to start it by this weekend :)
[2015-12-09T17:45:18.644Z] <53135b495e986b0712efc453> There are a few minor PRS of mine which u might want to consider for review xD 
[2015-12-09T17:57:46.273Z] <54d4a1d6db8155e6700f853b> sorry, not much time for reviews for the rest of the year :-/
[2015-12-09T17:58:15.804Z] <53810862048862e761fa2887> Are Transformers also expected not to do anything in place ?
[2015-12-09T18:44:49.800Z] <54d4a1d6db8155e6700f853b> yes
[2015-12-10T15:13:05.770Z] <53135b495e986b0712efc453> `"Need Review"` - #5907, #5823, #5703, #5568, #4115, #5883, #5983, #5971, #5971, #5945, #5929, #5815, #5920  and PRs ready for merge - #5981, #5946, #5925 and Issues (or PRs) which need a removal of `"Need Contributor"` - #5986, #5876, #5868, #5824, #5789, # 5738, #5583, #5367, #5298, #5269, #4804  (Going a bit overboard with the usage of tags - take with a grain of salt - * a "Stalled Work" tag (hoping Gael doesn't oppose ;) ) -  #5316 (and a lot more...) (this tag could be added after the author of the PR  says he is no longer interested / have time to work on it or doesn't respond with the status in a month's time, this will help people who wish to work on the related issue, understand that their new PR is welcome... we could just add the `"Need Contributor"` back to the related issue... but people get confused why there is an existing PR for that issue) * a "Action Needed" tag - #4804 Along with `"Need Review"` to denote that review has been done and it needs the author to respond to the review... (So we can filter PRs for review like "Need Review" and !"Action Needed")
[2015-12-10T15:20:38.152Z] <53810862048862e761fa2887> @rvraghav93 2 of my PRs also need reviews, you think they need to be tagged ?
[2015-12-10T15:50:07.410Z] <53135b495e986b0712efc453> "Need Review" of course ;) Could you list them here??
[2015-12-10T15:51:17.105Z] <53135b495e986b0712efc453> Nevermind! @amueller #5414, #5270 
[2015-12-10T15:52:20.766Z] <53135b495e986b0712efc453> and awesome you've fixed #5689... sorry I tried and gave up...
[2015-12-10T15:58:51.621Z] <53810862048862e761fa2887> That's ok, that issue still hasn't been fixed, though. I was making a mistake by not passing randon_state, but there is no reason why that test should fail
[2015-12-10T16:22:51.582Z] <54d4a1d6db8155e6700f853b> should we tag all "MRG" ones with "needs review"?
[2015-12-10T16:23:49.689Z] <53135b495e986b0712efc453> I was wondering that... but that would be too much... So I was thinking maybe we could have only 20 odd `"Need Review"` tags at a time? How does that sound?
[2015-12-10T16:24:11.212Z] <53135b495e986b0712efc453> We have at most 10 serious reviewers right?
[2015-12-10T16:24:23.041Z] <53135b495e986b0712efc453> The number of `[MRG*` issues are over 150
[2015-12-10T16:25:19.102Z] <54d4a1d6db8155e6700f853b> I tagged all of them, but we should untag those that actually wait for the person doing the review to get back
[2015-12-10T16:25:29.160Z] <54d4a1d6db8155e6700f853b> well how do you choose the 20 ?
[2015-12-10T16:25:43.628Z] <53135b495e986b0712efc453> By most recently commented...
[2015-12-10T16:27:19.141Z] <54d4a1d6db8155e6700f853b> how does that make sense?
[2015-12-10T16:27:38.206Z] <54d4a1d6db8155e6700f853b> if someone created the perfect pull request and no dev reviewed it for 2 years, then it will be never reviewed
[2015-12-10T16:29:43.591Z] <53135b495e986b0712efc453> Well rules are meant to be broken... :P We could have 10 more for such PRs? Or not... probably that was a stupid suggestion... nevermind ;) 
[2015-12-10T16:30:54.252Z] <53135b495e986b0712efc453> But there will be a question on how do we get to decide that 10 probably.. so its better that all `[MRG*` is "need review" tagged...
[2015-12-10T16:32:59.045Z] <54d4a1d6db8155e6700f853b> we should remove the ones where we are waiting on the contributor to address comments
[2015-12-10T16:35:27.553Z] <53135b495e986b0712efc453> Okay that sounds better :) If I catch something like that I'll just ping u here... and how about `"Work Stalled"` for stalled PRs?
[2015-12-10T16:35:41.564Z] <54d4a1d6db8155e6700f853b> that is the same as PR ;)
[2015-12-10T16:36:30.890Z] <53135b495e986b0712efc453> haha... I mean like it-not-gonna-be-updated-anymore PRs ;)
[2015-12-10T16:39:56.493Z] <54d4a1d6db8155e6700f853b> ?
[2015-12-10T16:42:59.142Z] <53135b495e986b0712efc453> For example in [this comment](https://github.com/scikit-learn/scikit-learn/issues/5229#issuecomment-149628243) the author of #5316 said that he is not working on it anymore... There are quite a few PRs like that and a few more where the author has stopped responding... I was wondering out aloud if we could tag those with `"Work stalled"`...
[2015-12-10T17:04:00.346Z] <54d4a1d6db8155e6700f853b> or close them?
[2015-12-10T17:05:03.606Z] <54d4a1d6db8155e6700f853b> well how do you know if something is stalled and what would be the benefit of the tag?
[2015-12-10T17:06:42.984Z] <53135b495e986b0712efc453> that is better... but I feel it should be done only for stalled PRs which have a related issue open and we should include a comment in the issue that "There was a stalled PR ##### That was closed due to inactivity"... but I am afraid that closing might be a bit rude?
[2015-12-10T17:06:53.319Z] <53135b495e986b0712efc453> I was thinking of doing a random search from time to time ;)
[2015-12-10T17:07:45.646Z] <53135b495e986b0712efc453> for comments  by authors saying so or comments which ask for status that go unresponded for more than a month...
[2015-12-10T17:28:12.934Z] <54d4a1d6db8155e6700f853b> @rvraghav93 is waterponey colocated with you?
[2015-12-10T17:28:29.402Z] <53135b495e986b0712efc453> Ah no why?
[2015-12-10T17:28:56.630Z] <54d4a1d6db8155e6700f853b> do you know who he is?
[2015-12-10T17:28:59.152Z] <54d4a1d6db8155e6700f853b> he is in paris, right?
[2015-12-10T17:29:08.210Z] <54d4a1d6db8155e6700f853b> I met so many people at the sprint.
[2015-12-10T17:31:47.799Z] <54d4a1d6db8155e6700f853b> right you are with alex. hm...
[2015-12-10T17:32:14.502Z] <53135b495e986b0712efc453> Ah he was sitting with us... but I am unable to recollect who he is...
[2015-12-10T17:33:42.145Z] <54d4a1d6db8155e6700f853b> hehe ok
[2015-12-10T21:06:38.021Z] <561a58f7d33f749381a8ff2f> any Dutch :P?
[2015-12-10T22:27:14.684Z] <5525b91815522ed4b3deb7d6> @amueller @rvraghav93 In sympy we have "PR: Author's turn". It is put once the PR is reviewed and we are waiting on the author to address the comments. This way it is sometime easier to identify stalled one's.  :smile: 
[2015-12-10T22:31:29.973Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar multi-class AUC might also be interesting: #3298
[2015-12-10T22:32:10.566Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar the ada-grad stuff here #3729 would be cool but is likely to be a bigger project
[2015-12-10T22:33:00.779Z] <54d4a1d6db8155e6700f853b> @leosartaj how often do you reassign them? if the PR is quite active, it changes often who's turn it is. Or do you only do that if it is stalled for a while?
[2015-12-10T22:33:04.501Z] <54d4a1d6db8155e6700f853b> it might be helpful
[2015-12-10T22:34:48.638Z] <5525b91815522ed4b3deb7d6> I have seen it to work best: 1. It is a big PR. Reviews take time. 2. Author replies in a while. Probably not a good idea when the PR is quite active. Works well for slower one's.
[2015-12-11T00:03:45.052Z] <54d4a1d6db8155e6700f853b> reviews on #4936 would be good ....
[2015-12-11T00:04:02.464Z] <54d4a1d6db8155e6700f853b> thanks @leosartaj :)
[2015-12-11T00:04:17.684Z] <5525b91815522ed4b3deb7d6> :smile:
[2015-12-11T15:26:20.894Z] <53135b495e986b0712efc453> Is #5995 an easy one? If so could you tag it with "Need contribs". I found a contributor looking for an issue ;) ([ref](https://github.com/scikit-learn/scikit-learn/issues/5879#issuecomment-162382187) )
[2015-12-11T15:34:51.829Z] <54d4a1d6db8155e6700f853b> we need to merge https://github.com/scikit-learn/scikit-learn/pull/5578 first
[2015-12-11T16:54:21.779Z] <53135b495e986b0712efc453> I have a probably lame question regarding cython code - Why is that we don't delete all the free the memory of all the members in the destructor? (Ref [the destructor of `Splitter` class](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_splitter.pyx#L105))
[2015-12-11T16:58:47.429Z] <53810862048862e761fa2887> What do you think should be freed and isn't ?
[2015-12-11T17:05:55.592Z] <53135b495e986b0712efc453> Any other attribute say `sample_weight`? (Fair warning this could be a very dumb question but I am quite new to cython ;))
[2015-12-11T17:08:37.533Z] <53810862048862e761fa2887> It should be freed, but where it is freed depends on the context of the code. For example, any object declared in Python should not get freed with `free` and Python's GC will pick it up. If an object is declared here and not freed, it might be getting freed elsewhere
[2015-12-11T17:09:03.529Z] <53135b495e986b0712efc453> Ahh!! That explains a lot! Thanks :)
[2015-12-11T17:17:04.058Z] <53135b495e986b0712efc453> so basically `sample_weight` of this splitter will hold the reference to the mem block managed elsewhere (or probably by the python GC) correct?
[2015-12-11T17:17:27.772Z] <53810862048862e761fa2887> Yes
[2015-12-11T17:17:32.785Z] <53135b495e986b0712efc453> Thanks!!
[2015-12-11T17:17:38.444Z] <53810862048862e761fa2887> I won't be surprised if that is infact a numpy array
[2015-12-11T17:18:09.363Z] <53135b495e986b0712efc453> Yes it is.. It will be user specified so... Now I understand this better!
[2015-12-13T19:33:59.803Z] <54b4f2d1db8155e6700e99c0> Hey Folks, with PCA, if you fit with all the components, you should be able to transform with a subset of them only. If Im not wrong, this is currently not possible. Should I open an issue?
[2015-12-13T22:47:30.966Z] <561a58f7d33f749381a8ff2f> @Djabbz  Sounds very strange. I don't think that's possible with PCA. Do you have literature where it says? As far as I know if you go compress 40 features into 10 features, you'd need measurements on all 40 features to result into 10.
[2015-12-14T18:58:59.202Z] <54d4a1d6db8155e6700f853b> @Djabbz we could add a parameter to the ``transform`` method but usually we don't like to do that. Can you give an example application?
[2015-12-14T18:59:13.330Z] <54d4a1d6db8155e6700f853b> You could just replace ``components_`` by ``components_[:n_features_you_want]``
[2015-12-16T20:18:19.143Z] <5363a92c048862e761fa03c3> @rvraghav93  [here](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/multiclass.py#L193) This line assumes  `Y` to be a sparse matrix. But if target variable `y` has only one class then  in  `Y = self.label_binarizer_.fit_transform(y)` `Y` becomes `numpy.ndarray` which makes `Y.tocsc()` fail. Is this intended?
[2015-12-16T20:35:57.919Z] <54d4a1d6db8155e6700f853b> there was some code to plot a neural network somewhere. does anyone remember where?
[2015-12-17T14:32:38.985Z] <564789be16b6c7089cbab8b7> @amueller  I am sure this isn't helpful but... http://www.texample.net/tikz/examples/neural-network/ is at least pretty 
[2015-12-17T16:03:56.590Z] <54d4a1d6db8155e6700f853b> thanks @lesshaste. I'd prefer python code but I have something similar than that now
[2015-12-17T17:07:29.415Z] <564789be16b6c7089cbab8b7> @amueller  I know already this is a dim question but.. I notice scikit-learn has said no to adding deep learning. However we do already have MLP and some people working on improving that code (e.g. adding dropout). Is there a clean line between MLPs and deep learning?
[2015-12-17T17:09:25.979Z] <564789be16b6c7089cbab8b7> I assume that an MLP with 20 layers is not deep learning for example?
[2015-12-17T17:12:40.056Z] <564789be16b6c7089cbab8b7> it seems that the three main types of neural networks are feed-forward, convolutional and recurrent.  If we just look at feed-forward neural networks, I am wondering if there is a clear view of what is in and what is out of scope?
[2015-12-17T17:14:22.391Z] <564789be16b6c7089cbab8b7> no is a perfectly acceptable answer :)
[2015-12-17T17:19:23.124Z] <54d4a1d6db8155e6700f853b> @lesshaste neural networks are by now basically synonymous with deep learning. convnets are actually feed-forward nets
[2015-12-17T17:19:54.699Z] <54d4a1d6db8155e6700f853b> I think the agreed scope is feed forward without convolutions
[2015-12-17T17:20:29.594Z] <564789be16b6c7089cbab8b7> @amueller  ok.. I ask as a recent mailing list question was "I'm interested in deep learning and wanna contribute to scikit-learn and try out for GSoC next summer. I was wondering if scikit-learn is looking to expand its neural nets package."
[2015-12-17T17:20:30.249Z] <54d4a1d6db8155e6700f853b> and no support for custom architectures, i.e. you can specify a list with the number of nodes in each hidden layer, but they will all have the same activation function and there are no skip connections etc
[2015-12-17T17:20:36.360Z] <564789be16b6c7089cbab8b7> and the answer was no
[2015-12-17T17:21:08.744Z] <564789be16b6c7089cbab8b7> v. interesting re: custom architectures
[2015-12-17T17:21:22.253Z] <54d4a1d6db8155e6700f853b> yeah we're not gonna expand beyond the model that is there. we want to make the mlp as good as possible, so we will add dropout, and if there is a consensus for a better of-the-shelf optimizer than adam, I think we'll be happy to add that, too
[2015-12-17T17:21:30.347Z] <564789be16b6c7089cbab8b7> it is highly unclear to me how much the bells and whistles actually make a difference when you measure classification performance
[2015-12-17T17:21:55.432Z] <54d4a1d6db8155e6700f853b> have you read sanders posts on the galazy zoo and plankton competitions?
[2015-12-17T17:22:06.833Z] <564789be16b6c7089cbab8b7> ah no... could you point me to them please?
[2015-12-17T17:22:29.843Z] <54d4a1d6db8155e6700f853b> http://benanne.github.io/2014/04/05/galaxy-zoo.html
[2015-12-17T17:22:40.296Z] <564789be16b6c7089cbab8b7> on the topic of gsoc.. it would be great if someone could fix/rewrite the variational Bayes module
[2015-12-17T17:22:45.705Z] <54d4a1d6db8155e6700f853b> http://benanne.github.io/2015/03/17/plankton.html
[2015-12-17T17:22:55.953Z] <54d4a1d6db8155e6700f853b> the GMM you mean?
[2015-12-17T17:23:11.233Z] <54d4a1d6db8155e6700f853b> there was a GSOC last year, but it did't finish yet :-/
[2015-12-17T17:24:01.087Z] <564789be16b6c7089cbab8b7> http://scikit-learn.org/stable/modules/generated/sklearn.mixture.VBGMM.html
[2015-12-17T17:24:12.171Z] <564789be16b6c7089cbab8b7> reading your link...
[2015-12-17T17:26:07.909Z] <564789be16b6c7089cbab8b7> @amueller  I read that article.. it's still not clear to me how much worse you would do with a simpler architecture. But I do think that image tasks seem uniquely well suited to convolutional networks
[2015-12-17T17:26:28.208Z] <564789be16b6c7089cbab8b7> however I notice that neural networks are now being used more for non-image based tasks on kaggle
[2015-12-17T17:27:08.148Z] <564789be16b6c7089cbab8b7> @amueller  I think you told me that VBGMM was basically broken.. but I may have remembered that wrong
[2015-12-17T17:28:44.870Z] <54d4a1d6db8155e6700f853b> there is a pull request with a rewrite of the vbgmm
[2015-12-17T17:28:47.111Z] <54d4a1d6db8155e6700f853b> but it is not finished
[2015-12-17T17:28:50.260Z] <54d4a1d6db8155e6700f853b> and the status is unclear to me
[2015-12-17T17:28:57.591Z] <54d4a1d6db8155e6700f853b> I'm a bit preoccupied with writing a book
[2015-12-17T17:29:03.535Z] <54d4a1d6db8155e6700f853b> that I want to finish early spring
[2015-12-17T17:29:08.980Z] <564789be16b6c7089cbab8b7> oh great! On machine learning?
[2015-12-17T17:29:21.255Z] <54d4a1d6db8155e6700f853b> machine learning in scikit-learn
[2015-12-17T17:29:29.535Z] <54d4a1d6db8155e6700f853b> err machine learning with python
[2015-12-17T17:29:49.092Z] <54d4a1d6db8155e6700f853b> it's a machine learning book for programmers without a lot of math (because there are many good stats / ml books out there already)
[2015-12-17T17:30:09.412Z] <54d4a1d6db8155e6700f853b> it aims to be very practical
[2015-12-17T17:30:54.445Z] <564789be16b6c7089cbab8b7> sounds wonderful
[2015-12-17T17:30:59.544Z] <564789be16b6c7089cbab8b7> I look forward to it!
[2015-12-17T17:31:02.564Z] <54d4a1d6db8155e6700f853b> thanks :)
[2015-12-17T17:31:10.355Z] <54d4a1d6db8155e6700f853b> (and I'll go back to that now ;)
[2015-12-17T17:31:19.207Z] <54d4a1d6db8155e6700f853b> check out the GMM rewrite pull request if you are interested
[2015-12-17T17:31:25.942Z] <564789be16b6c7089cbab8b7> although I am a little worried that ML is going to be overtaken by neural network mumbo jumbo :)
[2015-12-17T17:31:31.356Z] <564789be16b6c7089cbab8b7> I will do.. thanks
[2015-12-17T17:31:37.845Z] <564789be16b6c7089cbab8b7> good luck!
[2015-12-17T17:31:49.912Z] <564789be16b6c7089cbab8b7> (p.s. did you consider cloning yourself? :) )
[2015-12-17T17:32:01.507Z] <564789be16b6c7089cbab8b7> (as everyone wants your attention)
[2015-12-19T17:54:58.276Z] <53135b495e986b0712efc453> I sometimes have a feeling he already has.... ^^
[2015-12-19T18:00:32.508Z] <53135b495e986b0712efc453> @kaichogami Apologies for the late response! That indeed looks like a bug... Apparently `_fit_binary` seems to handle the case of constant `y`. Could you also fix this and add a test too? 
[2015-12-20T12:37:18.699Z] <5363a92c048862e761fa03c3> @rvraghav93 no problem. I'll do that. Just to be sure, I am supposed to open another pull request for this issue right?
[2015-12-20T12:39:55.284Z] <53135b495e986b0712efc453> If you have'nt raised one for that already you could just do it in a single pr...
[2015-12-20T12:40:15.419Z] <53135b495e986b0712efc453> Or maybe multiple PRS ur choice :)
[2015-12-21T11:06:10.421Z] <564789be16b6c7089cbab8b7> hi @rvraghav93 
[2015-12-21T16:24:13.546Z] <53135b495e986b0712efc453> Hey :)
[2015-12-21T16:50:24.436Z] <53135b495e986b0712efc453> your suggestion of `rpart` is great! `rpart` seems to do surrogate splits and handles the missing values pretty well.. but I guess its a bit computationally intensive, so I am going with Gilles' suggestion of finding the best split, with all the missing values sent to either side of the split (left or right).... Lets see how it works... This one modifies a loooot of code and I'm struggling with refactoring - procrastination - refactoring - giving up - getting back up and all other cycles in between ;P Hope I can gift a missing value supporting tree for christmas ;)
[2015-12-21T16:51:22.257Z] <53135b495e986b0712efc453> (rant w.r.t #5870)
[2015-12-21T17:28:13.187Z] <564789be16b6c7089cbab8b7> @rvraghav93  great!
[2015-12-21T17:28:27.095Z] <564789be16b6c7089cbab8b7> I look forward to it :)
[2015-12-22T00:09:42.990Z] <544906e2db8155e6700cdd16> Hi everyone!  I'm trying to run a grid search on a dataset that is stored in a Pandas DataFrame (something very similar to this example http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html#example-hetero-feature-union-py).  When I run my code I get the next error message: "ValueError: cannot label index with a null key" I've tried different approaches but I didn't be able to fix it. I have a working example that I can share with you if needed.
[2015-12-22T00:58:17.031Z] <53135b495e986b0712efc453> @mac2bua Could you paste your code into github gist/ pastebin and post the link here please?
[2015-12-22T03:33:58.582Z] <544906e2db8155e6700cdd16> Yes, of course I can!
[2015-12-22T03:34:08.910Z] <544906e2db8155e6700cdd16> https://gist.github.com/mac2bua/94f0f15bc327684d16ba
[2015-12-22T03:34:47.940Z] <544906e2db8155e6700cdd16> let me know if you need anything else
[2015-12-26T18:07:00.909Z] <53135b495e986b0712efc453> @aron-bordin Welcome to scikit-learn! Please check if any of [these](https://github.com/scikit-learn/scikit-learn/labels/Need%20Contributor) issues interest you and start working on it. Let me know if I can be of any help!
[2015-12-26T18:11:40.483Z] <567ed70316b6c7089cc03bc2> @rvraghav93 Thx, I'll check them
[2016-01-03T16:38:31.551Z] <553d32d715522ed4b3df8b92> Hi , First of all, wish you all a happy new year. I am new to scikit learn. I wanted to ask for help in working on issues which I have the ability to contribute. The issue regarding [meta-estimators](https://github.com/scikit-learn/scikit-learn/issues/5824) seemed nice thing to work on. Please let you know about your thoughts. I would be happy to work any other issue if this is beyond my scope. Thanks :)
[2016-01-03T16:40:27.095Z] <53135b495e986b0712efc453> Could you ping @hugobowne and ask him if he's still working on it? If not please feel free to take it up.
[2016-01-03T16:43:25.151Z] <553d32d715522ed4b3df8b92> Thank you so much. Will do that. 
[2016-01-03T16:54:20.266Z] <553d32d715522ed4b3df8b92> It would also help if some idea can be given regarding how to proceed. Sorry for my doubts on trivial issues, but I am new to the API. AFAIK, I see that the multi class classifiers are right now implemented to turn a binary classifier into a multiclass classifier. This issue is intended to implement meta estimators to turn binary classifiers to multioutput classifiers. Are multi output classifiers same as the multioutput-multiclass classifiers like dt, rf ? And also let me know if it is better to ask the doubts in here or do it at some other place ?
[2016-01-03T21:21:19.440Z] <53135b495e986b0712efc453> The outline of what needs to be done here is -   * Make `n_outputs` numbers of single output estimators * Train using `X (n_samples x n_features)`, `y (n_samples x n_outputs)` * Predict using `X(n_samples x n_features)` * For `output_i` in `range(n_outputs)` --> `y_predicted_i = estimator_i`, where `y_predicted_i` is of shape `(n_samples x 1)` * Vertically stack all the `y_predicted_i` -s to get the final `y_predicted` of shape `(n_samples x n_outputs)`     
[2016-01-03T21:23:27.927Z] <53135b495e986b0712efc453> and as far are `multioutput.py` is concerned, it should provide a meta estimator that changes single/multiclass single output to single/multiclass multioutput...
[2016-01-03T21:27:58.599Z] <53135b495e986b0712efc453> So essentially if you want binary_single_output_estimator to be made a multiclass multioutput you should be able to do both -  * `OVOClassifier(estimator=MultiOutputEstimator(estimator=binary_single_output_estimator))` * `MultiOutputEstimator(estimator=OVOClassifier(estimator=binary_single_output_estimator))`
[2016-01-03T21:28:58.431Z] <53135b495e986b0712efc453> You could add a test making sure both of them return the same predictions
[2016-01-03T21:32:46.322Z] <53135b495e986b0712efc453> I copied this to the issue so @mblondel or anyone else can correct me if I am wrong.
[2016-01-03T21:33:30.536Z] <53135b495e986b0712efc453> Also, I am unable to edit, we require it to be horizontally stacked, not vertically
[2016-01-04T05:03:14.318Z] <553d32d715522ed4b3df8b92> Thanks @rvraghav93 for the detailed explanation :-)
[2016-01-04T23:48:16.851Z] <54d4a1d6db8155e6700f853b> does someone have a face recognition example where using eigenfaces actually works better than raw pixels? I played around with lfw, but it seems to make results worse :-/
[2016-01-05T18:17:30.137Z] <567d7eca16b6c7089cc02a05> I am new to scikit and also want to contribute to, where should i start!
[2016-01-05T18:53:48.333Z] <55f3a7830fc9f982beb071a9> http://scikit-learn.org/stable/developers/
[2016-01-05T20:43:05.454Z] <53135b495e986b0712efc453> Start with easy issues that are tagged "Need Contributor"
[2016-01-06T03:36:07.977Z] <53135b495e986b0712efc453> Apparently we can protect branches from force push... hmmm... (https://help.github.com/articles/about-protected-branches)
[2016-01-06T12:30:43.170Z] <54e6371215522ed4b3dc3718> @rvraghav93 Can you have a look at my pull request #6114 or someone else? I have made changes to all the cython files which had descripancies.
[2016-01-06T12:31:33.635Z] <54e6371215522ed4b3dc3718> *discrepancies
[2016-01-10T14:28:48.488Z] <541d52b1163965c9bc205cf3> @amueller  what exactly is wrong with VBGMM 
[2016-01-12T20:53:21.380Z] <5395efa3a9176b500d1cd7fb> I get a 404 on http://scikit-learn.org/stable/faq/
[2016-01-12T22:17:48.487Z] <55901c1b15522ed4b3e2f949> @rvraghav93  I'll finish reviewing soon
[2016-01-12T22:18:09.553Z] <55901c1b15522ed4b3e2f949> I have two talks coming up soon which I need to work on
[2016-01-12T22:19:33.915Z] <53135b495e986b0712efc453> @jmschrei Please take your time! Thanks heaps for your reviews!!
[2016-01-12T22:20:22.919Z] <55901c1b15522ed4b3e2f949> I'm going to take a stab at parallelizing trees after yours is merged.
[2016-01-12T22:20:45.421Z] <55901c1b15522ed4b3e2f949> I've never liked the criterion objects so I'm considering getting rid of them.
[2016-01-12T22:20:57.796Z] <55901c1b15522ed4b3e2f949> But I think Gilles might not approve. <_<
[2016-01-12T22:20:58.044Z] <53135b495e986b0712efc453> And pass score-like objects??
[2016-01-12T22:21:24.263Z] <55901c1b15522ed4b3e2f949> I don't know. At least make them stateless, so it can be a single criterion despite the number of threads.
[2016-01-12T22:21:43.812Z] <55901c1b15522ed4b3e2f949> I think the tree module, while pretty efficient, is kind of a mess.
[2016-01-12T22:23:09.735Z] <53135b495e986b0712efc453> Really? I found it organized ;) Anyway do let me know if you feel I can be of any help. Alex has asked me to work on the trees for the next few months!!
[2016-01-12T22:29:40.954Z] <55901c1b15522ed4b3e2f949> Okay
[2016-01-12T22:29:55.356Z] <55901c1b15522ed4b3e2f949> I've been working with mxnet for a bit now but I might have more time soon.
[2016-01-13T08:16:19.631Z] <5571fe1015522ed4b3e17d90> @michaelaye Looks like the / at the end is the problem. http://scikit-learn.org/stable/faq.html works. I'll take a look at fixing the link on the main page.
[2016-01-13T11:55:01.284Z] <5571fe1015522ed4b3e17d90> @michaelaye the FAQ link at the bottom of the page is now fixed on the dev doc: http://scikit-learn.org/dev/
[2016-01-13T21:09:09.675Z] <5395efa3a9176b500d1cd7fb> Ok, but the link on /stable is still broken, FYI.
[2016-01-13T21:10:55.189Z] <5395efa3a9176b500d1cd7fb> but good to know that it actually works without the /
[2016-01-14T07:38:01.270Z] <5571fe1015522ed4b3e17d90> > Ok, but the link on /stable is still broken, FYI.
[2016-01-14T07:38:28.785Z] <5571fe1015522ed4b3e17d90> Yep this will be fixed on the next stable release
[2016-01-14T16:37:24.186Z] <54d4a1d6db8155e6700f853b> @halwai do you mean the old or the new?
[2016-01-14T18:43:36.130Z] <53135b495e986b0712efc453> 
[2016-01-15T20:44:38.767Z] <54d4a1d6db8155e6700f853b> @MechCoder https://github.com/scikit-learn/scikit-learn/issues/4497
[2016-01-15T21:54:34.814Z] <564789be16b6c7089cbab8b7> Is there an easy way to see what the new features etc might be for the upcoming 0.18 by searching https://github.com/scikit-learn/scikit-learn/pulls ?
[2016-01-15T21:54:58.020Z] <564789be16b6c7089cbab8b7> clearly this would be subject to change but I haven't found an appropriate tag to search for yet
[2016-01-15T22:43:57.146Z] <53810862048862e761fa2887> @amueller I have started working on https://github.com/vighneshbirodkar/sklearn-stub
[2016-01-19T05:00:22.130Z] <53810862048862e761fa2887> @amueller I have deployed Travis, and Coveralls and CircleCI is now building the doumentation
[2016-01-19T05:02:00.416Z] <53810862048862e761fa2887> http://vighneshbirodkar.github.io/sklearn-stub/docs/
[2016-01-19T16:20:13.793Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar sweet!
[2016-01-19T16:20:42.975Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar that is actually totally aweseom
[2016-01-19T16:21:36.811Z] <54d4a1d6db8155e6700f853b> can you add a "user guide" like page to the documentation that explains what exactly a user has to do to make this work for them?
[2016-01-19T16:23:23.888Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar this here can maybe help, too: https://github.com/uwescience/shablona
[2016-01-19T16:49:56.761Z] <541d52b1163965c9bc205cf3> @amueller   old one
[2016-01-19T16:55:20.352Z] <54d4a1d6db8155e6700f853b> @halwai I think the algorithm is wrong. The update doesn't conform to the literature, and it doesn't seem to work very well in many settings.
[2016-01-19T16:56:16.764Z] <541d52b1163965c9bc205cf3> @amueller  can i  help to set it right ?
[2016-01-19T16:56:56.017Z] <54d4a1d6db8155e6700f853b> well you can help fix the new implementation. have you looked at the pull request?
[2016-01-19T17:04:50.354Z] <541d52b1163965c9bc205cf3> @amueller  which pull request are you talking about can u share the link
[2016-01-19T17:11:50.741Z] <54d4a1d6db8155e6700f853b> #4802
[2016-01-19T17:37:01.806Z] <53810862048862e761fa2887> @amueller I'm on it 
[2016-01-19T17:49:27.984Z] <54d4a1d6db8155e6700f853b> Thanks :)
[2016-01-19T17:53:32.331Z] <53810862048862e761fa2887> @amueller I noticed one thing. Currently the CircleCI script installs python packages via both apt-get and pip. We could simplify it to only use pip. The cache in CircleCI caches pip packages and their subsequent installation will happen in no time. 
[2016-01-19T18:05:48.381Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar but installing numpy and scipy by pip is discouraged and will take forever and apt-get is also cached.
[2016-01-19T18:08:07.540Z] <53810862048862e761fa2887> @amueller I ran into some PYTHONPATH issues on CircleCI. Is it ok if I install numpy and scipy through pip for the stub package? 
[2016-01-19T18:13:48.371Z] <54d4a1d6db8155e6700f853b> that requires compiling, right? that will take very long. And the people that copy the stub will have trouble.
[2016-01-19T18:13:57.218Z] <54d4a1d6db8155e6700f853b> one option would be to just use conda
[2016-01-19T18:14:06.981Z] <54d4a1d6db8155e6700f853b> and not test a non-conda environment
[2016-01-19T18:17:40.642Z] <53810862048862e761fa2887> It does need compliing. But only for the first time. Doing it this way let's us keep the configuration to a minimum. Do you think I should switch to apt-get ?
[2016-01-19T18:28:43.480Z] <54d4a1d6db8155e6700f853b> how do you mean for the first time? the first time in master? or the first time for any pull request?
[2016-01-19T18:35:16.675Z] <53810862048862e761fa2887> CircleCI is only built over master to deploy the documentation. So the first time on master. PRs will be built by travis which uses apt-get
[2016-01-19T19:06:21.409Z] <53810862048862e761fa2887> I'm sorry. Travis uses conda right now.
[2016-01-19T19:11:11.711Z] <53135b495e986b0712efc453> @amueller could you take a look at #5568? 
[2016-01-19T19:11:43.050Z] <54d4a1d6db8155e6700f853b> @rvraghav93 It's on my list of the more urgent things ;)
[2016-01-19T19:12:00.360Z] <53135b495e986b0712efc453> Thanks :D
[2016-01-20T06:49:30.858Z] <569f27d8e610378809bd3960> hello
[2016-01-20T06:49:35.641Z] <569f27d8e610378809bd3960> <unconvertable>
[2016-01-21T05:05:29.246Z] <5496a05adb8155e6700e1a4b> Does sklearn kmeans uses Linde Buzo Gray algorithm for codebook generation?
[2016-01-21T13:22:13.995Z] <53135b495e986b0712efc453> have a look at this - http://docs.scipy.org/doc/scipy-0.14.0/reference/cluster.vq.html
[2016-01-21T18:25:35.781Z] <54d4a1d6db8155e6700f853b> @rvraghav93 how does that answer the question? @rajathkumarmp no it's just using lloyd's algorithm
[2016-01-21T20:03:10.713Z] <53135b495e986b0712efc453> Sorry I assumed he wanted vector quantisation
[2016-01-21T22:59:29.196Z] <54d4a1d6db8155e6700f853b> well yeah he asked which algorithm is implemented in kmeans. scipy's vq implements the same algorithm as sklearn does
[2016-01-21T23:05:50.161Z] <53135b495e986b0712efc453> Okay :grin: (I stupidly assumed since it was a vq module, maybe it does it using lbg as lbg seems to be the preferred alg for vq)
[2016-01-22T02:19:01.984Z] <560d8599d33f749381a7fa7c> 
[2016-01-22T04:17:25.668Z] <5496a05adb8155e6700e1a4b> @amueller thank you for clarifying. 
[2016-01-22T04:19:21.041Z] <5496a05adb8155e6700e1a4b> "The average complexity is given by O(k n T), were n is the number of samples and T is the number of iteration. The worst case complexity is given by O(n^(k+2/p)) with n = n_samples, p = n_features". This is mentioned in the docs. What is "k" here ? Also, is it O(KnT), Multiplication of all 3 parameters? 
[2016-01-22T04:40:25.343Z] <561d08d0d33f749381a937bf> Hi guys, im going to bombard this forum with a lot of newbee questions. Feel free to kick me out anytime. Ive got several IDs just in case.
[2016-01-22T16:19:27.407Z] <54d4a1d6db8155e6700f853b> @Fredilly lol. Maybe try stackoverflow with the sklearn tag
[2016-01-22T16:19:36.865Z] <54d4a1d6db8155e6700f853b> that will get you replies more quickly and more willingly ;)
[2016-01-22T16:19:57.031Z] <54d4a1d6db8155e6700f853b> @rajathkumarmp k is the number of clusters, knt is the multiplication
[2016-01-24T11:38:37.588Z] <53135b495e986b0712efc453> @jmschrei (This is probably a stupid idea), can we compute the accumulated sample_weights for all the samples and store it. (a double array of `n_samples` size)  Later we can compute the weighted n_samples for right or left by subtracting the last index's accumulated value from the first? (Would that speed up the impurity computation and also take us a step closer to having a state-less criterion?)
[2016-01-24T11:40:03.096Z] <53135b495e986b0712efc453> (There is also the class count that is being stored as a state, that also could be accumulated and stored but not sure if it would take up a lot of space.)
[2016-01-24T11:41:27.355Z] <53135b495e986b0712efc453> (Also we need not compute this accumulated sample_weights for all the samples, we could expand this 'cache' when we encounter new samples to avoid computing for samples well away any decision boundary?)
[2016-01-25T22:33:26.163Z] <54d4a1d6db8155e6700f853b> @ogrisel if you need reviews for 0.17.1 let me know. I'm a bit out of the loop right now
[2016-01-26T04:10:43.967Z] <5537027215522ed4b3df56ab> Hey guys, anyone has an idea why logistic regression doesn't give realistic probability estimates?
[2016-01-26T04:10:56.258Z] <5537027215522ed4b3df56ab> with the number of features is large?
[2016-01-26T04:12:49.690Z] <5537027215522ed4b3df56ab> random forest on the other hand gives more realistic estimates
[2016-01-26T04:16:59.745Z] <5537027215522ed4b3df56ab> it is basically overfitting on the things that seem to happen only a few times in the dataset, because they are "good predictors" mostly by chance. More aggressive L1 regularization always results in poorer performance
[2016-01-26T09:25:03.123Z] <5537027215522ed4b3df56ab> perhaps if we had bayesian logistic regression
[2016-01-26T18:15:30.484Z] <54d4a1d6db8155e6700f853b> @lqdc have you tried the calibration module?
[2016-01-28T19:16:50.443Z] <53810862048862e761fa2887> How does scikit-learn currently upload packages to PyPI ?
[2016-01-29T16:04:55.993Z] <53135b495e986b0712efc453> I recall @ogrisel or @amueller using twine for that I think. (Ref: https://gitter.im/scikit-learn/scikit-learn?at=552d71150e3138bb6be81ef4)
[2016-01-29T16:12:13.633Z] <54d4a1d6db8155e6700f853b> I've been using setuptools but twine is also an option
[2016-01-29T16:13:30.353Z] <53810862048862e761fa2887> I added instructions for setuptools in the stub project 
[2016-01-29T18:28:49.041Z] <54d4a1d6db8155e6700f853b> hm anyone wanna review #5270?
[2016-01-29T18:29:01.060Z] <54d4a1d6db8155e6700f853b> I think we should really move forward with OneHotEncoder
[2016-01-29T19:16:02.119Z] <53135b495e986b0712efc453> Is it possible to cythonize and test a single module alone without building scikit-learn fully?
[2016-01-29T19:37:57.617Z] <53810862048862e761fa2887> If you compile scikit-learn it only compiles changed files. 
[2016-01-30T02:01:46.565Z] <5537027215522ed4b3df56ab> @amueller thanks for the tip, but calibrating doesn't help (http://i.imgur.com/k8pF5p7.png)
[2016-01-30T02:02:49.538Z] <5537027215522ed4b3df56ab> perhaps, it's an issue with sparse datasets. I wonder what the general solution to this kind of thing is.. adding noise?
[2016-01-30T04:24:45.815Z] <5537027215522ed4b3df56ab> I was thinking of adding support for bayesian logistic regression since it's commonly used in the R world, but it  doesn't seem to scale to large number of features, because of MCMC + then we need pymc as a dependency. 
[2016-01-31T11:26:20.451Z] <5624bbb016b6c7089cb77b2a> Hi, lately I've been trying to think for a solution to project structure and organization, I've asked at [SO](http://stackoverflow.com/questions/35067412/python-machine-learning-data-science-project-structure) and [Reddit](https://www.reddit.com/r/Python/comments/43ima5/project_template_for_data_scienceanalysis/), since I'm using sklearn and creating new interfaces to the classes, I think this chat would be better. So... how do you guys organize the entire project folder? Also, do you use Pipelines, if so, wqhere do you place all the different transformer?
[2016-02-01T15:28:14.211Z] <54d4a1d6db8155e6700f853b> @davidgasquez this channel is more for scikit-learn project development. SO is usually good.
[2016-02-01T15:29:47.759Z] <54d4a1d6db8155e6700f853b> @davidgasquez I don't think there is any best practice for analysis code. I usually have a module that lives somewhere with the code. but you don't usually want your data under version control...
[2016-02-01T16:36:43.613Z] <5624bbb016b6c7089cb77b2a> @amueller Sorry for the question in the wrong place. Thanks for the reply!
[2016-02-02T16:48:23.225Z] <53135b495e986b0712efc453> @vighneshbirodkar Ah yes. Thanks for the response :) When cythonize.dat is rewritten (for some reason, say build clean etc) and I have a build error at say the 5th cython file the cythonize.dat is not updated with the hash records of first 4. This makes it to cythonize the first 4 again and again until 5th (and all subsequent) cython file compiles without error... 
[2016-02-02T16:48:40.377Z] <53135b495e986b0712efc453> Also could anyone review https://github.com/scikit-learn/scikit-learn/pull/6254 please?
[2016-02-02T16:48:53.138Z] <53135b495e986b0712efc453> @ogrisel ?
[2016-02-02T18:15:02.059Z] <5572bf2d15522ed4b3e182a1> Can I use a plain `linear_model.RANSACRegressor()` in `cross_validation.cross_val_score`?  Currently I am getting a `ValueError: No inliers found, possible cause is setting residual_threshold (None) too low.`
[2016-02-02T18:30:31.345Z] <5572bf2d15522ed4b3e182a1> Nevermind, seems to be a problem with my data
[2016-02-02T23:46:58.673Z] <53135b495e986b0712efc453> @amueller We should add this :P - https://github.com/domgetter/NCoC
[2016-02-03T17:58:13.844Z] <54d4a1d6db8155e6700f853b> @rvraghav93 we already have no code of conduct :P
[2016-02-03T18:47:03.931Z] <53135b495e986b0712efc453> Haha
[2016-02-03T20:03:08.955Z] <53810862048862e761fa2887> @amueller Can you take another look at #5270 ?
[2016-02-03T20:18:24.377Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar probably not today, but should be possible tomorrow
[2016-02-03T20:42:33.849Z] <53810862048862e761fa2887> Ok, thanks
[2016-02-04T15:53:54.892Z] <564789be16b6c7089cbab8b7> https://github.com/scikit-learn/scikit-learn/pull/4899 is this just waiting review?
[2016-02-04T15:54:52.474Z] <564789be16b6c7089cbab8b7> and this lovely PR seems to have stalled https://github.com/scikit-learn/scikit-learn/issues/5736
[2016-02-04T16:51:45.797Z] <53135b495e986b0712efc453> #4899 is waiting for more tests + reviews too.
[2016-02-04T22:24:54.222Z] <54d4a1d6db8155e6700f853b> I'm super behind, sorry
[2016-02-05T14:17:03.975Z] <564789be16b6c7089cbab8b7> I don't think anyone can say sorry! You are doing an amazing job.
[2016-02-06T04:12:53.595Z] <56a34c16e610378809bdc988> Hi fellows, please read the abstract of this page and have a look at it quickly :
[2016-02-06T04:12:55.865Z] <56a34c16e610378809bdc988> http://arxiv.org/pdf/1211.1513.pdf
[2016-02-06T04:13:13.066Z] <56a34c16e610378809bdc988> Can this be a good addition to the lib ?
[2016-02-06T04:13:54.341Z] <56a34c16e610378809bdc988> And I can see 401 Open PRs. They are not being merged quickly. Do they need some reviewing ? I can assist in best possible ways.
[2016-02-06T12:22:56.137Z] <561d08d0d33f749381a937bf> How can you tell that the input and response for the the iris data set are .data and .target? 
[2016-02-06T12:23:22.054Z] <561d08d0d33f749381a937bf> For digits, its something else.  Where does that information come from?
[2016-02-06T12:26:56.289Z] <5525b91815522ed4b3deb7d6> @Fredilly Take a look [here](http://scikit-learn.org/stable/datasets/index.html#datasets)
[2016-02-06T12:50:21.324Z] <561d08d0d33f749381a937bf> @leosartaj <unconvertable>
[2016-02-07T16:39:10.240Z] <56a34c16e610378809bdc988> Veteran contributors, please have a look at the link above ^^^
[2016-02-07T16:40:09.656Z] <56a34c16e610378809bdc988> If you think this can be a good addition to the lib, I will try to implement it. I have read it quickly once, if I get a yes, I will thoroughly go through it and start implementing it as a new class.
[2016-02-07T16:40:20.493Z] <56a34c16e610378809bdc988> it is named the "K-Plane Regression"
[2016-02-07T17:45:11.675Z] <5363a92c048862e761fa03c3> @karandesai-96 Have a look at [FAQs](http://scikit-learn.org/stable/faq.html#can-i-add-this-new-algorithm-that-i-or-someone-else-just-published)
[2016-02-07T20:34:15.415Z] <56a34c16e610378809bdc988> Oh,ok. I haven't see the specifications of the paper, will check it whether it meets the requirements. If not, I will upload it separate l
[2016-02-07T20:35:25.539Z] <56a34c16e610378809bdc988> It can get it reviewed and added as related projects.
[2016-02-08T08:43:12.511Z] <564789be16b6c7089cbab8b7> K-plane regression appears to have 2 citations which makes it too early for scikit learn if I understand correctly (IIUC?)
[2016-02-08T14:11:56.470Z] <54e07d6515522ed4b3dc0858> Not just 2 citations. 2 citations since 2013...
[2016-02-08T14:23:22.736Z] <54e07d6515522ed4b3dc0858> Just curious, @karandesai-96, why are you interested in this method? 
[2016-02-08T14:39:55.648Z] <56a34c16e610378809bdc988> It has better results than mine, on a public data set I used once.
[2016-02-08T14:40:09.387Z] <56a34c16e610378809bdc988> Yeah, it seems too early for sklearn
[2016-02-08T14:40:59.962Z] <56a34c16e610378809bdc988> ^^ This was the only reason why I was curious to know how it yielded better results... xD
[2016-02-08T17:19:15.234Z] <564789be16b6c7089cbab8b7> @karandesai-96  what works well is if you make a separate scikit learn compatible implementation and it can be added to http://scikit-learn.org/stable/related_projects.html potentially
[2016-02-09T14:08:58.837Z] <56a34c16e610378809bdc988> Yes, even I am thinking about it. Also, I will try to implement ths on certain public datasets I know. I'll see if it gives consistent results.
[2016-02-09T14:09:07.646Z] <56a34c16e610378809bdc988> It will consume sometime though.
[2016-02-09T14:29:00.641Z] <55a7b5b08a7b72f55c3f96ef> Hey all!
[2016-02-09T14:29:35.022Z] <55a7b5b08a7b72f55c3f96ef> Just started thinking about building up Machine Learning for a problem I'm facing and hopefully SciKit-Learn would help solve it
[2016-02-09T14:30:07.233Z] <55a7b5b08a7b72f55c3f96ef> Is this the best place to ask for it?
[2016-02-09T18:39:04.081Z] <564789be16b6c7089cbab8b7> does anyone know any good software for clustering big graphs? It seems scikit learn doesn't have stochastic block model support yet sadly
[2016-02-09T20:22:33.747Z] <54d4a1d6db8155e6700f853b> what's happening with appveyor?
[2016-02-09T20:22:35.416Z] <54d4a1d6db8155e6700f853b> @ogrisel?
[2016-02-09T20:22:56.038Z] <54d4a1d6db8155e6700f853b> https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.5177/job/tjveqfpn8bcdyrks
[2016-02-09T21:06:54.277Z] <564789be16b6c7089cbab8b7> @amueller  You mentioned a time series CV object in the mailing list. I would love to see that too
[2016-02-09T21:07:33.820Z] <54d4a1d6db8155e6700f853b> Depending on how you parametrize, it's pretty easy to write
[2016-02-09T21:07:50.684Z] <54d4a1d6db8155e6700f853b> if you assume homogeneous samples, you can just do a slight modification of kfold
[2016-02-09T21:08:08.932Z] <54d4a1d6db8155e6700f853b> if you want to use a time index, it becomes way trickier (as we need to get a time series object in)
[2016-02-09T21:09:41.682Z] <564789be16b6c7089cbab8b7> to be honest I am not even 100% sure of the best way to do CV on time series data. If you sample randomly from the series you are likely ruin your feature vectors. What is the right approach?
[2016-02-09T21:10:50.136Z] <564789be16b6c7089cbab8b7> oh actually I think I see
[2016-02-09T21:38:11.139Z] <564789be16b6c7089cbab8b7> what do you mean by using a time index?
[2016-02-09T21:43:25.081Z] <54d4a1d6db8155e6700f853b> lets say each datapoint is a day. and you want to use 5 fold on 100 days
[2016-02-09T21:43:38.927Z] <54d4a1d6db8155e6700f853b> then training set 1 is days 0-20, test set 1 is 20-40
[2016-02-09T21:43:56.552Z] <54d4a1d6db8155e6700f853b> training set 2 is 0-40, test set 2 is 40-60 etc
[2016-02-09T21:44:33.994Z] <54d4a1d6db8155e6700f853b> but say for each day you have some arbitrary number of datapoints. Then you need to know which day a datapoint belongs to.
[2016-02-09T21:44:49.407Z] <54d4a1d6db8155e6700f853b> actually, it's not that hard, it just needs a "label" attribute... 
[2016-02-09T21:50:25.136Z] <54d4a1d6db8155e6700f853b> see http://stats.stackexchange.com/questions/14099/using-k-fold-cross-validation-for-time-series-model-selection for example
[2016-02-09T21:51:05.531Z] <564789be16b6c7089cbab8b7> thanks
[2016-02-09T21:51:37.700Z] <564789be16b6c7089cbab8b7> so in short.. it would be great :)
[2016-02-09T21:52:38.965Z] <564789be16b6c7089cbab8b7> I am not sure what you call it but there is also event data which is slightly different from time series data. That is you have a sequence of times when events happen as opposed to labels at every second, say.
[2016-02-09T21:52:49.025Z] <564789be16b6c7089cbab8b7> is there any support for that sort of data?
[2016-02-09T21:52:51.570Z] <54d4a1d6db8155e6700f853b> that is what I mean
[2016-02-09T21:53:01.677Z] <564789be16b6c7089cbab8b7> oh I see!
[2016-02-09T21:53:06.784Z] <54d4a1d6db8155e6700f853b> with "having an arbitrary number of datapoint for every day"
[2016-02-09T21:53:19.687Z] <564789be16b6c7089cbab8b7> ah ok... so I am very interested in that
[2016-02-09T21:53:20.792Z] <54d4a1d6db8155e6700f853b> then you would need to specify a label
[2016-02-09T21:53:37.113Z] <564789be16b6c7089cbab8b7> although how exactly you build your feature vectors is also less obvious I think
[2016-02-09T21:55:11.855Z] <564789be16b6c7089cbab8b7> people who do machine learning on neuronal firing data are particularly interested in this
[2016-02-09T22:00:37.053Z] <54d4a1d6db8155e6700f853b> the feature vector is a different problem ;)
[2016-02-09T22:01:11.090Z] <54d4a1d6db8155e6700f853b> I think most people that do time series analysis are not necessarily in the sciences ;)
[2016-02-09T22:02:30.790Z] <564789be16b6c7089cbab8b7> ah :)
[2016-02-09T22:02:35.855Z] <564789be16b6c7089cbab8b7> then I am the odd one out :)
[2016-02-09T22:05:27.607Z] <564789be16b6c7089cbab8b7> on a different note, when I pip install scikit-learn, are all the C and Fortran dependencies compiled from source or are any binaries used? 
[2016-02-10T04:31:04.515Z] <55a7b5b08a7b72f55c3f96ef> I don't know much about Python but it seems that it works close to how .bat executables work. Can scikit-learn be used to create new files based on input?
[2016-02-10T04:32:18.380Z] <55a7b5b08a7b72f55c3f96ef> E.g. input customer profile and it generates a recommended real estate proposal
[2016-02-10T09:09:56.622Z] <564789be16b6c7089cbab8b7> @Qoyyuum  yes but this is the wrong place to ask basic python questions
[2016-02-10T14:06:54.031Z] <56b0a775e610378809bf7a7c> Hi everyone !!!  @amueller I was watching the pull request #4802. It seems blocked for several months now. Do you know what's the problem ?  I've seen that a lot of new codes was submitted at the same time. I image it's a real problem for the reviewers. Maybe it could be easier for them to divide the work of the GSoC in several pull request. Do you think it's a good solution ? I can work on it if you want. 
[2016-02-10T22:13:39.387Z] <54d4a1d6db8155e6700f853b> @tguillemot @ogrisel was mostly working on this. There was some bug there. I'm not sure about the exact status at the moment
[2016-02-10T22:13:54.838Z] <54d4a1d6db8155e6700f853b> has anyone seen this error on travis before? https://travis-ci.org/scikit-learn/scikit-learn/jobs/108346382 @ogrisel ?
[2016-02-11T08:40:07.852Z] <56b0a775e610378809bf7a7c> Ok. @ogrisel I'm the new engineer of Telecom and I'm working full time on scikit-learn, so tell me what I can do to help.
[2016-02-11T12:38:42.121Z] <541a528b163965c9bc2053de> Hi all @tguillemot , I replied to your email. Won't have time to follow up on that before next week though.
[2016-02-11T12:40:00.034Z] <541a528b163965c9bc2053de> @amueller merge #6260 ?
[2016-02-11T12:42:13.818Z] <56b0a775e610378809bf7a7c> @ogrisel No problem. Thx
[2016-02-11T15:38:14.885Z] <564789be16b6c7089cbab8b7> @amueller  Do you think it is worth my opening an issue about CV and time series data?
[2016-02-11T15:40:12.288Z] <56b80528e610378809c05a48> Hello @lesshaste , here is one https://github.com/scikit-learn/scikit-learn/issues/6322
[2016-02-11T15:54:10.653Z] <54d4a1d6db8155e6700f853b> @ogrisel merged #6260
[2016-02-11T15:55:22.610Z] <54d4a1d6db8155e6700f853b> @ogrisel I can work on #6332 and the bug fixes in ~2 hours, not earlier
[2016-02-11T16:09:47.551Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  thanks! How do I upvote it :)
[2016-02-11T16:10:45.381Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  there were two interesting cases I think. One where you have some value for each time tick and one where you can have different numbers of events per day
[2016-02-11T16:10:55.462Z] <56b80528e610378809c05a48> @lesshaste  Join Github!
[2016-02-11T16:11:25.691Z] <564789be16b6c7089cbab8b7> I have joined it! Can you upvote there?
[2016-02-11T16:11:34.761Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  I see both cases are already listed by amueller
[2016-02-11T16:11:40.366Z] <56b80528e610378809c05a48> Yes
[2016-02-11T16:12:25.210Z] <564789be16b6c7089cbab8b7> umm... how? By adding a comment or is there some upvote button?
[2016-02-11T16:13:36.583Z] <564789be16b6c7089cbab8b7> in any case I am very pleased you are taking this on
[2016-02-11T16:13:47.006Z] <564789be16b6c7089cbab8b7> thank you
[2016-02-11T16:14:39.581Z] <56b80528e610378809c05a48> Oh about upvote ... I mean join Github as a software engineer and add this function :)
[2016-02-11T16:14:59.057Z] <56b80528e610378809c05a48> 
[2016-02-11T16:15:33.969Z] <564789be16b6c7089cbab8b7> oh I see .. sorry :)
[2016-02-11T19:04:24.050Z] <54d4a1d6db8155e6700f853b> loool @yenchenlin1994 
[2016-02-11T19:04:32.034Z] <54d4a1d6db8155e6700f853b> (and I approve ;)
[2016-02-11T19:07:00.207Z] <564789be16b6c7089cbab8b7> me too :)
[2016-02-11T19:15:21.361Z] <564789be16b6c7089cbab8b7> although it's hard to visualise, is it true that the clustering algorithms perform roughly as the examples in https://github.com/scikit-learn/scikit-learn/pull/6305 when you increase the dimension?
[2016-02-11T19:15:43.366Z] <564789be16b6c7089cbab8b7> Maybe there is some numerical score that could be given on higher dimension data sets?
[2016-02-12T00:11:59.555Z] <54d4a1d6db8155e6700f853b> @lesshaste there is a PR for stability scores, but evaluating clustering is really hard
[2016-02-12T02:13:34.492Z] <56b80528e610378809c05a48> Hello @amueller ,
[2016-02-12T02:15:31.964Z] <56b80528e610378809c05a48> Would you please answer the question I asked in this issue lately? https://github.com/scikit-learn/scikit-learn/issues/6322  Oh and homogeneous and heterogeneous should be separated into two classes, right?
[2016-02-12T06:17:17.557Z] <564789be16b6c7089cbab8b7> @amueller  thanks. I hope that PR works out. I seem to remember it had made quite a lot of progress
[2016-02-12T07:30:28.734Z] <564789be16b6c7089cbab8b7> @amueller  https://github.com/scikit-learn/scikit-learn/pull/4301 ?
[2016-02-12T16:11:03.153Z] <54d4a1d6db8155e6700f853b> @lesshaste yes
[2016-02-12T16:23:24.428Z] <54d4a1d6db8155e6700f853b> @ogrisel are you around?
[2016-02-12T17:42:05.321Z] <53135b495e986b0712efc453> Does anyone know if it is a better idea to form the `neighbors/binary_tree.pxi` into a proper `pyx` + `pxd` file rather than importing the pxi file at `kd_tree.pyx` and `ball_tree.pyx`. From [this](https://github.com/cython/cython/wiki/FAQ#what-is-the-difference-between-a-pxd-and-pxi-file-when-should-either-be-used) (Thanks  to @tomdlt) article, I understand that pxi file gets included at both the places. Would it be better to import than to include or am I missing something?
[2016-02-12T17:48:29.753Z] <54d4a1d6db8155e6700f853b> ok I set up the travis correctly and reproduced locally, so I'll spend the rest of the day fixing numpy dev compatibility
[2016-02-12T17:50:47.687Z] <53135b495e986b0712efc453> @amueller I'm free for the evening (and weekend). I am starting the work on multiple metric grid search... (I have some notes on how you had wanted it implemented) I'll ping you and joel if I get into trouble ;)
[2016-02-12T17:52:22.599Z] <54d4a1d6db8155e6700f853b> have you talked to @MechCoder ? he was also thinking about the problem
[2016-02-12T17:52:38.812Z] <54d4a1d6db8155e6700f853b> it's valentines day on Sunday, I might be busy ;)
[2016-02-12T17:52:47.695Z] <54d4a1d6db8155e6700f853b> also I want to make sure everything is ready for the 0.17.1 release
[2016-02-12T17:52:54.247Z] <53135b495e986b0712efc453> Yes I spoke to him too out of github ;)
[2016-02-12T17:53:04.145Z] <54d4a1d6db8155e6700f853b> cool
[2016-02-12T17:53:04.962Z] <53135b495e986b0712efc453> Hehe :P Have a nice time ;)
[2016-02-12T20:04:49.633Z] <54d4a1d6db8155e6700f853b> Anyone who knows the sequential dataset well? I'm stumped on #6334
[2016-02-12T21:30:28.027Z] <54d4a1d6db8155e6700f853b> ok, all "fixed"
[2016-02-15T11:52:05.935Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  hi.. In https://github.com/scikit-learn/scikit-learn/pull/6351 which of the variants listed in the R example are you doing for the homogeneous case?
[2016-02-15T11:52:24.569Z] <564789be16b6c7089cbab8b7> or all of them?
[2016-02-15T13:49:24.371Z] <561d08d0d33f749381a937bf> Anyone familiar with the amazon employee access challenge on kaggle? http://bit.ly/1oj7FtX   It provides a training set and testing set. The training set contains target response but the testing set doesnt. Do I still perform train_test_split on training set? 
[2016-02-15T16:53:09.565Z] <56b80528e610378809c05a48> Hello @lesshaste   Yes, Ive only committed the homogeneous part by now. Actually, Im a little confused about the heterogeneous case.
[2016-02-15T16:59:30.653Z] <56b80528e610378809c05a48> If I got 1 sample for 1st day, 2 samples for 2nd day and 3 samples for 3rd day, then I decide to do 2 folds heterogeneous cv, what will happen?
[2016-02-15T17:00:00.928Z] <56b80528e610378809c05a48> ping @amueller @lesshaste 
[2016-02-15T17:01:41.155Z] <56b80528e610378809c05a48> Do all samples we collect in the same day should be in the same fold?
[2016-02-15T17:40:30.406Z] <54d4a1d6db8155e6700f853b> sorry, I'm pretty busy right now
[2016-02-15T17:41:49.237Z] <56b80528e610378809c05a48> Its pretty okay ... take your time :)
[2016-02-15T17:50:48.132Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  even in the homogeneous part there are various options for how to do the cross-validation
[2016-02-15T17:54:07.998Z] <56b80528e610378809c05a48> oh sorry for my ambiguous description. I implemented the basic case, like the example amueller gave in the discussion between you and him before.
[2016-02-15T20:58:17.742Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  ah ok thanks. I am not even sure how interesting the other cases are to be honest
[2016-02-15T20:58:33.448Z] <564789be16b6c7089cbab8b7> we need some data and tests I suppose
[2016-02-16T08:02:58.729Z] <56b80528e610378809c05a48> @lesshaste Hello,
[2016-02-16T08:03:08.361Z] <56b80528e610378809c05a48> Can you annser my question above?
[2016-02-16T08:03:21.776Z] <56b80528e610378809c05a48> If I got 1 sample for 1st day, 2 samples for 2nd day and 3 samples for 3rd day, then I decide to do 2 folds heterogeneous cv, what will happen?
[2016-02-16T08:53:02.400Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  I am not sure exactly how you are doing the heterogeneous case I have to admit. Why are you splitting by days? 
[2016-02-16T08:53:35.698Z] <564789be16b6c7089cbab8b7> maybe @amueller has a better idea what is going on in this case
[2016-02-16T08:53:56.641Z] <564789be16b6c7089cbab8b7> does R have anything for the heterogeneous case?
[2016-02-16T09:26:39.525Z] <53135b495e986b0712efc453> @lesshaste Do you have any good datasets in mind with missing values for benching?
[2016-02-16T09:29:19.226Z] <564789be16b6c7089cbab8b7> @rvraghav93  is this for time series data or something else?
[2016-02-16T09:29:26.205Z] <53135b495e986b0712efc453> I tried to test my implementation of MCAR and NMAR (missingness correlated with class 1) on the covtype dataset and looks like the implementation in #5974 seems to perform slightly better than or as good as imputation for NMAR cases, which was expected and really bad performance for the MCAR case, which is also expected as it tries to extract information out of utter randomness.
[2016-02-16T09:29:50.502Z] <564789be16b6c7089cbab8b7> CAR == completely at random. What is MAR again?
[2016-02-16T09:30:28.385Z] <564789be16b6c7089cbab8b7> ok I am back in context :)
[2016-02-16T09:30:46.809Z] <53135b495e986b0712efc453> MAR is one where the missingness is dependent on either the missing values or the observed values (`X`). MCAR is where the missingness is totally random... and NMAR is where the missingness is correlated with the target...
[2016-02-16T09:31:17.946Z] <53135b495e986b0712efc453> for our case we can assume MAR and MCAR are similar for they both will perform better with imputation...
[2016-02-16T09:31:45.302Z] <564789be16b6c7089cbab8b7> @rvraghav93  I think you mean MNAR 
[2016-02-16T09:31:48.419Z] <564789be16b6c7089cbab8b7> missing not at random
[2016-02-16T09:31:59.426Z] <53135b495e986b0712efc453> or Not Missing At Random ;)
[2016-02-16T09:32:21.816Z] <53135b495e986b0712efc453> hehe both mean the same... some papers use MNAR and some NMAR I think
[2016-02-16T09:32:43.145Z] <564789be16b6c7089cbab8b7> not missing at random sounds too much like the data is not missing to me :)
[2016-02-16T09:33:02.398Z] <53135b495e986b0712efc453> Ah hmm
[2016-02-16T09:34:29.478Z] <564789be16b6c7089cbab8b7> but to answer you question.. I don't have any great test sets sorry.. but when I have a moment I will search online to see if I can find smoe
[2016-02-16T09:34:41.168Z] <53135b495e986b0712efc453> Okay thanks!!
[2016-02-16T09:35:12.236Z] <564789be16b6c7089cbab8b7> does R use any particular test set for this?
[2016-02-16T09:36:16.459Z] <53135b495e986b0712efc453> I don't know this implementation seems intuitive and is supported by Ding and Simonoff's paper but apparently none of the R packages use this... A lot use multiple techniques of imputation and rpart alone uses a surrogate split method...
[2016-02-16T09:37:10.406Z] <564789be16b6c7089cbab8b7> ah...
[2016-02-16T09:37:16.891Z] <564789be16b6c7089cbab8b7> http://www.stat.columbia.edu/~gelman/arm/missing.pdf is quite definitive too
[2016-02-16T09:37:54.438Z] <564789be16b6c7089cbab8b7> of course what would be great would be to test your method against rpart on the same data :)
[2016-02-16T09:37:55.975Z] <53135b495e986b0712efc453> Okay thanks for the link
[2016-02-16T09:38:29.815Z] <53135b495e986b0712efc453> Yea :/ thats what I am planning to do now and see how good it performs...
[2016-02-16T09:38:53.391Z] <564789be16b6c7089cbab8b7> is this the paper you are using http://people.stern.nyu.edu/jsimonof/jmlr10.pdf ?
[2016-02-16T09:38:58.809Z] <53135b495e986b0712efc453> yeapp
[2016-02-16T09:39:33.561Z] <53135b495e986b0712efc453> That seems to be pretty detailed... I am gonna give it a thorough read now and see how I can reproduce their results...
[2016-02-16T09:39:42.234Z] <53135b495e986b0712efc453> That and rpart
[2016-02-16T09:41:29.500Z] <53135b495e986b0712efc453> @jmschrei Your thoughts on #5974 ?
[2016-02-16T09:41:40.950Z] <564789be16b6c7089cbab8b7> @rvraghav93  too much to read! http://link.springer.com/article/10.1007/s10115-011-0424-2 :)
[2016-02-16T09:41:56.910Z] <564789be16b6c7089cbab8b7> @rvraghav93  I think what you are doing is awesome :)
[2016-02-16T09:42:09.874Z] <564789be16b6c7089cbab8b7> and I really love the way things are done by the devs at scikit learn
[2016-02-16T09:42:13.430Z] <53135b495e986b0712efc453> :)
[2016-02-16T09:42:17.954Z] <53135b495e986b0712efc453> thanks for the links!
[2016-02-16T09:42:35.418Z] <564789be16b6c7089cbab8b7> what I particularly love is the way that methods are rejected if they can't be shown to actually work on publicly available data!
[2016-02-16T09:43:00.961Z] <564789be16b6c7089cbab8b7> if only everything was so evidence based
[2016-02-16T09:44:45.834Z] <564789be16b6c7089cbab8b7> and also the aim to automate everything :)  I am excited by the PR to automate the choice of the number of clusters for example when clustering
[2016-02-16T09:45:44.017Z] <564789be16b6c7089cbab8b7> @rvraghav93  can you access that paper I linked to?
[2016-02-16T10:08:41.101Z] <564789be16b6c7089cbab8b7> @rvraghav93  the paper I linked to also has links public data sets it uses to test its missing value imputation .  They are all fro http://archive.ics.uci.edu/ml/ I think
[2016-02-16T10:10:31.894Z] <564789be16b6c7089cbab8b7> @rvraghav93  there is even a "missing values?" field I see :) E.g. https://archive.ics.uci.edu/ml/datasets/Horse+Colic
[2016-02-16T16:36:48.885Z] <53135b495e986b0712efc453> Oops @lesshaste Thanks for correcting me... Its MNAR not NMAR :( I've been using it wrongly all along
[2016-02-16T18:36:29.630Z] <564789be16b6c7089cbab8b7> np :)
[2016-02-16T18:38:01.340Z] <564789be16b6c7089cbab8b7> @rvraghav93  do you think of any those "missing values" data sets could be useful?
[2016-02-16T20:45:38.516Z] <564789be16b6c7089cbab8b7> I just asked this on the hyper-parameter optimization PR but maybe it was better for here. I don't know how relevant this is but have generic optimization methods such as basin hopping been considered and rejected for hyper-parameter optimization? 
[2016-02-16T21:50:05.356Z] <53135b495e986b0712efc453> Yea thanks the adult dataset is reasonably big and has missing values... I'm gonna try that out by encoding all the categorical values as we don't have categorical value support yet...
[2016-02-16T21:54:18.980Z] <564789be16b6c7089cbab8b7> @rvraghav93 sounds good. 
[2016-02-16T22:42:29.090Z] <5624bbb016b6c7089cb77b2a> Any answer to [this](https://github.com/scikit-learn/scikit-learn/pull/2805)?
[2016-02-17T09:42:24.056Z] <564789be16b6c7089cbab8b7> @rvraghav93  actually it might be worth saying what I do in practice. I run dictvectorizer with categorical variables and then missing values just become another category. It would be great to compare to that approach as it works quite well, at least when I use a decision tree based classifier/regressor
[2016-02-17T09:43:25.778Z] <564789be16b6c7089cbab8b7> maybe it wouldn't work so well with other classifiers but that would also be good to know
[2016-02-17T14:24:59.898Z] <561d08d0d33f749381a937bf> Is there any point to train_test_split when I could be simply using GridSearchCV?
[2016-02-17T16:10:12.045Z] <564789be16b6c7089cbab8b7> @Fredilly  speed?
[2016-02-17T19:20:40.845Z] <56c4c780e610378809c1f19a> Hello, please review my pull request: https://github.com/scikit-learn/scikit-learn/pull/5900
[2016-02-18T06:31:58.715Z] <5363a92c048862e761fa03c3> I am trying to update my local scikit-learn folder by using `git pull upstream master` but then I am getting this: ``` (devscikit)kaichogami@kaichogami:~/codes/development_scikit-learn/scikit-learn$ git pull upstream master From https://github.com/scikit-learn/scikit-learn  * branch            master     -> FETCH_HEAD Updating 1aa0ec2..1b27536 error: The following untracked working tree files would be overwritten by merge: 	continuous_integration/circle/build_doc.sh 	continuous_integration/circle/check_build_doc.py 	continuous_integration/circle/push_doc.sh 	doc/tutorial/statistical_inference/unsupervised_learning_fixture.py 	examples/cluster/plot_face_compress.py 	examples/cluster/plot_face_segmentation.py 	examples/cluster/plot_face_ward_segmentation.py 	examples/mixture/plot_gmm_covariances.py Please move or remove them before you can merge. Aborting ``` I messed up some merge conflicts although that I was not in `master` branch.  What would be the best approach to resolve this?
[2016-02-18T06:45:33.965Z] <56c4f19ae610378809c1f8ae> hmm
[2016-02-18T06:45:43.344Z] <56c4f19ae610378809c1f8ae> im presuming you want to preserve the untracked working tree files?
[2016-02-18T14:03:58.954Z] <541a528b163965c9bc2053de> Assuming you don't care about any local changes to your master branch or uncommit changes:  ```bash git checkout master git reset --hard upstream/master ```
[2016-02-18T14:07:16.558Z] <541a528b163965c9bc2053de> BTW, you should never commit anything to your local master. Always use branches.
[2016-02-18T15:08:04.790Z] <541a528b163965c9bc2053de> @amueller I am building the wheels for osx and windows for 0.17.1, how did you sync with conda people?
[2016-02-18T15:27:38.990Z] <54d4a1d6db8155e6700f853b> @ogrisel I emailed them. give me a minute
[2016-02-18T15:28:27.567Z] <541a528b163965c9bc2053de> The 0.17.1 tag is already public
[2016-02-18T15:28:33.203Z] <541a528b163965c9bc2053de> I am ready to upload :)
[2016-02-18T15:28:44.300Z] <54d4a1d6db8155e6700f853b> just email support@continuum.io
[2016-02-18T15:28:52.761Z] <541a528b163965c9bc2053de> actually no, I would like to run a couple more tests.
[2016-02-18T15:29:06.325Z] <54d4a1d6db8155e6700f853b> I cc'ed peter wang, which might have helped the process lol
[2016-02-18T15:29:11.335Z] <541a528b163965c9bc2053de> Alright I will sync up with them
[2016-02-18T15:29:31.942Z] <54d4a1d6db8155e6700f853b> thanks for working on the release again, and sorry I'm not more help
[2016-02-18T15:29:48.219Z] <54d4a1d6db8155e6700f853b> I'm doing a company visit today and also I'm dead sick. hurray ^^
[2016-02-18T15:32:36.093Z] <541a528b163965c9bc2053de> No pbm :) Hope you'll feel better soon. BTW thanks for the PyData Berlin reco :)
[2016-02-18T15:35:22.829Z] <53135b495e986b0712efc453> @ogrisel Ah caught you on gitter - Now could you please review and merge this - #6254 ? :P
[2016-02-18T15:37:52.158Z] <541a528b163965c9bc2053de> done :)
[2016-02-18T15:37:58.511Z] <53135b495e986b0712efc453> Merci ;)
[2016-02-18T15:38:30.138Z] <541a528b163965c9bc2053de> I thought your French lessons would only start next month ;)
[2016-02-18T15:40:12.748Z] <53135b495e986b0712efc453> Next month I'll progress to full sentences in French ^_^
[2016-02-18T15:41:34.865Z] <541a528b163965c9bc2053de> I sent an email to continuum.
[2016-02-18T17:07:29.285Z] <5363a92c048862e761fa03c3> @nelson-liu 
[2016-02-18T17:13:16.205Z] <5363a92c048862e761fa03c3> @nelson-liu I think I accidentally committed in `master` which resulted in that.  @ogrisel Thank you, that helped me. I do use different branches. Will be extra careful next time! :) 
[2016-02-18T18:19:12.125Z] <541a528b163965c9bc2053de> scikit-learn 0.17.1 is online!
[2016-02-18T18:19:13.747Z] <541a528b163965c9bc2053de> :beers:
[2016-02-18T18:19:33.616Z] <56c4f19ae610378809c1f8ae> :clap: 
[2016-02-18T18:31:58.090Z] <56c4f19ae610378809c1f8ae> @kaichogami got it, glad you got it fixed!
[2016-02-18T20:14:55.079Z] <56c625c3e610378809c22760> Never knew that the gitter channel was this active! @nelson-liu please add this to the doc!
[2016-02-18T20:17:16.918Z] <56c4f19ae610378809c1f8ae> yeah I find it a bit odd that it isnt in there already...searching gitter in the repos issue history even shows many people referencing collaborating / talking on it. at least its much more active than irc :P
[2016-02-18T20:18:13.061Z] <56c625c3e610378809c22760> haha yeah true
[2016-02-18T21:24:42.282Z] <564789be16b6c7089cbab8b7> 
[2016-02-19T04:52:44.300Z] <561d08d0d33f749381a937bf> Why does predict_proba give better accuracy than the predict function? Whats the difference? 
[2016-02-19T04:53:29.619Z] <561d08d0d33f749381a937bf> What are the best parameters for param_grid when performing GridSearchCV on  svm?
[2016-02-19T05:04:29.159Z] <561d08d0d33f749381a937bf> @ogrisel wohoo
[2016-02-19T05:11:06.517Z] <56c4f19ae610378809c1f8ae> I'll try to answer your question in a few minutes when I return to a computer. 
[2016-02-19T05:22:54.082Z] <56c4f19ae610378809c1f8ae> @Fredilly as for your second question, it really depends on your dataset. Could you describe it? 
[2016-02-19T05:24:42.127Z] <56c4f19ae610378809c1f8ae> for predict_proba vs predict, theyre two completely different methods. predict_proba predicts the probability of your input being a certain class. Predict returns what class the model predicts your input to be (e.g. by taking the class with the highest probability from predict_proba)
[2016-02-19T05:24:47.727Z] <56c4f19ae610378809c1f8ae> does that make sense?
[2016-02-19T05:28:44.217Z] <56c4f19ae610378809c1f8ae> (if anyone else wants to clarify / correct / validate my explanation, please do)
[2016-02-19T09:18:25.276Z] <561d08d0d33f749381a937bf> @nelson-liu That makes sense. From my understanding, predict_proba does the same thing as predict but it requires a threshhold value to activate in case of binary outputs. It still doesnt explain why it gets better results
[2016-02-19T09:19:15.282Z] <56c4f19ae610378809c1f8ae> Im not sure what you mean by <unconvertable> get better results. are you doing binary classification?
[2016-02-19T09:21:01.856Z] <561d08d0d33f749381a937bf> Yes...I get .55 score with predict and .88 score with predict_proba
[2016-02-19T09:23:14.223Z] <56c4f19ae610378809c1f8ae> how are you getting a score with predict_proba? shouldnt it output an array with 2 elements?
[2016-02-19T09:25:46.684Z] <561d08d0d33f749381a937bf> It does, but I slice the output and use the one that gives a true value. 
[2016-02-19T09:26:36.816Z] <56c4f19ae610378809c1f8ae> so to verify, you slice the output, find out which has the highest probability, and use that as the predicted, correct? what class are you using for classification?
[2016-02-19T09:27:41.338Z] <561d08d0d33f749381a937bf> Logistic Regression and Gradient Boosting Classifier
[2016-02-19T09:29:41.251Z] <56c4f19ae610378809c1f8ae> hmm how are you using two?
[2016-02-19T09:30:25.581Z] <561d08d0d33f749381a937bf> I tried both separately just to see which produced a better result and noticed that predict_proba gave a much higher accuracy in both cases.
[2016-02-19T09:31:22.299Z] <561d08d0d33f749381a937bf> Should that always be the case? Im always discovering new techniques that completely invalidate everything else Ive learned.
[2016-02-19T09:31:56.116Z] <56c4f19ae610378809c1f8ae> well generally the way predict works it that it takes the likelihoods generated by predict_proba, and then chooses the most likely one
[2016-02-19T09:32:01.481Z] <56c4f19ae610378809c1f8ae> so they should be the same.
[2016-02-19T09:32:04.877Z] <56c4f19ae610378809c1f8ae> i feel like that shouldnt be happening haha but I have no empirical evidence to back up my claims. would you mind letting me see your code to ensure there are no random bugs?
[2016-02-19T09:39:19.744Z] <561d08d0d33f749381a937bf> ``` encoder = preprocessing.OneHotEncoder() encoder.fit(np.vstack((X, X_test))) X = encoder.transform(X) X_test = encoder.transform(X_test)  # LogisticRegression logreg = LogisticRegression(C=3) logreg.fit(X, y) y_pred = logreg.predict_proba(X_test)[:, 1] df = pd.DataFrame({'id': test.id, 'Action': y_pred}) df.tail() df.to_csv('kagglesubmission.csv') #scores about .88  ```
[2016-02-19T09:44:49.014Z] <56c4f19ae610378809c1f8ae> why do you slice [:, 1]?
[2016-02-19T09:46:51.021Z] <56c4f19ae610378809c1f8ae> Maybe theres some pandas magic going on that Im not familiar with, but if you slice [:,1] arent you always getting the probabilities of the second element of model.classes_? Is there some way that you check whether this is greater than or less than the probability of the other class, and then put the correctly labeled prediction into the df?
[2016-02-19T09:47:40.034Z] <561d08d0d33f749381a937bf> That way I select the column with a probability of 1.  
[2016-02-19T09:47:50.837Z] <561d08d0d33f749381a937bf> This is more magic than science to me.
[2016-02-19T09:49:06.049Z] <561d08d0d33f749381a937bf> One quick question: Is it possible that gridsearchcv give worse score accuracy? I get .946 off the bat on an svm implementation but I get about .92 with the best parameters from gridsearchcv.
[2016-02-19T09:49:58.746Z] <56c4f19ae610378809c1f8ae> its possible that you might not be controlling for randomness between grid search and if you do a train test split or something. You should set a consistent random seed to ensure replicability.
[2016-02-19T09:52:00.027Z] <56c4f19ae610378809c1f8ae> (in response to your previous comment about selecting the column with probability 1) hmm thats not how it works. lets say you have a model that takes in inputs x, y and you want to predict whether these inputs belong in A or B from it (binary classification). if you call predict_proba([x,y]), then it would output an array with the probabilities that the input [x,y] is each class, e.g. np.array([[ 0.4,0.6]]).
[2016-02-19T09:53:18.613Z] <56c4f19ae610378809c1f8ae> lets say the output of `model.classes_` is `[A,B]`. This would indicate that the input vector you fed in (`[x,y]`) has a 40% chance of being something of class A, and a 60% chance of being something in class B.
[2016-02-19T09:55:53.142Z] <561d08d0d33f749381a937bf> I see what you mean but choosing the column with the highest true positives means you can immediately compare with null accuracy and decide whether to improve sensitivity of specificity.
[2016-02-19T09:56:31.690Z] <56c4f19ae610378809c1f8ae> what do you mean highest true positives?
[2016-02-19T09:58:05.836Z] <561d08d0d33f749381a937bf> Predicting a correct value of true. Eg predicting >0.5 when the real value is 1
[2016-02-19T09:59:23.474Z] <561d08d0d33f749381a937bf> In my classification problem, if I just predicted 1 everytime, I would be correct 94% of the time.
[2016-02-19T10:00:21.971Z] <561d08d0d33f749381a937bf> One of the two columns, [X, y] would have more 1s. When I slice, I use that column for predictions.
[2016-02-19T10:00:29.173Z] <56c4f19ae610378809c1f8ae> Oh. is that just an innate feature of the dataset? So basically you want to predict based on some sort of confidence ratio? e.g. you know its most likely 1, so predict 1 every time unless theres a very high confidence for 0?
[2016-02-19T10:01:08.722Z] <56c4f19ae610378809c1f8ae> what do the two columns [X,y] represent?
[2016-02-19T10:02:57.728Z] <561d08d0d33f749381a937bf> They represent whether a user is granted access permission or not
[2016-02-19T10:03:22.035Z] <56c4f19ae610378809c1f8ae> no sorry i mean is [x,y] the input, the result of predict_proba(), etc?
[2016-02-19T10:04:46.520Z] <561d08d0d33f749381a937bf> its the result of the predict_proba
[2016-02-19T10:06:50.904Z] <56c4f19ae610378809c1f8ae> when you have the return result of predict_proba(), the confidence of 1 is in one column and the confidence of 0 is the other. you cant really pick out <unconvertable> which column has more ones?
[2016-02-19T10:07:49.822Z] <56c4f19ae610378809c1f8ae> (on that note, the reason why predict() and predict_proba() are different is because of the way youre using predict_proba() is not the same as how predict() would generate labels for your input vectors)
[2016-02-19T10:08:37.066Z] <561d08d0d33f749381a937bf> You certainly can. Simply print out the first X elements of both columns and youll see a pattern immediately.
[2016-02-19T10:08:39.318Z] <561d08d0d33f749381a937bf> I see what you mean.
[2016-02-19T10:09:26.119Z] <56c4f19ae610378809c1f8ae> when you print out the two columns, do you get 0s and 1s..?
[2016-02-19T10:09:48.440Z] <56c4f19ae610378809c1f8ae> the 0s and 1s are categorical and are assigned to one column each
[2016-02-19T10:10:17.573Z] <561d08d0d33f749381a937bf> I get 0.10~0.99
[2016-02-19T10:10:56.492Z] <56c4f19ae610378809c1f8ae> ok, that seems fairly reasonable. I feel like the reason you see a pattern is simply because 95% of your dataset is labeled one haha.
[2016-02-19T10:11:55.830Z] <561d08d0d33f749381a937bf> Exactly.....going through the trouble of squeezing that extra 1% is insane.
[2016-02-19T10:12:22.713Z] <56c4f19ae610378809c1f8ae> then why even bother using ml if you could just always guess `1` and be right 95% of the time?
[2016-02-19T10:12:32.284Z] <561d08d0d33f749381a937bf> Tell that to Kaggle
[2016-02-19T10:12:53.713Z] <56c4f19ae610378809c1f8ae> oh its a kaggle competition? would you mind sending me the link. that may help me explain haha
[2016-02-19T10:13:28.640Z] <561d08d0d33f749381a937bf> https://www.kaggle.com/c/amazon-employee-access-challenge
[2016-02-19T10:13:58.484Z] <561d08d0d33f749381a937bf> Getting my feet wet.....my head is spinning....most of this is just trial and error. 
[2016-02-19T10:15:25.210Z] <56c4f19ae610378809c1f8ae> hmm if you want to get your feet wet, id suggest titanic on kaggle. This is a pretty good tutorial https://github.com/savarin/pyconuk-introtutorial
[2016-02-19T10:16:24.736Z] <56c4f19ae610378809c1f8ae> but regardless, predict_proba() doesnt work the way you think it does. Taking one column and encoding everything as that only happens to work because a large portion of your dataset is one label.
[2016-02-19T10:17:53.777Z] <561d08d0d33f749381a937bf> I did that one....was pretty helpful. The employee challenge and vowpal rabbit challenge prepare you more thoroughly for real world ML problems
[2016-02-19T10:18:21.989Z] <56c4f19ae610378809c1f8ae> did you use predict_proba() in titanic?
[2016-02-19T10:19:05.538Z] <56c4f19ae610378809c1f8ae> its probably best to just stick to using predict() and further tuning your model / performing feature selection
[2016-02-19T10:19:33.021Z] <56c4f19ae610378809c1f8ae> Its just a coincidence in this case that predict_proba() seems to work so much better than predict()
[2016-02-19T10:20:15.331Z] <561d08d0d33f749381a937bf> From what Ive gathered so far, tuning features is tedious and not usually worth the hassle unless you have like a 100 features.
[2016-02-19T10:20:49.048Z] <56c4f19ae610378809c1f8ae> thats not always true haha. feature engineering is quite important in the real world to distinguish signal from noise in data.
[2016-02-19T10:22:23.234Z] <56c4f19ae610378809c1f8ae> e.g. if you wanted to predict whether an employee has access and you were given information about their salary, working hours, and favorite place to eat lunch on amazons campus. this is only 3 features, but its quite evident that where they eat lunch on amazons campus likely has no correlation / is not related to whether theyd have access.
[2016-02-19T10:23:13.636Z] <56c4f19ae610378809c1f8ae> actually thats not necessarily true, maybe there are more high scale places reserved for executives or something but do you see my point?
[2016-02-19T10:24:35.258Z] <561d08d0d33f749381a937bf> Youre probably right. Thats where <unconvertable> domain expertise <unconvertable> or just plain old common sense comes into play.
[2016-02-19T10:26:43.212Z] <56c4f19ae610378809c1f8ae> Yup. 
[2016-02-19T10:27:39.676Z] <56c4f19ae610378809c1f8ae> Beyond that, feature engineering in terms of normalization and other transformations on the data can also be quite useful to do things like remove outliers, etc. 
[2016-02-19T10:29:41.145Z] <561d08d0d33f749381a937bf> Youre absolutely right. Have you tried gbm? Its awesome....I wanna learn more about XGboost. They produce high accuracies right off the bat.
[2016-02-19T10:50:19.391Z] <564789be16b6c7089cbab8b7> In https://github.com/scikit-learn/scikit-learn/pull/5491 I am confused by which classifier is having its hyper parameters optimized in the examples with graphs. Does anyone know?
[2016-02-19T11:30:35.359Z] <564789be16b6c7089cbab8b7> @MechCoder If you happen to be about I think this question is aimed at you :)
[2016-02-19T14:33:49.342Z] <541a528b163965c9bc2053de> if your possible target classes are consecutive integers like `[0, 1, 2]` the `predict(X_test)` should return the same as `predict_proba(X_test).argmax(axis=1)`. `predict_proba` is just a way to ask for the confidence levels of the model when it's making a prediction. The final classification decision should be exactly the same.
[2016-02-20T06:58:05.773Z] <56c4f19ae610378809c1f8ae> @rvraghav93 and @jnothman I just uploaded a first draft of the issue / pr template we were discussing, please let me know what you think :) its at #6411.
[2016-02-20T15:52:47.648Z] <544906e2db8155e6700cdd16> @Fredilly Here's my two cents... I think that the difference that you saw in the results is related to the metric used by Kaggle to measure the performance: Area Under the (ROC) Curve. According to this issue (https://github.com/scikit-learn/scikit-learn/issues/1393) the auc score will give better scores if you feed it with probabilities instead of binary decisions. 
[2016-02-22T09:20:50.960Z] <56c4f19ae610378809c1f8ae> hey @ogrisel not sure if youre around, but Im having some issues rebasing commits in https://github.com/scikit-learn/scikit-learn/pull/6417. I took the original contributors commits and rebased master on top of it. However, I am trying to squash it now and am unable to. Do you have any advice as to how to fix this?
[2016-02-22T10:03:32.543Z] <541a528b163965c9bc2053de> @nelson-liu done
[2016-02-22T10:04:26.730Z] <541a528b163965c9bc2053de> I meant I gave it a review. It seems squashed enough to me. What problems do you have?
[2016-02-22T10:05:28.107Z] <56c4f19ae610378809c1f8ae> Ah, thanks! well, commit https://github.com/nelson-liu/scikit-learn/commit/6209098c38cb7aa4e7aad381407da6f42fe7b464 has quite a long diff, and Id rather not pollute the commit history with that
[2016-02-22T10:05:51.849Z] <56c4f19ae610378809c1f8ae> additionally, itd be nice to squash the commits into 1 instead of having 4 separate commits
[2016-02-22T10:14:15.046Z] <56c4f19ae610378809c1f8ae> when I currently try to squash the commits, i get a bunch of merge conflicts and such. running `git rebase -i HEAD~3` (to squash my last 3 commits) ends up for some reason pulling up interactive rebase for ~211 commits onto https://github.com/nelson-liu/scikit-learn/commit/09672f516d8592fb82f42e5da3ee0f29210d7366, even though the head is at https://github.com/nelson-liu/scikit-learn/commit/8bea87efc7f6db484f583c15d36a775d82381ef3
[2016-02-22T10:17:45.966Z] <541a528b163965c9bc2053de> Right I did no see that from the github diff view of the PR. Indeed this comment should be removed.
[2016-02-22T10:19:45.589Z] <541a528b163965c9bc2053de> I would start over again from the original contributor's PR. Squash the top commits first, then rebase on master and fix the conflicts. Then add your changes on top and squash again.
[2016-02-22T10:20:42.935Z] <541a528b163965c9bc2053de> nelson-liu/scikit-learn@6209098 has many changes with conflict markers that should not be part of this PR.
[2016-02-22T10:21:13.327Z] <541a528b163965c9bc2053de> The commits in https://github.com/scikit-learn/scikit-learn/pull/5968 are clean though.
[2016-02-22T10:21:13.828Z] <56c4f19ae610378809c1f8ae> got it
[2016-02-22T10:29:59.066Z] <56c4f19ae610378809c1f8ae> how do you generally resolve merge conflicts? im using `git mergetool`, which is opening opendiff on my osx machine
[2016-02-22T10:30:19.573Z] <56c4f19ae610378809c1f8ae> wondering if this might be why conflict markers are there?
[2016-02-22T10:40:51.870Z] <56c4f19ae610378809c1f8ae> anyway, I just pushed a new version at https://github.com/scikit-learn/scikit-learn/pull/6419. can you let me know if there are any issues?
[2016-02-22T10:41:30.498Z] <541a528b163965c9bc2053de> edit the files with the conflicts,  look for section with conflict markers, edit the code to replace the segments in conflict with the expected code segment and remove the markers
[2016-02-22T10:42:19.075Z] <56c4f19ae610378809c1f8ae> ah ok, i wasnt aware that you could just do it through the text editor. I think ive properly done it in the last PR, could you let me know?
[2016-02-22T10:42:24.179Z] <541a528b163965c9bc2053de> check that there are no other files with conflict markers and then `git add` the files where you resolved the conflicts and `git rebase --continue`
[2016-02-22T18:43:11.662Z] <54d4a1d6db8155e6700f853b> does anyone have a good example of when l2 normalizer is useful? I only ever really use l1
[2016-02-22T18:43:52.319Z] <541a528b163965c9bc2053de> if you want to compute cosine similarities: preprocess the data once and then use np.dot.
[2016-02-22T22:38:15.045Z] <54d4a1d6db8155e6700f853b> hm... good point, but slightly to advanced ^^
[2016-02-23T09:20:09.975Z] <56b80528e610378809c05a48> Hello @amueller , sorry for disrupting you. Could you please answer my question in #6322 ?
[2016-02-23T09:20:25.100Z] <541a528b163965c9bc2053de> For TF-IDF vectorization, normalizing by l2 norm makes BoW representation more invariant to doc length (similar idea but rephrased :).
[2016-02-23T09:35:03.026Z] <56c4f19ae610378809c1f8ae> Maybe a bit off topic, but should the topic in the IRC channel be changed to reflect the release of 0.17.1? (Does anyone ever use the IRC anymore? Ive been on it for the past week and havent seen a single message in the channel)
[2016-02-23T09:37:13.146Z] <541a528b163965c9bc2053de> I don't remember who has op rights. I think I do but I don't remember the password of my NickServ account.
[2016-02-23T09:40:10.416Z] <56c4f19ae610378809c1f8ae> seems like only @amueller does, or thats what `/msg chanserv access #scikit-learn LIST` is reporting.
[2016-02-23T12:34:20.485Z] <53135b495e986b0712efc453> @ogrisel could you close this - https://github.com/scikit-learn/scikit-learn/issues/5622
[2016-02-24T22:06:05.132Z] <54e07d6515522ed4b3dc0858> any reason why `GradientBoostingClassifier`'s `decision_function` does not allow sparse data? ([relevant line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/gradient_boosting.py#L1469))
[2016-02-24T22:06:36.128Z] <54e07d6515522ed4b3dc0858> basically you can fit on sparse, but can't predict
[2016-02-24T22:07:49.296Z] <54e07d6515522ed4b3dc0858> Hmm, got it, it's because [`predict_stages`](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/_gradient_boosting.pyx#L101) doesn't support it.
[2016-02-25T09:48:34.169Z] <56aa7e09e610378809beb481> hi
[2016-02-25T14:14:44.684Z] <53135b495e986b0712efc453> Hello @unautre 
[2016-02-25T14:15:17.006Z] <53135b495e986b0712efc453> BTW Can anyone give a final review on https://github.com/scikit-learn/scikit-learn/pull/5568 (@amueller @ogrisel @vighneshbirodkar?)
[2016-02-25T15:54:09.193Z] <56b80528e610378809c05a48> Sorry to disturb. Can anyone please help review on #6371  and #6395 ? A merge can urge me to face my midterm tomorrow :pray: 
[2016-02-25T16:12:02.052Z] <54d4a1d6db8155e6700f853b> @rvraghav93 I'll try to review #5568 today
[2016-02-25T16:38:10.335Z] <56c625c3e610378809c22760> Just had a doubt regarding issue #6443. How is it that this failure is not happening on travis but is just happening locally? Shouldn't both be synced atleast for the same python version?
[2016-02-25T17:04:24.147Z] <56c625c3e610378809c22760> Is anybody else getting this error on their system or is it just me :/
[2016-02-25T17:22:18.328Z] <53135b495e986b0712efc453> @amueller Thanks a tonnnnnne for the review!
[2016-02-25T17:22:42.446Z] <53135b495e986b0712efc453> @yenchenlin1994 I can have a look...
[2016-02-25T17:33:33.863Z] <54d4a1d6db8155e6700f853b> @rvraghav93 sorry for being kinda offline at the moment. I really wanna get going with the book ;)
[2016-02-25T17:33:56.322Z] <54d4a1d6db8155e6700f853b> btw, do you know if anyone started working on the multiple metrics? I think @MechCoder asked me about it.
[2016-02-25T18:14:39.564Z] <56b80528e610378809c05a48> @rvraghav93 thanks a lot!
[2016-02-25T18:37:37.682Z] <56c625c3e610378809c22760> could someone also help review #6176 and #6173 if time permits :P
[2016-02-29T16:29:13.069Z] <56d19aa5e610378809c3dde8> Hello! Can anyone tell me how can I make this python script ignore DS store files... very silly issue. I have this function, I've googled but I don't know where to put the code in my current function. Thank you!  def list_files(dir): 	r = [] 	subdirs = [x[0] for x in os.walk(dir)]  	for subdir in subdirs: 		files = os.walk(subdir).__next__()[2] 		if (len(files) > 0): 			for file in files: 				r.append(subdir + "/" + file) 	return r      the_list = list_files(file_rep)
[2016-02-29T16:39:08.524Z] <56c4f19ae610378809c1f8ae> I dont think this is necessarily the proper venue for your question. That being said, your code doesnt work properly on my mac. Theoretically though, you would wrap your `r.append()` statement in an if-block that checks if the filename is .DS_Store.
[2016-02-29T16:40:59.292Z] <54d4a1d6db8155e6700f853b> @thejivester you can go to stackoverflow
[2016-02-29T19:05:45.348Z] <56c4f19ae610378809c1f8ae> Did scikit-learn apply to Google summer of code? 
[2016-02-29T21:15:23.301Z] <54d4a1d6db8155e6700f853b> @nelson-liu it is under the umbrella of the PSF
[2016-02-29T21:16:29.708Z] <56c4f19ae610378809c1f8ae> Ah ok. I talked to Terri and she said that scikit-learn hasn't submitted a proposal yet, are there plans to do so? 
[2016-02-29T21:19:22.736Z] <54d4a1d6db8155e6700f853b> was the deadline already? Yes, there is a plan to submit a proposal
[2016-02-29T21:20:12.219Z] <56c4f19ae610378809c1f8ae> Oh OK, just wanted to know. The deadline is March 8th iirc
[2016-02-29T21:20:20.130Z] <56c4f19ae610378809c1f8ae> (don't quote me on that) 
[2016-02-29T21:20:27.422Z] <54d4a1d6db8155e6700f853b> 7th of march
[2016-02-29T21:31:31.659Z] <54d4a1d6db8155e6700f853b> @rvraghav93 do you have anything for the multiple metrics? I think it might be easier to work on that before trying to clean up
[2016-02-29T21:47:41.786Z] <54d4a1d6db8155e6700f853b> If you're busy with your other PRs, I can look into it.
[2016-02-29T22:38:29.939Z] <53135b495e986b0712efc453> Okay please go ahead. I am just fighting with the tree code. I am sorry :/ I will take up something else instead of it later.... 
[2016-03-01T00:25:26.457Z] <53810862048862e761fa2887> Guys, take a look at http://contrib.scikit-learn.org/project-template/
[2016-03-01T00:26:07.880Z] <53810862048862e761fa2887> Right now the because of the code and website being hosted in the same root folder, the source files are available on that url
[2016-03-01T00:26:30.698Z] <53810862048862e761fa2887> For example,  http://contrib.scikit-learn.org/project-template/setup.py. Is that a problem ?
[2016-03-01T00:45:18.500Z] <56c4f19ae610378809c1f8ae> i registered scikit-learn.ml and redirected it to the main site haha
[2016-03-01T00:46:07.952Z] <56c4f19ae610378809c1f8ae> [http://scikit-learn.ml](http://scikit-learn.ml)
[2016-03-01T07:27:36.249Z] <53135b495e986b0712efc453> Thats sweet! You should ping @ogrisel 
[2016-03-01T07:28:41.856Z] <56c4f19ae610378809c1f8ae> on another note, does anyone know whether its possible to do multi-line links in markdown? If not, maybe we can get a scikit-learn link shortener to make the issue/pr template more digestible.
[2016-03-01T07:30:05.649Z] <56c4f19ae610378809c1f8ae>  short things like [http://sklearn.ml/contributing](http://sklearn.ml/contributing)
[2016-03-01T07:30:30.796Z] <53135b495e986b0712efc453> Did you register sklearn.ml too? :P
[2016-03-01T07:31:15.667Z] <56c4f19ae610378809c1f8ae> haha yeah .ml domains are free and quite applicable to a variety of projects i feel haha
[2016-03-01T07:31:34.272Z] <56b80528e610378809c05a48> smart move haha
[2016-03-01T07:32:03.985Z] <56c4f19ae610378809c1f8ae> was just trying to see if there was a way to cut down clutter in docs, so the idea of link shortening came up (e.g. how google does goo.gl)
[2016-03-01T07:39:36.194Z] <53135b495e986b0712efc453> Really? I am getting one then ;)
[2016-03-01T07:55:43.851Z] <53135b495e986b0712efc453> @nelson-liu Thanks for the nice idea :D
[2016-03-01T07:56:00.804Z] <56c4f19ae610378809c1f8ae> np =)
[2016-03-01T08:57:37.902Z] <56c4f19ae610378809c1f8ae> aw, just got an email that for some reason [sklearn.ml](sklearn.ml) was already registered and that i dont have the rights to it. oh well, [scikit-learn.ml](scikit-learn.ml) will do for link shortening.
[2016-03-01T08:57:47.598Z] <56c4f19ae610378809c1f8ae> in that vein, should we move the discussion about the issue / pr template to https://github.com/scikit-learn/scikit-learn/issues/6394 or just create a new issue?
[2016-03-01T13:20:08.736Z] <53135b495e986b0712efc453> Arrrgh some advertising company purchased sklearn.ml. It would have been cool to have it redirect to our page too!
[2016-03-01T16:59:23.159Z] <54e07d6515522ed4b3dc0858> why is it important to have different domains?
[2016-03-01T17:30:50.256Z] <56c4f19ae610378809c1f8ae> Have you taken a look at the pr / issue template? 
[2016-03-01T17:31:35.130Z] <56c4f19ae610378809c1f8ae> A lot of the links in there are very long, and since you can't create multi-line links in markdown it greatly diminishes readability 
[2016-03-01T17:31:57.669Z] <56c4f19ae610378809c1f8ae> So I was thinking maybe use the  .ml domain for link shortening internally 
[2016-03-01T17:32:17.003Z] <56c4f19ae610378809c1f8ae> Basically: it's not important, just an idea haha
[2016-03-01T19:21:39.287Z] <53135b495e986b0712efc453> @vene I thought it would be cool to have a .ml domain :p BTW @nelson-liu there was a thread claiming those free .ml providers as scam. Be careful!
[2016-03-01T19:22:23.525Z] <53135b495e986b0712efc453> As for the link shortener we should implement it at our main site.
[2016-03-01T19:22:37.363Z] <56c4f19ae610378809c1f8ae> yeah, thatd be great. I didnt know we had that sort of functionality
[2016-03-01T19:22:51.853Z] <56c4f19ae610378809c1f8ae> Im drafting up a new, more template-y version of the templates right now
[2016-03-01T19:23:05.210Z] <53135b495e986b0712efc453> Sounds great!
[2016-03-01T19:23:29.894Z] <56c4f19ae610378809c1f8ae> if only there was a way to default to preview mode or something...but I feel like that would get cumbersome after awhile once youve learned the guidelines / template. Raw output is hard to format nicely.
[2016-03-01T19:27:03.518Z] <53135b495e986b0712efc453> In the end I'm guessing github will realize they just need to improve their interface rather than providing these hacky workarounds
[2016-03-01T20:32:13.174Z] <56c4f19ae610378809c1f8ae> haha that would be ideal. made a pr at https://github.com/scikit-learn/scikit-learn/pull/6470
[2016-03-03T18:50:53.421Z] <56c4f19ae610378809c1f8ae> we reached 10,000 stars today :beers: 
[2016-03-03T22:40:12.874Z] <56b80528e610378809c05a48> :+1: 
[2016-03-04T05:10:34.537Z] <56d918bde610378809c4f013> Hi
[2016-03-04T05:13:07.264Z] <56d918bde610378809c4f013> I have an issue with affinity propagation
[2016-03-04T11:51:26.705Z] <53135b495e986b0712efc453> 10k stars!! :beers:
[2016-03-05T18:17:08.632Z] <541a528b163965c9bc2053de> :beers:
[2016-03-07T19:11:30.594Z] <54d4a1d6db8155e6700f853b> @ogrisel someone just told me that doing conda upgrade --all breaks scikit-learn. I think that's related to the CI failure
[2016-03-07T20:43:19.043Z] <560313510fc9f982beb1a331> Yeah, they started bundling mkl with everything. To fix this, you should try to install `nomkl` first and then install everything else that is BLAS dependent.
[2016-03-08T17:21:05.258Z] <541a528b163965c9bc2053de> >  conda upgrade --all breaks scikit-learn  scikit-learn installed from conda or built from the source prior to the upgrade? What does break mean? A specific test fails? or a segfault at `import sklearn`?
[2016-03-08T18:10:21.309Z] <54d4a1d6db8155e6700f853b> @ogrisel running conda upgrade twice actually makes it work again
[2016-03-08T18:10:23.199Z] <54d4a1d6db8155e6700f853b> it was a linking issue
[2016-03-08T18:10:39.876Z] <54d4a1d6db8155e6700f853b> there is a specific version of sklearn on conda that is not properly linked, but I think they fixed it now
[2016-03-08T18:10:50.487Z] <54d4a1d6db8155e6700f853b> (and I meant installed from conda)
[2016-03-08T20:56:51.765Z] <541a528b163965c9bc2053de> ok great
[2016-03-08T22:01:39.374Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar maybe also compare against https://github.com/jkarnows/rpcaADMM
[2016-03-08T22:01:53.975Z] <54d4a1d6db8155e6700f853b> and possibly https://github.com/dganguli/robust-pca
[2016-03-08T22:33:56.029Z] <54d4a1d6db8155e6700f853b> oh @vighneshbirodkar you should definitely try https://gist.github.com/bmcfee/a378bfe31a75769c583e first
[2016-03-08T23:11:45.804Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar brian says to read this book ^^ http://www.web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf
[2016-03-08T23:12:10.691Z] <54d4a1d6db8155e6700f853b> (the variable names are taken from there, in particular 3.11 and 3.12)
[2016-03-09T13:09:11.619Z] <5478876cdb8155e6700d907b> hello guys, who do I badger about strange travis failures: https://github.com/scikit-learn/scikit-learn/pull/6166#issuecomment-194246460
[2016-03-09T13:09:36.723Z] <5478876cdb8155e6700d907b> in one it fails to find libgfortran and in the other some tests related to scorers and memmapping fail :-/
[2016-03-10T03:44:05.020Z] <52a485b6ed5ab0b3bf04fab6> I opened an issue here https://github.com/scikit-learn/scikit-learn/issues/6513
[2016-03-10T04:47:28.166Z] <53810862048862e761fa2887> @amueller I fixed a bug in Brian's code that was causing the low rank output to be scaled differently. It optimizes the objective better than the last PCP implementation.
[2016-03-10T15:24:50.227Z] <56cad8a7e610378809c2bef5> roles of data structure and algorithm in open source?
[2016-03-10T20:54:11.447Z] <564789be16b6c7089cbab8b7> I was reading https://github.com/scikit-learn/scikit-learn/pull/5974#issuecomment-194840168
[2016-03-10T20:54:25.818Z] <564789be16b6c7089cbab8b7> can anyone explain what MV means?
[2016-03-10T22:31:37.142Z] <53135b495e986b0712efc453> Missing Value ;)
[2016-03-10T22:32:02.154Z] <53135b495e986b0712efc453> And yes thanks please share your thoughts on it.
[2016-03-11T07:17:08.773Z] <564789be16b6c7089cbab8b7> @rvraghav93  ah thanks... I do have some small thoughts in fact
[2016-03-11T07:33:38.536Z] <564789be16b6c7089cbab8b7> @rvraghav93  first.. what are the dotted lines?
[2016-03-11T07:36:37.139Z] <564789be16b6c7089cbab8b7> @rvraghav93  and what is the bootstrap you refer to? (sorry these are naive questions)
[2016-03-11T07:37:18.021Z] <564789be16b6c7089cbab8b7> also, one standard way to handle missing values when using a random forest is just to treat them as categorical values. That is make a new feature "X is missing" and set it to 1 if it is missing.
[2016-03-11T07:37:26.689Z] <564789be16b6c7089cbab8b7> would it be worth comparing to that approach?
[2016-03-11T08:23:34.537Z] <564789be16b6c7089cbab8b7> I found the bootstrap option so please cancel that part of my question :)
[2016-03-11T11:31:31.854Z] <53135b495e986b0712efc453> Yes! You are right. This approach does exactly the same thing. It tries to send the missing values to the best partition as if it were a categorical variable.
[2016-03-11T11:31:58.905Z] <53135b495e986b0712efc453> BTW hurraayyy we have github reactions to comments and PR comments...
[2016-03-11T11:34:39.150Z] <564789be16b6c7089cbab8b7> :)
[2016-03-11T11:34:47.115Z] <564789be16b6c7089cbab8b7> @rvraghav93  isn't that a lot simpler in that case?
[2016-03-11T11:35:53.449Z] <53135b495e986b0712efc453> Sorry. I don't get you. Simpler in which case?
[2016-03-11T11:37:53.052Z] <53135b495e986b0712efc453> Oh wait you mean make a new feature for "X is missing"... Hmm no this approach does not do that...
[2016-03-11T11:38:55.541Z] <53135b495e986b0712efc453> But how will you do that? What will you do with the missing values in the features which are not "This feature is missing"?
[2016-03-11T11:40:26.843Z] <564789be16b6c7089cbab8b7> what I do in practice is make the feature categorical if it is missing and then just run dictvectorizer
[2016-03-11T11:40:32.158Z] <564789be16b6c7089cbab8b7> which handles it all for me
[2016-03-11T11:42:46.551Z] <53135b495e986b0712efc453> That just explodes your feature space no? Also could you give me a minimal code example so I can be sure to follow what you mean.
[2016-03-11T11:44:19.725Z] <564789be16b6c7089cbab8b7> it creates one new feature per feature at most
[2016-03-11T11:44:22.251Z] <564789be16b6c7089cbab8b7> so at most doubles
[2016-03-11T11:44:33.611Z] <564789be16b6c7089cbab8b7> I don't have any code here sorry
[2016-03-11T11:45:35.194Z] <53135b495e986b0712efc453> No my question is lets say I have a data `X = [[1.2,], [2.2,], [np.nan,]]` How does your new data (after your preprocessing for missing values) look like?
[2016-03-11T11:49:21.309Z] <564789be16b6c7089cbab8b7> 
[2016-03-11T11:52:43.890Z] <564789be16b6c7089cbab8b7> I think it looks like [[1.2,0], [2.2,0], [0,1]]
[2016-03-11T11:53:02.346Z] <564789be16b6c7089cbab8b7> assuming I am parsing this correctly
[2016-03-11T11:53:20.484Z] <564789be16b6c7089cbab8b7> you just add one more feature for each feature that can have a missing value
[2016-03-11T12:09:36.801Z] <564789be16b6c7089cbab8b7> @rvraghav93  does this make sense?
[2016-03-11T12:10:32.713Z] <564789be16b6c7089cbab8b7> @rvraghav93 I am not sure what you mean by "What will you do with the missing values in the features which are not "This feature is missing""
[2016-03-11T12:51:56.545Z] <53135b495e986b0712efc453> Say we have 10 features and the 10th feature has missing values. We now have 11 features right? Will that mean we amplify the importance of the 10th feature and not the other features? Anyway this is an interesting case for comparison. I will compare that and let you know how it performs in comparison with the implemented method.
[2016-03-11T12:53:47.103Z] <53135b495e986b0712efc453> My intuition is that, at a higher level, both these methods are similar...
[2016-03-11T12:54:14.688Z] <53135b495e986b0712efc453> both as in the one that you propose and my implementation at #5974
[2016-03-11T13:13:44.451Z] <564789be16b6c7089cbab8b7> @rvraghav93  "Will that mean we amplify the importance of the 10th feature and not the other features?" That hadn't occurred to me as a possibility as the 11th feature is only ever 1 or 0
[2016-03-11T13:14:02.492Z] <564789be16b6c7089cbab8b7> I would love to see the results of your testing on this
[2016-03-11T13:15:52.601Z] <564789be16b6c7089cbab8b7> @rvraghav93  "We now have 11 features right? " yes
[2016-03-11T13:20:34.262Z] <53135b495e986b0712efc453> "as the 11th feature is only ever 1 or 0" - Correct! But I'm not sure if the feature importance will now be shared between the 10th and 11th feature or will be independently assigned... Have to look into it. Nevertheless this is a good comparison for my method. Another thing that I tried was replacing the missing values by the 10*maximum across all the features... This seems to not perform as well as the implementation. Thanks for your inputs! Please feel free to share more thoughts!
[2016-03-11T13:22:41.964Z] <564789be16b6c7089cbab8b7> @rvraghav93  thanks. I should say that I am particularly interested in categorical variables so things like replacing missing values by huge values never occurs to me :)
[2016-03-11T13:23:03.719Z] <564789be16b6c7089cbab8b7> @rvraghav93  were the dotted lines the timings? I mean in the graphs 
[2016-03-11T13:24:28.183Z] <564789be16b6c7089cbab8b7> @rvraghav93  you make a very interesting point about feature importance.  
[2016-03-11T13:49:36.174Z] <53135b495e986b0712efc453> Yes! the dotted lines are time taken for `cross_val_score` . I'm now trying to plot the time taken for a single fit.
[2016-03-11T14:10:22.324Z] <564789be16b6c7089cbab8b7> @rvraghav93 thanks. 
[2016-03-11T14:25:07.649Z] <564789be16b6c7089cbab8b7> @rvraghav93  actually categorical values in general make the imputation strategies for missing values tricky, or at least different
[2016-03-11T14:25:16.779Z] <564789be16b6c7089cbab8b7> I think this is an important use case
[2016-03-11T14:25:55.451Z] <53135b495e986b0712efc453> I think the imputation strategy for categorical value should be 'median' or 'mode' instead of 'mean' no?
[2016-03-11T14:27:25.555Z] <53135b495e986b0712efc453> And if the categorical support is introduced (in https://github.com/scikit-learn/scikit-learn/pull/4899), handling missing values in categorical features is not difficult. The missing simply becomes an additional category.
[2016-03-11T14:28:21.382Z] <564789be16b6c7089cbab8b7> @rvraghav93  mode could work but I am not sure what median would mean as there is no natural ordering
[2016-03-11T14:28:32.615Z] <564789be16b6c7089cbab8b7> @rvraghav93  I really hope https://github.com/scikit-learn/scikit-learn/issues/4899 makes progress
[2016-03-11T14:28:38.398Z] <53135b495e986b0712efc453> yes correct. Median is not appropriate.
[2016-03-11T14:29:22.984Z] <53135b495e986b0712efc453> #4899 is next on my list, (as #5974 is brought to a reviewable state).
[2016-03-11T14:29:25.039Z] <564789be16b6c7089cbab8b7> although mode is a little worrying too.. imagine lots of categories which occur 7,8,9 or 10 times. It's not clear the missing ones should be given to the category that occurs 10 times
[2016-03-11T14:29:38.669Z] <564789be16b6c7089cbab8b7> @rvraghav93 Great and a huge thank you.
[2016-03-11T14:29:44.298Z] <53135b495e986b0712efc453> :D
[2016-03-11T14:30:16.347Z] <564789be16b6c7089cbab8b7> I think we need a smarter imputation for categorical values
[2016-03-11T14:30:21.140Z] <53135b495e986b0712efc453> Yes that is a valid point.
[2016-03-11T14:30:44.462Z] <53135b495e986b0712efc453> The best way to handle is to consider missing to be a separate category.
[2016-03-11T14:30:50.589Z] <564789be16b6c7089cbab8b7> right!
[2016-03-11T14:31:44.717Z] <564789be16b6c7089cbab8b7> actually, and this is somewhat off topic sorry, there is a nice problem where you have numerical values but some of them should really be treated as categories
[2016-03-11T14:31:59.681Z] <564789be16b6c7089cbab8b7> so 10 is nowhere near 11, say, but 1000 is near 1001
[2016-03-11T14:32:36.194Z] <564789be16b6c7089cbab8b7> you can imagine this comes from some measurements of the output of a computer
[2016-03-11T14:32:58.220Z] <564789be16b6c7089cbab8b7> what I do in that case is put the feature in twice, once as numerical and once as categorical and let the RF work it :)
[2016-03-11T14:33:09.306Z] <564789be16b6c7089cbab8b7> but that only works if the number of different numerical values is not too large
[2016-03-11T14:34:03.121Z] <564789be16b6c7089cbab8b7> end of off topic :)
[2016-03-12T13:59:00.999Z] <564789be16b6c7089cbab8b7> what's the default scoring scheme when using  cross_val_score with RandomForestRegressor?
[2016-03-12T13:59:19.365Z] <564789be16b6c7089cbab8b7> If the docs say, I haven't seen it
[2016-03-13T07:04:34.244Z] <564789be16b6c7089cbab8b7> I found it ... I think it should be renamed :)
[2016-03-13T09:18:04.767Z] <53135b495e986b0712efc453> Which one should be renamed?
[2016-03-13T09:55:53.363Z] <564789be16b6c7089cbab8b7> "score(X, y[, sample_weight]) 	Returns the coefficient of determination R^2 of the prediction." This is confusing I think. It's really a correlation coefficient. Why is it called R^2?
[2016-03-13T09:56:01.742Z] <564789be16b6c7089cbab8b7> it is a value between -1 and 1
[2016-03-13T09:56:08.462Z] <564789be16b6c7089cbab8b7> as far as I can tell
[2016-03-13T09:56:29.445Z] <564789be16b6c7089cbab8b7> @rvraghav93  ^^
[2016-03-13T15:16:30.438Z] <5537027215522ed4b3df56ab> Hey guys, would it make sense to contribute confidence intervals for linear models?
[2016-03-13T15:17:36.614Z] <5537027215522ed4b3df56ab> because without standard errors for each coefficient estimated from test data, it's hard to interpret coefficients
[2016-03-13T15:22:11.034Z] <5537027215522ed4b3df56ab> i work with data that changes over time, so in my case I need confidence intervals on output probabilities for new samples. When using the standard output probabilities,  they are sometimes wrong and confidence intervals would help figure out a) how wrong you are and b) which coefficients have lower standard errors over time for more robust feature selection
[2016-03-13T15:46:09.261Z] <54e07d6515522ed4b3dc0858> @lesshaste not really. Training R^2 is between 0 and 1, but on unseen data it can become negative.  And "coefficient of determination" is an established term in statistics.
[2016-03-13T16:50:11.271Z] <564789be16b6c7089cbab8b7> @vene Hi. If it's an established term then that is what we should use. Maybe a very brief explanation of the range it can take on test data and why could be added?
[2016-03-13T16:58:25.142Z] <564789be16b6c7089cbab8b7> @vene  I managed to get these scores [-0.38971809 -1.32178009 -0.20038367]  . What is the range? It clearly isn't -1 to 1
[2016-03-13T16:59:41.603Z] <54e07d6515522ed4b3dc0858> It's -INF to 1, I think.
[2016-03-13T17:26:27.361Z] <564789be16b6c7089cbab8b7>  @vene  that's interesting. It would be great if something definitive and clear could be added to the docs about this. Please :)
[2016-03-13T18:38:51.931Z] <54e07d6515522ed4b3dc0858> @lesshaste have you read this? http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score
[2016-03-13T18:41:23.546Z] <54e07d6515522ed4b3dc0858> the intuition is: a model can never do worse than predicting the mean *on training data*. (at least a linear model that can set all its coefs to 0) but it can do much worse on test data if it overfits.
[2016-03-13T18:46:59.355Z] <54e07d6515522ed4b3dc0858> on "hard" regression problems (few samples, many irrelevant features) MSE/MAE can lead you to believe you're doing well,  if you don't compare against a dummy baseline that predicts the mean, or something simple like that. I've fallen in this trap.
[2016-03-13T18:59:58.210Z] <564789be16b6c7089cbab8b7> @vene Oops! I hadn't read that. Sorry that's my bad
[2016-03-13T19:00:25.257Z] <564789be16b6c7089cbab8b7> @vene  I seem to have a hard regression problem currently :(
[2016-03-13T19:05:25.451Z] <56e5af1285d51f252ab894f7> hey, if anyone has any remote remote , designer,  DevOps  or Sysadmin jobs they can post them at http://webwork.io
[2016-03-13T19:13:06.095Z] <54e07d6515522ed4b3dc0858> @lesshaste did you try feature selection?
[2016-03-13T19:14:57.089Z] <54e07d6515522ed4b3dc0858> @lqdc confidence intervals are cool, but it seems more in the domain of statsmodels. And I think it's actually already implemented in statsmodels.
[2016-03-13T19:15:55.029Z] <54e07d6515522ed4b3dc0858> [for OLS at least](http://statsmodels.sourceforge.net/devel/generated/statsmodels.regression.linear_model.OLSResults.conf_int.html#statsmodels.regression.linear_model.OLSResults.conf_int)
[2016-03-13T19:20:54.833Z] <54e07d6515522ed4b3dc0858> seems like it's there for [GLM](http://statsmodels.sourceforge.net/devel/generated/statsmodels.genmod.generalized_linear_model.GLMResults.conf_int.html#statsmodels.genmod.generalized_linear_model.GLMResults.conf_int) too
[2016-03-13T19:24:50.195Z] <564789be16b6c7089cbab8b7> @vene  I didn't.. I just assumed that randomforestregressor doesn't really benefit from that. Is that wrong?
[2016-03-13T19:31:45.942Z] <54e07d6515522ed4b3dc0858> I haven't used random forests much, dunno.
[2016-03-13T19:39:29.871Z] <564789be16b6c7089cbab8b7> @vene  I think problem is that I have 140 samples where I am used to 100s of thousands
[2016-03-13T19:39:37.501Z] <564789be16b6c7089cbab8b7> so my intuition for what works is wrong
[2016-03-13T19:45:27.466Z] <54e07d6515522ed4b3dc0858> I never actually managed to get random forests to outperform linear models on the datasets I worked with
[2016-03-13T19:45:34.807Z] <54e07d6515522ed4b3dc0858> which are usually <<10k samples
[2016-03-13T19:47:22.859Z] <564789be16b6c7089cbab8b7> @vene that's a very interesting observation! I have found them to be great when I have a mix of categorical and numerical values and lots of data
[2016-03-13T19:48:53.387Z] <564789be16b6c7089cbab8b7> @vene  maybe I should send you my data to see what you can make of it :)
[2016-03-13T19:52:13.435Z] <564789be16b6c7089cbab8b7> because I am completely failing currently
[2016-03-13T19:52:15.463Z] <56b80528e610378809c05a48> Hello guys, Is there anyone familiar with cythons fused type?  ```cython cimport cython  ctypedef fused char_or_float:     cython.char     cython.float  def show_me():     cdef char_or_float  cython.char a = 127  show_me() ```
[2016-03-13T19:54:32.900Z] <56b80528e610378809c05a48> Oh theres a typo
[2016-03-13T19:55:30.331Z] <56b80528e610378809c05a48> Following script dosnt work ...  ```cython cimport cython  ctypedef fused char_or_float:     cython.char     cython.float  def show_me():     cdef char_or_float a = 127.0  show_me() ```
[2016-03-13T19:56:02.843Z] <56b80528e610378809c05a48> Can somebody tell me whats the problem?
[2016-03-13T20:01:29.710Z] <54e07d6515522ed4b3dc0858> can you assign 127.0 to a char normally?
[2016-03-13T20:01:53.092Z] <56b80528e610378809c05a48> yes
[2016-03-13T20:02:17.964Z] <54e07d6515522ed4b3dc0858> what is it supposed to do? it doesn't typecheck to me to assign a float to a char
[2016-03-13T20:04:59.223Z] <56b80528e610378809c05a48> really?
[2016-03-13T20:05:28.613Z] <56b80528e610378809c05a48> But it works for me ...
[2016-03-13T20:05:38.405Z] <56b80528e610378809c05a48> Thx for your help!
[2016-03-13T20:06:37.897Z] <56b80528e610378809c05a48> It is not  assign a float to a char
[2016-03-13T20:06:59.202Z] <56b80528e610378809c05a48> It is to declare a type that can accept either cython.char or  cython.float
[2016-03-13T20:07:26.744Z] <54e07d6515522ed4b3dc0858> yes, the type is declared correctly. But you can't instantiate and assign to it like that, apparently
[2016-03-13T20:08:20.099Z] <54e07d6515522ed4b3dc0858> It should work if you make it a function argument, if I understand correctly
[2016-03-13T20:10:42.564Z] <54e07d6515522ed4b3dc0858> I mean, what are you trying to do in this example? Why do you want your type to be generic if you're assigning a float to it?
[2016-03-13T20:11:50.037Z] <56b80528e610378809c05a48> oh yeah I simplify the code alot
[2016-03-13T20:13:50.727Z] <54e07d6515522ed4b3dc0858> it's not that; I don't think it makes sense to assign a literal to a fused type
[2016-03-13T20:13:58.197Z] <54e07d6515522ed4b3dc0858> this works, for example:
[2016-03-13T20:14:23.905Z] <54e07d6515522ed4b3dc0858> ``` %%cython  cimport cython  ctypedef fused char_or_float:     cython.char     cython.float  cdef char_or_float add_1(char_or_float x):     return x + 1  def show_me():     cdef cython.char a = 1     print(add_1(a))  show_me()```
[2016-03-13T20:15:07.817Z] <54e07d6515522ed4b3dc0858> note i'm declaring and assigning to a char, not to a char_or_float. But I can pass it to a function that takes char_or_float
[2016-03-13T20:15:33.599Z] <56b80528e610378809c05a48> I see
[2016-03-13T20:15:41.417Z] <56b80528e610378809c05a48> thanks for the clarafacation
[2016-03-13T20:16:24.328Z] <54e07d6515522ed4b3dc0858> in theory I'd imagine, for your example,  that the compiler *could* just specialize your char_or_float to a float when you assign to it. But I can see why they didn't implement that, it doesn't really have a point.
[2016-03-13T20:17:11.310Z] <54e07d6515522ed4b3dc0858> Are you familiar with C++ templates?
[2016-03-13T21:06:57.492Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar thanks. Sorry, I'm still travelling. How does it compare in terms of runtime?
[2016-03-14T02:21:26.346Z] <5537027215522ed4b3df56ab> @vene  That makes sense but stats models doesn't deal with a million features
[2016-03-14T02:22:57.797Z] <5537027215522ed4b3df56ab> basically the whole lib doesn't work for omre than like 20 features
[2016-03-14T08:56:06.070Z] <564789be16b6c7089cbab8b7> Also statsmodels in general is not developed very quickly or actively. I used to follow it but gave up.
[2016-03-14T11:16:19.116Z] <54e07d6515522ed4b3dc0858> Maybe there is a way to initialize the statsmodels result object with our coefs.
[2016-03-14T11:16:45.189Z] <54e07d6515522ed4b3dc0858> And use their post processing
[2016-03-14T16:42:14.044Z] <564789be16b6c7089cbab8b7> @vene  that's a nice idea. 
[2016-03-14T16:47:26.183Z] <564789be16b6c7089cbab8b7> @lqdc  Do you want to open an issue with an example large enough that  statsmodels can't cope?
[2016-03-14T16:47:38.299Z] <564789be16b6c7089cbab8b7> and paste in @vene's thought maybe
[2016-03-14T17:42:26.304Z] <5537027215522ed4b3df56ab> @lesshaste sounds good
[2016-03-15T05:33:52.908Z] <56c625c3e610378809c22760> just had a small doubt; how to compile a .cpp file into a python extension? I generate the cpp file by using --cplus extension but how can I compile after this? Is there an easier way to do the whole process?
[2016-03-15T05:57:10.850Z] <56c625c3e610378809c22760> no probs. running `python setup.py build_ext --inplace` from source works plus you can see the command for compiling a c++ file into a python extension
[2016-03-15T15:43:21.872Z] <54c630d6db8155e6700f168d> Hey everybody, I'm struggling a little bit with understanding how I'm going to deploy a scikit learn algorithm which has been implemented using scaled feature values
[2016-03-15T15:45:21.792Z] <54c630d6db8155e6700f168d> You see, I'm creating a calculator which'll do a logistic classification based upon a few values given by the user.
[2016-03-15T15:51:06.456Z] <54c630d6db8155e6700f168d> And I don't get how  I can scale the values I get from the user using the same scaler as I used in the algorithm itself.
[2016-03-15T15:51:19.372Z] <54c630d6db8155e6700f168d> Would love to get help if anybody's interested !
[2016-03-15T19:15:44.809Z] <56cc7481e610378809c304aa> @perborgen  I'm not sure if this is what you're looking for but, if you're using preprocessing.StandardScaler, you could set scale_, mean_ and variance_ explicitly once you've gotten those values from fitting the scalar with your training set. You'd only need to persist those somehow. 
[2016-03-16T06:09:17.303Z] <56b80528e610378809c05a48> Hey guys, can anyone tell me why the CI failed at [this line](https://travis-ci.org/scikit-learn/scikit-learn/jobs/116304478#L2329)? According to the [doc](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.rand.html), scipy.sparse.rand() should accept `random_state`as an argument.
[2016-03-16T06:10:17.462Z] <56b80528e610378809c05a48> And there is no erro if I run `nosetests` on my own computer.
[2016-03-16T07:22:33.215Z] <56b80528e610378809c05a48> Oh I got it ... CIs scipy version = 0.9
[2016-03-18T08:45:07.067Z] <564789be16b6c7089cbab8b7> hi @rvraghav93 
[2016-03-18T14:34:05.396Z] <564789be16b6c7089cbab8b7> @rvraghav93  In relation to the email thread "Class Weight Random Forest Classifier " I should say that I remember it making no difference for me either when I tried it some time last year
[2016-03-20T05:40:13.508Z] <56c625c3e610378809c22760> Hey everyone, could some please review #6221? Just need a second affirmative on that one. Thanks!
[2016-03-20T05:40:54.142Z] <56c4f19ae610378809c1f8ae> sure ill take a look
[2016-03-20T06:00:06.885Z] <56c4f19ae610378809c1f8ae> done @dsquareindia :)
[2016-03-20T06:02:14.219Z] <56c625c3e610378809c22760> 
[2016-03-20T06:02:26.630Z] <56c625c3e610378809c22760> Thanks a lot @nelson-liu !
[2016-03-21T19:44:42.240Z] <53135b495e986b0712efc453> @dsquareindia @maniteja123 @nelson-liu @yenchenlin1994 Please make sure you submit your proposals soon into the withgoogle website. I believe the deadline is in less than 3 days... Thanks and good luck :)
[2016-03-21T19:45:24.761Z] <56c4f19ae610378809c1f8ae> Will do, thanks for the reminder! 
[2016-03-21T19:47:12.326Z] <53135b495e986b0712efc453> I'm not sure who else is interested. If there is any other interested person, please make sure you submit it within the next 3 days as you won't be able to do so after the deadline... (don't worry about it being perfect. **Just make sure that you clearly outline, at a high level what you wish to achieve within the timeslot**...)
[2016-03-21T20:34:36.230Z] <55a36f535e0d51bd787b3400> Hi everyone, (I'm not sure this is the best place to ask; else let me know.).  I'm trying to cross-val a KMeans clustering and retrieve the most likely cluster:  ``` kmeans = list() for x in X:     dist = pairwise_distances(x)     kmeans.append(KMeans().fit_predict(dist)) ```  Although the clusters are very similar across iterations, the cluster labels are (obviously) random.  Do you know how I can aggregate these labels to find the most robust clusters across iterations: e.g.  `cluster_idx = scipy.stats.mode([sample for sample in kmeans])`
[2016-03-21T21:24:29.844Z] <56c4f19ae610378809c1f8ae> Hmm, you should x-post to stackoverflow. Theyd probably be more responsive
[2016-03-21T21:24:45.598Z] <55a36f535e0d51bd787b3400> @nelson-liu ok thanks!
[2016-03-21T21:36:10.979Z] <55a36f535e0d51bd787b3400> http://stats.stackexchange.com/questions/202883/how-to-combine-the-results-of-several-clustering-with-scikit-learn
[2016-03-22T00:09:14.405Z] <56b80528e610378809c05a48> Great thanks for your reminder!
[2016-03-22T06:13:56.321Z] <56c625c3e610378809c22760> I had some doubts regarding the project which I have listed in my [proposal](https://github.com/scikit-learn/scikit-learn/wiki/%5BDevashish%5D-GSoC-2016-project-proposal:-Adding-fused-types-to-Cython-files) itself.  It would be wonderful if anyone could give their opinions on them. Thanks!
[2016-03-22T06:15:07.963Z] <56b80528e610378809c05a48> Hello @dsquareindia , you mean the type issue in ensemble?
[2016-03-22T06:17:41.776Z] <56c625c3e610378809c22760> yeah there wouldn't be a huge difference by adding fused types there right? I could work on that later after crucial modules have already been worked on. wdyt?
[2016-03-22T06:17:59.412Z] <56b80528e610378809c05a48> Yeah I think so
[2016-03-22T06:19:48.116Z] <56c4f19ae610378809c1f8ae> I agree with yen
[2016-03-22T11:39:52.208Z] <564789be16b6c7089cbab8b7> hi @rvraghav93 
[2016-03-22T13:43:42.861Z] <53135b495e986b0712efc453> Hi!
[2016-03-22T14:50:06.953Z] <564789be16b6c7089cbab8b7> @rvraghav93  Hi. Have you a moment to discuss the categorical features/random forest/benchmark issue?
[2016-03-22T15:07:29.382Z] <53135b495e986b0712efc453> @lesshaste Yup!
[2016-03-22T15:09:27.323Z] <564789be16b6c7089cbab8b7> @rvraghav93  great!  So... a) what is going on? :) What I mean is, do xgboost and H20 actually support categorical variables at all?
[2016-03-22T15:19:51.678Z] <53135b495e986b0712efc453> Yes apparently they do... :/ We are working on that and we'll become awesome in a few more months B)
[2016-03-22T15:20:23.609Z] <564789be16b6c7089cbab8b7> @rvraghav93  ok but the comment on the PR was that it would actually not help
[2016-03-22T15:20:26.322Z] <564789be16b6c7089cbab8b7> which is what confused me
[2016-03-22T15:23:06.522Z] <53135b495e986b0712efc453> No I definitely do think introducing native support for categorical variables would indeed speed up our rf
[2016-03-22T15:25:02.195Z] <564789be16b6c7089cbab8b7> "It looks like they are using decision tree-based classifiers (i.e., RandomForestClassifier and GradientBoostingClassifier) rather than extra-random tree-based classifiers. And it looks like their dataset's categorical features (airlines, origin & destination airports) probably have cardinality > 64. These two factors together mean NOCATS can't be used."
[2016-03-22T15:25:04.767Z] <564789be16b6c7089cbab8b7> did you see that?
[2016-03-22T15:25:37.423Z] <53135b495e986b0712efc453> Hmmm I didn't see that.. Give me a moment!
[2016-03-22T15:28:42.333Z] <564789be16b6c7089cbab8b7> thanks
[2016-03-22T15:34:33.251Z] <53135b495e986b0712efc453> Okay so I think before benchmarking against H2O and xgb. We need to make the splitting of categories locally optimal (we should decide what way the categories go at each split) and not just globally optimal. Then if the cardinality is > 64, we need to investigate why they support such high cardinality and whether or not we could do the same...
[2016-03-22T15:34:57.198Z] <53135b495e986b0712efc453> I think even R has restrictions on the cardinality of the categorical features...
[2016-03-22T15:35:17.046Z] <564789be16b6c7089cbab8b7> R does but the R RF code is bad
[2016-03-22T15:35:29.967Z] <53135b495e986b0712efc453> How about rpart? I hear good things about it...
[2016-03-22T15:35:41.813Z] <564789be16b6c7089cbab8b7> well.. the default version is.. there are better versions and people also use xgboost with R
[2016-03-22T15:37:21.435Z] <564789be16b6c7089cbab8b7> rpart maybe be better .. hmm which version do they use in their benchmark?
[2016-03-22T15:39:03.879Z] <564789be16b6c7089cbab8b7> http://www.wise.io/tech/benchmarking-random-forest-part-1 is another example that shows how bad R randomForest is though
[2016-03-22T15:39:04.879Z] <53135b495e986b0712efc453> Also one another thing to note is that xgboost works somewhat differently compared to sklearn's rf as they seem to use approximate splitting and a second order objective as described in the paper that got recently published by Tianqi Chen...  You should look into that paper... I think there is a section which briefly explains why they are faster than us... I haven't had time to take a good look into that paper. But if you do, please share your insights...
[2016-03-22T15:39:47.850Z] <564789be16b6c7089cbab8b7> ok thanks.  There is also H20 but I don't know how well their implementation us
[2016-03-22T15:41:19.565Z] <564789be16b6c7089cbab8b7> in any case.. it would be great to have somewhere where concrete improvements relevant to that benchmark could be discussed. It all seems slightly confusing at the moment
[2016-03-22T15:41:24.405Z] <53135b495e986b0712efc453> I think our top priority, as far as the tree based modules are concerned, is to merge the missing value support and the categorical variable support soon into scikit-learn... Once that is done we can think of making it better comparing it with xgboost...
[2016-03-22T15:42:09.602Z] <53135b495e986b0712efc453> Maybe if these two are done, I'll see if I can make a blog post with readable code that compares the rf implementations... ;)
[2016-03-22T15:42:14.926Z] <56b80528e610378809c05a48> you mean [this paper ](http://learningsys.org/papers/LearningSys_2015_paper_32.pdf)
[2016-03-22T15:42:17.471Z] <56b80528e610378809c05a48> ?
[2016-03-22T15:42:28.748Z] <53135b495e986b0712efc453> yupp!
[2016-03-22T15:43:45.789Z] <53135b495e986b0712efc453> No that one is a condensed version... wait
[2016-03-22T15:44:14.037Z] <53135b495e986b0712efc453> http://arxiv.org/pdf/1603.02754v1.pdf
[2016-03-22T15:45:12.820Z] <56b80528e610378809c05a48> Oh I am really interest in gradient boosting since Microsoft use it to [learn how to play Minecraft](http://research.microsoft.com/en-us/um/people/alekha/arxiv_geql.pdf)
[2016-03-22T15:45:27.885Z] <53135b495e986b0712efc453> Or maybe both are same... I'm not sure... The last link is the one that I have on my table accumulating dust... Have to read it soon :@
[2016-03-22T15:45:38.029Z] <564789be16b6c7089cbab8b7> @rvraghav93 That's a great idea!
[2016-03-22T15:46:53.004Z] <56b80528e610378809c05a48> Thanks for the link and sorry to interrupt :worried: 
[2016-03-22T15:47:00.163Z] <53135b495e986b0712efc453> np
[2016-03-22T15:47:06.956Z] <564789be16b6c7089cbab8b7> @yenchenlin1994  interruptions welcome :)
[2016-03-22T15:47:24.673Z] <56b80528e610378809c05a48> :smile: 
[2016-03-22T15:48:10.831Z] <564789be16b6c7089cbab8b7> @rvraghav93  one more dim question.. :) I see in the NOCATS PR (RandomForestClassifier, full, One-hot) AUC: 0.712132537822 and  (RandomForestClassifier, truncated(8), NOCATS) AUC: 0.668807372591
[2016-03-22T15:48:19.876Z] <564789be16b6c7089cbab8b7> why is the second so much worse than the first?
[2016-03-22T15:50:07.353Z] <564789be16b6c7089cbab8b7> is it the truncated part?
[2016-03-22T15:50:35.998Z] <564789be16b6c7089cbab8b7> I assume so.. so is there no example that shows NOCATS doing better?
[2016-03-22T15:50:44.798Z] <564789be16b6c7089cbab8b7> I am not sure I understood "the full dataset with NOCATS categorical splitting (actually no random forest in this case),"
[2016-03-23T10:32:42.111Z] <53a5cf04a9176b500d1ced1a> Hi guys, how are you able to make imports like "from sklearn.some_module import some_func" from any python file. Have you changed sys.path from anywhere? Thanks
[2016-03-23T10:33:39.999Z] <56b80528e610378809c05a48> Can you `import sklearn`?
[2016-03-23T10:35:34.636Z] <53a5cf04a9176b500d1ced1a> Actually I was just browsing code.
[2016-03-23T10:35:38.240Z] <53a5cf04a9176b500d1ced1a> For example in this file
[2016-03-23T10:35:38.727Z] <53a5cf04a9176b500d1ced1a> https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/covariance/tests/test_covariance.py
[2016-03-23T10:35:56.948Z] <53a5cf04a9176b500d1ced1a> We are able to do `from sklearn.utils.testing import something`
[2016-03-23T10:36:14.763Z] <53a5cf04a9176b500d1ced1a> I was wondering how were you able to do that? Is there any configuration for this?
[2016-03-23T10:38:36.646Z] <53a5cf04a9176b500d1ced1a> @yenchenlin1994 there?
[2016-03-23T10:53:18.150Z] <5525b91815522ed4b3deb7d6> @SaurabhJha No, there isn't any. This is how the import system of python works.
[2016-03-23T10:53:39.794Z] <56b80528e610378809c05a48> a [reference](http://stackoverflow.com/questions/448271/what-is-init-py-for)
[2016-03-23T10:59:11.627Z] <56b80528e610378809c05a48> it shows how `__init.py__` works!
[2016-03-23T11:03:51.596Z] <53a5cf04a9176b500d1ced1a> yeah. cool
[2016-03-23T11:04:36.666Z] <56b80528e610378809c05a48> Hope this answers your question :smile: 
[2016-03-23T11:07:07.885Z] <53a5cf04a9176b500d1ced1a> yes. Thank you :)
[2016-03-23T15:30:30.231Z] <56f2b66385d51f252aba60dd> Hi. Trying to use LogisticRegression with multi_class='multinomial'. Ending up with this error:  __init__() got an unexpected keyword argument 'multi_class'
[2016-03-23T15:30:42.515Z] <56f2b66385d51f252aba60dd> sklearn version is '0.15.2'
[2016-03-23T15:31:09.404Z] <56f2b66385d51f252aba60dd> Can anybody please help?
[2016-03-24T05:53:03.222Z] <56f2dfde85d51f252aba689b> Hi @VarunKShetty , it seems that such parameter doesnt exist. Check the documentation to see which parameters can be used.
[2016-03-24T09:16:21.005Z] <54c630d6db8155e6700f168d> @ksafford Thanks a lot, that helped!
[2016-03-24T13:29:44.087Z] <5552313315522ed4b3e0482a> @VarunKShetty  LogisticRegression in 0.15.2 doesn't support multi_class, if you update to the 0.17.1 version it should work.
[2016-03-24T19:03:33.668Z] <56f2b66385d51f252aba60dd> Thanks @dvdnglnd 
[2016-03-24T19:03:44.581Z] <56f2b66385d51f252aba60dd> I'll now go figure out how to update it 
[2016-03-24T22:43:47.150Z] <56c4f19ae610378809c1f8ae> Hi everyone. I have a featureunion of several pipelines, is there any way I can turn the featureunion into a numpy array for use in other applications?
[2016-03-24T22:44:07.938Z] <56c4f19ae610378809c1f8ae> e.g. in this case, Im using scikit-learn to do the preprocessing, and keras for the learning
[2016-03-24T23:32:31.430Z] <54e07d6515522ed4b3dc0858> You should be able to call transform to obtain an array
[2016-03-24T23:36:37.116Z] <54e07d6515522ed4b3dc0858> As long as your pipelines have only transformers and no predictors
[2016-03-24T23:38:02.268Z] <54e07d6515522ed4b3dc0858> It doesn't really make sense to me to turn the "feature union" into an array, but to apply it on data to obtain an array. Or am I misunderstanding?
[2016-03-24T23:38:22.769Z] <56c4f19ae610378809c1f8ae> ah, no you arent misunderstanding, I was.
[2016-03-24T23:38:53.466Z] <56c4f19ae610378809c1f8ae> the featureunion is just a scaffold of various steps, which you then pass things into and get a numpy array. Is this what you were thinking?
[2016-03-25T20:29:00.193Z] <54d4a1d6db8155e6700f853b>  @ogrisel do you know what happened to the pdf docs? They are gone :-/
[2016-03-27T04:23:13.855Z] <53810862048862e761fa2887> @amueller Isn't ADMM guaranteed to produce an optimal solution irrespective of the value of `mu` ? I am referring to equation 5.1 [here](http://statweb.stanford.edu/~candes/papers/RobustPCA.pdf)
[2016-03-27T04:24:21.795Z] <53810862048862e761fa2887> `mu` is multiplied by a factor which should be 0 for all feasible solutions.
[2016-03-28T13:45:56.782Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar well the solutions are not feasible
[2016-03-28T13:46:23.578Z] <54d4a1d6db8155e6700f853b> and with very small mu they are very far from being feasible 
[2016-03-29T10:44:05.724Z] <564789be16b6c7089cbab8b7> hi @rvraghav93 
[2016-03-29T17:32:03.865Z] <551061f615522ed4b3ddb1c0> Anyone can help on https://github.com/scikit-learn/scikit-learn/issues/6574?
[2016-03-29T18:10:56.296Z] <564789be16b6c7089cbab8b7> @nelson-liu   I love your GSOC proposal by the way
[2016-03-29T18:13:02.205Z] <56c4f19ae610378809c1f8ae> thanks @lesshaste :)
[2016-03-29T19:40:31.337Z] <55901c1b15522ed4b3e2f949> The GMM documentation says that all components are initialized to mean 0, identity covariance.
[2016-03-29T19:40:46.336Z] <55901c1b15522ed4b3e2f949> How is it possible to update the components if each component is identical?
[2016-03-29T19:45:14.040Z] <55901c1b15522ed4b3e2f949> I vaguely recall something about sklearn using kmeans++ to initialize the components somewhere. Maybe I'm imagining things.
[2016-03-29T22:22:40.556Z] <55901c1b15522ed4b3e2f949> The code seems to imply it uses a round of kmeans to initialize the components, but the documentation doesn't say that.
[2016-03-29T22:50:26.234Z] <53135b495e986b0712efc453> @lesshaste Hello! Sorry I've been a bit busy lately. ;(
[2016-03-31T14:20:40.577Z] <54d4a1d6db8155e6700f853b> I feel like I should know that, but does scikit-learn have a doi?
[2016-03-31T21:58:26.139Z] <56c4f19ae610378809c1f8ae> @amueller I dont think so? I just searched the docs and couldnt find it. It also isnt in the original publication. I also looked at a few papers that cited scikit-learn, but they omitted the DOI
[2016-04-01T04:03:36.644Z] <54e07d6515522ed4b3dc0858> I don't recall us having one.
[2016-04-01T15:08:30.767Z] <56c3065ce610378809c1ab7d> hi, pls i will need some explanation. if i have a honeypot logfile, and i want to apply neural network to the logfile, so i can get analysis type of the logfile, which i want to use to generate intrusion signature.
[2016-04-01T15:11:43.094Z] <54d4a1d6db8155e6700f853b> @ikennarene what is your question?
[2016-04-01T15:15:05.322Z] <56c3065ce610378809c1ab7d>  i am thinking of applying classification and clustering algorithm on a honeypot logfile, after which i want to generate intrusion signature based on the algorithm results, pls can i get more explanation on this, and approach i can use if possible. thanks
[2016-04-01T18:13:00.148Z] <54d4a1d6db8155e6700f853b> so you want to detect intrusions? Do you know which ones were intrusions or not?
[2016-04-01T19:30:45.184Z] <56c3065ce610378809c1ab7d> @amueller unknown  
[2016-04-01T19:44:01.167Z] <54d4a1d6db8155e6700f853b> try outlier detections methods like isolationforest
[2016-04-01T21:50:41.792Z] <56c4f19ae610378809c1f8ae> hi everyone. Im working with countvectorizer, and I already have a corpus that has been pretokenized and everything. How would i extract ngrams from it? setting `analyzer=str.split()` breaks the ngram_range argument. Would i have to write my own analyzer? setting the default (`analyzer=word`) does not work for me because that strips punctuation and I want to keep punctuation.
[2016-04-02T08:41:07.177Z] <564789be16b6c7089cbab8b7> @rvraghav93  no problem at all!
[2016-04-02T09:44:07.888Z] <564789be16b6c7089cbab8b7> http://scikit-learn.org/dev/auto_examples/ensemble/plot_isolation_forest.html has a nice looking example but it would be great if it had a little more explanation about the decision boundaries? Why are there 4 areas that are non-anomalous and not just two for example?
[2016-04-03T09:27:37.704Z] <5592d95215522ed4b3e31c79> hello everyone
[2016-04-03T12:02:07.237Z] <54e07d6515522ed4b3dc0858> Nrlson-liu it should be str.split rather than str.split()
[2016-04-03T19:01:44.774Z] <56c4f19ae610378809c1f8ae> ah, yeah sorry that was a typo on my part. i ended up just making a custom analyzer.
[2016-04-03T19:05:55.645Z] <54e07d6515522ed4b3dc0858> str.split has worked for me
[2016-04-03T19:13:05.821Z] <56c4f19ae610378809c1f8ae> using str.split seems to break ngram_range, though?
[2016-04-03T19:15:01.868Z] <56c4f19ae610378809c1f8ae> e.g.  ``` >>> from sklearn.feature_extraction.text import CountVectorizer >>> ngram_vectorizer = CountVectorizer(analyzer=str.split, ngram_range=(1, 2)) >>> ngram_vectorizer.fit_transform(['The quick brown fox jumped over the lazy dog .']) <1x10 sparse matrix of type '<type 'numpy.int64'>' 	with 10 stored elements in Compressed Sparse Row format> >>> print ngram_vectorizer.get_feature_names() ['.', 'The', 'brown', 'dog', 'fox', 'jumped', 'lazy', 'over', 'quick', 'the] ```
[2016-04-03T19:15:57.601Z] <56c4f19ae610378809c1f8ae> looking at the code for `CountVectorizer`, it seems like the analyzer argument is also responsible for making ngrams. So `str.split` would only make unigrams?
[2016-04-05T01:37:26.320Z] <553d32d715522ed4b3df8b92> @jnothman I am here now :)
[2016-04-05T02:12:47.525Z] <54b2524adb8155e6700e8a8e> Okay. I think you're misinterpreting the numpy error's relevance to this situation.
[2016-04-05T02:13:53.925Z] <54b2524adb8155e6700e8a8e> But np.where(mask_matrix.max(axis=0))[0] might not quite work, because `mask_matrix.max(axis=0)` returns a 2d matrix. 
[2016-04-05T02:14:11.959Z] <54b2524adb8155e6700e8a8e> `np.flatnonzero(mask_matrix.max(axis=0))` should fix that issue, though
[2016-04-05T02:16:09.093Z] <54b2524adb8155e6700e8a8e> I don't get at all how you could be getting an error on a *print* statement!
[2016-04-05T02:19:15.254Z] <54b2524adb8155e6700e8a8e> I hope you got that @maniteja123 
[2016-04-05T02:19:29.372Z] <553d32d715522ed4b3df8b92> Yeah thanks, that was the reason for the ValueError
[2016-04-05T02:20:22.953Z] <553d32d715522ed4b3df8b92> But still didn't get the comment regarding the *print* statement :worried: 
[2016-04-05T02:22:00.560Z] <553d32d715522ed4b3df8b92> Also ``np.flatnonzero`` gives an error ``AttributeError: ravel not found``
[2016-04-05T02:22:39.763Z] <54b2524adb8155e6700e8a8e> Oh. Okay. I'm not in the right frame of mind. This should be easy for me!
[2016-04-05T02:23:03.126Z] <54b2524adb8155e6700e8a8e> np.where(masked_matrix.max(axis=0).toarray().ravel())[0] should work!
[2016-04-05T02:23:28.686Z] <54b2524adb8155e6700e8a8e> or equivalently: `np.flatnonzero(masked_matrix.max(axis=0))`
[2016-04-05T02:23:54.110Z] <54b2524adb8155e6700e8a8e> or just
[2016-04-05T02:24:01.961Z] <54b2524adb8155e6700e8a8e> masked_matrix.nonzero()[1]
[2016-04-05T02:24:04.349Z] <54b2524adb8155e6700e8a8e> sorry,
[2016-04-05T02:24:12.371Z] <54b2524adb8155e6700e8a8e> `masked_matrix.max(axis=0).nonzero()[1]`
[2016-04-05T02:30:16.324Z] <553d32d715522ed4b3df8b92> Thanks I got the idea now.  Will implement and get back to you.
[2016-04-05T02:37:28.539Z] <553d32d715522ed4b3df8b92> ``` (0, 0)	4.0   (1, 0)	6.0   (2, 0)	7.0   (0, 1)	2.0   (1, 1)	3.66666666667   (2, 1)	6.0   (0, 2)	1.0   (1, 3)	1.0 ``` This is the transformed X for X = sp.csc_matrix([[-1, 2], [6, -1], [7, 6]]). I think it is working now as you expected.  Thanks for all the help.
[2016-04-05T02:37:36.931Z] <54b2524adb8155e6700e8a8e> Yay!
[2016-04-05T02:37:53.622Z] <54b2524adb8155e6700e8a8e> I hope you're able to go through the steps and understand how this is doing what we want too...
[2016-04-05T02:38:12.817Z] <553d32d715522ed4b3df8b92> Gotcha.. it is clearer now.. 
[2016-04-05T02:39:55.829Z] <553d32d715522ed4b3df8b92> just a question, when you call ``eliminate_zeros`` all the zero entries are removed. Doesn't that happen by default when the sparse matrix is built ?
[2016-04-05T02:48:03.985Z] <553d32d715522ed4b3df8b92> Oh okay got it.. Building the matrix using the ``_with_data`` logic still populates the zeroes and needs to be manually removed to make it sparse.
[2016-04-05T02:54:32.855Z] <553d32d715522ed4b3df8b92> I will add some tests for sparse matrices too. Is there anything else you want me to look into here ? I need to go to my college now. Won't have access to the internet. Sorry. Will reply by evening. Thanks again for all the help.
[2016-04-05T14:00:47.894Z] <56a12a1de610378809bd831b> Hi all.  Is scikit-learn 0.17.1 the recommended version to use for new projects?  Thanks.
[2016-04-05T15:23:30.917Z] <56c4f19ae610378809c1f8ae> @staffhorn generally, yes
[2016-04-05T15:40:12.435Z] <56b80528e610378809c05a48> Anyone can help me review [this PR]? (https://github.com/scikit-learn/scikit-learn/pull/6593) :pray: 
[2016-04-07T16:18:42.624Z] <56b80528e610378809c05a48> Hey guys
[2016-04-07T16:19:06.239Z] <56b80528e610378809c05a48> Whats the recommended way to recompile a single .pyx file after I modify it?
[2016-04-07T16:20:29.162Z] <53135b495e986b0712efc453> You just do the `python setup.py build_ext` or `python setup.py build_ext -i` (for inplace building) again. It generates c and recompiles for the changed cython sources only.
[2016-04-07T16:20:51.411Z] <56c4f19ae610378809c1f8ae> if you just want to compile, you could do `cython primes.pyx`. but you probably want to build in place again for it all to work together.
[2016-04-07T16:21:01.159Z] <56c4f19ae610378809c1f8ae> yup, what @rvraghav93 said
[2016-04-07T16:21:05.647Z] <53135b495e986b0712efc453> ;)
[2016-04-07T16:21:40.474Z] <56b80528e610378809c05a48> oh okay thanks for your quick help :smile: 
[2016-04-07T16:22:44.358Z] <56b80528e610378809c05a48> Yeah @nelson-liu you are right, only compile is not what I want haha
[2016-04-07T16:29:40.241Z] <53135b495e986b0712efc453> > Anyone can help me review [this PR]?  ![](https://i.imgur.com/FNqNVVw.png) ;P
[2016-04-07T16:30:06.350Z] <56c4f19ae610378809c1f8ae> lol we should put that in contributing.rst :P haha  just kidding
[2016-04-07T16:30:08.672Z] <56b80528e610378809c05a48> hahahahaha
[2016-04-07T16:30:16.153Z] <56b80528e610378809c05a48> good idea
[2016-04-07T16:30:37.118Z] <53135b495e986b0712efc453> (just kidding) we should add THIS in the PR template ;P
[2016-04-07T16:44:06.550Z] <56b80528e610378809c05a48> :satisfied: 
[2016-04-07T17:04:46.078Z] <54e07d6515522ed4b3dc0858> Do we have a make target to cythonize only what's needed?
[2016-04-07T17:13:57.915Z] <53135b495e986b0712efc453> By only what's needed, you mean to say - Only specific modules?
[2016-04-07T17:33:40.377Z] <55866cb115522ed4b3e23aa4> is python 3.x fully supported by scikit
[2016-04-07T17:33:51.915Z] <56c4f19ae610378809c1f8ae> yes, it should be.
[2016-04-07T17:34:11.659Z] <56c4f19ae610378809c1f8ae> i know 3.5 is fully supported
[2016-04-07T17:34:45.845Z] <56c4f19ae610378809c1f8ae> its been tested with 3.4 / 3.5, and 3.3 should also work. not sure about 3.1 or 3.2
[2016-04-07T17:35:42.977Z] <55866cb115522ed4b3e23aa4> in that case if i want to get into contributing to scikit, using python 3 syntax for `print` should not be a problem in pull requests
[2016-04-07T17:36:23.334Z] <56c4f19ae610378809c1f8ae> indeed
[2016-04-07T17:36:33.541Z] <56c4f19ae610378809c1f8ae> if you look at https://github.com/scikit-learn/scikit-learn/search?utf8=%E2%9C%93&q=print, youll see that the <unconvertable> print' statements are all functions
[2016-04-07T17:37:25.022Z] <56c4f19ae610378809c1f8ae> make sure to `from __future__ import print_function`, though.
[2016-04-07T19:28:01.428Z] <56c4f19ae610378809c1f8ae> @rvraghav93 / others working with the tree module - if youve read breimans <unconvertable> Classification and Regression Trees, would you recommend it as a resource to get familiar with the theory?
[2016-04-07T20:33:13.574Z] <56c4f19ae610378809c1f8ae> might as well tag @glouppe as well
[2016-04-07T20:42:09.916Z] <56c63d67e610378809c22b14> i'd like to do classification/regression with multiple outputs, but each example only has the observed labels for one of the outputs. Although the DataSet object has entires for masks, which seems like it should fit the bill, I'm getting the impression that the masks only works for rnns and not for feedfoward classification/regression nets. Is that correct?
[2016-04-07T20:44:23.526Z] <56c4f19ae610378809c1f8ae> can you link the example you were looking at?
[2016-04-08T11:05:12.877Z] <56ed0b8885d51f252ab9a1b8> Hi guys
[2016-04-08T11:30:21.388Z] <56ed0b8885d51f252ab9a1b8> I have images with different objects in them such as trees, grass,river etc and want to classify which object is present in each image. Can anyone help me do the following a) load all the images one time from a folder b)Extract features b) Concatenate all features features into a matrix or a vector. This is my link to the working files https://github.com/Ben-Kobby/My-Project.git. Thank you.
[2016-04-08T11:34:17.201Z] <56c625c3e610378809c22760> Hey everyone, just had a small doubt. I'm trying to implement a feature selection algorithm which uses a term-category matrix. I'm trying to implement it on the 20NG dataset. Currently I'm using `CountVectorizer` to produce the term-doc matrix (by  transposing the output of `fit_transform`). However I want to create a term-category matrix from this by mapping the count in these docs to another matrix with 20 columns. What would be the most efficient way to do this mapping? Thanks in advance!
[2016-04-08T13:11:28.085Z] <53135b495e986b0712efc453> @nelson-liu Yes its a good resource, but is pretty huge. You could start with some simple youtube videos/blog posts explaining the concept of CART and learn more as you go (atleast that is what I did)... Please feel free to ping myself or Jacob (here or in e-mail) if you need any help.
[2016-04-14T20:56:06.499Z] <570beab4187bb6f0eadeef70> hey all, is there anyone experienced using LSTM-RNN for labeling each frame of a video data
[2016-04-14T22:11:23.691Z] <55901c1b15522ed4b3e2f949> No,  but I can sound confident when I tell you stuff.
[2016-04-14T22:12:06.082Z] <56c4f19ae610378809c1f8ae> haha :smile:
[2016-04-14T22:14:19.704Z] <557fdd5f15522ed4b3e1f9bd> @dsquareindia I don't think your question is answerable as currently stated. How do you intend to map counts to categories?
[2016-04-14T22:15:12.575Z] <54e07d6515522ed4b3dc0858> @dsquareindia it sounds like you want to use [LabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) to get a categorical one-hot Y, then just do Y.T * X
[2016-04-14T22:15:33.489Z] <54e07d6515522ed4b3dc0858> where X is the output of CountVectorizer. This should give you word counts per category.
[2016-04-14T22:16:38.334Z] <54e07d6515522ed4b3dc0858> (I'm using * instead of dot because X is sparse)
[2016-04-14T22:16:39.569Z] <557fdd5f15522ed4b3e1f9bd> @vene +1 I suppose @dsquareindia is making the claim that if a document is labeled X, then a term in that document should also belong to the category X. 
[2016-04-14T22:16:54.468Z] <557fdd5f15522ed4b3e1f9bd> correct?
[2016-04-14T22:49:48.805Z] <54e07d6515522ed4b3dc0858> You can find reason to count word-category occurrences without making that strong assumption. Maybe he's using the count matrix to do some other calculations afterwards.
[2016-04-15T01:14:47.563Z] <557fdd5f15522ed4b3e1f9bd> @vene makes sense, thanks.
[2016-04-15T01:20:13.331Z] <54e07d6515522ed4b3dc0858> I think our chi2 feature selector is asking these lines
[2016-04-15T01:35:54.467Z] <54e07d6515522ed4b3dc0858> *along these lines
[2016-04-15T09:04:17.022Z] <56c625c3e610378809c22760> Thanks a lot @Zintinio and @vene for the help! Yes I want to use that count matrix for some further calculations. Also, yes I'm making the assumption that if a doc is labeled X then the term belonging to that doc also belongs to the category X. Basically if a particular term occurs in a document categorized as X, then in the term-cat matrix the entry correspoding to that term and cat (X in this case) is updated by one. I then assign certain weights for each term for each category and see how much that term contributes to each category. This is in turn used in performing feature selection.
[2016-04-15T11:16:46.519Z] <570beab4187bb6f0eadeef70> hey all, is there anyone experienced using LSTM-RNN for labeling each frame of a video data
[2016-04-15T11:49:45.952Z] <53135b495e986b0712efc453> @oakkas re-posting the same question will not get you a response ;) If you have a particular question that is not suitable for a quick discussion, I would suggest that you post it as a thread to our mailing list or stackoverflow. If people know about it and your question interests them, they will respond in detail.
[2016-04-15T11:52:13.858Z] <53135b495e986b0712efc453> That being said, LSTM-RNN is deep learning stuff that is not a part of scikit-learn. You would be better off contacting the Mailing List of some deep learning library like theano, tensorflow or caffe... Or even better like I said before stackoverflow.
[2016-04-15T15:24:43.631Z] <54d4a1d6db8155e6700f853b> reddit seems to be decent for deep learning discussions these days
[2016-04-15T20:03:20.457Z] <53810862048862e761fa2887> Any idea whats happening here ? Due to some reason numpy does not print strings with quotes
[2016-04-15T20:03:27.251Z] <53810862048862e761fa2887> https://travis-ci.org/scikit-learn/scikit-learn/jobs/123430159
[2016-04-18T21:01:48.008Z] <544906e2db8155e6700cdd16> hi everyone, I'd like to compare different scorers for univariate feature selection. Currently scikit-learn provides chi2 and f_classif but I'd like to use others like document frequency, infogain and bi-normal separation too (here is a comparative study http://www.jmlr.org/papers/volume3/forman03a/forman03a.pdf).  I've already written a vectorized implementation of infogain but according to the chi2 documentation (http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2) it seems that it should return the infogain scores along with an array containing the p_values of each feature. How should I calculate/interpret that p_values?
[2016-04-19T00:24:42.086Z] <530c03e25e986b0712efafb8> Howdy folks, I've been playing with sklearn for an example using [dask.distributed](http://github.com/dask/distributed) `Futures`.  I suspect that I'm making poor choices regarding machine learning and would appreciate feedback.  https://gist.github.com/mrocklin/80b0d6f57dedc1628954ced5ef5500b0
[2016-04-20T15:43:52.167Z] <530c03e25e986b0712efafb8> http://matthewrocklin.com/blog/work/2016/04/20/dask-distributed-part-5
[2016-04-20T16:43:48.733Z] <56c4f19ae610378809c1f8ae> I read this blog post recently describing how the Atom editor developers manage github issues, and i think lots of the advice given could apply to  scikit-learn as well! http://blog.atom.io/2016/04/19/managing-the-deluge-of-atom-issues.html
[2016-04-21T08:01:41.400Z] <541a528b163965c9bc2053de> Sorry too late to reply: I commented on your post. I think besides the randomized parameter search or exhaustive grid search use case, the other common machine learning use case that really benefit from distributed training is gradient boosted trees. The implementation of boosted trees in scikit-learn is not really amenable to cluster-wise distribution in its current form. However xgboost is really mature in that regard and already provides hadoop yarn integration. I think it would run great on top of dask.distributed. They also plan better integration with pandas dataframe but this is still on the roadmap.
[2016-04-21T15:18:58.113Z] <569ebe44e610378809bd2db4> I am a little concerned about example http://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html#example-feature-selection-plot-feature-selection-py
[2016-04-21T15:19:22.262Z] <569ebe44e610378809bd2db4> there is not blue bar for the second feature
[2016-04-21T15:19:34.294Z] <569ebe44e610378809bd2db4> and smaller bar for the forth one
[2016-04-21T15:19:54.313Z] <569ebe44e610378809bd2db4> thus I am not sure how the example proves that feature selection improves SVM..
[2016-04-24T06:09:55.967Z] <5693aff116b6c7089cc207c3> Hi all,
[2016-04-24T06:12:31.448Z] <5693aff116b6c7089cc207c3> I am new to sklearn, and I really like this stuff. I want to contribute, but I think, I must use sklearn to a good level. And then start diving into methods. Can you suggest me a way to start? At end I want to be a one of the core contributor of sklearn, no matter how much time or years it takes.
[2016-04-24T06:13:42.820Z] <56c4f19ae610378809c1f8ae> A good place to start is to try kaggle competitions
[2016-04-24T06:15:51.797Z] <5693aff116b6c7089cc207c3> And I can start using sklearn from basics here?
[2016-04-24T06:16:37.067Z] <557c765a15522ed4b3e1de4f> are you trying to learn sklearn or are yout rying to learn data science?
[2016-04-24T06:17:01.287Z] <56c4f19ae610378809c1f8ae> I think the former, but the best way to do so much s to learn basic data science imo
[2016-04-24T06:17:27.235Z] <56c4f19ae610378809c1f8ae> *is to learn 
[2016-04-24T06:17:33.892Z] <557c765a15522ed4b3e1de4f> well it seems to me they are very different learning tasks
[2016-04-24T06:19:11.520Z] <56c4f19ae610378809c1f8ae> If the goal is to eventually contribute, you'd want knowledge of how the various algorithms work, what their use cases are, etc. The easiest way to do this imo is to just use them in various applications. 
[2016-04-24T06:19:26.600Z] <5693aff116b6c7089cc207c3> Yes sklearn. I am a pythonist, and I want to dwelve into sklearn functions and contribute. Right way is to strengthen my basics. I think I can go with what @nelson-liu  suggested.
[2016-04-24T06:19:44.568Z] <557c765a15522ed4b3e1de4f> doesn't make any sense to me but whatevs
[2016-04-24T06:21:34.084Z] <5693aff116b6c7089cc207c3> @elbamos according to you, what is the right approach, if someone wants to be a good contributor to sklearn?
[2016-04-24T06:25:17.330Z] <56b80528e610378809c05a48> If the goal is to contribute, then [here](http://scikit-learn.org/stable/developers/contributing.html#easy-issues) has already answered your question
[2016-04-24T06:28:10.818Z] <5693aff116b6c7089cc207c3> Thanks @yenchenlin1994 @elbamos  @nelson-liu 
[2016-04-24T20:34:37.161Z] <557c765a15522ed4b3e1de4f> @harshul1610 To answer your question:  Implementing a machine-learning algorithm is hard.  Its not enough to be able to program.  You have to really understand the *math*, and debugging the math is challenging.  And you have to also understand how data scientists actually use these algorithms.   
[2016-04-25T01:16:28.206Z] <5693aff116b6c7089cc207c3> Makes sense. Thanks. :)
[2016-04-25T22:27:53.613Z] <53135b495e986b0712efc453> Hey @nelson-liu I won't be able to help review the Mae before this weekend.  But please use the time to make yourself more familiar with the tree module. Look at the splitter.pyx and learn about pointers and array operations in cython. Use the `%%cython` ipython cell magic to try out small programs... I would advice against spending time on other simple PRs as I feel you have enough experience to move on to core scikit learn and learn the more awesome stuff! :)
[2016-04-25T22:31:44.054Z] <53135b495e986b0712efc453> Also I'll add you to a trello board for your GSoC by this weekend. I found it useful myself. If you can spare some time please go ahead and add one yourself and invite myself and Jacob to that!
[2016-04-25T22:42:12.303Z] <56c4f19ae610378809c1f8ae> sure, so do you want me to create the trello board or will you add me?
[2016-04-25T22:42:20.916Z] <56c4f19ae610378809c1f8ae> Ill just make one and add you
[2016-04-25T23:01:09.676Z] <53135b495e986b0712efc453> Yes thanks for doing that! I've added a cython card with some toy exercises for you to try out. (Hope you don't find my micro managing annoying... ^_^)
[2016-04-25T23:01:42.749Z] <56c4f19ae610378809c1f8ae> haha i dont, its great. does trello have chat capabilities? I think itd be best if we moved gsoc-related discussion away from this gitter channel to avoid spam
[2016-04-25T23:05:06.433Z] <53135b495e986b0712efc453> It doesn't have any chat capability.  comment system there is also not super convenient. I wouldn't consider this spam. I would keep it here itself! (Typically gsoc communications occur at irc and you are asked to provide the irc nick. Looks like gitter is the new irc. ;) )
[2016-04-25T23:06:31.469Z] <53135b495e986b0712efc453> What time zone are you in btw?
[2016-04-25T23:06:48.588Z] <56c4f19ae610378809c1f8ae> PST, but Im up early and sleep late ;)
[2016-04-25T23:09:01.573Z] <53135b495e986b0712efc453> Haha. Good to know. 
[2016-04-28T10:44:11.653Z] <564789be16b6c7089cbab8b7> Hi.. I have a binary classification task with 300 positive examples 300 million negative
[2016-04-28T10:44:16.652Z] <564789be16b6c7089cbab8b7> Is there a sensible way to handle this?
[2016-04-28T10:47:03.215Z] <569ebe44e610378809bd2db4> what do you mean by "to handle" ?
[2016-04-28T10:48:09.958Z] <564789be16b6c7089cbab8b7> well I would like to use the knowledge about the  300 million negative examples to learn what "normal" looks like
[2016-04-28T10:49:33.714Z] <564789be16b6c7089cbab8b7> @hmha  I could just throw it at a random forest and ignore the massive skew. Is that a sensible thing to do?
[2016-04-28T10:51:48.039Z] <569ebe44e610378809bd2db4> @lesshaste sorry, I don't have enough knowledge yet to help you
[2016-04-28T10:53:42.776Z] <564789be16b6c7089cbab8b7> @hmha  no problem at all
[2016-04-28T10:54:28.684Z] <564789be16b6c7089cbab8b7> it would be nice if some of these were in scikit-learn https://github.com/fmfn/UnbalancedDataset
[2016-04-28T11:42:46.252Z] <54e07d6515522ed4b3dc0858> If you think a linear model could work, you could optimize for AUC by training on pairwise differences of positive and negative examples.
[2016-04-28T11:50:53.574Z] <564789be16b6c7089cbab8b7> @vene  An interesting suggestion.  Unfortunately it my case I don't think linear models will work
[2016-04-28T11:51:19.867Z] <564789be16b6c7089cbab8b7> Also, there are a lot of pairs of positive and negative examples aren't there?
[2016-04-28T12:51:22.922Z] <54e07d6515522ed4b3dc0858> there are a lot indeed, but you could stochastically subsample the pairs and do partial_fit sgd iterations
[2016-04-28T12:51:35.894Z] <54e07d6515522ed4b3dc0858> it's the idea used in sofia-ml, which is pretty great
[2016-04-28T13:47:10.431Z] <564789be16b6c7089cbab8b7> now I need to look up sofia-ml! :)
[2016-04-28T13:58:03.759Z] <564789be16b6c7089cbab8b7> @vene  but for my problem I can't see that linear models would work
[2016-04-28T13:58:44.755Z] <564789be16b6c7089cbab8b7> the "numerical data" has special values that seem to indicate particular things. So 1,56,123 have some meaning from 200-10000 don't for example. Except I don't get told what those are
[2016-04-28T13:59:04.109Z] <564789be16b6c7089cbab8b7> random forests are good at picking these out
[2016-04-28T15:05:57.372Z] <54e07d6515522ed4b3dc0858> true. You could discretize the data, I guess. In random forests you can just use sample weights to deal with class imbalance.
[2016-04-28T15:06:45.068Z] <54e07d6515522ed4b3dc0858> actually it seems now you can actually use `class_weight="balanced"`
[2016-04-28T15:06:48.027Z] <564789be16b6c7089cbab8b7> the problem is its not clear a priori how to bin the numerical data, if that is what you mean
[2016-04-28T15:06:58.144Z] <564789be16b6c7089cbab8b7> I am not 100% convinced that actually does anything :)
[2016-04-28T15:07:04.075Z] <564789be16b6c7089cbab8b7> there is an issue about that I think
[2016-04-28T15:07:18.537Z] <564789be16b6c7089cbab8b7> but I will certainly try that
[2016-04-28T15:45:18.167Z] <54e07d6515522ed4b3dc0858> it should reweigh the samples accordingly. The problem is, that isn't guaranteed to be better.
[2016-04-28T15:45:27.912Z] <564789be16b6c7089cbab8b7> ah ok
[2016-04-28T15:45:29.827Z] <564789be16b6c7089cbab8b7> that's interesting
[2016-04-28T23:45:27.867Z] <54e07d6515522ed4b3dc0858> @lesshaste I'm not saying there is no bug there, I am not familiar with the code
[2016-04-28T23:46:00.168Z] <54e07d6515522ed4b3dc0858> but I'm saying that, even with linear models, `class_weight="balanced` does not necessarily lead to better generalization
[2016-04-28T23:50:13.472Z] <54e07d6515522ed4b3dc0858> If you're into deep learning stuff, you can use a similar sampling strategy + pairwise training there. I think they call it "contrastive loss" in that world :)
[2016-04-29T04:04:57.002Z] <5629b22416b6c7089cb7f6f7> @lesshaste other options for imbalanced data: 1) when it is that skewed, try anomaly detection. 2) I found this downsampling+bagging from Wallace et. al. to be principled approach (https://scholar.google.com/scholar?cluster=225520837537786880&hl=en&as_sdt=0,5&as_vis=1)
[2016-04-29T06:07:47.579Z] <53810862048862e761fa2887> @ogrisel @amueller  You think it's necessary to upload the wheels of the template project on Rackspace ? Granted the wheels won't be of much use, but it could serve as an example for projects which clone it.
[2016-04-29T08:57:24.492Z] <54bd1809db8155e6700ed1e4> does anyone know when the argument `loss_func` was removed from GridSearchCV? Cannot find it in the changelog
[2016-04-29T09:44:48.798Z] <56c4f19ae610378809c1f8ae> @HolgerPeters https://github.com/scikit-learn/scikit-learn/pull/3411
[2016-04-29T09:47:05.108Z] <56c4f19ae610378809c1f8ae> Seems like it was planned to be removed in 0.15, but might have been removed later. I couldnt find any mention of it in the changelog as well.
[2016-04-29T09:49:10.986Z] <56c4f19ae610378809c1f8ae> date on that is july 17, 2014. 0.15.0 was released on July 15 2014, and 0.15.1 was released on Aug 1 2014. Im presuming it was thus gone by 0.15.1?
[2016-04-29T13:15:26.955Z] <564789be16b6c7089cbab8b7> @cfperez  thanks very much
[2016-04-29T13:15:48.308Z] <564789be16b6c7089cbab8b7> @vene I will look up "contrastive loss" thanks
[2016-04-29T13:17:38.426Z] <564789be16b6c7089cbab8b7> @cfperez  in my case I am wondering whether the extreme nature of the class imbalance (300 versus 300 millions) means that black box methods might not be appropriate
[2016-04-29T13:17:55.324Z] <564789be16b6c7089cbab8b7> that is i may have to do something other than try to infer the model from the data
[2016-04-29T14:29:17.810Z] <54d4a1d6db8155e6700f853b> @vighneshbirodkar Sounds like a good idea
[2016-04-30T12:18:04.833Z] <57231db2659847a7aff51acf> @cfperez  downsampling and probably boosting?
[2016-05-03T15:17:29.801Z] <53135b495e986b0712efc453> @amueller @ogrisel when is the 0.18 release?
[2016-05-04T04:47:05.849Z] <564789be16b6c7089cbab8b7> @rvraghav93  and what new features will be in it?
[2016-05-04T12:25:25.194Z] <53135b495e986b0712efc453> Here you go - http://scikit-learn.org/dev/whats_new.html#version-0-18 ;)
[2016-05-04T13:05:27.646Z] <53135b495e986b0712efc453> Hey @yenchenlin1994! Have you made an introductory blog post for the community bonding period? :) If so could you start a thread to our mailing list "GSoC 2016: Adding fused types to Cython files", where you could post the progress of your GSoC/blog post links etc?
[2016-05-04T13:31:55.874Z] <54d4a1d6db8155e6700f853b> @rvraghav93 @ogrisel I'd like to do one in june for the book, but I'm not sure if that will be possible
[2016-05-04T15:00:04.949Z] <53135b495e986b0712efc453> Yes let's make it possible B) I've removed all the deprecated stuff. Now coming to `model_selection`, Do you think https://github.com/scikit-learn/scikit-learn/pull/6697 is going in the right direction? (Keeping in mind that we will add multiple metric support next)
[2016-05-04T15:00:59.283Z] <53135b495e986b0712efc453> There are around 30 items open for the 0.18 milestone - https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+is%3Aissue+milestone%3A0.18
[2016-05-04T15:44:39.103Z] <54d4a1d6db8155e6700f853b> @rvraghav93 a quick glance says the PR looks good but I have to continue writing right now ;)
[2016-05-04T15:44:42.087Z] <54d4a1d6db8155e6700f853b> at least for two more weeks
[2016-05-04T15:44:59.744Z] <53135b495e986b0712efc453> Ok I'll get it merged meanwhile B)
[2016-05-04T15:47:41.520Z] <54d4a1d6db8155e6700f853b> there are probably a lot of bugs that are not tagged 0.18 but should be fixed
[2016-05-04T16:42:38.774Z] <53135b495e986b0712efc453> @ogrisel Could we split our gitter channel into two? `scikit-learn(-general)`/`scikit-learn-dev`. Both can be read by anyone, the second will be writable only to core devs/devs who have contributed significantly? It will help filter out noise that we occasionally get here!
[2016-05-04T16:48:24.901Z] <53135b495e986b0712efc453> Ah looks like it's not yet available - https://github.com/gitterHQ/gitter/issues/1112 :/
[2016-05-04T18:28:05.962Z] <53135b495e986b0712efc453> Any way could we have a separate dev room nevertheless `scikit-learn/(scikit-learn-)dev` maybe?
[2016-05-04T19:31:35.578Z] <564789be16b6c7089cbab8b7> @rvraghav93  this room is very low traffic isn't it?
[2016-05-04T19:32:19.681Z] <53135b495e986b0712efc453> Indeed. But I felt a dedicated dev room would be cool. Something like slack ;)
[2016-05-04T19:32:34.553Z] <564789be16b6c7089cbab8b7> :)  .. what is "slack"?
[2016-05-04T19:32:50.942Z] <53135b495e986b0712efc453> https://slack.com/
[2016-05-04T19:33:15.612Z] <564789be16b6c7089cbab8b7> ooh.. I think the fact I didn't know that is a reason itself to have a separate room :)
[2016-05-04T19:35:37.605Z] <53135b495e986b0712efc453> Haha no. It's just that sometimes conversation not related to dev could be kept in a separate room :)
[2016-05-04T19:36:09.883Z] <564789be16b6c7089cbab8b7> :) The risk for non-devs is that all the devs will leave this other room I suppose and it will end up like #scikit-learn on irc
[2016-05-04T19:37:27.920Z] <53135b495e986b0712efc453> No they won't. All scikit-learn devs love to answer user questions if its relevant to scikit-learn. ;)
[2016-05-04T19:37:39.861Z] <564789be16b6c7089cbab8b7> :)
[2016-05-04T19:37:58.971Z] <564789be16b6c7089cbab8b7> I have  a question! :)
[2016-05-04T19:38:07.132Z] <557c765a15522ed4b3e1de4f> @rvraghav93 Dude, I think you should follow the torch7 gitter for a few days before you say things like that
[2016-05-04T19:38:32.132Z] <53135b495e986b0712efc453> What goes on there?
[2016-05-04T19:39:19.946Z] <557c765a15522ed4b3e1de4f> the number of "my neural net won't predict right I think torch is broken will you configure it for me" questions is so annoying, I'm afraid the major devs are going to decide open sourcing isn't worth their trouble
[2016-05-04T19:39:21.316Z] <53135b495e986b0712efc453> Holy wow. Its a huge mess of newbie questions.
[2016-05-04T19:39:30.549Z] <557c765a15522ed4b3e1de4f> and they're obnoxious too.
[2016-05-04T19:39:32.834Z] <53135b495e986b0712efc453> Yes I just saw.
[2016-05-04T19:39:59.976Z] <557c765a15522ed4b3e1de4f> one guy actually demanded that he thought there was sa bug in a piece of code, and he gave an example task he said the developer should program to prove that the code works
[2016-05-04T19:40:18.471Z] <53135b495e986b0712efc453> Hahaha xD
[2016-05-04T19:40:25.897Z] <557c765a15522ed4b3e1de4f> i'm not making that up man
[2016-05-04T19:40:27.759Z] <564789be16b6c7089cbab8b7> we are much nicer here :)
[2016-05-04T19:40:51.155Z] <564789be16b6c7089cbab8b7> is on on topic for me to ask a question about clustering here? 
[2016-05-04T19:40:52.156Z] <53135b495e986b0712efc453> LOL hope we don't get such users. That has something to do with our awesome documentation I suppose!
[2016-05-04T19:41:08.206Z] <53135b495e986b0712efc453> Oh yes you wanted to ask me something. Yes please go ahead!
[2016-05-04T19:41:08.610Z] <564789be16b6c7089cbab8b7> the documentation is awesome!
[2016-05-04T19:41:58.288Z] <557c765a15522ed4b3e1de4f> and just fyi - the guy who is one of the key maintainers of torch, who answers the bulk of questions, is a senior engineer in facebook's AI group in NYC.  (Really great, nice guy too.)  I cannot for the life of me understand why he is answerjkng questions like that at 3 a.m., as his reward for having contributed literally thousands of hours of work to the machine learning community between his torch development and the papers he's written and code he's open-sourced. 
[2016-05-04T19:42:47.237Z] <564789be16b6c7089cbab8b7> I have lots of feature vectors with numerical.  The numerical values are a little odd however.  Say the numbers are in the range 1-10000 the 69 and 123 might have a particular meaning but I don't get to know which ones those are in advance.  A random forest works really well for classification as it magically picks out those special values. So that part is great
[2016-05-04T19:43:05.100Z] <564789be16b6c7089cbab8b7> I would now like to cluster my vectors. What on Earth would a good method be?
[2016-05-04T19:43:32.253Z] <564789be16b6c7089cbab8b7> the point being that distances are highly non-linear due to this odd feature of the numerical values
[2016-05-04T19:44:01.869Z] <557c765a15522ed4b3e1de4f> @lesshaste - your numerical variables are actually categorical.  Or they're a mix of categorical and continuous variables, and your data isn't in a tidy format.  Either way, there are literally multiple whole textbooks on selecting a good clustering method. 
[2016-05-04T19:44:03.122Z] <53135b495e986b0712efc453> @elbamos I guess that also helps devs understand which part of their code is so unintuitive to newbies. I mean that's like a window, although nasty one, into the users mind. "Okay this is a common concern with everyone. Let's document this as a FAQ."
[2016-05-04T19:44:39.475Z] <564789be16b6c7089cbab8b7> @elbamos  they are exactly a mix of categorical and numerical I suppose. They are all integer valued so not exactly continuous.
[2016-05-04T19:44:44.611Z] <557c765a15522ed4b3e1de4f> @rvraghav93 I appreciate your ability to look on the bright side, but after being in that forum for a while...
[2016-05-04T19:45:01.397Z] <53135b495e986b0712efc453> @lesshaste I think you need to first separate out the 69 and 123 into 2 separate features. And later try out different clustering algorithms on it?
[2016-05-04T19:45:24.590Z] <564789be16b6c7089cbab8b7> @elbamos  oh I did some research but didn't find anything that covered this situation where a particular feature is part categorical and part numerical but you don't know in advance which parts are which
[2016-05-04T19:45:40.386Z] <557c765a15522ed4b3e1de4f> @lesshaste if you have a single variable that's a combination of categorical and continuous variables, then your data isn't in a tidy format, and unless you did that on purpose because you're super-ultra-smart, you aren't going to be able to get results out of that.
[2016-05-04T19:46:11.032Z] <557c765a15522ed4b3e1de4f> the reson you're not finding anything covering it, is that what you need to do is break each variable up to separate categorical and numerical parts.  that is part of the task of cleaning your data which is part of every machine learning project. 
[2016-05-04T19:46:23.943Z] <564789be16b6c7089cbab8b7> @elbamos  ok I do.  The point is that using a random forest as a classifier works really well so I somehow feel I should be able to use this fact
[2016-05-04T19:46:52.290Z] <564789be16b6c7089cbab8b7> @rvraghav93  ok but to find the 69 and 123 I need to actually build a classifier
[2016-05-04T19:47:04.249Z] <564789be16b6c7089cbab8b7> or at least I don't know another way
[2016-05-04T19:47:05.244Z] <53135b495e986b0712efc453> You could use the random forest classifier to do that right?
[2016-05-04T19:47:34.549Z] <557c765a15522ed4b3e1de4f> that's because part of the random forest algorithm finds cut-points in each variable, so its attempting to take the variables make them all categorical. except your data includes multiple actual variables in individual data variables
[2016-05-04T19:47:46.723Z] <564789be16b6c7089cbab8b7> ok so I could do that. Do a supervised learning stage to separate our numerical and categorical parts , then split the data and do an unsupervised clustering
[2016-05-04T19:48:04.550Z] <53135b495e986b0712efc453> Yes
[2016-05-04T19:48:38.044Z] <53135b495e986b0712efc453> But when you know the data == 69 means something different, why don't you just filter that out  (data==69)?
[2016-05-04T19:48:51.831Z] <564789be16b6c7089cbab8b7> well it's not quite that simple sadly
[2016-05-04T19:49:14.313Z] <53135b495e986b0712efc453> Okay then use the rf. That would be possible I think!
[2016-05-04T19:49:24.737Z] <564789be16b6c7089cbab8b7> these are byte counts in some network traffic. Some individual byte counts indicate particular behaviour 
[2016-05-04T19:49:38.452Z] <564789be16b6c7089cbab8b7> but the others are just how large the data transfer happens to be
[2016-05-04T19:49:49.194Z] <557c765a15522ed4b3e1de4f> then what you want to do is create additional variables for whether the byte count matches particular known behaviors
[2016-05-04T19:50:01.835Z] <564789be16b6c7089cbab8b7> I feel there should be an entirely unsupervised way. For example https://labs.genetics.ucla.edu/horvath/RFclustering/RFclustering.htm ?
[2016-05-04T19:50:09.624Z] <564789be16b6c7089cbab8b7> but I know nothing about that work
[2016-05-04T19:50:34.644Z] <564789be16b6c7089cbab8b7> @elbamos  yes I can do that. But do I still split the feature into parts to do the clustering?
[2016-05-04T19:52:04.962Z] <557c765a15522ed4b3e1de4f> @lesshaste data science is a science.  there isn't a single recipe.  you need to experiment to find the right recipe for your data and your goal.  You can't just take data in raw form and feed it into scikit-learn and expect to get a result that's useful.  scikit is a tool for doing science, it doesn't do the science for you.  again, there are literally entire textbooks on selecting different clustering algorithms. 
[2016-05-04T19:53:09.394Z] <564789be16b6c7089cbab8b7> @elbamos  yes thank you. I did do some research but I feel the resources I have found don't talk about mixed numerical and categorical features so mcuh
[2016-05-04T19:53:17.347Z] <564789be16b6c7089cbab8b7> but I am no expert
[2016-05-04T19:53:34.612Z] <564789be16b6c7089cbab8b7> or at least not the sort of mixture I am talking about
[2016-05-04T19:53:46.499Z] <564789be16b6c7089cbab8b7> @rvraghav93  do you think paper is interesting?
[2016-05-04T19:54:28.421Z] <564789be16b6c7089cbab8b7> it's also very hard to evaluate how well you have clustered it seems
[2016-05-04T19:54:52.781Z] <564789be16b6c7089cbab8b7> I was very interested in the PR that tries to estimate the correct number of clusters by the way
[2016-05-04T19:57:23.430Z] <564789be16b6c7089cbab8b7> hmm.. maybe the isolation forests we have now in scikit-learn are based on that paper?
[2016-05-04T22:49:39.849Z] <53135b495e986b0712efc453> Isolation forest IIRC is for anomaly detection? I may be wrong. Sorry I don't have much knowledge on that!
[2016-05-04T22:57:23.405Z] <54e07d6515522ed4b3dc0858> How about a random forest embedding + k-means, @lesshaste ?
[2016-05-05T05:30:38.323Z] <564789be16b6c7089cbab8b7> @vene How do you do a random forest embedding?
[2016-05-05T05:32:48.489Z] <564789be16b6c7089cbab8b7> Oh...reading about it now.
[2016-05-05T07:11:05.927Z] <56b80528e610378809c05a48> hello @rvraghav93   Really sorry for the late reply, just survived from my midterm :smile:  Yeah Ill send it to the mailing list today!
[2016-05-05T07:11:17.600Z] <56c4f19ae610378809c1f8ae>  yay, congrats!
[2016-05-05T07:11:43.267Z] <56b80528e610378809c05a48> haha you too
[2016-05-05T08:35:04.748Z] <564789be16b6c7089cbab8b7> when was random forest embedding added to scikit-learn?
[2016-05-05T16:17:45.296Z] <564789be16b6c7089cbab8b7> @vene  thanks I will try that idea. Do you happen to know when was random forest embedding added to scikit-learn?
[2016-05-05T16:18:28.047Z] <564789be16b6c7089cbab8b7> oh.. 0.13! Not sure how I missed it
[2016-05-05T16:18:41.999Z] <54e07d6515522ed4b3dc0858> I think at least 2ish releases ago
[2016-05-05T16:18:46.542Z] <54e07d6515522ed4b3dc0858> Oh
[2016-05-05T16:19:10.406Z] <564789be16b6c7089cbab8b7> do you have a view about https://labs.genetics.ucla.edu/horvath/RFclustering/RFclustering.htm ?
[2016-05-05T16:19:31.608Z] <564789be16b6c7089cbab8b7> I can't quite tell if it would provide something significantly new to what scikit learn already has
[2016-05-05T16:19:43.948Z] <564789be16b6c7089cbab8b7> if you follow the citations it seems isolation forests come from a similar idea
[2016-05-05T16:20:11.291Z] <564789be16b6c7089cbab8b7> I could open an issue I suppose but I feel a little ignorant on this topic
[2016-05-05T16:21:38.740Z] <564789be16b6c7089cbab8b7> @amueller  As the author of the random forest embedding, does this provide anything extra?
[2016-05-05T16:22:34.244Z] <564789be16b6c7089cbab8b7> @amueller  where "this" is https://labs.genetics.ucla.edu/horvath/RFclustering/RFclustering.htm
[2016-05-05T16:26:23.138Z] <54e07d6515522ed4b3dc0858> That tech report is really hard to skim
[2016-05-05T16:27:59.282Z] <54e07d6515522ed4b3dc0858> @lesshaste, the random forest embedding uses totally randomized trees, ie there is no learning
[2016-05-05T16:28:50.868Z] <564789be16b6c7089cbab8b7> yes... I did try myself.   http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf?q=isolationThis performs a comparison with this method apparently
[2016-05-05T16:29:14.221Z] <564789be16b6c7089cbab8b7> " In the first experiment we compare iForest with ORCA [3], LOF [6] and Random Forests (RF) [12]" where [12] is https://labs.genetics.ucla.edu/horvath/RFclustering/RFclustering.htm
[2016-05-05T16:30:32.343Z] <54e07d6515522ed4b3dc0858> I don't know anything about how isolation forests work. But it seems that the RFclustering approach trains a discriminative RF between the real data and randomly sampled data.
[2016-05-05T16:30:57.373Z] <564789be16b6c7089cbab8b7> ok that's interesting already
[2016-05-05T16:31:00.739Z] <54e07d6515522ed4b3dc0858> and uses that repr for clustering
[2016-05-05T16:32:12.169Z] <54e07d6515522ed4b3dc0858> Sampling-based approaches to anomaly detection never really struck me as a great idea. But in your case you might be able to tweak it more, because you know some things about the "ideal" generative process of your data
[2016-05-05T16:32:31.654Z] <54e07d6515522ed4b3dc0858> ie if network traffic were random
[2016-05-05T16:33:40.966Z] <564789be16b6c7089cbab8b7> what methods currently in scikit learn are suitable when the distance between features is highly non-linear? That is not at all Euclidean
[2016-05-05T16:34:08.752Z] <54e07d6515522ed4b3dc0858> what do you mean by distance between features?
[2016-05-05T16:35:21.039Z] <54e07d6515522ed4b3dc0858> btw if you plot a histogram of your data do you have some sort of "spikes" at the values that you say you want to treat as categorical?
[2016-05-05T16:36:05.938Z] <564789be16b6c7089cbab8b7> well yes sort of. Properly clustered there would be spikes in particular clusters but not in others
[2016-05-05T16:36:08.068Z] <54e07d6515522ed4b3dc0858> you might be able to hand-craft some sort of PGM mixture model
[2016-05-05T16:36:17.113Z] <564789be16b6c7089cbab8b7> what is PGM?
[2016-05-05T16:36:22.832Z] <54e07d6515522ed4b3dc0858> probabilistic graphical model
[2016-05-05T16:36:25.783Z] <54e07d6515522ed4b3dc0858> so a generative model
[2016-05-05T16:36:31.114Z] <564789be16b6c7089cbab8b7> ah yes.. well that would be great
[2016-05-05T16:36:40.880Z] <564789be16b6c7089cbab8b7> but it's hard to model network traffic
[2016-05-05T16:37:16.694Z] <54e07d6515522ed4b3dc0858> you have some latent variables that correspond to your payloads, and when you sample, you have a chance to sample from a random poisson(?) or to exactly(?) pick out the payload
[2016-05-05T16:37:19.281Z] <564789be16b6c7089cbab8b7> I meant distance between feature vectors, not feature. In other words (1,23) might be very far from (1,25) but (2,24) might be very close
[2016-05-05T16:37:56.257Z] <564789be16b6c7089cbab8b7> and (1,25) and (1,26) might be very close
[2016-05-05T16:38:02.998Z] <564789be16b6c7089cbab8b7> so it's just not a simple euclidean distance
[2016-05-05T16:41:56.520Z] <54e07d6515522ed4b3dc0858> Well, discriminative methods, even linear ones, could capture such a threshold I think
[2016-05-05T17:16:07.279Z] <564789be16b6c7089cbab8b7> interesting.. I did try linear regression on some labelled data and it was a disaster
[2016-05-05T17:16:12.537Z] <564789be16b6c7089cbab8b7> where a random forest worked really well
[2016-05-05T17:16:21.632Z] <564789be16b6c7089cbab8b7> I mean the linear regression essentially failed completely
[2016-05-05T21:15:28.660Z] <54e07d6515522ed4b3dc0858> is your task a regression task?
[2016-05-07T18:08:23.010Z] <572e2e2bc43b8c601971aa31> hey guys i'm new here 
[2016-05-07T18:08:44.887Z] <572e2e2bc43b8c601971aa31> needed some help  regarding machine learning
[2016-05-07T18:08:58.553Z] <572d31b4c43b8c6019718fca> Whats up? :)
[2016-05-07T18:09:23.473Z] <572e2e2bc43b8c601971aa31> i've just started studying about machine learning
[2016-05-07T18:09:54.427Z] <572e2e2bc43b8c601971aa31> and everywhere i read that machine learning course on Coursera by Andrew Ng
[2016-05-07T18:10:01.259Z] <572e2e2bc43b8c601971aa31> is good to begin with
[2016-05-07T18:10:13.649Z] <572e2e2bc43b8c601971aa31> but it is not focused on python 
[2016-05-07T18:10:24.566Z] <572e2e2bc43b8c601971aa31> and i want to use machine learning in python
[2016-05-07T18:10:43.248Z] <572e2e2bc43b8c601971aa31> so should i consider learning from somewhere else?
[2016-05-07T18:10:52.428Z] <572e2e2bc43b8c601971aa31> help me out
[2016-05-07T18:11:08.742Z] <54e07d6515522ed4b3dc0858> You can do the assignments in Python if you want to
[2016-05-07T18:11:14.259Z] <572d31b4c43b8c6019718fca> If you can do machine learning in one language, youll have little to no trouble switching languages :)
[2016-05-07T18:12:21.065Z] <572e2e2bc43b8c601971aa31> and what would you recommend on some good resources
[2016-05-07T18:12:39.139Z] <572d31b4c43b8c6019718fca> Good resources for what specifically?
[2016-05-07T18:12:54.299Z] <572e2e2bc43b8c601971aa31> or anything that can help me learn faster 
[2016-05-07T18:13:13.889Z] <572e2e2bc43b8c601971aa31> i'm not sure i have just started 
[2016-05-07T18:13:29.331Z] <572e2e2bc43b8c601971aa31> maybe how to implement the algorithms in python 
[2016-05-07T18:13:40.102Z] <572e2e2bc43b8c601971aa31> where should i learn that from
[2016-05-10T10:09:23.834Z] <549fecafdb8155e6700e3675> Has autoencoder not been implemented in scikit ?
[2016-05-10T10:43:50.378Z] <553d32d715522ed4b3df8b92> I suppose #2099 is a WIP for sparse auto encoder.
[2016-05-10T11:18:24.549Z] <56b0803ee610378809bf7535> Hello all, every time I get the error: "ERROR:py4j.java_gateway:Error while sending or receiving. Traceback (most recent call last):   File "/data/analytics/Spark1.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py", line 746, in send_command     raise Py4JError("Answer from Java side is empty") Py4JError: Answer from Java side is empty ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server Traceback (most recent call last):   File "/data/analytics/Spark1.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py", line 690, in start     self.socket.connect((self.address, self.port))   File "/usr/local/anaconda/lib/python2.7/socket.py", line 228, in meth     return getattr(self._sock,name)(*args) error: [Errno 111] Connection refused ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server Traceback (most recent call last):   File "/data/analytics/Spark1.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py", line 690, in start     self.socket.connect((self.address, self.port))   File "/usr/local/anaconda/lib/python2.7/socket.py", line 228, in meth     return getattr(self._sock,name)(*args) error: [Errno 111] Connection refused". My conf-file: "spark.serializer org.apache.spark.serializer.KryoSerializer  spark.kryoserializer.buffer.max 1500mb spark.driver.memory 65g #spark.driver.extraJavaOptions -Djava.io.tmpdir=/data/spark-tmp  spark.driver.extraJavaOptions -XX:-PrintGCDetails -XX:-PrintGCTimeStamps -XX:-PrintTenuringDistribution #XX:PermSize=20480m  spark.python.worker.memory 65g spark.local.dir /data/spark-tmp" The amount of data is about 5Gb.
[2016-05-10T11:20:36.172Z] <56b0803ee610378809bf7535> Does anybody know the answer?
[2016-05-10T11:24:46.842Z] <541a528b163965c9bc2053de> @AlexanderModestov please do not paste large (unquoted) error messages in the conversation but instead use a link to some gist or pastebin. Furthermore this seems to be specific to spark and not related to scikit-learn (the `sklearn` package does not even occur in the traceback) so I don't think this is the right place to ask such a question. You might want to ask this question on stackoverflow with the spark tag.
[2016-05-10T11:41:36.508Z] <56b0803ee610378809bf7535> @ogrisel I'm sorry. It's not about sklearn ...
[2016-05-10T14:13:38.941Z] <564789be16b6c7089cbab8b7> @vene  Hi. Sorry I meant logistic regression
[2016-05-11T02:29:27.598Z] <53135b495e986b0712efc453> @amueller By making GridSearchCV work well with EstimatorCV did you mean implementing generalized cross-validation? (https://github.com/scikit-learn/scikit-learn/issues/1626)
[2016-05-11T02:30:03.364Z] <557c765a15522ed4b3e1de4f> is anyone here very competitive about the relative capabilities of scikit-learn and R?  @amueller ?
[2016-05-11T09:22:07.365Z] <557c765a15522ed4b3e1de4f> ... because with the R package I just pushed to my git, I would really enhjoy some trash talking
[2016-05-11T14:47:50.732Z] <54d4a1d6db8155e6700f853b> @elbamos well I'd like to be scikit-learn as good as possible, and if you have an implementation that is much better than ours in some respect, I'd love to have your input ;)
[2016-05-11T14:48:06.075Z] <54d4a1d6db8155e6700f853b> @elbamos what did you push?
[2016-05-11T14:48:34.775Z] <54d4a1d6db8155e6700f853b> @rvraghav93 well part of that. I want to be able to use an EstimatorCV in GridSearchCV.
[2016-05-11T14:49:04.481Z] <54d4a1d6db8155e6700f853b> @rvraghav93 like using a CV object in a pipeline.
[2016-05-11T14:51:34.603Z] <54d4a1d6db8155e6700f853b> if you find a way to enable ``make_pipeline(StandardScaler(), LogisticRegressionCV())`` grid-searchable, that would be a start
[2016-05-11T14:52:35.891Z] <54d4a1d6db8155e6700f853b> or ``make_pipeline(SelectPercentile(...), LogisticRegressionCV())``
[2016-05-11T16:24:09.899Z] <557c765a15522ed4b3e1de4f> @amueller largevis. It's like tsne but efficient on ultra large datasets because it scales in O(n). The algo is only two weeks old, they haven't presented their reference code yet. You have a few hours to catch up though - I found a bug in my C++ code that's gonna take me a while to fix
[2016-05-11T17:43:39.648Z] <54d4a1d6db8155e6700f853b> ^^ I don't think this is a race.
[2016-05-11T17:43:49.575Z] <54d4a1d6db8155e6700f853b> you could also add python wrappers to your R package
[2016-05-11T17:44:48.395Z] <54d4a1d6db8155e6700f853b> barnes-hut t-sne is also O(n) right?
[2016-05-11T17:46:28.060Z] <54d4a1d6db8155e6700f853b> @elbamos  I hope it's BSD licensed ;)
[2016-05-11T17:46:48.466Z] <56c4f19ae610378809c1f8ae> barnes hut t-sne is O(N log N)
[2016-05-11T17:46:55.718Z] <56c4f19ae610378809c1f8ae> http://arxiv.org/abs/1301.3342
[2016-05-11T17:47:23.756Z] <54d4a1d6db8155e6700f853b> hm makes sense
[2016-05-11T17:47:35.034Z] <54d4a1d6db8155e6700f853b> @elbamos let me know if you have an mnist picture ;)
[2016-05-11T20:35:59.780Z] <557c765a15522ed4b3e1de4f> they say (n log n) i actually think its a little worse, at least as implemented.  whether largeVis really scales remains to be seen -- in theory its O(n) holding everything else constant, but when you grow n, you add nearest neighbors and sgd iterations too. 
[2016-05-11T20:36:40.251Z] <557c765a15522ed4b3e1de4f> @amueller Will do ;) Should be tonight actually -- the algo is working now on small data sets (does iris beautifully) but something is making it segfault when i scale up to mnist.  working on it now
[2016-05-11T20:36:55.021Z] <557c765a15522ed4b3e1de4f> oh, and if I were in your shoes, I would totally agree its not a race
[2016-05-11T21:06:46.131Z] <561a58f7d33f749381a8ff2f> hey guys, about decision tree
[2016-05-11T21:06:56.981Z] <561a58f7d33f749381a8ff2f> how do we visualize it?
[2016-05-11T21:07:06.144Z] <56c4f19ae610378809c1f8ae> you can export it to graphviz
[2016-05-11T21:07:20.407Z] <56c4f19ae610378809c1f8ae> see http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html
[2016-05-11T21:07:56.412Z] <561a58f7d33f749381a8ff2f> oh, randomforests do not have this?
[2016-05-11T21:07:59.966Z] <561a58f7d33f749381a8ff2f> that's my actual question
[2016-05-11T21:08:18.704Z] <561a58f7d33f749381a8ff2f> no `rf.tree_`
[2016-05-11T21:09:18.666Z] <56c4f19ae610378809c1f8ae> no `rf.tree_`, but theres something else that I think you want
[2016-05-11T21:09:32.772Z] <561a58f7d33f749381a8ff2f> `feature_importances_` not
[2016-05-11T21:09:43.099Z] <56c4f19ae610378809c1f8ae> you can use `randomforest.estimators_` to get a  list of DecisionTreeRegressors
[2016-05-11T21:09:43.174Z] <561a58f7d33f749381a8ff2f> I want to actually convert a randomforest into categorical variables
[2016-05-11T21:10:19.958Z] <561a58f7d33f749381a8ff2f> ahhh, the separate instances do have the tree
[2016-05-11T21:10:21.835Z] <561a58f7d33f749381a8ff2f> awesome :)
[2016-05-11T21:10:39.068Z] <56c4f19ae610378809c1f8ae> yup, then just `export_graphviz` on all of them
[2016-05-11T21:12:12.016Z] <561a58f7d33f749381a8ff2f> I have the idea that the categorical variables as binary decisions in a sparse matrix would be awesome 
[2016-05-11T21:12:20.503Z] <561a58f7d33f749381a8ff2f> have RF as a preprocessing
[2016-05-11T21:12:26.978Z] <561a58f7d33f749381a8ff2f> and then do sparse Ridge on top of it
[2016-05-11T21:13:29.574Z] <561a58f7d33f749381a8ff2f> or NN
[2016-05-11T21:17:11.129Z] <561a58f7d33f749381a8ff2f> rf.tree_.feature and .tree_.threshold are the ones huh :)
[2016-05-11T21:19:21.211Z] <56c4f19ae610378809c1f8ae> hmm wheres `tree.feature_`?
[2016-05-11T21:19:26.044Z] <56c4f19ae610378809c1f8ae> it seems like it would be what you want though
[2016-05-11T21:20:55.954Z] <561a58f7d33f749381a8ff2f> `tree_.feature`, `tree_.threshold`
[2016-05-11T21:20:58.778Z] <561a58f7d33f749381a8ff2f> yea it works
[2016-05-11T21:21:05.956Z] <56c4f19ae610378809c1f8ae> nice, good to hear
[2016-05-11T21:22:45.244Z] <561a58f7d33f749381a8ff2f> it could basically transform a non-linear problem to a linear one, well.. if it can be captured by a decision tree
[2016-05-11T21:25:55.423Z] <557c765a15522ed4b3e1de4f> @nelson-liu If your plan is to treat each tree's prediction as a a distinct categorical variable and then make your actual prediction by applying ridge regression or some other mechanism to those variables, I will bet you 10:1 odds that (a) you never implement this algorithm because of the dimensionality of what you'd have to feed into the ridge regression, or (b) if you do implement it, it overfits
[2016-05-11T21:26:51.494Z] <561a58f7d33f749381a8ff2f> I was thinking to PCA it perhaps lol
[2016-05-11T21:26:53.978Z] <56c4f19ae610378809c1f8ae> 
[2016-05-11T21:27:41.196Z] <561a58f7d33f749381a8ff2f> or at least to remove too strongly correlating kind of duplicates
[2016-05-11T21:28:58.817Z] <561a58f7d33f749381a8ff2f> @elbamos  I thought it more of a preprocessing step
[2016-05-11T21:29:09.070Z] <561a58f7d33f749381a8ff2f> indeed it'd be too intense
[2016-05-11T21:29:31.296Z] <557c765a15522ed4b3e1de4f> oops sorry nelson, i mixed your two chats up
[2016-05-11T21:31:19.590Z] <561a58f7d33f749381a8ff2f> what about from a single decision tree?
[2016-05-11T21:32:07.346Z] <561a58f7d33f749381a8ff2f> is there a situation in which you could imagine that using the leaf node's id as a binary var for a next model useful?
[2016-05-11T21:32:40.248Z] <561a58f7d33f749381a8ff2f> as kind of feature engineering step
[2016-05-11T21:32:45.846Z] <557c765a15522ed4b3e1de4f> wanna try something funky for preprocessing that would probably work?  take your data and cut it into square cunks, like if your data is 1000 dimensional, chop it into one 31 * 31 square and one 7 * 7 square.  The run a convolution over both squares using a kernel initialized to have mean 0 and unit norm.  you can control the amount of dimensional reduction by controlling the size of the kernel.
[2016-05-11T21:32:53.975Z] <5537027215522ed4b3df56ab> I think I've seen people use node ids as IVs before for the next estimator
[2016-05-11T21:33:02.739Z] <5537027215522ed4b3df56ab> and they got "better" results
[2016-05-11T21:33:57.623Z] <561a58f7d33f749381a8ff2f> that sounds very interesting elbamos
[2016-05-11T21:34:02.732Z] <5537027215522ed4b3df56ab> Some people on kaggle at least improved their model by a fraction of a percent. It's very empirical, but was useful in their case.
[2016-05-11T21:34:41.375Z] <557c765a15522ed4b3e1de4f> @lqdc that's just the effect of a suppressor variable on overfitting.  
[2016-05-11T21:35:47.322Z] <5537027215522ed4b3df56ab> i.e. less overfitting because the number of splits is regularized?
[2016-05-11T21:36:24.606Z] <561a58f7d33f749381a8ff2f> googled suppressor: one variable that increases the effect of another var
[2016-05-11T21:36:29.829Z] <561a58f7d33f749381a8ff2f> lol
[2016-05-11T21:36:47.222Z] <561a58f7d33f749381a8ff2f> strange naming
[2016-05-11T21:36:54.764Z] <561a58f7d33f749381a8ff2f> I'm interested for this particular challenge: http://blackboxchallenge.com/
[2016-05-11T21:37:05.898Z] <561a58f7d33f749381a8ff2f> super nasty one
[2016-05-11T21:38:32.166Z] <5537027215522ed4b3df56ab> Hey guys, I have a question: How do you deal with unrealistic estimates for probabilities for some estimators?  I tried using CIs (#6773), which were fine in my case, but apparently this is not the preferred approach.
[2016-05-11T21:39:36.668Z] <5537027215522ed4b3df56ab> Is that competition for spam filtering?
[2016-05-11T21:39:46.691Z] <5537027215522ed4b3df56ab> i can imagine mail.ru dealing with lots of that
[2016-05-11T21:39:54.530Z] <561a58f7d33f749381a8ff2f> it's a reinforcement learning comp
[2016-05-11T21:40:27.374Z] <561a58f7d33f749381a8ff2f> on each round (there are ~1.2m)
[2016-05-11T21:40:30.618Z] <557c765a15522ed4b3e1de4f> @lqdc no, any time you add a variable to your training data, performance on the training data will improve slightly, regardless of whether there's a genuine relationship.  That's just the math.  Its called a "suppressor" variable because it suppresses the true error.  But the result is just increased overfitting. 
[2016-05-11T21:40:33.523Z] <561a58f7d33f749381a8ff2f> you get 35 values  
[2016-05-11T21:40:54.344Z] <561a58f7d33f749381a8ff2f> you can influence the 36th variable by choosing 1 out of 4 actions
[2016-05-11T21:41:07.094Z] <561a58f7d33f749381a8ff2f> the 36th var goes from -1.1 to 1.1
[2016-05-11T21:41:14.944Z] <561a58f7d33f749381a8ff2f> every round you also get the reward
[2016-05-11T21:41:24.503Z] <561a58f7d33f749381a8ff2f> reward can be super delayed
[2016-05-11T21:41:30.154Z] <561a58f7d33f749381a8ff2f> rules unclear
[2016-05-11T21:41:53.022Z] <561a58f7d33f749381a8ff2f> 35 vars are roughly between -18 and 12 or something, mostly around -1 to 1
[2016-05-11T21:41:59.316Z] <557c765a15522ed4b3e1de4f> @lqdc if you want an example of this, create a 20 * 100 normally distributed random matrix, and 20 randomly selected labels.  split the data into a training and a test set by row.  Run randomforest over the training data, trying to predict the labels.  observe your error (it will be zero).  then run the generated model on your test set. 
[2016-05-11T21:42:01.798Z] <561a58f7d33f749381a8ff2f> it is very non-linear
[2016-05-11T21:42:27.261Z] <557c765a15522ed4b3e1de4f> this is why having features that don't truly correlate leads to inferior performance
[2016-05-11T21:44:42.703Z] <5537027215522ed4b3df56ab> But let's say the original random forest made an incorrect estimate for a split on some variable for which there was little data. Then just getting to that variable in some of the trees would be additional information
[2016-05-11T21:45:12.441Z] <5537027215522ed4b3df56ab> i.e. trees too deep and too few of them
[2016-05-11T21:45:15.159Z] <557c765a15522ed4b3e1de4f> no, it wouldn't.  it would be a reduction in information. 
[2016-05-11T21:46:15.227Z] <557c765a15522ed4b3e1de4f> a prediction based on a training data set can't ever contain any more information than the amount of information in the training set plus the amount of information in the example.
[2016-05-11T21:48:01.685Z] <5537027215522ed4b3df56ab> sure, but an incorrect decision based on original information by an upstream estimator can be worse than just the original information in a downstream estimator. IE you are recovering information that was lost
[2016-05-11T21:48:37.739Z] <5537027215522ed4b3df56ab> I'll try to construct a synthetic test for this
[2016-05-12T12:19:40.478Z] <53135b495e986b0712efc453> @amueller okay thanks!
[2016-05-12T16:27:53.081Z] <54d4a1d6db8155e6700f853b> When using EM, perplexity in LDA should be monotonic, right?
[2016-05-16T18:02:04.808Z] <54d4a1d6db8155e6700f853b> is there ever a case when the requirements.txt is parsed automatically?
[2016-05-16T18:03:09.539Z] <56c4f19ae610378809c1f8ae>  what do you mean? i occasionally run `pip install -r requirements.txt <unconvertable> upgrade`?
[2016-05-16T18:03:55.461Z] <56c4f19ae610378809c1f8ae> assuming versions are not pinned, of course
[2016-05-17T00:46:34.566Z] <54d4a1d6db8155e6700f853b> I mean if you pip install without specifying r, requirements.txt is not read from the package, right?
[2016-05-17T00:48:05.238Z] <56c4f19ae610378809c1f8ae> Not from requirements.txt, you specify install dependencies somewhere else iirc. 
[2016-05-17T00:49:33.037Z] <56c4f19ae610378809c1f8ae> http://python-packaging-user-guide.readthedocs.io/en/latest/requirements/#install-requires-vs-requirements-files
[2016-05-17T00:50:32.192Z] <56c4f19ae610378809c1f8ae> "Whereas `install_requires` metadata is automatically analyzed by pip during an install, requirements files are not, and only are used when a user specifically installs them using `pip install -r`." so the answer to your question is no I believe 
[2016-05-17T03:24:39.913Z] <557c765a15522ed4b3e1de4f> @amueller The largevis implementation is now in what i'd call "beta," meaning I think it works and I'm now inviting people to try it out before I announce.  So please give it a whirl :)
[2016-05-17T04:37:10.747Z] <557c765a15522ed4b3e1de4f> Does anyone have some really heavy hardware they wouldn't mind devoting to the interests of science for like an hour? 
[2016-05-17T04:37:21.711Z] <56c4f19ae610378809c1f8ae> how heavy?
[2016-05-17T04:38:07.994Z] <56c4f19ae610378809c1f8ae> I could get access, but I would have to run the jobs for you.
[2016-05-17T04:39:29.140Z] <56c4f19ae610378809c1f8ae> lots of cores, but no real gpu if that matters to you
[2016-05-17T06:11:18.901Z] <557c765a15522ed4b3e1de4f> I need sample datasets for clustering to test this package...
[2016-05-17T06:11:56.335Z] <56c4f19ae610378809c1f8ae> ah i see
[2016-05-17T06:12:23.766Z] <56c4f19ae610378809c1f8ae> if you give me a script to generate data / evaluate i could run it for you
[2016-05-17T06:13:03.235Z] <557c765a15522ed4b3e1de4f> @nelson-liu https://github.com/elbamos/largeVis I have scripts... the authors of the paper used a machine with 512 GB of RAM and 32 cores.  They claim it could do mnist in 25 minutes. 
[2016-05-17T06:13:10.255Z] <557c765a15522ed4b3e1de4f> i think they're kinda full of it :p 
[2016-05-17T06:13:49.431Z] <557c765a15522ed4b3e1de4f> well that's not fair
[2016-05-17T06:13:49.901Z] <557c765a15522ed4b3e1de4f> not full of it
[2016-05-17T06:13:56.018Z] <557c765a15522ed4b3e1de4f> but i think their hardware was helping a lot
[2016-05-17T06:14:47.183Z] <56c4f19ae610378809c1f8ae> well, we can test their hypothesis :) i can run the script on a machine with similar specs
[2016-05-17T06:15:14.997Z] <557c765a15522ed4b3e1de4f> yay!  do you have R installed?  what's the best way to get the data and script to you? ftp?
[2016-05-17T06:15:21.416Z] <557c765a15522ed4b3e1de4f> :) :) :)
[2016-05-17T06:15:28.363Z] <56c4f19ae610378809c1f8ae> ill pm you
[2016-05-17T19:14:55.793Z] <557c765a15522ed4b3e1de4f> @amueller A few days ago I think someone around here was saying to contact him when I had an mnist visualization... https://github.com/elbamos/largevis
[2016-05-17T19:23:07.940Z] <54d4a1d6db8155e6700f853b> @elbamos is it faster than our t-sne?
[2016-05-17T19:23:55.406Z] <557c765a15522ed4b3e1de4f> @amueller It scales in O(n). 
[2016-05-17T19:24:19.338Z] <54d4a1d6db8155e6700f853b> that's an asymptotic statement ;)
[2016-05-17T19:24:38.915Z] <557c765a15522ed4b3e1de4f> ... said the guy with the slow manifold visualization implementation. 
[2016-05-17T19:25:20.576Z] <54d4a1d6db8155e6700f853b> well I was just asking you if it was slow and you didn't give a proper answer ;)
[2016-05-17T19:26:09.331Z] <557c765a15522ed4b3e1de4f> how long does your t-sne take to do 42000 verticies of mnist?
[2016-05-17T19:26:39.452Z] <54d4a1d6db8155e6700f853b> not sure
[2016-05-17T19:26:47.562Z] <54d4a1d6db8155e6700f853b> how long does your code take?
[2016-05-17T19:26:52.352Z] <557c765a15522ed4b3e1de4f> try it -- i'll get my calendar out.
[2016-05-17T19:27:14.247Z] <54d4a1d6db8155e6700f853b> I think like an hour or so
[2016-05-17T19:27:22.935Z] <557c765a15522ed4b3e1de4f> On this low-RAM 2008 mac pro, about an hour.  On modern hardware, about 10 minutes. 
[2016-05-17T19:27:29.667Z] <54d4a1d6db8155e6700f853b> cool
[2016-05-17T19:27:31.994Z] <54d4a1d6db8155e6700f853b> that's def faster
[2016-05-17T19:27:42.686Z] <557c765a15522ed4b3e1de4f> i think the difference really shows around 10 million rows...
[2016-05-18T06:29:08.507Z] <557c765a15522ed4b3e1de4f> can anyone suggest a good "standard" dataset for evaluating the performance of a clustering/visualization package?  I'm looking for something with a few hundred thousand rows.  (I've tested on mnist, and my machine doesn't have the RAM to handle 1M+ row datasets.)
[2016-05-18T16:27:13.462Z] <54d4a1d6db8155e6700f853b> I don' think there are many standard datasets
[2016-05-19T11:16:09.450Z] <53f1f08a107e137846bab1c2> This is regarding Scikit-Learn Day, Paris. Will the talks be in french or english?
[2016-05-22T20:15:03.188Z] <5586719a15522ed4b3e23add> Hi everyone,  I am new to this room, found it through gitter listing. I am a usual scikit-learn user. Would this be a place to know more about projects using the tool? Thanks! 
[2016-05-22T20:16:23.306Z] <56c4f19ae610378809c1f8ae> Hmm not quite, thus room is mainly used for developer chat. 
[2016-05-22T20:27:22.656Z] <5586719a15522ed4b3e23add> @nelson-liu Hi, I guess you are referring to me? > Hmm not quite, thus room is mainly used for developer chat.  I see... I guess that it is the desired use. A quick scroll-up seems to show a plethora of different interesting topics... :) I will respect the main interest of the founders though. Thanks for the info! I hope there is no issue is I stay as observer meanwhile?
[2016-05-22T20:28:07.470Z] <56c4f19ae610378809c1f8ae> Of course, we definitely talk about other things :)
[2016-05-22T20:29:19.034Z] <5586719a15522ed4b3e23add> Thanks!! :)
[2016-05-22T20:31:00.816Z] <56c4f19ae610378809c1f8ae> Np! BTW, does anyone have a 32 bit machine (ideally linux) and would be willing to spare a few minutes to pull down some code from one of my branches and run a nosetests? 
[2016-05-22T20:31:50.000Z] <557c765a15522ed4b3e1de4f> a 32-bit linux machine?
[2016-05-22T20:33:27.774Z] <56c4f19ae610378809c1f8ae> Yeah I mean running a 32 bit OS  I mean haha
[2016-05-22T20:33:43.844Z] <557c765a15522ed4b3e1de4f> yeah i caught what you meant, its just my time machine is in the shop
[2016-05-22T20:34:59.722Z] <56c4f19ae610378809c1f8ae> Ah got it. I have some tests failing on appveyor, only when running on windows 32 bit though.  I'm considering setting up a vm to debug, but I'm also curious if it breaks on Linux 32 bit bc it's a lot easier to get Linux set up and running on a vm vs windows haha
[2016-05-22T20:49:02.300Z] <557c765a15522ed4b3e1de4f> hah yeah i don't even try to support windows
[2016-05-24T11:34:24.616Z] <53135b495e986b0712efc453> @amueller if you can spare a few minutes, review for https://github.com/scikit-learn/scikit-learn/pull/6697 please? ;)
[2016-05-24T19:24:06.751Z] <54d4a1d6db8155e6700f853b> @rvraghav93 a few minutes, right :P thanks for the ping, though. I'll try to take a look.
[2016-05-24T19:25:44.932Z] <53135b495e986b0712efc453> My hope is you'll get fully nerdsniped in those few minutes ;)
[2016-05-24T19:26:21.448Z] <53135b495e986b0712efc453> And with that PR merged multiple metric is just a few lines of code away B)
[2016-05-25T21:13:05.166Z] <53165e195e986b0712efc93c> Given an estimator `est`, is there a standard way to determine if the estimator has previously been fit? Check if any `*_` attributes are present (e.g. `coef_`)?
[2016-05-25T21:13:22.288Z] <56c4f19ae610378809c1f8ae> i do believe there is a fitted attribute
[2016-05-25T21:14:18.390Z] <53165e195e986b0712efc93c> Hmmm, if there is it doesn't seem to be present on all estimators.
[2016-05-25T21:15:04.183Z] <56c4f19ae610378809c1f8ae> maybe this might help? https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/estimator_checks.py#L1035
[2016-05-25T21:15:41.355Z] <56c4f19ae610378809c1f8ae> oops wrong link
[2016-05-25T21:15:45.785Z] <56c4f19ae610378809c1f8ae> although that might be helpful
[2016-05-25T21:15:50.823Z] <56c4f19ae610378809c1f8ae> i was meaning to send this: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py#L650
[2016-05-25T21:16:54.911Z] <53165e195e986b0712efc93c> Yeah, that's useful if you know what attributes to check for. Oh well.
[2016-05-25T21:17:03.051Z] <53165e195e986b0712efc93c> Thanks for the links.
[2016-05-25T21:17:06.610Z] <56c4f19ae610378809c1f8ae> is there any estimator you have in mind?
[2016-05-25T21:17:11.862Z] <56c4f19ae610378809c1f8ae> or is this one youve built yourself
[2016-05-25T21:17:24.605Z] <56c4f19ae610378809c1f8ae> or are you just looking for a more general solution
[2016-05-25T21:17:35.772Z] <53165e195e986b0712efc93c> General solution preferably.
[2016-05-25T21:18:06.064Z] <53165e195e986b0712efc93c> I'm working with scikit-learn and dask (which does things lazily). It'd be nice to be able to catch not-fit errors at graph build time instead of at execution time.
[2016-05-25T21:18:13.255Z] <53165e195e986b0712efc93c> Not necessary though, just nice :)
[2016-05-25T21:18:30.271Z] <56c4f19ae610378809c1f8ae> that makes sense, hmm yeah im not too sure how to do that sorry :(
[2016-05-26T17:31:35.737Z] <541a528b163965c9bc2053de> you can check if there is any attribute that ends in "_". If not it's not fitted.
[2016-05-26T17:32:04.879Z] <541a528b163965c9bc2053de> Unless it's stateless, like the HashingVectorizer that does not require any fit to start transforming :P
[2016-05-26T23:59:38.896Z] <572bc25ac43b8c60197160c9> Hi nice to know this group exists 
[2016-05-27T00:00:06.339Z] <572bc25ac43b8c60197160c9> ##hello
[2016-05-27T00:00:13.421Z] <572bc25ac43b8c60197160c9> #hello
[2016-05-27T00:14:34.182Z] <54d4a1d6db8155e6700f853b> lol
[2016-05-28T10:32:52.544Z] <54b2524adb8155e6700e8a8e> Seeing this a little late, @jcrist, you might try performing predict/transform, a `NotFittedError` should be indicative, but other errors may occur uninformatively.
[2016-06-02T15:11:46.404Z] <5573124c15522ed4b3e184c2> Hi, all. Sorry if this is the wrong place to ask my question - but I'd like to use Naive Bayes, training by a list of sentences with their own labels (i.e. multiple different sentences per label). However, each sentence carries a certain importance weight that I'd like for them to play a role in while classifying - some sentences I want to have more of an impact than others. I was considering just resampling these sentences and creating duplicates or whatever depending on importance, but that seems horribly inefficient (especially because importance values/weights are essentially continuous)  Is there any way to weight certain samples to be more important?  ***TL;DR:** In other words, my training data is of the form ```[label, sentence, weight]```, where I might have multiple different weights and sentences for the same label, of course. I'm not actually sure what the best way might be to go about classifying this using scikit-learn. Any ideas?
[2016-06-02T15:29:32.740Z] <56c4f19ae610378809c1f8ae> Can't you specify the weight as a parameter at fit time?  
[2016-06-02T15:30:07.299Z] <56c4f19ae610378809c1f8ae> See: http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.fit
[2016-06-02T15:30:15.960Z] <56c4f19ae610378809c1f8ae> Not sure if that answered your question 
[2016-06-02T15:33:28.900Z] <5573124c15522ed4b3e184c2> That should do the trick! Thanks
[2016-06-03T11:14:42.521Z] <57504263c43b8c6019765b0e>  is there any chinese develper ? I have an translate project ,hope volunteers join in it.
[2016-06-03T11:14:51.059Z] <57504263c43b8c6019765b0e> here is the repo    https://github.com/lzjqsdd/scikit-learn-doc-cn
[2016-06-06T23:15:30.884Z] <53135b495e986b0712efc453> Andy, could you close this one - https://github.com/scikit-learn/scikit-learn/issues/5669?
[2016-06-06T23:15:32.883Z] <53135b495e986b0712efc453> @amueller 
[2016-06-06T23:15:43.650Z] <54d4a1d6db8155e6700f853b> you summoned me
[2016-06-06T23:15:45.222Z] <54d4a1d6db8155e6700f853b> ah
[2016-06-06T23:16:30.503Z] <54d4a1d6db8155e6700f853b> done
[2016-06-06T23:21:01.185Z] <53135b495e986b0712efc453> lol... How's your writing going? :)
[2016-06-07T03:44:18.795Z] <5581814615522ed4b3e20c6a> What is the best way to save the trained models other than Pickle?
[2016-06-07T03:53:55.902Z] <55a487245e0d51bd787b4e45> @BastinRobin Quite unfortunately, there isn't an easy path to that in sklearn.
[2016-06-07T03:53:58.237Z] <55a487245e0d51bd787b4e45> @BastinRobin You're looking for a format to store some arrays and some random parameters? What are your constraints?
[2016-06-07T06:11:16.115Z] <575664f0c43b8c601978412c> hello ,everyone
[2016-06-07T09:46:33.724Z] <5581814615522ed4b3e20c6a> @mikegraham I just want to know if pickle is the best or not for storing
[2016-06-07T10:01:50.971Z] <564789be16b6c7089cbab8b7> @BastinRobin  It's OK ... imho sklearn is crying out for someone to volunteer to implement a better solution
[2016-06-07T14:02:00.101Z] <57565ad2c43b8c6019783fbb> Where would I have to go if I want to learn about A.Is
[2016-06-07T14:17:08.319Z] <56e9685085d51f252ab91b6d> Hello everyone
[2016-06-07T14:17:30.600Z] <56e9685085d51f252ab91b6d> I've made a pipeline for a classification problem
[2016-06-07T14:18:58.039Z] <56e9685085d51f252ab91b6d> learning goes fast thanks to parallel with n_jobs=-1
[2016-06-07T14:19:33.036Z] <56e9685085d51f252ab91b6d> but when i use the predict function, it goes very slow, and only one process is used
[2016-06-07T14:19:59.181Z] <56e9685085d51f252ab91b6d> is there a way to make prediction in parallel?
[2016-06-07T17:17:57.947Z] <55a487245e0d51bd787b4e45> @BastinRobin pickle is a very problematic solution: it is fragile, not safely transferable, not explicitly specified, etc. It is all that sklearn is geared to and it will be a lot of work to use something else.
[2016-06-07T17:18:53.046Z] <55a487245e0d51bd787b4e45> @BastinRobin For a narrow use case, you can hack something up. There isn't a more general solution
[2016-06-07T17:19:31.716Z] <55a487245e0d51bd787b4e45> @kmehl Probably not with plain sklearn, but you can probably make a specialized evaluator for the slow parts. Have you profiled? Where is the time being spent?
[2016-06-07T17:27:47.363Z] <564789be16b6c7089cbab8b7> @mikegraham  would making a better solution make a good discrete project? There are quite a lot of people who are keen to work on scikit learn it seems so if it was clearly advertised it might get someone to bite
[2016-06-07T17:29:51.129Z] <564789be16b6c7089cbab8b7> I think a good solution would be very popular
[2016-06-07T18:09:49.536Z] <55a487245e0d51bd787b4e45> @lesshaste I don't know how welcome it would be -- it would be a lot of work and a huge maintenance burden.
[2016-06-08T07:14:17.299Z] <564789be16b6c7089cbab8b7> @mikegraham  Ah. I am not 100% clear why it would be a huge maintenance problem. Doesn't that depend on whatever elegant solution someone comes up with? Or to put it another way, if the problem is stated in parts with "part 1) Devise a solution that minimises the maintenance needed" would this not be plausible?
[2016-06-08T07:15:00.661Z] <564789be16b6c7089cbab8b7> has someone done a survey to see what other solutions exist out there?
[2016-06-08T07:15:32.770Z] <564789be16b6c7089cbab8b7> For example in R or weka
[2016-06-08T07:16:38.831Z] <564789be16b6c7089cbab8b7> From a very quick look, the standard solution in R just seems to be saveRDS https://stat.ethz.ch/R-manual/R-devel/library/base/html/readRDS.html
[2016-06-08T07:19:50.018Z] <564789be16b6c7089cbab8b7> spark has this https://databricks.com/blog/2016/05/31/apache-spark-2-0-preview-machine-learning-model-persistence.html
[2016-06-08T07:20:46.032Z] <564789be16b6c7089cbab8b7> weka has https://weka.wikispaces.com/Saving+and+loading+models
[2016-06-08T08:32:05.182Z] <5571fe1015522ed4b3e17d90> @lesshaste  @BastinRobin  @mikegraham you can use joblib.dump (based on pickle with some optimization on numpy arrays) too, see http://scikit-learn.org/stable/modules/model_persistence.html#model-persistence for more details. There were some discussion on the mailing list IIRC about this for example http://thread.gmane.org/gmane.comp.python.scikit-learn/14905/focus=14909.
[2016-06-08T09:09:10.381Z] <564789be16b6c7089cbab8b7> @lesteve  Thanks. That mailing list thread is somehow slightly negative. I would love to see an objective and technical analysis of the situation.
[2016-06-08T09:10:01.517Z] <564789be16b6c7089cbab8b7> For example, what is wrong with developing the PMML idea?
[2016-06-08T09:12:00.169Z] <564789be16b6c7089cbab8b7> iirc  joblib.dump makes a large number of small files. One simple improvement would be to reduce the number of files to 1 or 2
[2016-06-08T09:13:16.562Z] <564789be16b6c7089cbab8b7> ah.. I see the other problems are mentioned
[2016-06-08T09:13:16.910Z] <5571fe1015522ed4b3e17d90> > For example, what is wrong with developing the PMML idea?
[2016-06-08T09:14:29.485Z] <5571fe1015522ed4b3e17d90> I don't think there is anything wrong per se. It's just that it is quite some work and it probably won't happen inside scikit-learn. Not an expert though. There may have been other discussions on the mailing list on this serialization issues. It does come up from time to time.
[2016-06-08T09:15:27.154Z] <564789be16b6c7089cbab8b7> OK thanks. I am just a big fan of having clearly stated tasks for keen volunteers to pick from. I feel lots of people want to contribute to scikit learn as it is so great :)
[2016-06-08T09:15:37.436Z] <5571fe1015522ed4b3e17d90> > iirc joblib.dump makes a large number of small files. One simple improvement would be to reduce the number of files to 1 or 2  For the record, joblib master creates only a single pickle file (and not one per numpy array as previously)
[2016-06-08T09:15:39.983Z] <541a528b163965c9bc2053de> PMML is a very verbose XML-based format. The new spark mllib lightweight format  would probably be better much more efficient.
[2016-06-08T09:15:58.323Z] <564789be16b6c7089cbab8b7> @ogrisel  Oh that sounds very interesting. 
[2016-06-08T09:16:11.298Z] <564789be16b6c7089cbab8b7> 
[2016-06-08T09:16:18.828Z] <541a528b163965c9bc2053de> @lesshaste it's from the link you just sent
[2016-06-08T09:16:33.004Z] <564789be16b6c7089cbab8b7> @ogrisel  the spark link?
[2016-06-08T09:16:49.328Z] <541a528b163965c9bc2053de> yes, didn't you read it?
[2016-06-08T09:17:00.826Z] <564789be16b6c7089cbab8b7> no I did :) I just sent a lot of links
[2016-06-08T09:17:43.340Z] <564789be16b6c7089cbab8b7> to be clear, the interesting part is that an expert (that's you) thinks it might be relevant
[2016-06-08T09:17:56.228Z] <564789be16b6c7089cbab8b7> my knowledge is very shallow in this area
[2016-06-08T09:22:01.713Z] <564789be16b6c7089cbab8b7> @lesteve  I didn't know  joblib master creates only a single pickle file. Thank you
[2016-06-08T09:22:36.547Z] <541a528b163965c9bc2053de> It's only in the master branch of joblib so far. It will be part of the next release.
[2016-06-08T09:23:37.467Z] <541a528b163965c9bc2053de> If someone starts implementing tools to save sklearn models to / load from the spark 2 serialization format, please reference the repo in https://github.com/scikit-learn/scikit-learn/blob/master/doc/related_projects.rst#interoperability-and-framework-enhancements
[2016-06-08T09:30:28.118Z] <541a528b163965c9bc2053de> This will require a good python parquet implementation. The most promising implementation should be the official https://github.com/apache/parquet-cpp but the python bindings are not ready yet but progress  is happening, see eg: http://wesmckinney.com/blog/pandas-and-apache-arrow/
[2016-06-08T10:23:21.162Z] <564789be16b6c7089cbab8b7> very interesting
[2016-06-08T13:34:56.758Z] <57565ad2c43b8c6019783fbb> any of you guys work with c++
[2016-06-08T14:13:26.340Z] <57565ad2c43b8c6019783fbb> Im trying to make an AI using python
[2016-06-08T15:13:51.893Z] <55a487245e0d51bd787b4e45> @lesshaste To avoid the problems of pickle in full, you need to be explicit. To be explicit, you need to have your data model change every time anything applicable changes.
[2016-06-08T19:46:00.201Z] <55495eb515522ed4b3dffb00> hello, I am seeing many feature scaling methods, but I cannot find things like RobustScaler and etc on the internet.
[2016-06-08T19:46:13.502Z] <55495eb515522ed4b3dffb00> what are they called in academic society?
[2016-06-08T21:06:07.565Z] <55495eb515522ed4b3dffb00> and what is difference between scale and standardscaler?
[2016-06-08T21:06:16.689Z] <55495eb515522ed4b3dffb00> is standardscaler just a class implementation of scale?
[2016-06-08T21:10:15.523Z] <55a487245e0d51bd787b4e45> @keonkim Yes, scale is a function that returns the result, StandardScaler can go in a pipeline or whatever.
[2016-06-08T21:12:32.580Z] <55a487245e0d51bd787b4e45> @keonkim I don't know that RobustScaler has a consistent academic name. To indicate what they did, someone might describe it. I've seen it contrasted with naive scaling by calling it "IQR", but that's not a formal name for the scaling technique, which merely uses the actual IQR to do its job. A lot of people might know what you mean if you just said "IQR scaling" or "Scaled to the IQR" though.
[2016-06-09T00:35:10.697Z] <53135b495e986b0712efc453> @ogrisel @amueller Could you cancel all my appveyor builds. I forgot to use the CI skip and it seems to block other PRs...
[2016-06-09T00:59:21.007Z] <55495eb515522ed4b3dffb00> @mikegraham Thanks! 
[2016-06-09T01:40:45.183Z] <56c4f19ae610378809c1f8ae> @rvraghav93 what is this ci skip you speak of? 
[2016-06-09T06:55:50.047Z] <54c630d6db8155e6700f168d> Hey all! I have a question regarding CountVectorizer. Is is possible to 'reverse engineer' the original text from the vectors?
[2016-06-09T06:56:48.968Z] <54c630d6db8155e6700f168d> I'm wondering as I just wrote an article on our methods, and I want to share our vectorized data, but cannot share if it's possible for people to figure out the original input text based on this (as the original text contains sensitive info).
[2016-06-09T06:57:11.318Z] <54c630d6db8155e6700f168d> For reference, here is the article: https://medium.com/xeneta/boosting-sales-with-machine-learning-fbcf2e618be3
[2016-06-09T07:03:24.691Z] <56c4f19ae610378809c1f8ae> haha I saw this on hacker news earlier
[2016-06-09T07:03:33.798Z] <56c4f19ae610378809c1f8ae> I dont think its possible to reverse engineer countvectorizer
[2016-06-09T07:03:39.948Z] <54c630d6db8155e6700f168d> @nelson-liu Cool
[2016-06-09T07:04:56.336Z] <54c630d6db8155e6700f168d> Even if you have access to the vectorizer through a file (using joblib)
[2016-06-09T07:04:57.692Z] <54c630d6db8155e6700f168d> ?
[2016-06-09T07:06:42.995Z] <56c4f19ae610378809c1f8ae> yup, seems like it
[2016-06-09T07:06:56.384Z] <56c4f19ae610378809c1f8ae> the countvectorizer code is here, https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py it doesnt store the raw documents
[2016-06-09T07:07:29.064Z] <56c4f19ae610378809c1f8ae> although its possible ofc to get the vocabulary, so if individual words are sensitive then that might pose a problem.
[2016-06-09T07:29:46.949Z] <54c630d6db8155e6700f168d> I see. And if you have the vocabulary, and the vectors, you can kind of recreate keyword-based descriptions.
[2016-06-09T07:31:21.023Z] <54c630d6db8155e6700f168d> I think I'll rather just share the vectorized descriptions, and not the joblib vectorizer.
[2016-06-09T07:31:38.017Z] <54c630d6db8155e6700f168d> That'll make it impossible to guess the words, right?
[2016-06-09T07:31:52.389Z] <54c630d6db8155e6700f168d> Really appreciate your help @nelson-liu :)
[2016-06-09T07:48:43.639Z] <56c4f19ae610378809c1f8ae> Yup that is correct @perborgen 
[2016-06-09T07:48:53.562Z] <54c630d6db8155e6700f168d> Thanks!
[2016-06-09T07:49:46.340Z] <56c4f19ae610378809c1f8ae> What do you mean vectorized descriptions actually? 
[2016-06-09T08:45:13.575Z] <54c630d6db8155e6700f168d> Sorry for my late reply.  I mean after using the CountVectorizer to turn text into vectors.
[2016-06-09T08:45:43.040Z] <54c630d6db8155e6700f168d> That's what I refer to aws 'vectorized descriptions' (as my input text is company descriptions).
[2016-06-09T12:21:17.525Z] <564789be16b6c7089cbab8b7> @mikegraham What's your view on the spark 2 serialization format ?
[2016-06-09T12:37:10.295Z] <53135b495e986b0712efc453> @nelson-liu If you add `[ci skip]` to a commit message, Appveyor/Travis will skip the tests for that commit... This could be useful if you just push your unfinished work (for a review or to switch computers)...
[2016-06-09T19:20:44.421Z] <55a487245e0d51bd787b4e45> @lesshaste As in kyro or something else?
[2016-06-09T19:20:55.833Z] <55a487245e0d51bd787b4e45> @lesshaste In any event, I'm probably not fit to weigh in :)
[2016-06-10T23:55:55.013Z] <56333d0d16b6c7089cb8d5c7> hello, I had a quick question.
[2016-06-10T23:56:02.210Z] <56333d0d16b6c7089cb8d5c7> I wanted to take up the issue https://github.com/scikit-learn/scikit-learn/issues/6867
[2016-06-10T23:56:24.755Z] <56333d0d16b6c7089cb8d5c7> I could some one please share the link to new gaussian process.
[2016-06-10T23:57:07.565Z] <56333d0d16b6c7089cb8d5c7> So the user guide is http://scikit-learn.org/stable/modules/gaussian_process.html
[2016-06-11T00:01:48.908Z] <56333d0d16b6c7089cb8d5c7> 2nd question (https://github.com/scikit-learn/scikit-learn/issues/6857) I cannot find the file references.rst in  the scikit-learn/doc folder. Where is this file present?.  
[2016-06-11T02:21:51.683Z] <5582b5a615522ed4b3e21903> @krishnakalyan3 someone else who commented on that issue couldn't find it either. And neither could I from a quick look.
[2016-06-11T09:39:08.775Z] <56333d0d16b6c7089cb8d5c7> @pdurbin  thank anyway :)
[2016-06-13T00:37:06.469Z] <53135b495e986b0712efc453> @krishnakalyan3 I think @amueller meant that the `GPRegressor` class does not have a reference to that user guide. 
[2016-06-13T08:51:37.911Z] <56333d0d16b6c7089cb8d5c7> @rvraghav93 just created a pull request could you let me know if things are okay?
[2016-06-13T14:32:43.528Z] <53135b495e986b0712efc453> Thanks for the PR! I'll look into that :)
[2016-06-13T14:41:30.017Z] <53135b495e986b0712efc453> @amueller Could you share your suggestions about https://github.com/scikit-learn/scikit-learn/pull/6380#issuecomment-185699518 please?
[2016-06-13T16:55:06.009Z] <564789be16b6c7089cbab8b7> it would be great if one could visualise boosted trees (e.g. xgboost) too
[2016-06-13T17:34:00.796Z] <54d4a1d6db8155e6700f853b> @lesshaste in scikit-learn you can
[2016-06-13T17:34:07.504Z] <54d4a1d6db8155e6700f853b> xgboost no idea
[2016-06-13T18:11:17.665Z] <564789be16b6c7089cbab8b7> if you look at http://www.r-bloggers.com/an-introduction-to-xgboost-r-package/ and scroll down to https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/xgb.plot.multi.png can you do that sort of thing in scikit-learn?
[2016-06-13T18:12:26.533Z] <564789be16b6c7089cbab8b7> @amueller  Sorry I meant that for you
[2016-06-13T18:13:04.301Z] <54d4a1d6db8155e6700f853b> well for scikit-learn trees yes, for xgboost trees obviously not, because that has nothing to do with xgboost?
[2016-06-13T18:13:15.297Z] <54d4a1d6db8155e6700f853b> that would go into the xgboost package...
[2016-06-13T18:13:23.656Z] <54d4a1d6db8155e6700f853b> err has nothing to do with scikit-learn
[2016-06-13T18:13:55.692Z] <564789be16b6c7089cbab8b7> oh I must have missed this completely.  Would you mind pointing me to the docs for ensembled tree visualization?
[2016-06-13T18:14:28.564Z] <564789be16b6c7089cbab8b7> I take your xgboost point of course :) I only ever use it through scikit-learn so sometimes forget it isn't part of it
[2016-06-13T18:40:10.830Z] <54d4a1d6db8155e6700f853b> well you can plot each tree in the ``estimators_``
[2016-06-13T18:40:26.895Z] <564789be16b6c7089cbab8b7> true.. they seem to have a nice trick for plotting one merged tree
[2016-06-13T18:41:10.907Z] <564789be16b6c7089cbab8b7> I am still intrigued if one can derive a single decision tree from an ensemble of trees which is easier to interpret and almost as good as a classifier/regressor
[2016-06-13T18:41:23.392Z] <564789be16b6c7089cbab8b7> this would seem potentially useful
[2016-06-15T09:33:19.596Z] <56b0a775e610378809bf7a7c> @amueller I think the issue #6857 is solved by #6886. Can you confirm it was what you wanted ? Thx ;)
[2016-06-15T18:58:35.285Z] <5761a537c2f0db084a1e0fe7> Hi all. I just wanted to ask, is there anything else I should do in https://github.com/scikit-learn/scikit-learn/pull/6874 or just wait? :)
[2016-06-15T20:43:22.214Z] <53135b495e986b0712efc453> @yenchenlin @nelson-liu The GSoC midterms are approaching. Hope you guys are ready with your blogs posts? :)
[2016-06-15T21:32:41.766Z] <56c4f19ae610378809c1f8ae> soon :shipit: :)
[2016-06-16T09:16:52.298Z] <53135b495e986b0712efc453> Good to know!!
[2016-06-16T11:30:11.190Z] <53135b495e986b0712efc453> @amueller @ogrisel Is #6897 the correct fix for the Circle CI build failure on master?
[2016-06-16T20:13:45.270Z] <54d4a1d6db8155e6700f853b> @raghavrv sorry haven't looked
[2016-06-16T20:14:07.326Z] <54d4a1d6db8155e6700f853b> But my book is now in beta if anyone wants to check it out ;) http://shop.oreilly.com/product/0636920030515.do
[2016-06-17T01:39:18.141Z] <5763118fc2f0db084a1e46cf> just in case you need machine learning engine in java/scala, checkout [smile](https://github.com/haifengl/smile), which includes many algorithms.
[2016-06-17T03:40:11.830Z] <564789be16b6c7089cbab8b7> hi..sorry if I missed it but does scikit learn support regularized greedy forests? https://arxiv.org/pdf/1109.0887.pdf 
[2016-06-17T03:42:12.126Z] <564789be16b6c7089cbab8b7> or is there a PR for it?
[2016-06-17T07:29:37.161Z] <56333d0d16b6c7089cb8d5c7> @amueller I was looking into this issue https://github.com/scikit-learn/scikit-learn/issues/6120. Could you let me know if the images need to be updated should I just fix the print message?.
[2016-06-17T08:55:38.505Z] <564789be16b6c7089cbab8b7> @amueller I am looking forward to buying your book!
[2016-06-17T12:14:23.972Z] <55d842e50fc9f982beae3dcf> 
[2016-06-17T14:19:28.728Z] <54d4a1d6db8155e6700f853b> @lesshaste regularized greedy forests has only 18 cites. so no to both ;)
[2016-06-17T14:44:11.084Z] <564789be16b6c7089cbab8b7> @amueller  that's interesting.  I was going by the usage in kaggle competitions. But I really like your quality control system and support it entirely :)
[2016-06-17T14:44:39.222Z] <54d4a1d6db8155e6700f853b> @lesshaste is it? what is it used for?
[2016-06-17T14:44:54.620Z] <564789be16b6c7089cbab8b7> https://github.com/TimSalimans/HiggsML 
[2016-06-17T14:45:07.242Z] <564789be16b6c7089cbab8b7> "This is the code for my second place finish in Kaggle's HiggsML challenge. It is a blend of a large number of boosted decision tree ensembles constructed using Regularized Greedy Forest."
[2016-06-17T14:45:20.526Z] <564789be16b6c7089cbab8b7> as an example
[2016-06-17T14:45:40.984Z] <54d4a1d6db8155e6700f853b> oh wait, is that the paper that describes the regularization used in XGBoost?
[2016-06-17T14:46:24.625Z] <564789be16b6c7089cbab8b7> I didn't think so but I could be wrong. there is a distinct piece of software called http://stat.rutgers.edu/home/tzhang/software/rgf/
[2016-06-17T15:04:09.373Z] <564789be16b6c7089cbab8b7> @amueller  were you thinking of https://arxiv.org/abs/1603.02754 ?
[2016-06-17T15:13:46.177Z] <564789be16b6c7089cbab8b7> hmm.. https://www.kaggle.com/c/higgs-boson/forums/t/10053/did-anyone-try-rgf-regularized-greedy-forest ... maybe can be ignored now that xgboost rules everything :)
[2016-06-18T09:42:35.549Z] <567d7eca16b6c7089cc02a05> Hi, I am new to scikit-learn , I want to contribute, can i get some guidance. Frankly I am having problems in understanding the easy issues. Sorry for being naive
[2016-06-18T09:58:40.186Z] <56b80528e610378809c05a48> Hi :smile: , which issues are you solving?
[2016-06-18T09:59:30.611Z] <56b80528e610378809c05a48> or trying to understand
[2016-06-18T10:01:21.654Z] <567d7eca16b6c7089cc02a05> I tried to understand more than one... but I am unable to narrow down the scope of the problem
[2016-06-18T10:01:37.807Z] <56b80528e610378809c05a48> May you paste the link?
[2016-06-18T10:01:57.799Z] <567d7eca16b6c7089cc02a05> https://github.com/scikit-learn/scikit-learn/issues/6796
[2016-06-18T10:02:17.041Z] <567d7eca16b6c7089cc02a05> this is one of them....
[2016-06-18T10:04:25.501Z] <56b80528e610378809c05a48> I see, maybe you should leave a comments there and tag the issue opener for more specific elaboration.
[2016-06-18T10:04:51.438Z] <56b80528e610378809c05a48> Doing this can help you make sure you are on the right path!
[2016-06-18T10:05:05.765Z] <567d7eca16b6c7089cc02a05> Actually I am not fimiliar with the code-base. So I dont know what to ask him
[2016-06-18T10:05:44.783Z] <567d7eca16b6c7089cc02a05> Can you assign me a task, as a mentor
[2016-06-18T10:06:07.532Z] <56b80528e610378809c05a48> No haha, Im not a pro here.
[2016-06-18T10:06:24.083Z] <567d7eca16b6c7089cc02a05> atleast you can guide me!
[2016-06-18T10:06:58.928Z] <567d7eca16b6c7089cc02a05> I am lost in here.... and i want to get some task for myself
[2016-06-18T10:21:59.889Z] <56b80528e610378809c05a48> You can leave a comment about how you gonna solve this, and ask the issue opener whether you are correct.  It looks like to implement a function based on [this script](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) which can conveniently plot the confusion matrix, you can find doc of confusion matrix [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)
[2016-06-18T10:22:39.952Z] <567d7eca16b6c7089cc02a05> Thanks Yen
[2016-06-20T11:23:30.578Z] <5766ec81c2f0db084a1ec669> @amueller hey man, glad to see you here. Is your book out already? Got a potential buyer here ;)
[2016-06-20T16:48:09.174Z] <56c4f19ae610378809c1f8ae> @c4ndym4n not andy, but its in beta rn http://shop.oreilly.com/product/0636920030515.do
[2016-06-21T01:31:31.776Z] <56333d0d16b6c7089cb8d5c7> I have a question
[2016-06-21T01:32:14.158Z] <56333d0d16b6c7089cb8d5c7> after doing a git pull of sklearn repository
[2016-06-21T01:32:14.622Z] <56c4f19ae610378809c1f8ae> hi
[2016-06-21T01:32:29.894Z] <56333d0d16b6c7089cb8d5c7> say I am woking on a bug
[2016-06-21T01:32:41.967Z] <56333d0d16b6c7089cb8d5c7> how do I test my changes on the code?
[2016-06-21T01:32:50.439Z] <56c4f19ae610378809c1f8ae> what do you mean test?
[2016-06-21T01:32:55.226Z] <56c4f19ae610378809c1f8ae> like run the unit tests?
[2016-06-21T01:33:08.126Z] <56333d0d16b6c7089cb8d5c7> nope
[2016-06-21T01:33:25.573Z] <56c4f19ae610378809c1f8ae> or run random python code that might use scikit-learn on the version that you have modified
[2016-06-21T01:33:31.683Z] <56333d0d16b6c7089cb8d5c7> let say i added a print statement in one of the classes
[2016-06-21T01:33:46.953Z] <56333d0d16b6c7089cb8d5c7> that had a bug
[2016-06-21T01:33:56.384Z] <56c4f19ae610378809c1f8ae> ah. so you want the print statement to show up when it is run.
[2016-06-21T01:34:07.540Z] <56333d0d16b6c7089cb8d5c7> and I want to test that class in an ipython notebook
[2016-06-21T01:34:12.926Z] <56333d0d16b6c7089cb8d5c7> yup
[2016-06-21T01:35:02.923Z] <56c4f19ae610378809c1f8ae> so im not sure how you have it installed currently, but I uninstalled the pip version i had. then, I installed it again from source with `python setup.py develop`
[2016-06-21T01:35:32.311Z] <56333d0d16b6c7089cb8d5c7> ah okay
[2016-06-21T01:35:45.744Z] <56c4f19ae610378809c1f8ae> then, whenver you change code in a compiled extension (.pyx file, say youre making changes to it or repulling from upstream or switching branches), you have to recompile with `python setup.py build_ext --inplace`
[2016-06-21T01:36:26.185Z] <56c4f19ae610378809c1f8ae> the way you can tell if it is working is if you run
[2016-06-21T01:36:39.964Z] <56c4f19ae610378809c1f8ae> ``` In [1]: import sklearn  In [2]: print sklearn.__file__ /Users/nelsonliu/Documents/Github/scikit-learn/sklearn/__init__.pyc ```
[2016-06-21T01:36:49.526Z] <56c4f19ae610378809c1f8ae> that should point to wherever youve cloned the sklearn repo
[2016-06-21T01:39:21.764Z] <56333d0d16b6c7089cb8d5c7> many thanks
[2016-06-21T01:39:23.841Z] <56333d0d16b6c7089cb8d5c7> :)
[2016-06-21T01:39:32.197Z] <56c4f19ae610378809c1f8ae> np, let me know if that worked for you
[2016-06-21T01:40:44.139Z] <56333d0d16b6c7089cb8d5c7> so every time a git pull is done
[2016-06-21T01:41:00.244Z] <56333d0d16b6c7089cb8d5c7> you recompile
[2016-06-21T01:41:04.802Z] <56333d0d16b6c7089cb8d5c7> with python setup.py build_ext --inplace 
[2016-06-21T01:41:05.491Z] <56333d0d16b6c7089cb8d5c7> ?
[2016-06-21T01:41:26.023Z] <56c4f19ae610378809c1f8ae> uh you technically dont have to recompile if none of the .pyx files are changed, but i generally do so anyway because I dont want to bother looking at what was pulled
[2016-06-21T01:41:38.870Z] <56c4f19ae610378809c1f8ae> its quick anyway
[2016-06-21T01:49:42.379Z] <56333d0d16b6c7089cb8d5c7> ok
[2016-06-21T02:49:24.904Z] <56333d0d16b6c7089cb8d5c7> thanks @nelson-liu  it worked
[2016-06-21T02:49:38.540Z] <56c4f19ae610378809c1f8ae> good to hear
[2016-06-21T21:26:04.115Z] <54f7c23815522ed4b3dcd290> I have limited data science experience, and reasonable programming experience. What are the best ways to get started??
[2016-06-22T00:11:24.629Z] <55aee1ab0fc9f982beaa80a5> @crimsonsoccer55 what do you want to do?
[2016-06-22T21:27:15.994Z] <574454a0c43b8c601974a563> Hi all :smile:
[2016-06-22T21:28:05.778Z] <574454a0c43b8c601974a563> I just want mention that Im working on a module which ports trained (sklearn) decision tree models to Java and C. Have a look if you are interested: https://github.com/nok/sklearn-decision-tree-porting
[2016-06-22T21:28:59.975Z] <574454a0c43b8c601974a563> 
[2016-06-22T21:40:06.637Z] <55aee1ab0fc9f982beaa80a5> Does anyone know if there are plans to expand the MLP/RBM modules to include more hierarchical learning techniques 
[2016-06-24T01:36:05.036Z] <576c83e3c2f0db084a1fa0c2> @nok  404 error on your link
[2016-06-24T08:47:07.313Z] <574454a0c43b8c601974a563> @alayassir https://github.com/nok/scikit-learn-model-porting (under active development)
[2016-06-24T10:19:11.110Z] <56333d0d16b6c7089cb8d5c7> @amueller could you please let me know how to proceed with https://github.com/scikit-learn/scikit-learn/issues/6120
[2016-06-24T17:32:23.979Z] <54e07d6515522ed4b3dc0858> It seems impossible to pass check_estimator for a sparse classifier that does not do multi-class out of the box.
[2016-06-24T17:33:04.273Z] <54e07d6515522ed4b3dc0858> Because of [this test](https://github.com/scikit-learn/scikit-learn/blob/51a765a/sklearn/utils/estimator_checks.py#L301)
[2016-06-24T17:36:59.076Z] <54e07d6515522ed4b3dc0858> @neale not sure what you mean by hierarchical learning, but in general any framework expansion of the neural network components is out of scope for scikit-learn
[2016-06-24T21:03:17.843Z] <55aee1ab0fc9f982beaa80a5> @vene why is that out of scope, there is a beta MLP module that works pretty well
[2016-06-24T21:03:55.615Z] <55aee1ab0fc9f982beaa80a5> Giving users the ability to build networks layer by layer should be feasible 
[2016-06-24T21:07:15.243Z] <54e07d6515522ed4b3dc0858> @neale I didn't say it's infeasable, it just doesn't fit within the simple API that scikit-learn strives for. There are great libraries that allow modular composition of deep nets, like Lasagne and Keras. Check out the scikit-learn [faq](http://scikit-learn.org/stable/faq.html) for more about this "vision".
[2016-06-24T21:09:20.650Z] <55aee1ab0fc9f982beaa80a5> @vene I hadn't seen that before, I got it now
[2016-06-24T21:09:26.109Z] <54e07d6515522ed4b3dc0858> Currently scikit-learn pipelines and feature unions are extremely simple objects, and steps in a pipeline cannot and do not communicate with each other, but instead are trained independently.
[2016-06-24T21:10:12.048Z] <55aee1ab0fc9f982beaa80a5> Yeah I always assumed the contributions weren't there, not that scikit actively stayed away from those kinds of models 
[2016-06-25T20:30:15.585Z] <5739265bc43b8c6019731a58> GSOC admins need to resolve the evaluation situation immediately I'm on irc .. Python Gsoc Admin
[2016-06-26T04:41:19.068Z] <55901c1b15522ed4b3e2f949> @meflin what is the issue?
[2016-06-26T15:31:44.735Z] <55a487245e0d51bd787b4e45> @jmschrei It seemed that the student evals were overdue
[2016-06-26T15:32:18.557Z] <55a487245e0d51bd787b4e45> @jmschrei (At this point, I think there is a risk of sklearn being blacklisted from GSOC)
[2016-06-26T16:23:28.763Z] <55901c1b15522ed4b3e2f949> @mikegraham I submitted my student eval days ago
[2016-06-26T16:31:10.011Z] <55901c1b15522ed4b3e2f949> okay seems like it has been resolved
[2016-06-26T22:30:08.135Z] <5739265bc43b8c6019731a58> everything is resolved and good thanks for all your hard work
[2016-06-26T22:30:42.365Z] <53135b495e986b0712efc453> Thanks for the update :)
[2016-06-29T23:27:29.247Z] <53135b495e986b0712efc453> @amueller Would you be interested in doing the honor of giving a -1 and closing this? :P (https://github.com/scikit-learn/scikit-learn/pull/5883)
[2016-06-30T02:11:17.507Z] <576bb437c2f0db084a1f7ead> Any node wrapper for Scikitlearn?
[2016-06-30T03:45:28.022Z] <55d054b70fc9f982bead8af7> Hi everyone , I am Khanh and newbie in Scikit-learn :D 
[2016-06-30T11:39:40.565Z] <56ee4f3185d51f252ab9c4a1> Hi everyone, I have this: ```rf = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)     clf = Pipeline([('preproc', StandardScaler()),('classifier', rf)])```
[2016-06-30T11:43:36.864Z] <56ee4f3185d51f252ab9c4a1> fit the classifier with all of the training set     ```data = clf.fit(features, labels)``` where ```features``` & ```labels``` are of size 4
[2016-06-30T11:44:00.302Z] <56ee4f3185d51f252ab9c4a1> And I save it as a Pickle object. 
[2016-06-30T11:44:19.523Z] <56ee4f3185d51f252ab9c4a1> Now, How can I extract those array of features and labels again??
[2016-06-30T11:44:27.469Z] <56ee4f3185d51f252ab9c4a1> Any idea any one?
[2016-06-30T11:48:33.580Z] <56c4f19ae610378809c1f8ae> what is it? What specifically are you saving as a Pickle object
[2016-06-30T12:08:43.262Z] <56ee4f3185d51f252ab9c4a1> the ```data``` variable. Which is a pipeline class object. 
[2016-06-30T12:08:48.921Z] <56ee4f3185d51f252ab9c4a1> <class 'sklearn.pipeline.Pipeline'>
[2016-06-30T12:21:22.091Z] <56c4f19ae610378809c1f8ae> hmm as far as i know there is no way to get the input features and labels from a fitted classifier...
[2016-06-30T12:39:02.999Z] <56ee4f3185d51f252ab9c4a1> :( 
[2016-06-30T16:03:29.593Z] <54d4a1d6db8155e6700f853b> @girisagar46 what would be the point of storing the dataset in the model?
[2016-06-30T19:14:25.515Z] <56818d2d16b6c7089cc06972> Hello. I am using sklearn to try to predict lux values from a iOS camera data. I have created some training data for multiple models of iPad/iPods, and have it working to some degree, but still get something like 20% error.
[2016-06-30T19:15:20.841Z] <56818d2d16b6c7089cc06972> I am relatively new to sklearn, and am wondering where I can get feedback on my iPython notebook to improve my results. Is this a good place? If so, what is the best way to share a notebook and relevant external files?
[2016-07-02T12:24:40.979Z] <54317aec163965c9bc208ec9> @nspaeth without looking at your approach I know that cameras automatically adjust themselves to keep the brightness of an image in a "useful range". I don't think this is a good project for someone starting in machine learning. The only way I see this working is that the algorithm needs to understand about certain camera "artefacts" and then use these to interpret the brightness. I can't see this working short of a deep convolutional network.
[2016-07-05T05:08:02.329Z] <5581814615522ed4b3e20c6a> hi guys i m having a doubt If i train a classifier and pickle it. How to make it relearn everytime when i introduce a new test example. Is it like everytime i want to predict something i need to retrain with updated training set or will the updating can happen on the go.?
[2016-07-05T05:31:46.214Z] <54317aec163965c9bc208ec9> @BastinRobin In my opinion retraining with every new test example is a bad idea, mainly because it will change the accuracy characteristics of your model over time. Not necessarily always towards the better.  Some Bayesian methods support very natural "updating". Otherwise you can look into "Reinforcement learning" which may be better suited to your task if you need to learn "online".
[2016-07-05T05:33:24.101Z] <54317aec163965c9bc208ec9> It may also be a good Idea to keep the new examples in a special "out of sample" test set, and evaluate ongoing accuracy on that test set.
[2016-07-05T06:39:15.394Z] <5581814615522ed4b3e20c6a> @akloster  thank you :)
[2016-07-05T09:31:32.764Z] <5757de1ec43b8c6019787b6c> Hi  I have a txt file containing words and corresponding word vectors . I want to plot this using tSNE
[2016-07-05T09:31:45.389Z] <5757de1ec43b8c6019787b6c> Can anyone point me to good example ?
[2016-07-05T09:44:55.124Z] <553d32d715522ed4b3df8b92> Hi, I have read a few articles on word embeddings and tsne but am new to these topics. Some of the websites were
[2016-07-05T09:44:57.324Z] <553d32d715522ed4b3df8b92> https://lvdmaaten.github.io/tsne/
[2016-07-05T09:45:08.603Z] <553d32d715522ed4b3df8b92> http://blog.christianperone.com/2016/01/voynich-manuscript-word-vectors-and-t-sne-visualization-of-some-patterns/
[2016-07-05T09:47:10.723Z] <553d32d715522ed4b3df8b92> And I came across this just now.. https://www.quora.com/How-do-I-visualise-word2vec-word-vectors/answer/Vered-Shwartz hope it is helpful.
[2016-07-05T19:29:51.048Z] <54b4f2d1db8155e6700e99c0> Hey Folks, Id like to understand the implementation of the Random Forests. Is there a specific reason why _parallel_build_trees() is a function and not a method?
[2016-07-05T23:42:03.135Z] <53135b495e986b0712efc453> Because it is a helper which is called inside the `fit` method.
[2016-07-05T23:42:44.574Z] <53135b495e986b0712efc453> The `n_jobs` param that you set at the initialization of `RandomForestClassifier` controls the number of processes used by `fit`...
[2016-07-05T23:47:03.548Z] <53135b495e986b0712efc453> The `fit`  uses `joblib`'s `delayed` to run the `_parallel_build_trees` helper in batches to build `n_jobs` trees at a time.
[2016-07-08T16:40:10.611Z] <53135b495e986b0712efc453> Is there a way to install sklearn to python package namespace under a different name (say `skmaster`) it would be nice to have two versions of scikit-learn installed under different names to compare against master... 
[2016-07-08T18:09:21.607Z] <53810862048862e761fa2887> @raghavrv You can open 2 different shells and activate 2 different environments in them ?
[2016-07-08T18:11:16.740Z] <56c4f19ae610378809c1f8ae> it'd be useful to be able to run both in the same script for easy comparison / benchmarking
[2016-07-09T12:33:42.151Z] <53135b495e986b0712efc453> @vighneshbirodkar yes indeed but like @nelson-liu says it would be nice to use it both in a single script... I tried messing around with the setup.py file but looks like there are quite a lot of imports inside sources which do not use relative imports (hence explicitly importing from `sklearn.module`...)... I'd have to change all of that ;(
[2016-07-12T11:04:17.598Z] <53135b495e986b0712efc453> @ogrisel could you reset travis cache at #5974 please?
[2016-07-14T21:09:40.945Z] <574454a0c43b8c601974a563> Now you can port a learned AdaBoost classifier based on pruned DecisionTree estimators to Java:
[2016-07-14T21:09:44.048Z] <574454a0c43b8c601974a563> https://github.com/nok/scikit-learn-model-porting/blob/master/examples/classification/adaboost_predict.py
[2016-07-14T21:10:52.113Z] <574454a0c43b8c601974a563> But note that the project is still under active development. :-)
[2016-07-15T04:06:00.736Z] <564789be16b6c7089cbab8b7> is https://github.com/mblondel/svmlight-loader still the recommended way to read in very large libsvm format files? It is quote old now and scikit-learn has been through many versions in the last 3 years
[2016-07-15T14:33:57.448Z] <54d4a1d6db8155e6700f853b> @lesshaste might still be faster
[2016-07-15T17:10:35.613Z] <53135b495e986b0712efc453> @vighneshbirodkar Are you planning to continue work on the GBCV PR? Or would it be okay if I gave a hand?  (Either by push access to your repo or by cherry-picking the commits?)
[2016-07-15T18:39:50.664Z] <564789be16b6c7089cbab8b7> @amueller True
[2016-07-15T18:41:22.495Z] <564789be16b6c7089cbab8b7> I have a general ML classification question.. I hope this isn't the wrong place. I have data which is labelled into A, B, C, D, E and Other. In the end I just want to tell if new data is in A-E or other. That is perform a binary classification. A,B,C, D and E are very different from each other however. Should I build 5 binary classifiers and combine them somehow or just go straight for a binary A-E versus Other classifier? I am using a random forest currently.
[2016-07-15T18:43:51.035Z] <564789be16b6c7089cbab8b7> I could try to build a multiclass classifiers but the class sizes are very imbalanced and I am not sure how well RF copes with that
[2016-07-15T19:29:24.618Z] <56c4f19ae610378809c1f8ae> is there any tool to lint cython? through working on the tree .pyx files, ive noticed there are lots of style discrepancies...
[2016-07-15T19:29:57.737Z] <564789be16b6c7089cbab8b7> @nelson-liu https://www.jetbrains.com/help/pycharm/2016.1/cython-support.html
[2016-07-15T19:30:54.228Z] <56c4f19ae610378809c1f8ae> hmm is there any method that doesnt rely on pycharm? e.g. pep8 flake8 or a similar standard
[2016-07-15T19:31:15.121Z] <564789be16b6c7089cbab8b7> not that I am aware of sadly
[2016-07-15T19:46:34.001Z] <564789be16b6c7089cbab8b7> @nelson-liu https://udiboy1209.github.io/2016-06-18-cython-needs-a-flake-and-lint-tool/
[2016-07-15T19:47:16.640Z] <564789be16b6c7089cbab8b7> that's a pretty up to date complaint
[2016-07-15T19:47:49.534Z] <56c4f19ae610378809c1f8ae> haha ok, so seems like one doesnt exist sadly. thanks for the help @lesshaste :)
[2016-07-15T19:48:11.142Z] <564789be16b6c7089cbab8b7> my pleasure.. any idea about my general classification query above by any chance?
[2016-07-15T19:48:37.374Z] <564789be16b6c7089cbab8b7> not really sure where the best place is for question like that so sorry it is a tiny bit OT for this gitter
[2016-07-15T19:50:15.427Z] <56c4f19ae610378809c1f8ae> ive seen general ML questions here so it should (?) be fine? I dont think RF copes very well with unbalanced multiclass data...do you have ample data for each of the classes?
[2016-07-15T19:50:40.749Z] <564789be16b6c7089cbab8b7> well I have millions of Other records but only thousands of the A-E cases
[2016-07-15T19:51:08.104Z] <564789be16b6c7089cbab8b7> is there anything better suited to the task?
[2016-07-15T19:53:01.905Z] <56c4f19ae610378809c1f8ae> hmm have you looked into resampling methods?
[2016-07-15T19:53:24.342Z] <564789be16b6c7089cbab8b7> do you mean just sampling the same record repeatedly? I never saw the point in that to be honest
[2016-07-15T19:57:13.585Z] <56c4f19ae610378809c1f8ae> hmm i mean you can try taking a random sample of your data, then fit your model on one set and use a held out set to find good probability cutoffs with an ROC curve or something...
[2016-07-15T19:59:25.484Z] <56c4f19ae610378809c1f8ae> and you dont have to sample the same record repeatedly, but take a random sample of your other classes to generate a synthetic balanced dataset
[2016-07-15T20:00:31.909Z] <56c4f19ae610378809c1f8ae> this answer on crossvalidated looks good, could be a starting point for more reading? http://stats.stackexchange.com/questions/131255/class-imbalance-in-supervised-machine-learning
[2016-07-15T20:35:16.973Z] <564789be16b6c7089cbab8b7> thanks
[2016-07-15T20:36:07.449Z] <564789be16b6c7089cbab8b7> "Some methods, like random forests, don't need any modifications." I wonder how true that is
[2016-07-15T21:06:39.319Z] <56c4f19ae610378809c1f8ae> yeah, same. please let me know what ends up working best for you?
[2016-07-15T21:10:42.790Z] <54e07d6515522ed4b3dc0858> There's also https://github.com/fmfn/imbalanced-learn, which will soon become part of scikit-learn-contrib
[2016-07-15T21:12:55.150Z] <56c4f19ae610378809c1f8ae> this looks great, thanks for the link @vene !
[2016-07-16T02:32:02.567Z] <56c4f19ae610378809c1f8ae>  weve reached 7000 PRs / issues :octocat:  not sure if its a cause for celebration, though :)
[2016-07-16T07:27:25.766Z] <564789be16b6c7089cbab8b7> @vene oh cool!
[2016-07-16T07:39:26.914Z] <564789be16b6c7089cbab8b7> Another basic question.. I have some data which is mixed categorical and numerical. There are various different ways I could preprocess it before trying to train my classifier. At the moment I just have a python script which I have to edit and rerun. Is there some neat way, using pipelines maybe(?) to make this all more systematic?  I would like to do the equivalent of gridsearch really but with the different ways of preprocessing the data
[2016-07-16T12:05:15.219Z] <56c4f19ae610378809c1f8ae> Well depends what you want to do? You could write your own transformers and that would work 
[2016-07-16T14:23:30.760Z] <54d4a1d6db8155e6700f853b> hey sprinters!
[2016-07-16T14:23:47.223Z] <56c4f19ae610378809c1f8ae> :wave: 
[2016-07-16T14:23:59.088Z] <54d4a1d6db8155e6700f853b> I tagged some issues with "sprint" that might be good entry points: https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+is%3Aissue+label%3ASprint
[2016-07-16T14:24:06.808Z] <54d4a1d6db8155e6700f853b> other good tags are "easy" and "needs contributor"
[2016-07-16T14:24:46.917Z] <54d4a1d6db8155e6700f853b> You can find the contributor guide here: http://scikit-learn.org/dev/developers/index.html
[2016-07-16T14:26:09.680Z] <54d4a1d6db8155e6700f853b> Please start with something very simple, happy to talk about more complicated issues. You can also start reviewing other pull requests, or see if there are pull requests that have been stalled for a long time.
[2016-07-16T14:43:21.835Z] <56c4f19ae610378809c1f8ae> @lesshaste thinking more about it, transformers are probably what you want. there are a bunch of preprocessing tools within the library natively but if youre writing your own scripts, its pretty trivial to wrap them in a transformer and put them into a pipeline
[2016-07-16T14:46:00.054Z] <54d4a1d6db8155e6700f853b> Ok pasted the above message here: https://github.com/scikit-learn/scikit-learn/wiki/Scipy-2016-Sprint-instructions
[2016-07-16T14:46:48.758Z] <56b0a775e610378809bf7a7c> Hey sprinters. Thanks for helping us. Tell us if you need help for something. Have a good sprints.
[2016-07-16T14:48:50.881Z] <56c4f19ae610378809c1f8ae> if anyone needs help on things or setting up dev environment or finding things to start, id be happy to help
[2016-07-16T15:00:54.205Z] <54d4a1d6db8155e6700f853b> Btw, if any issue says "change X", if this is an API change or if it changes behavior of the code, instead of actually changing it, you need to deprecate the old behavior http://scikit-learn.org/dev/developers/contributing.html#deprecation
[2016-07-16T15:27:12.561Z] <54d4a1d6db8155e6700f853b> btw, if you find bugs or stuff is not working properly, also feel free to open issues or talk to me or the other developers
[2016-07-16T15:29:23.699Z] <54d4a1d6db8155e6700f853b> so if you want to create a new conda environment for the sprint, you should create one with all the dependencies, fork and clone the repo, and then do pip install -e . (while in the scikit-learn folder that you cloned)
[2016-07-16T15:33:00.754Z] <53135b495e986b0712efc453> Hi to sprinters from Paris! Have fun! :)
[2016-07-16T15:36:21.429Z] <56b0a775e610378809bf7a7c> @raghavr are you working today ?
[2016-07-16T16:05:07.147Z] <53135b495e986b0712efc453> I got bored at home and came to the lab. The Internet speed is very good here ;) And I will be glad to help if there is any PR to review. :)
[2016-07-16T16:17:56.963Z] <56d577ffe610378809c46670> @nelson-liu Hey, I'm a beginner in ML. I was looking for some good first time issues which don't involve completing documention. I went through the list of issues on GitHub but would really appreciate if you or anyone could point to any specific issue for beginners. Thanks. 
[2016-07-16T16:21:24.934Z] <56c4f19ae610378809c1f8ae> this PR stalled and might be a good place to pick back up? https://github.com/scikit-learn/scikit-learn/issues/6670
[2016-07-16T16:25:55.393Z] <56d577ffe610378809c46670> Sure, I'll ping if I face any  problems.
[2016-07-16T16:26:11.864Z] <54d4a1d6db8155e6700f853b> I tried to make sure all the issues that are still available are tagged as "need contributors"
[2016-07-16T16:33:19.496Z] <578a5f01c2f0db084a23472d> Hi @amueller , I have some time and since there is a scikit learn sprint going on now, I was thinking of contributing remotely from Tuebingen. Is this possible?  I will be glad to work on some documentation stuff. 
[2016-07-16T16:33:38.527Z] <54d4a1d6db8155e6700f853b> @btabibian hey. Any contributions are always welcome :)
[2016-07-16T16:34:07.825Z] <54d4a1d6db8155e6700f853b> the ones that are tagged sprint are very easy ones. If there is something that strikes your fancy, let me know!
[2016-07-16T16:34:13.024Z] <54d4a1d6db8155e6700f853b> (I mean other than the sprint ones)
[2016-07-16T16:34:50.329Z] <578a5f01c2f0db084a23472d> I go for the most easy ones now :D, maybe this: https://github.com/scikit-learn/scikit-learn/issues/6865 ? :)
[2016-07-16T16:39:17.041Z] <54d4a1d6db8155e6700f853b> sure, thanks :)
[2016-07-16T16:44:36.070Z] <54d4a1d6db8155e6700f853b> For anyone joining recently important links and advice is here: https://github.com/scikit-learn/scikit-learn/wiki/Scipy-2016-Sprint-instructions
[2016-07-16T19:55:01.769Z] <54d4a1d6db8155e6700f853b> does anyone want to pick this up? https://github.com/scikit-learn/scikit-learn/pull/5551
[2016-07-16T21:01:40.153Z] <54d4a1d6db8155e6700f853b> I'll be in 103 for a bit
[2016-07-16T23:10:08.401Z] <54d4a1d6db8155e6700f853b> FYI, there are issues that need contributors that don't have any of the tags. the tags are a very rough approximation to the state of the issues
[2016-07-16T23:22:54.599Z] <56b0a775e610378809bf7a7c> If you need a review of your PR just add @tguillemot in the PR and I will have a look
[2016-07-17T20:45:04.761Z] <54ac29f9db8155e6700e6980> @amueller , I just sent a requirement about the book. thanks!
[2016-07-18T10:00:52.679Z] <564789be16b6c7089cbab8b7> I am trying to follow the example at http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html but using a random forest. It seems decision_function doesn't exist for the random forest classifier
[2016-07-18T10:01:07.016Z] <564789be16b6c7089cbab8b7> what should I use instead (sorry for the simple question)?
[2016-07-18T10:02:46.924Z] <564789be16b6c7089cbab8b7> it is this line that is causing the problem y_score = classifier.fit(X_train, y_train).decision_function(X_test) 
[2016-07-18T14:45:06.180Z] <564789be16b6c7089cbab8b7> ok cancel that..silly me
[2016-07-18T14:59:07.839Z] <55d6ea0d0fc9f982beae242d> Using KNN in sklearn, is there anyway to have the weights be based on the labels of datapoints? More specifically, I have some unbalanced data and would like to combat this by weighting samples of less common labels higher. I could of course just add copies of the under represented classes but this adds some non determinism if I choose the extra copies randomly so I thought just weighting them would be better.  Is this possible?
[2016-07-18T15:03:42.965Z] <56c4f19ae610378809c1f8ae> Hmm I don't think so. You could just set a random seed for sampling up if you're worried about reproducibility. 
[2016-07-18T15:21:22.872Z] <55d6ea0d0fc9f982beae242d> yep sure, but should I add a feature request for this?
[2016-07-18T15:54:51.294Z] <564789be16b6c7089cbab8b7> how can you mix calibratedclassifier and onevsrestclassifier? I just want to do classifier = OneVsRestClassifier(RandomForestClassifier()) but with the classifier correctly calibrated
[2016-07-18T19:59:29.556Z] <564789be16b6c7089cbab8b7> apologies if this is slightly OT but.. my really simple xgboost code for the MNIST data set is way slower than ExtraTreesClassifer http://paste.ubuntu.com/19943014/ . What am I doing wrong?
[2016-07-19T10:23:40.171Z] <56d577ffe610378809c46670> Hey, Can someone explain what's the difference between [MRG] and [MRG+1] in case of PR's?
[2016-07-19T10:30:39.781Z] <564789be16b6c7089cbab8b7> @manu-chroma  What does MRG stand for to start with?
[2016-07-19T10:39:13.591Z] <553d32d715522ed4b3df8b92> MRG is for the PR when it is ready for review, MRG + X is when X number of core developers are okay with PR. In general it is around 2 or 3.
[2016-07-19T10:39:40.749Z] <564789be16b6c7089cbab8b7> Cool. what does MRG actually stand for?
[2016-07-19T10:40:22.699Z] <553d32d715522ed4b3df8b92> Merge p0ppp
[2016-07-19T10:40:35.421Z] <564789be16b6c7089cbab8b7> oh :)
[2016-07-19T10:40:39.740Z] <553d32d715522ed4b3df8b92> Sorry.. typos..
[2016-07-19T10:40:58.555Z] <56d577ffe610378809c46670> @lesshaste https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist
[2016-07-19T10:40:59.351Z] <553d32d715522ed4b3df8b92> Merge is MRG and work in progress as WIP
[2016-07-19T10:41:09.037Z] <564789be16b6c7089cbab8b7> oh cool
[2016-07-19T10:42:01.641Z] <564789be16b6c7089cbab8b7> I have just tried for the first time to use xgboost with sklearn and am getting poor results and it is very slow.  I realise xgboost is not core scikit-learn but would any very kind person be able to give a newbie a hand please?
[2016-07-19T10:43:01.062Z] <564789be16b6c7089cbab8b7> my very simple sample script is just running on the MNIST digits data and it is at http://paste.ubuntu.com/20022811/  . What am I doing wrong?
[2016-07-19T10:54:44.214Z] <5508681715522ed4b3dd6630> Hello, I am trying to do MNIST task with data from Kaggle and not data in scikitlearn. I am getting accuracies ~90% using LinearSVC, SGDClassifier and KNeighborsClassifier.  But every algorithm just gives a label for a test image as output. That is fine.  I just wanted to have log probabilities of each class. For example if a test image is given- I want an array of length of classes with probabilities that test image is from this class.
[2016-07-19T10:54:55.632Z] <5508681715522ed4b3dd6630> Is there any way to do that using sklearn?
[2016-07-19T10:56:41.096Z] <564789be16b6c7089cbab8b7> @SnShine  Are you using predict_proba ?
[2016-07-19T10:58:11.241Z] <5508681715522ed4b3dd6630> No. 
[2016-07-19T10:58:15.618Z] <5508681715522ed4b3dd6630> I will go through that.
[2016-07-19T11:14:20.777Z] <553d32d715522ed4b3df8b92> @SnShine As @lesshaste said, this might probably be what you are looking for http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict_proba
[2016-07-19T11:15:12.651Z] <553d32d715522ed4b3df8b92> @lesshaste Even I am a novice and haven't used XGBoost before but maybe the loss function needs to be changed for multiclass classification ?
[2016-07-19T11:27:50.523Z] <564789be16b6c7089cbab8b7> @maniteja123 Let me try that. There must be at least one xgboost here soon :)
[2016-07-19T11:36:46.100Z] <564789be16b6c7089cbab8b7> @maniteja123  According to https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py it should use multi:softprob if the number of classes > 2 I think
[2016-07-19T11:42:53.619Z] <553d32d715522ed4b3df8b92> Yup I suppose you are right, it should set the objective automatically as in https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py#L405.  Sorry I have no idea about the performance then. Just to know, what is the cv score you are getting using XGBoost ?
[2016-07-19T11:43:35.083Z] <564789be16b6c7089cbab8b7> I get [ 0.9323022 0.93157206 0.92796762 0.93271406 0.93854216] from 5-fold cv of xgboost and it takes a really really long time
[2016-07-19T11:43:58.421Z] <564789be16b6c7089cbab8b7> I get [ 0.96216538 0.96465548 0.96428146 0.96558295 0.9670081 ] from ExtraTreesClassifier and it is really quick
[2016-07-19T11:44:05.055Z] <564789be16b6c7089cbab8b7> I am clearly doing something wrong
[2016-07-19T11:48:20.875Z] <564789be16b6c7089cbab8b7> can you reproduce my problem?
[2016-07-19T11:48:35.476Z] <553d32d715522ed4b3df8b92> Oh thanks for the results. I too will try running the script on my machine and tune various parameters for the XgBoost model. 
[2016-07-19T11:49:26.751Z] <553d32d715522ed4b3df8b92> My machine doesn't have a good RAM. But will try to reproduce in VM and get back to you.
[2016-07-19T11:49:39.325Z] <564789be16b6c7089cbab8b7> thanks! It shouldn't need much RAM
[2016-07-19T11:50:48.885Z] <564789be16b6c7089cbab8b7> sadly the xgboost google group seems pretty dead as does their gitter room
[2016-07-19T11:51:54.659Z] <564789be16b6c7089cbab8b7> xgboost seems to use 1.6GB on my machine for that dataset
[2016-07-19T11:51:58.747Z] <553d32d715522ed4b3df8b92> http://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn Have you looked at the ``evals_result`` dict mentioned in the docs
[2016-07-19T11:52:10.830Z] <564789be16b6c7089cbab8b7> no! Do you think it might help?
[2016-07-19T11:52:58.325Z] <564789be16b6c7089cbab8b7> (got to go out for 30 minutes.. thanks so much for looking at this!)
[2016-07-19T11:53:12.026Z] <553d32d715522ed4b3df8b92> Also this page http://xgboost.readthedocs.io/en/latest//parameter.html has ``eval_metric`` which has ``merror`` for multi class error
[2016-07-19T11:53:38.787Z] <553d32d715522ed4b3df8b92> I should thank you for getting me started to look into this :)
[2016-07-19T11:54:41.640Z] <553d32d715522ed4b3df8b92> I am not sure if it might help but it seemed relevant to multi class but was mentioned it was specific to the objective.``eval_metric [ default according to objective ]``. So do have a look and let us know if you get any insight. Thanks!
[2016-07-19T12:42:07.544Z] <564789be16b6c7089cbab8b7> Interesting.. I am currently also confused why it is so slow when everyone says how fast xgboost is!
[2016-07-19T12:45:31.230Z] <564789be16b6c7089cbab8b7> @maniteja123  just changing to objective="multi:softmax" increased the CV scores!
[2016-07-19T12:45:39.140Z] <564789be16b6c7089cbab8b7> for reasons I am 100% unclear about
[2016-07-19T12:47:50.128Z] <564789be16b6c7089cbab8b7> 
[2016-07-19T15:29:45.205Z] <553d32d715522ed4b3df8b92> Hi, sorry for the slow reply. That's great to know. Is the algorithm running faster now ?
[2016-07-19T15:30:01.406Z] <564789be16b6c7089cbab8b7> @maniteja123  no.. it is still super slow
[2016-07-19T15:32:03.398Z] <553d32d715522ed4b3df8b92> Oh okay. Hopefully someone experienced can provide an explanation for these results. 
[2016-07-19T15:32:14.095Z] <564789be16b6c7089cbab8b7> it would be great
[2016-07-19T15:32:20.749Z] <553d32d715522ed4b3df8b92> Have you tried asking on kaggle ?
[2016-07-19T15:32:32.705Z] <564789be16b6c7089cbab8b7> yes... I asked on the forum there and have no reply yet
[2016-07-19T15:32:44.501Z] <564789be16b6c7089cbab8b7> I mean I asked on the forum for the digits recognizer challenge
[2016-07-19T15:34:57.618Z] <553d32d715522ed4b3df8b92> Oh I see. I don't know any other forum. Maybe stack overflow ? (Sorry for my naive suggestions)
[2016-07-19T15:35:11.183Z] <564789be16b6c7089cbab8b7> my friend also asked on SO
[2016-07-19T15:35:12.759Z] <564789be16b6c7089cbab8b7> no answer :)
[2016-07-19T15:36:31.470Z] <553d32d715522ed4b3df8b92> Okay so I too am waiting for the rra
[2016-07-19T15:36:40.738Z] <553d32d715522ed4b3df8b92> *reply
[2016-07-19T15:37:03.547Z] <553d32d715522ed4b3df8b92> :-)
[2016-07-19T15:37:10.455Z] <564789be16b6c7089cbab8b7> one problem is that I don't understsand the parameters despite the huge number of "guides" online
[2016-07-19T15:37:23.534Z] <564789be16b6c7089cbab8b7> which make xgboost run slower or faster? Can you find the answer to that?
[2016-07-19T15:40:25.445Z] <553d32d715522ed4b3df8b92> Maybe having a look at this paper https://arxiv.org/pdf/1603.02754v3 can help  us in understanding the algorithm better ? I too shall try reading it once
[2016-07-19T15:40:50.051Z] <564789be16b6c7089cbab8b7> it's definitely worth reading
[2016-07-19T15:51:37.256Z] <553d32d715522ed4b3df8b92> @lesshaste have you tried with different number of threads ? I saw some issue about multi threading here https://github.com/dmlc/xgboost/issues/523
[2016-07-19T15:52:31.175Z] <564789be16b6c7089cbab8b7> hmmm... no not yet but that page does say it is fine in python
[2016-07-19T15:55:24.511Z] <553d32d715522ed4b3df8b92> Yeah sorry just read the whole issue. I just thought it might be a reason.
[2016-07-19T16:19:11.047Z] <564789be16b6c7089cbab8b7> @maniteja123  I have a much simpler question now :)  I simply want to modify http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html for the digits dataset we are using
[2016-07-19T16:19:19.275Z] <564789be16b6c7089cbab8b7> have you managed to get that to work?
[2016-07-19T16:49:36.799Z] <553d32d715522ed4b3df8b92> @lesshaste if I understand you correctly you are referring to 
[2016-07-19T16:49:49.889Z] <553d32d715522ed4b3df8b92> The ROC for multi class right ?
[2016-07-19T16:52:02.872Z] <553d32d715522ed4b3df8b92> We need to binarize the output for that to work and plot for each of the classes ?
[2016-07-19T18:03:32.278Z] <564789be16b6c7089cbab8b7> @maniteja123  thanks.. that was indeed the  answer
[2016-07-19T18:26:24.497Z] <553d32d715522ed4b3df8b92> @lesshaste great. glad that it was helpful!
[2016-07-21T20:44:26.612Z] <564789be16b6c7089cbab8b7> hi.. I am trying to find the most important features in a large random forest and it takes about 1 second per feature and there are 10s of thousands of features. The random forest only took ten minutes to build in total.
[2016-07-21T20:44:33.748Z] <564789be16b6c7089cbab8b7> am I doing something wrong or is this expected?
[2016-07-21T21:20:49.633Z] <564789be16b6c7089cbab8b7> ah.. I think I might realise my mistake!
[2016-07-21T21:23:49.800Z] <564789be16b6c7089cbab8b7> for i in xrange(len(clf.feature_importances_)):     print clf.feature_importances_[i]
[2016-07-21T21:24:19.046Z] <564789be16b6c7089cbab8b7> does this recompute the whole feature_importances_ array in each step of the for loop?
[2016-07-23T08:53:49.958Z] <56b80528e610378809c05a48> Hello can anyone help me on this [test-failing](https://github.com/scikit-learn/scikit-learn/pull/6913#issuecomment-234704911) issue?
[2016-07-23T08:56:18.272Z] <56b80528e610378809c05a48> My test pass on 64-bit computer but fail on 32-bit computer, and the occurs at [this line](https://github.com/yenchenlin/scikit-learn/blob/cd-fused-types/sklearn/src/cblas/ATL_srefaxpy.c#L131).
[2016-07-23T08:59:43.531Z] <56b80528e610378809c05a48> I wonder what is the difference to call [ATL_srefaxpy.c](https://github.com/yenchenlin/scikit-learn/blob/cd-fused-types/sklearn/src/cblas/ATL_srefaxpy.c) on 32-bit and 64-bit computer when fitting `np.float32` data?
[2016-07-23T10:09:54.743Z] <553d32d715522ed4b3df8b92> Hi everyone, just a small question. Is the link to ``nose`` package [here](http://scikit-learn.org/stable/developers/advanced_installation.html#testing) the expected one ?
[2016-07-23T10:12:02.475Z] <553d32d715522ed4b3df8b92> @yenchenlin1994 the tests are failing on AppVeyor , so it is Windows environment right ? Is it failing on 32 bit machines working on ubuntu or mac too ?
[2016-07-23T10:13:05.533Z] <56b80528e610378809c05a48> Good point. I am not sure about ubuntu but not on mac
[2016-07-23T10:13:16.456Z] <56b80528e610378809c05a48> @maniteja123 thanks.
[2016-07-23T10:14:21.474Z] <56b80528e610378809c05a48> And the link you pointed out seems obviously wrong :smile: 
[2016-07-23T10:15:15.725Z] <553d32d715522ed4b3df8b92> Yeah the other day someone was asking about the testing instructions and then I accidentally stumbled upon this. I just thought it should be clarified once !
[2016-07-23T10:24:15.635Z] <553d32d715522ed4b3df8b92> And in case you don't have access to one, I can checkout your branch and check on my machine. I am running Ubuntu 14.04 on 32 bit VM machine.
[2016-07-23T10:25:42.718Z] <56b80528e610378809c05a48> I only try to reproduce it using 32-bit Python but run on an 64-bit mac
[2016-07-23T10:26:10.527Z] <56b80528e610378809c05a48> thanks a lot!
[2016-07-23T10:27:18.010Z] <56b80528e610378809c05a48> It looks good on 32-bit Python with 64-bit mac
[2016-07-23T10:32:45.631Z] <553d32d715522ed4b3df8b92> Oh okay. I have no other idea about the possibility for the error. Sorry.
[2016-07-24T02:03:37.600Z] <56b80528e610378809c05a48> Hello @maniteja123 , can you tell me the results on Ubuntu 14.04, 32 bit VM machine?
[2016-07-24T02:03:39.645Z] <56b80528e610378809c05a48> thanks!
[2016-07-24T08:09:11.218Z] <564789be16b6c7089cbab8b7> hi... has there been any work in incorporating minhash to help cluster large sets of documents?
[2016-07-24T08:15:33.762Z] <564789be16b6c7089cbab8b7> also.. in this very highly cited paper "Clustering Large Graphs via the Singular Value Decomposition" http://www.cc.gatech.edu/fac/vempala/papers/dfkvv.pdf the main algorithm is to take a random submatrix (suitably chosen) to make the SVD computation feasible. Has this been proposed at all for sklearn?
[2016-07-24T11:31:36.064Z] <572c72eec43b8c60197173f7> <unconvertable> , .,... .....   <unconvertable> .,,
[2016-07-24T11:32:17.256Z] <572c72eec43b8c60197173f7> <unconvertable>
[2016-07-25T14:32:12.328Z] <53135b495e986b0712efc453> @amueller I spotted you online ;) Could you take a look at https://github.com/scikit-learn/scikit-learn/pull/7071 please? ;)
[2016-07-25T14:32:42.156Z] <54d4a1d6db8155e6700f853b> @raghavrv is it still wip? ;)
[2016-07-25T14:32:55.217Z] <53135b495e986b0712efc453> I can change the title if it will help :P
[2016-07-25T14:33:20.474Z] <53135b495e986b0712efc453> But no... Just one major thing to do... Switch to threading.
[2016-07-26T13:45:14.310Z] <565c21ed16b6c7089cbcae65> Hi guys i'm new to the room i'm working on a subject and i'm looking for someone that have experience with this subject to advice me and hopefully point me to the right direction, my project is as following a document classification i have a big data base with texts for all kind off categories holidays politics sport etc i already managed for now if if i enter a text to my code that it detects which category it belongs using SVM classifier 
[2016-07-26T13:46:21.177Z] <565c21ed16b6c7089cbcae65> what i want to do next is to predict a category for a costumer but until now i don't know yet how to start this
[2016-07-26T13:46:44.134Z] <564789be16b6c7089cbab8b7> do you have any training data?
[2016-07-26T13:47:09.374Z] <564789be16b6c7089cbab8b7> you want a recommendation system it seems
[2016-07-26T13:47:20.292Z] <564789be16b6c7089cbab8b7> have you looked up that general term?
[2016-07-26T13:47:45.499Z] <565c21ed16b6c7089cbcae65> yes i do have a training data
[2016-07-26T13:47:58.216Z] <565c21ed16b6c7089cbcae65> yes i wnat to have a recommendation system
[2016-07-26T13:50:42.683Z] <565c21ed16b6c7089cbcae65> to explain more my situation  i'm doing in an internship and my company has a data base with tones of messages each text is tagged to a catogery
[2016-07-26T13:51:07.064Z] <564789be16b6c7089cbab8b7> ok sure.. so the first thing to do is to look up recommendation systems really
[2016-07-26T13:51:10.511Z] <564789be16b6c7089cbab8b7> are you stuck somewhere?
[2016-07-26T13:52:43.104Z] <565c21ed16b6c7089cbcae65> until now what i managed to do is classify this data and when i enter a text as an input my system manages to tell me to which catogery it belongs 
[2016-07-26T13:53:52.115Z] <565c21ed16b6c7089cbcae65> now my next step is prediction i have to predict what a user wants i looked up some terms like recommendation system but didn't find something really helpfull what i can start with
[2016-07-26T13:57:09.736Z] <564789be16b6c7089cbab8b7> try http://muricoca.github.io/crab/
[2016-07-26T15:26:15.970Z] <565c21ed16b6c7089cbcae65> what do you think about pyspark 
[2016-07-26T15:26:29.973Z] <564789be16b6c7089cbab8b7> it's perfectly fine :)
[2016-07-26T15:38:14.412Z] <565c21ed16b6c7089cbcae65> im on a linux debian trying to install it
[2016-07-26T15:38:25.141Z] <565c21ed16b6c7089cbcae65> there some preinstalls to do
[2016-07-26T15:38:38.481Z] <565c21ed16b6c7089cbcae65> java 8 scala etc...
[2016-07-26T16:35:07.916Z] <564789be16b6c7089cbab8b7> but it's completely offtopic here
[2016-07-26T16:36:47.956Z] <565c21ed16b6c7089cbcae65> i used scilearn for my code so i thought ill get some from info here but thank you ill stop bothering you guys 
[2016-07-26T19:55:29.568Z] <561a58f7d33f749381a8ff2f> guys, what do you think about this post :D http://stats.stackexchange.com/questions/225773/sparsity-as-missing-data-mle
[2016-07-26T21:10:59.404Z] <54d4a1d6db8155e6700f853b> does anyone know anything about the sample_without_replacement  function... it's kinda weird
[2016-07-28T08:42:59.257Z] <57908b05c2f0db084a23fc9a> Has anyone used Amazon Machine Learning... I am sorry if I have asked question in wrong chat room
[2016-07-28T14:33:46.719Z] <56b0a775e610378809bf7a7c> Is there any problems with travis, appveyor, ... ?
[2016-07-28T14:34:10.050Z] <56b0a775e610378809bf7a7c> The new PR are not tested
[2016-07-28T14:46:21.432Z] <54d4a1d6db8155e6700f853b> @87sanchavan_twitter yeah this is not a good place to ask. Go to stackoverflow
[2016-07-28T14:46:35.215Z] <54d4a1d6db8155e6700f853b> @tguillemot I noticed that yesterday. Can you point me towards a PR?
[2016-07-28T14:48:14.877Z] <56b0a775e610378809bf7a7c> @amueller #6651 #7101 
[2016-07-28T14:48:49.578Z] <56b0a775e610378809bf7a7c> That's strange because I saw that the travis works on it on the activity (on the right)
[2016-07-28T15:13:43.190Z] <54d4a1d6db8155e6700f853b> fuck that was me
[2016-07-28T15:14:19.445Z] <56b0a775e610378809bf7a7c> @amueller No pb ;)
[2016-07-28T15:14:30.012Z] <54d4a1d6db8155e6700f853b> Need to check with @ogrisel 
[2016-07-28T15:17:48.955Z] <54d4a1d6db8155e6700f853b> @tguillemot can you try pushing again to one of the PRs?
[2016-07-28T15:19:25.137Z] <56b0a775e610378809bf7a7c> @amueller Travis was launched on #6651
[2016-07-28T15:19:47.549Z] <56b0a775e610378809bf7a7c> but not circle or appveyor
[2016-07-28T15:20:36.723Z] <54d4a1d6db8155e6700f853b> now I only need to find out how access to appveyor and coveralls and circleci was granted
[2016-07-28T15:21:08.852Z] <56b0a775e610378809bf7a7c> ;)
[2016-07-28T15:21:16.263Z] <56b0a775e610378809bf7a7c> Just to know what was the problem ?
[2016-07-28T15:21:42.633Z] <54d4a1d6db8155e6700f853b> can you try again?
[2016-07-28T15:22:41.871Z] <56b0a775e610378809bf7a7c> ok for appveyor and travis
[2016-07-28T15:52:08.723Z] <54d4a1d6db8155e6700f853b> and again
[2016-07-28T17:46:55.716Z] <54d4a1d6db8155e6700f853b> hm looks like I took away my ability to restart travis or clear the cache
[2016-07-28T17:46:56.799Z] <54d4a1d6db8155e6700f853b> great
[2016-07-28T17:48:14.693Z] <54d4a1d6db8155e6700f853b> ah, fixed
[2016-07-28T19:50:56.451Z] <54d4a1d6db8155e6700f853b> @raghavrv you around?
[2016-07-28T19:51:10.291Z] <54d4a1d6db8155e6700f853b> @raghavrv Where is the warm start used in the gradient boosting CV?
[2016-07-29T16:24:49.812Z] <56c9d685e610378809c29d5d> I don't want to derail this chat so if there's a more appropriate place please redirect me.  I'm working on an ML library which draws a lot of inspiration from sklearn. I'd love to talk with some of the devs on sklearn who may be able to share some insights into things they'd like to be able to change/do differently. Or things that they think have worked really well that I might not appreciate.
[2016-07-29T18:01:19.001Z] <54d4a1d6db8155e6700f853b> @raghavrv you around now?
[2016-07-29T18:01:35.208Z] <54d4a1d6db8155e6700f853b> @AtheMathmo which language?
[2016-07-29T18:02:07.803Z] <54d4a1d6db8155e6700f853b> @AtheMathmo have you read the API paper? And there are talks by me and by Gael about the api design
[2016-07-29T23:12:31.947Z] <56c9d685e610378809c29d5d> @amueller It's written in rust. Happy to share here if you want. I also gave a talk on it yesterday that I would be happy to share.  I haven't read the API paper or seen the talks. Would you be able to provide me links to those? Thanks!
[2016-07-29T23:14:27.937Z] <56c4f19ae610378809c1f8ae> @AtheMathmo heres the paper: https://arxiv.org/abs/1309.0238
[2016-07-29T23:15:26.173Z] <56c9d685e610378809c29d5d> @nelson-liu thanks!
[2016-07-29T23:48:17.820Z] <56c9d685e610378809c29d5d> I really like how the transformer interface is described. It's a problem I haven't found a nice way to tackle yet in my own work.
[2016-07-30T00:08:38.875Z] <53135b495e986b0712efc453> @amueller Sorry I totally missed the chat... :( BTW the warm start is being set at [this line](https://github.com/scikit-learn/scikit-learn/pull/7071/files#diff-439a21b751083bf0e4a535e8f9075520R794)
[2016-07-30T13:53:33.762Z] <54d4a1d6db8155e6700f853b> yeah found it finally ;)
[2016-07-30T17:11:59.154Z] <578a4f87c2f0db084a23455f> Does "LGTM" mean +1, or it's kind of uncertain +1? Never seen this in other projects.
[2016-07-30T17:13:03.663Z] <56b80528e610378809c05a48> Generally LGTM from a core contributor means +1
[2016-07-30T17:13:17.438Z] <578a4f87c2f0db084a23455f> Thanks!
[2016-07-30T17:13:19.170Z] <56b80528e610378809c05a48> You can then modify your PR title
[2016-07-31T23:26:51.649Z] <56c4f19ae610378809c1f8ae> is there anyway to run gridsearchcv and save _all_ all of the models you train to disk?
[2016-07-31T23:27:14.625Z] <56c4f19ae610378809c1f8ae> or is it only possible to get the `best_estimator_` and then just save that
[2016-08-01T13:35:12.450Z] <53135b495e986b0712efc453> That would be extremely space costly for some models. For instance knn basically stores your training data. If you decide to store all the models that would explode the memory. This is why it is not implemented. Do you have any specific use case where you need this? Also the `results_`give you more statistics than before. Finally you could always loop through all the parameters and retrain the models if you need.
[2016-08-02T08:22:08.375Z] <57a0575540f3a6eec05d8bc7> can anyone pleaes tell me where should I start for data science
[2016-08-02T08:23:43.365Z] <56b80528e610378809c05a48> Quora is your friend :)  https://www.quora.com/How-can-I-become-a-data-scientist-1
[2016-08-02T08:25:08.592Z] <56b80528e610378809c05a48> Its better to ask these kind of questions on quora (and youll get more responses), this place is more specific for scikit-learn development
[2016-08-02T08:41:02.737Z] <57a0575540f3a6eec05d8bc7> @yenchenlin Thanks for this But I have concern with language whether I should go with python or R
[2016-08-02T08:41:53.021Z] <56b80528e610378809c05a48> I personally dont have much experience with R, so I cant answer this question, sorry.
[2016-08-02T08:46:25.520Z] <57a0575540f3a6eec05d8bc7> @yenchenlin Currently I am working with python  and I am new to machine learning and for that I was asking
[2016-08-02T10:02:11.170Z] <5644994d16b6c7089cba759b> correct choice. 
[2016-08-02T18:26:20.818Z] <54d4a1d6db8155e6700f853b> @leem2714 it depends a lot on what you want to do. Are you more interested in prediction or inference? What kind of methods would you like to use?
[2016-08-04T08:02:27.001Z] <56e7a3c885d51f252ab8d6ce> hello guysss i m new here and what t learn data science can anyone suggest good stuff for learning data science
[2016-08-04T09:56:55.405Z] <5729ef37c43b8c60197119b1>  @phalodi You will probably get more info on Quora or even just doing a search on Google.  This area is more suited to specific scikit-learn development.
[2016-08-04T11:55:10.273Z] <56b0a775e610378809bf7a7c> @amueller @ogrisel coveralls is still down, can you reset it ?
[2016-08-04T20:05:26.878Z] <57a39e9340f3a6eec05df999> hey guys, i'm new here. i just want to confirm if anyone has successfully installed cuda in ubuntu 16.04 for theano gpu usage?
[2016-08-05T11:20:27.705Z] <56d577ffe610378809c46670> Hey, I'm not able to locate the ``load_breast_cancer`` in http://scikit-learn.org/dev/modules/classes.html#module-sklearn.datasets. The only reference I can find in docs is here http://scikit-learn.org/dev/datasets/index.html#breast-cancer-wisconsin-diagnostic-database
[2016-08-05T11:21:57.711Z] <56d577ffe610378809c46670> There is no reference to it's method details. Why is so ?
[2016-08-05T15:40:22.248Z] <53135b495e986b0712efc453> @amueller Andy are you around and have a few minutes to talk about the gbcv?
[2016-08-09T20:21:08.298Z] <54d4a1d6db8155e6700f853b> @raghavrv sorry not today
[2016-08-09T20:21:16.547Z] <54d4a1d6db8155e6700f853b> have you talked with @pprett ?
[2016-08-10T11:52:45.812Z] <53135b495e986b0712efc453> Np. I'll try sending him an e-mail and let you know...
[2016-08-12T14:58:46.759Z] <57a061aa40f3a6eec05d8d26> Hello, is there an easy way to get leaf node count from decision tree? I can get total node count, but is there a way to get also leaf node count?
[2016-08-12T16:35:29.335Z] <56c4f19ae610378809c1f8ae> @mkoske first get `tree._tree.left_children`and right_children I think it's called. Then count the number of elements where the value is - 1, those are leaves
[2016-08-12T16:42:48.763Z] <56c4f19ae610378809c1f8ae> ``` In [1]: from sklearn.datasets import load_boston In [2]: from sklearn.tree import DecisionTreeRegressor In [3]: boston = load_boston() In [4]: tree = DecisionTreeRegressor() In [5]: tree.fit(boston.data, boston.target) In [6]: internal_tree = tree.tree_ In [7]: left_children = internal_tree.children_left In [8]: right_children = internal_tree.children_right In [9]: leaf_count = 0 In [10]: for i in left_children:     ...:     if i == -1:     ...:         leaf_count += 1     ...: In [11]: for i in right_children:     ...:     if i == -1:     ...:         leaf_count += 1     ...: In [12]: leaf_count Out[12]: 940 ``` 
[2016-08-12T17:04:59.279Z] <56c4f19ae610378809c1f8ae> oops, sorry you only have to go through it once.....
[2016-08-12T17:05:21.569Z] <56c4f19ae610378809c1f8ae> going through it twice is double counting
[2016-08-12T17:13:27.759Z] <56c4f19ae610378809c1f8ae> since left_children and right_children are -1 if they dont have a left or right child, (thus leaf) and a node cant have only a left or a right child.
[2016-08-12T19:24:22.773Z] <57a061aa40f3a6eec05d8d26> Ok, thanks. I'll do that
[2016-08-14T14:41:28.948Z] <55f3a7830fc9f982beb071a9> Does anyone know a good reference for how the verbose arguement acts?
[2016-08-14T18:56:24.927Z] <57a061aa40f3a6eec05d8d26> how does decision tree find the cut point?
[2016-08-14T18:57:17.057Z] <56c4f19ae610378809c1f8ae> haha youre getting yourself into a pretty deep rabbit hole here ;) do you mean decision trees in general or specifically scikit-learns implementation
[2016-08-14T18:57:44.275Z] <57a061aa40f3a6eec05d8d26> scikit-learn's implementation
[2016-08-14T18:58:04.036Z] <56c4f19ae610378809c1f8ae> ill pm you, its a bit convoluted and i dont want to spam the channel. is that ok?
[2016-08-14T18:58:14.420Z] <57a061aa40f3a6eec05d8d26> yes, it's ok
[2016-08-15T11:27:39.078Z] <565b64bd16b6c7089cbc9de9> Hi, is  `skl.svm.LinearSVC` handling unknown/NaN values? I couldn't find that information in the class documentation page
[2016-08-16T14:05:58.783Z] <53135b495e986b0712efc453> @nirizr You need to impute those missing values (using `sklearn.preprocessing.Imputer`) first before passing on to the `LinearSVC`.
[2016-08-16T14:07:46.892Z] <56b80528e610378809c05a48> @raghavrv I got you! Can you give #7187 another quick review?
[2016-08-16T14:08:37.275Z] <565b64bd16b6c7089cbc9de9> @raghavrv Thanks a lot! Are there easy ways to get more advanced strategies? regression, nearest neighbors? 
[2016-08-16T14:34:19.505Z] <53135b495e986b0712efc453> @yenchenlin Thanks for the ping. Done... Some minor comments and +1 :)
[2016-08-16T15:52:51.757Z] <53135b495e986b0712efc453> @ogrisel you around? ;)
[2016-08-16T16:02:29.730Z] <56212f4e16b6c7089cb74321> hey everyone, i have a _curiosity_ for you!
[2016-08-16T16:02:31.408Z] <56212f4e16b6c7089cb74321> ``` def pipeline_to_weights_and_bias(clf):    <unconvertable> """ Turns a SKLearn StandardScaler() --> LogisticRegression()  <unconvertable> <unconvertable> pipeline into single weights and bias. """  <unconvertable> <unconvertable> assert set(clf.named_steps.keys()) == {'logisticregression', 'standardscaler'}  <unconvertable> <unconvertable> lr = clf.named_steps['logisticregression']  <unconvertable> <unconvertable> sc = clf.named_steps['standardscaler']  <unconvertable> <unconvertable> W = (lr.coef_ / sc.scale_)  <unconvertable> <unconvertable> B = lr.intercept_ - (lr.coef_ / sc.scale_).dot(sc.mean_.T)  <unconvertable> <unconvertable> return (W, B) ```
[2016-08-16T16:02:54.461Z] <56212f4e16b6c7089cb74321> for those doing logistic regression, this turns a StandardScaler + LR pipeline into a single weight+bias matrix
[2016-08-16T16:03:11.063Z] <56212f4e16b6c7089cb74321> you use it like this: ``` X = np.random.randn(10000, 512) W,B = pipeline_to_weights_and_bias(clf) assert np.allclose( clf.decision_function(X), W.dot(X.T) + B )  %timeit clf.decision_function(X) #=> 10 loops, best of 3: 122 ms per loop  %timeit W.dot(X.T) + B #=> The slowest run took 7.54 times longer than the fastest. This could mean that an intermediate result is being cached. #=> 1000 loops, best of 3: 265 us per loop ```
[2016-08-16T16:03:18.803Z] <56212f4e16b6c7089cb74321> the speedup is significant
[2016-08-16T16:03:37.035Z] <56212f4e16b6c7089cb74321> the real funny part is that the resulting calculation runs only on a single core, even though it's hundreds of times faster than sklearn vanilla pipeline
[2016-08-16T16:04:01.613Z] <56212f4e16b6c7089cb74321> now, i have 1800 of these classifiers to run. it's much faster to do a (1800,512) * (512, N) matrix operation than to call 1800 pipelines in sequence
[2016-08-16T16:04:47.063Z] <56c4f19ae610378809c1f8ae> hmm, thats pretty interesting
[2016-08-16T16:05:00.421Z] <56212f4e16b6c7089cb74321> this makes me wonder if sklearn couldn't benefit from some pipeline optimization tricks? i know i'd love like a `FastAssortmentOfScaledLogisticRegressionClassifiers` class
[2016-08-16T16:05:43.514Z] <56212f4e16b6c7089cb74321> but of course there could be other possible ways to hand-tune other combinations of linear transformations (e.g. PCA and random projections are the same thing)
[2016-08-16T16:07:40.644Z] <56c4f19ae610378809c1f8ae> for that question, I suggest you raise an issue; not everyone is on / checks gitter :) 
[2016-08-16T22:20:23.120Z] <564a00d016b6c7089cbae908> I want to build a recommendation system for movies. What are all things I should learn. I am presently doing undergraduate course with basics in python, web dev and java.
[2016-08-16T22:33:38.951Z] <564a00d016b6c7089cbae908> I had completed ML course by Andrew ng and ML through case study by Carlos on coursera
[2016-08-16T22:33:50.342Z] <564a00d016b6c7089cbae908> 
[2016-08-17T06:51:47.564Z] <56f4e1b785d51f252abab7d7> just out of curiousity, am I supposed to pour the whole dataset to `gridsearchcv.fit`?
[2016-08-17T06:54:54.375Z] <56f4e1b785d51f252abab7d7> my dataset has roughly 15M (* 500 features) in total, and I am testing with just 2M of them, I wanted to throw them all into `.fit` but kept getting out-of-memory warning (obviously)
[2016-08-17T20:04:54.111Z] <57b3fd8640f3a6eec05fe0e8> Can you pass .5mil at a time 4 times? 
[2016-08-17T20:05:20.198Z] <57b3fd8640f3a6eec05fe0e8> I mean if you are being limited by the memory.. probably make data set smaller? :)
[2016-08-17T20:07:28.212Z] <57b3fd8640f3a6eec05fe0e8> @shivakrishna9 depends on how you are trying to relate those 2.
[2016-08-17T20:24:45.008Z] <56c4f19ae610378809c1f8ae> @Jeffrey04 a common thing people do to get around this is to just get more ram ;) might be worth looking into using an AWS machine or something for a little bit. Passing .5mil 4 times isnt really theoretically sound, because then its difficult to discern which model is actually the best because the results might be affected by the fact that the model only sees part of the dataset.
[2016-08-17T20:49:19.907Z] <57b3fd8640f3a6eec05fe0e8> @nelson-liu ahh i see, but is a model with .5mil better then a model with .5mil * 4 model? There might be a chance for certain training set, the second is better? 
[2016-08-17T20:50:58.342Z] <57b3fd8640f3a6eec05fe0e8> I mean, i think i see what you mean (error from each .5mil being fed adds up (maybe compounds)).
[2016-08-17T20:51:38.156Z] <565b64bd16b6c7089cbc9de9> @Jeffrey04 It might be worth seeing how diverse is your data, perhaps you can neatly drop a certain percentage of it without impacting the model too much.
[2016-08-17T20:52:10.277Z] <56c4f19ae610378809c1f8ae> sure, but the point of using GridSearchCV is to pick the best model for an unseen test set, is it not? <unconvertable> more data is better <unconvertable> is a common adage that is generally true. but lets say you have 1.5 million mislabeled samples (for some reason); if you were to  luckily select just the .5 million samples that were clean and train on them, youd do well. By selecting a subset of the data, youre inherently biasing the model a bit.
[2016-08-17T20:53:51.671Z] <56c4f19ae610378809c1f8ae> training on 4 partitions of a set and picking the one that does best on the most out of 4 != training on the whole set and picking the best one
[2016-08-17T20:54:41.782Z] <57b3fd8640f3a6eec05fe0e8> But that assumes there is an easy way to sort through the 2M to narrow it down to .5m. in which case, what the 2 of you recommended sounds good.
[2016-08-17T20:56:35.767Z] <57b3fd8640f3a6eec05fe0e8> I didn't mean have 4 separate trained instance.. hmm, but it any case, it's not possibly to feed .5 at a time , does it's stuff, frees some memory and you add to it? is what i was trying to ask.
[2016-08-17T20:58:59.259Z] <56c4f19ae610378809c1f8ae> ah sorry i misunderstood then. yeah, thats called <unconvertable> warm start. some models in scikit-learn implement it, but Im not sure if its gridsearchcv compatible...
[2016-08-17T21:00:09.509Z] <57b3fd8640f3a6eec05fe0e8> Ahh, i am very new to all of this so questions make more sense in my head than when i type. ^^
[2016-08-17T21:00:50.479Z] <56c4f19ae610378809c1f8ae> yeah, doesnt seem like gridsearchcv can use warm start
[2016-08-17T21:03:27.228Z] <57b3fd8640f3a6eec05fe0e8> Is there any other keyword i can search for? "warm start scikit" isn't giving me anything that explains concepts. :s
[2016-08-17T21:04:08.049Z] <565b64bd16b6c7089cbc9de9> Can gridsearchcv implement partial_fit for estimators that support it?
[2016-08-17T21:05:19.744Z] <56c4f19ae610378809c1f8ae> well warm start is only implemented for models where it makes theoretical sense to do it. like in SGD Estimators, warm start lets you start at a previous solution instead of randomly initializing.
[2016-08-17T21:05:47.450Z] <57b3fd8640f3a6eec05fe0e8> Ahh..
[2016-08-17T21:06:22.683Z] <56c4f19ae610378809c1f8ae> hmm I dont think so @nirizr but im not 100% sure
[2016-08-17T21:14:16.678Z] <565b64bd16b6c7089cbc9de9> It's definitely not possible now. I'm not familiar with sklearn's code at all, but looks like a call to `fit` may be replaced with a call to `partial_fit`, when it is supported.
[2016-08-17T21:15:50.368Z] <57b3fd8640f3a6eec05fe0e8> Thats good to know! partial_fit is something like a warm start then?
[2016-08-17T21:16:43.569Z] <57b3fd8640f3a6eec05fe0e8> This is a bit offtopic but : http://webhostingegg.com/vps/top-alternative-amazon-aws-ec2/
[2016-08-17T21:17:02.046Z] <57b3fd8640f3a6eec05fe0e8> Wondering if there were non aws recommendation.
[2016-08-17T21:19:46.145Z] <565b64bd16b6c7089cbc9de9> `partial_fit` feeds the estimator with partial data iteratively, having it only process portions of all available data at a time. There are some considerations there (how to split the partitions, sizes, the order in which data is fed) and sklearn doesn't support that for gridsearchcv as far as I can tell.
[2016-08-17T21:21:39.245Z] <57b3fd8640f3a6eec05fe0e8> Ahh! thank you kindly for the detailed explanations! 
[2016-08-17T21:36:16.487Z] <57a061aa40f3a6eec05d8d26> @nelson-liu Hello! You gave me earlier (few days ago) short code snippet to count leaf nodes. But It seems not to work and I don't know why. The value for `leaf_count` variable seems to be even one more than `tree.node_count`.  
[2016-08-17T21:36:36.962Z] <56c4f19ae610378809c1f8ae> i mentioned after the snippet to remove one of the loops
[2016-08-17T21:36:59.149Z] <56c4f19ae610378809c1f8ae> so if you take out one of the for loops, that should do the trick
[2016-08-17T21:37:40.724Z] <56c4f19ae610378809c1f8ae> ``` In [1]: from sklearn.datasets import load_boston In [2]: from sklearn.tree import DecisionTreeRegressor In [3]: boston = load_boston() In [4]: tree = DecisionTreeRegressor() In [5]: tree.fit(boston.data, boston.target) In [6]: internal_tree = tree.tree_ In [7]: left_children = internal_tree.children_left In [8]: right_children = internal_tree.children_right In [9]: leaf_count = 0 In [10]: for i in left_children:     ...:     if i == -1:     ...:         leaf_count += 1     ...: ```
[2016-08-17T21:37:54.421Z] <56c4f19ae610378809c1f8ae> because left_children is an array that maps each node to another node that is its left child
[2016-08-17T21:38:02.724Z] <56c4f19ae610378809c1f8ae> but if it has no left child, its marked as -1
[2016-08-17T21:38:22.546Z] <56c4f19ae610378809c1f8ae> a node cannot have a left child and no right child or no right child and a left chlid, so iterating through one of the children arrays is enough
[2016-08-17T21:38:44.416Z] <57a061aa40f3a6eec05d8d26> Ok, thanks :)
[2016-08-17T21:39:30.109Z] <57a061aa40f3a6eec05d8d26> So, my tree has ~2300 leaf nodes :) That's large tree
[2016-08-17T22:50:07.392Z] <57b3fd8640f3a6eec05fe0e8> http://scikit-learn.org/stable/auto_examples/decomposition/plot_image_denoising.html  Didn't realize you can do crazy stuff like this.. :o 
[2016-08-18T04:55:10.244Z] <56f4e1b785d51f252abab7d7> @ItchyJunk OOOoo? gridsearchcv allows multiple calls to `.fit`?
[2016-08-18T05:03:38.668Z] <56f4e1b785d51f252abab7d7> OOOOOOOOH, yea, I am using sgdclassifier, lemme try (: > It's definitely not possible now. I'm not familiar with sklearn's code at all, but looks like a call to `fit` may be replaced with a call to `partial_fit`, when it is supported.
[2016-08-18T05:21:00.478Z] <56f4e1b785d51f252abab7d7> well after a quick test i am able to do multiple `.fit` calls, but not sure whether the classifier uses all the training set tho
[2016-08-18T05:55:12.859Z] <56f4e1b785d51f252abab7d7> I really need to get some sleep, i misread and thought this is already implemented #facepalm > It's definitely not possible now. I'm not familiar with sklearn's code at all, but looks like a call to `fit` may be replaced with a call to `partial_fit`, when it is supported.
[2016-08-18T08:30:50.016Z] <57b3fd8640f3a6eec05fe0e8> @Jeffrey04 multiple .fit is not the same as calling 1 .fir for the 2M data apparent.y
[2016-08-18T08:31:04.076Z] <56f4e1b785d51f252abab7d7> yea, I realized that
[2016-08-18T08:31:12.589Z] <57b3fd8640f3a6eec05fe0e8> ^.^
[2016-08-18T08:31:18.601Z] <56f4e1b785d51f252abab7d7> i misread for some reason
[2016-08-18T08:31:27.427Z] <56f4e1b785d51f252abab7d7> *facepalm*
[2016-08-18T08:31:39.298Z] <56f4e1b785d51f252abab7d7> argh... markdown
[2016-08-18T08:31:59.321Z] <57b3fd8640f3a6eec05fe0e8> Oh, the general agreement here was you should have a way to narrow you 2 mil down to .5 mil better training data
[2016-08-18T08:33:31.174Z] <57b3fd8640f3a6eec05fe0e8> But i was curious about the memory management itself .. so partial_fit and warm start was mentioned for some cases..
[2016-08-18T08:33:55.162Z] <57b3fd8640f3a6eec05fe0e8> So is there a way for you to narrow it down or was that not the case? :P
[2016-08-18T09:12:01.149Z] <56f4e1b785d51f252abab7d7> @ItchyJunk that's what I did previously, i was wondering if that's the proper way to do it
[2016-08-18T09:13:31.859Z] <56f4e1b785d51f252abab7d7> if i fetch fair enough random sample for gridsearchcv, I probably should get parameters that should be quite close to the "ideal" ones
[2016-08-18T09:13:58.092Z] <56f4e1b785d51f252abab7d7> then i can proceed and retrain the proper model with the not-so-ideal parameters
[2016-08-18T09:14:07.554Z] <56f4e1b785d51f252abab7d7> ^ my previous workaround
[2016-08-18T09:15:19.346Z] <56f4e1b785d51f252abab7d7> also I am trying to break into multiple smaller classifiers, so each classifier should be built with much smaller dataset
[2016-08-18T09:15:59.366Z] <56f4e1b785d51f252abab7d7> so whenever i try to classify some data, i would run through all of them, and pick the best result with highest probability or something
[2016-08-18T09:18:47.134Z] <57b3fd8640f3a6eec05fe0e8> Yeah I suppose if the difference is small enough, approximation should be fine.
[2016-08-18T15:49:59.323Z] <5730c2dcc43b8c601971eca1> Quick question:  After having downloaded scikit-learn on my machine, How can I compile the modified code package to iPython (ie import sklearn2 as sk ?) . Where should I put the repository scikit-learn so Python can recognize it ?
[2016-08-18T16:24:37.224Z] <565b64bd16b6c7089cbc9de9> @Jeffrey04 I do think it is quite easy to add, as far as I can understand sklearn's code.
[2016-08-19T02:37:01.769Z] <57b3fd8640f3a6eec05fe0e8> @arita37 Not sure what you are asking? are you asking how to import the scikit in your python code? In which case, you just import it like any module. I might be misunderstanding though.
[2016-08-19T14:52:15.455Z] <57b71cc040f3a6eec0605326> Hey. Is it me or the current python version does not have neural networks ? I followed that : http://scikit-learn.org/dev/modules/neural_networks_supervised.html and got an import error with "from sklearn.neural_network import MLPClassifier" 
[2016-08-19T14:52:37.780Z] <56c4f19ae610378809c1f8ae> neural nets are in 0.18, not 0.17.1 (which is the stable version)
[2016-08-19T14:52:52.785Z] <56c4f19ae610378809c1f8ae> theres a release coming soon, but you can get it in the meanwhle by downloading and installing the master branch
[2016-08-19T14:53:01.794Z] <57b71cc040f3a6eec0605326> Ok thanks a lo
[2016-08-19T14:53:02.723Z] <57b71cc040f3a6eec0605326> t
[2016-08-21T00:12:03.663Z] <56f2390385d51f252aba4de9> Does anyone know how the images are generated in the "example gallery" documentation?Im trying to contribute an example but the plot legend and title are cut off on the html page in my local build.
[2016-08-21T09:53:08.808Z] <564789be16b6c7089cbab8b7> @mlliou112  I don't think dropout has been implemented yet which afaik is crucial for getting good out of sample prediction performance
[2016-08-21T09:53:28.156Z] <564789be16b6c7089cbab8b7> I once saw a PR for it I think but I am not sure what happened
[2016-08-21T09:56:47.584Z] <564789be16b6c7089cbab8b7> https://github.com/scikit-learn/scikit-learn/issues/6175 and https://github.com/glennq/scikit-learn/tree/mlp_dropout_new . Maybe these are stalled?
[2016-08-21T11:05:06.188Z] <564789be16b6c7089cbab8b7> on a similar note... has https://github.com/scikit-learn/scikit-learn/pull/4899 stalled? I am hugely looking forward it. 
[2016-08-21T15:24:44.052Z] <57b3fd8640f3a6eec05fe0e8> http://www.telegraph.co.uk/technology/2016/01/28/first-driverless-buses-travel-public-roads-in-the-netherlands/
[2016-08-21T15:32:42.488Z] <564789be16b6c7089cbab8b7> @ItchyJunk  yes but what's the point :) Bus drivers take a lot of passengers so I can't believe it saves much money
[2016-08-21T19:43:59.258Z] <57b3fd8640f3a6eec05fe0e8> @_@ what the point of automating vehicles? 
[2016-08-23T08:16:20.734Z] <56f4e1b785d51f252abab7d7> if i am getting mostly score=0.2 in my gridsearchcv for sgdclassifier, what can I do to increase the score
[2016-08-23T08:16:24.001Z] <56f4e1b785d51f252abab7d7> ```    classifier = GridSearchCV(SGDClassifier(),                               {                                   'loss': ['hinge', 'modified_huber', 'log'],                                   'penalty': ['elasticnet', 'l2', 'l1'],                                   'alpha': [0.000004,                                             0.0000045,                                             0.000005,                                             0.0000055,                                             0.000006],                                   'warm_start': [True],                                   'l1_ratio': [0.12, 0.13, 0.14, 0.15]                               },                               iid=False,                               n_jobs=8,                               verbose=10,                               scoring='f1_weighted',                               refit=False) ```
[2016-08-23T10:19:58.999Z] <57b3fd8640f3a6eec05fe0e8> http://scikit-learn.org/stable/modules/grid_search.html#gridsearch-scoring
[2016-08-24T02:15:28.517Z] <57b3fd8640f3a6eec05fe0e8> https://plus.google.com/+VincentVanhoucke/posts/8T7DSJhGY3u
[2016-08-24T15:19:27.576Z] <572748b5c43b8c601970c18f> did in room speak about opencv???
[2016-08-24T15:22:29.099Z] <572748b5c43b8c601970c18f> i want to make real-time  object tracking with open-cv in python and i want to sent cordinate of object to tracking module??? who can help me. Thank a lot .;-)
[2016-08-25T22:42:06.064Z] <574c0070c43b8c601975aee3> 
[2016-08-30T05:19:32.248Z] <55889fee15522ed4b3e27273> Hi, i would like to ask a question. i'm building a chat bot, how does scikit-learn learns the requests and predict a close enough accurate response? how does scikit-learn come into play in chat bots?
[2016-08-30T10:21:20.665Z] <57b3fd8640f3a6eec05fe0e8> @kennetham you know what neural network is or reinforcement learning is or what markov chain is?
[2016-08-30T10:23:37.938Z] <57b3fd8640f3a6eec05fe0e8> https://en.wikipedia.org/wiki/Scikit-learn
[2016-08-30T15:53:10.120Z] <55889fee15522ed4b3e27273> @ItchyJunk yes i do. but not an expert. care to share a little?
[2016-08-30T15:53:32.866Z] <55889fee15522ed4b3e27273> using scikit-learn, how do i build a answer and response using training and prediction?
[2016-08-30T22:54:10.188Z] <57b3fd8640f3a6eec05fe0e8> If you just want sample code there is plenty, if you wondering the mechanics behind it, there are different approaches. I'd look into different algos and see what they do.
[2016-08-30T22:54:11.073Z] <57b3fd8640f3a6eec05fe0e8> https://en.wikipedia.org/wiki/Markov_chain
[2016-08-30T22:55:40.920Z] <57b3fd8640f3a6eec05fe0e8> Example is, statistical analysis of words to see how likely is one word associated with the other. then use that to generate sentences
[2016-08-30T22:59:44.771Z] <57b3fd8640f3a6eec05fe0e8> https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html
[2016-08-31T08:04:35.572Z] <55889fee15522ed4b3e27273> got it. thanks! i understand markov chain mechanics, but was wondering if there are other better alternatives
[2016-08-31T08:04:52.403Z] <55889fee15522ed4b3e27273> plus you mentioned tensorflow using syntaxnet, i think that is awesome
[2016-08-31T08:08:54.149Z] <57b3fd8640f3a6eec05fe0e8> @kennetham ahh there are different algos each with their ups and downs i think.
[2016-08-31T09:16:15.538Z] <55889fee15522ed4b3e27273> @ItchyJunk is it possible to use for example NLTK to do NLP parsing, then I use tf-idf and Bag of words to classify the tokens, and possibly attempt to make a prediction? does that even work?
[2016-08-31T14:31:05.233Z] <54e09a6d15522ed4b3dc08d0> Hello everyone! Is anyone enrolling in Hinton's ML Coursera course https://www.coursera.org/learn/neural-networks ?
[2016-09-01T06:26:11.357Z] <579e492240f3a6eec05d5245> Hi, how do you guys do dl experiments (in terms of infrastructure). Will Amazon ec2 instances suffice for research purposes? Thanks for your help. 
[2016-09-01T10:26:13.499Z] <57b3fd8640f3a6eec05fe0e8> @kennetham I know very little about language processing, but in theory, it sounds like it would work? pretty sure  you'll find out why it doesn't when you code it out :P 
[2016-09-01T22:59:43.228Z] <562a7da216b6c7089cb80965> @vyraun it realls depends on the scale of the analysis that you're doing. I'm a neuroscientist who works mostly with fMRI data, which can be pretty big, so our labs tend to have dedicated computers with many cores and a good deal of RAM, but I could certainly replicate that environment on ec2 if I wanted to pay as I went
[2016-09-02T03:03:28.298Z] <579e492240f3a6eec05d5245> @dankessler thanks.
[2016-09-03T21:03:06.740Z] <53fdba59163965c9bc200ba2> Hi guys. I'd like to learn how to use machine learn as a black box. Do you recommend a book or course? Thanks
[2016-09-03T22:44:45.831Z] <57b3fd8640f3a6eec05fe0e8> Not sure what you mean by "black box" here.
[2016-09-03T22:45:09.301Z] <57b3fd8640f3a6eec05fe0e8> https://gist.github.com/off99555/b6190df237562aa6e8c922c485dc7ad0
[2016-09-03T22:45:21.058Z] <57b3fd8640f3a6eec05fe0e8> Here is some machine learning resources in general, if that helps.
[2016-09-03T22:45:42.055Z] <57b3fd8640f3a6eec05fe0e8> Sorry for that link expanding
[2016-09-03T22:45:47.941Z] <57b3fd8640f3a6eec05fe0e8> now sure how to make it not do that
[2016-09-04T03:53:02.728Z] <56a34c16e610378809bdc988> Hello @amueller @nelson-liu @GaelVaroquaux I had a look at #7319. 
[2016-09-04T03:53:37.004Z] <56a34c16e610378809bdc988> Well I agree, nose has some deprecated code now
[2016-09-04T03:53:48.891Z] <56a34c16e610378809bdc988> Shifting to pytest can be a really good choice.
[2016-09-04T03:54:43.033Z] <56a34c16e610378809bdc988> I recently completed GSoC 16 with _TARDIS_, I am staying there as a regular contributor, although I always wanted to get involved in an ML centric community.
[2016-09-04T03:55:37.573Z] <56a34c16e610378809bdc988> Throughout my project I have worked a lot with pytest, and read a lot of its docs - I can take up this issue to solve on a regular basis.
[2016-09-04T03:56:28.549Z] <56a34c16e610378809bdc988> While I have used a little of scikit, I am planning to get comfortable with the codebase for sometime, and then move ahead with a series of PRs. Would you accept my PRs a few weeks down the line ?
[2016-09-04T03:56:49.168Z] <56a34c16e610378809bdc988> ( Because I see you are choosing it for next GSoC )
[2016-09-04T03:59:07.265Z] <56c4f19ae610378809c1f8ae> hi @karandesai-96, thanks for inquiring! Id suggest you copy and paste your message onto the issue, since not everyone checks gitter.
[2016-09-04T03:59:32.627Z] <56b80528e610378809c05a48> +1 on what @nelson-liu said
[2016-09-04T03:59:36.972Z] <56a34c16e610378809bdc988> @nelson-liu very well :D
[2016-09-04T04:00:31.649Z] <56c4f19ae610378809c1f8ae> that would help it get more visibility + there might be nuances in the switch to consider that would require input from other developers, so best to see if you can get a solid green light there first
[2016-09-04T04:03:11.058Z] <56a34c16e610378809bdc988> Great, done. I'll be happy to take it up if :traffic_light: :checkered_flag: 
[2016-09-04T04:06:35.951Z] <56c4f19ae610378809c1f8ae> great, id also be happy to pitch in :) i dont know too much about py.tests and this seems like a good opportunity to learn
[2016-09-04T04:57:58.066Z] <53fdba59163965c9bc200ba2> Thanks @ItchyJunk
[2016-09-05T07:16:05.922Z] <56f4e1b785d51f252abab7d7> just out of curiousity, for `RadiusNeighborsClassifier` I am trying multiple `.fit()` calls,  and the code didnt throw any exceptions, can I assume it is possible to fit my whole collection into it with multiple `.fit()` calls?
[2016-09-05T07:17:25.812Z] <57b3fd8640f3a6eec05fe0e8> Probably no?
[2016-09-05T07:51:51.845Z] <56f4e1b785d51f252abab7d7> oh?
[2016-09-05T08:06:07.645Z] <56f4e1b785d51f252abab7d7> so subsequent `.fit()` calls overwrite the previous call?
[2016-09-05T08:52:37.067Z] <56f4e1b785d51f252abab7d7> ok, apparently that's the case S:
[2016-09-05T10:00:13.741Z] <565b64bd16b6c7089cbc9de9> @Jeffrey04 Yes. You're correct. each `fit` call will overwrite previous calls. Some estimators have `partial_fit` for what you're looking for, which isn't easily achievable for each classifier.
[2016-09-05T12:34:23.539Z] <57b3fd8640f3a6eec05fe0e8> Nice, I guessed correctly = )
[2016-09-06T04:08:46.487Z] <57be017740f3a6eec0612914> @vyraun i suggest you use AWS EMR directly, which supports hadoop and spark 1.x.
[2016-09-06T04:09:52.015Z] <57be017740f3a6eec0612914> you can quickly try it w/o spending hours on setting up the cluster.
[2016-09-06T04:10:29.120Z] <57be017740f3a6eec0612914> who is taking the Udacity "Intro to ML" class here?
[2016-09-06T04:14:10.800Z] <57008ddd187bb6f0eadd989b> I'm takin Stanford (coursera) and MIT (OCW) ML classes
[2016-09-06T04:16:56.427Z] <57be017740f3a6eec0612914> @tjgerot you are awesome. I took a few Stanford lessons and feel difficult.
[2016-09-06T04:19:24.682Z] <57008ddd187bb6f0eadd989b> Haha I usually have to watch them 2-3 times over. They start off head first in the math and I haven't taken calc yet so it's been pretty slow learning. But MIT posts a lot of their courses on YouTube, so I'm going through the Artificial Intelligence course, much easier. How's the Udemy one?
[2016-09-06T04:20:52.865Z] <57be017740f3a6eec0612914> Udacity's "intro ML" is good. the tools (sklearn, ntlk) they use is more recent, not R, octave, numpy. see results quick :)
[2016-09-06T04:28:38.331Z] <579e492240f3a6eec05d5245> 
[2016-09-06T04:31:18.392Z] <579e492240f3a6eec05d5245> @txie thanks for the suggestion. Will try <unconvertable>
[2016-09-06T04:42:24.501Z] <579e492240f3a6eec05d5245> 
[2016-09-06T19:41:27.533Z] <564a0e2916b6c7089cbaead6> Are there plans for a codesprint at #ODSC this year?
[2016-09-06T19:43:23.058Z] <564a0e2916b6c7089cbaead6> @txie I am just about completed with the Udacity ML Nanodegree. 
[2016-09-07T03:48:28.641Z] <578a4f87c2f0db084a23455f> Guys from scikit-learn team, could someone check and add +1 to this https://github.com/scikit-learn/scikit-learn/pull/6116 ?
[2016-09-07T04:20:51.689Z] <57c97e4040f3a6eec062f82d> hello, i am begin learn deep learning
[2016-09-07T04:21:36.054Z] <57c97e4040f3a6eec062f82d> i am reading http://www.deeplearningbook.org/
[2016-09-07T12:37:34.055Z] <57430fe4c43b8c60197476d9> Does scikit-learn already have or intend to have metric-learning algorithms included?
[2016-09-07T17:34:56.838Z] <53fdba59163965c9bc200ba2> Hi  guys. Id to `train_test_split` but on `stratify` I need of a multi-label data. Any idea how can I do, it?
[2016-09-07T17:39:35.539Z] <53fdba59163965c9bc200ba2> On my Pandas a had 4 columns. `[X, y, area, stratify]`. On `stratify` I populated with a string concatenation of `area` and `y` values. But this hack does not working.
[2016-09-07T17:40:55.298Z] <53fdba59163965c9bc200ba2> `train_test_split(df[X], df[y], test_size=0.3, stratify=df[stratify])`I got the error: `ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of labels for any class cannot be less than 2.` 
[2016-09-07T20:47:36.527Z] <564789be16b6c7089cbab8b7> Why is there exit() in the middle of the code at http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html ?
[2016-09-07T20:52:01.396Z] <564789be16b6c7089cbab8b7> the code has nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf) exit() print("done in %0.3fs." % (time() - t0))
[2016-09-07T20:54:10.149Z] <57b3fd8640f3a6eec05fe0e8> idk maybe NMF does something that requires you to exit() to go back into your code?
[2016-09-07T20:54:24.312Z] <564789be16b6c7089cbab8b7> @ItchyJunk  that would be surprising
[2016-09-07T20:54:57.483Z] <564789be16b6c7089cbab8b7> exit is a synonym for quit I believe
[2016-09-07T20:55:32.514Z] <564789be16b6c7089cbab8b7> surely it's a typo?
[2016-09-07T20:55:43.204Z] <57b3fd8640f3a6eec05fe0e8> ok, it quits out of what ever NMF does to get back to your code
[2016-09-07T20:56:24.312Z] <564789be16b6c7089cbab8b7> you don't think it's a bug?
[2016-09-07T20:59:17.122Z] <57b3fd8640f3a6eec05fe0e8> it might be..
[2016-09-08T08:17:22.152Z] <5571fe1015522ed4b3e17d90> @lesshaste the exit() is not in the dev doc so it has been fixed in master. See http://scikit-learn.org/dev/auto_examples/applications/topics_extraction_with_nmf_lda.html.
[2016-09-08T15:02:15.525Z] <57430fe4c43b8c60197476d9> @amueller , is there any interest in merging the Metric Learning algorithm implemented [#4789](https://github.com/scikit-learn/scikit-learn/pull/4789) ? And whether any Metric Learning algorithms are in the pipeline?
[2016-09-08T15:02:44.209Z] <54d4a1d6db8155e6700f853b> @bhargavvader Yes there is interest. but currently we are mostly working on a release
[2016-09-08T15:03:00.416Z] <54d4a1d6db8155e6700f853b> only the things in PRs are in the pipeline AFAIK
[2016-09-08T15:03:58.700Z] <54d4a1d6db8155e6700f853b> @raghavrv can you maybe work at making the new grid-search docs render correctly?
[2016-09-08T15:20:37.977Z] <57430fe4c43b8c60197476d9> @amueller , cool, I'll start by giving it a shot. It can be reviewed after the release is done and you guys get some time :)
[2016-09-09T06:11:36.260Z] <56c625c3e610378809c22760> Hey is anyone coming for PyCon Rennes from here? 
[2016-09-09T14:33:43.438Z] <54d4a1d6db8155e6700f853b> only india ;)
[2016-09-09T17:38:19.997Z] <55a36f535e0d51bd787b3400> Hi guys, I recently re-installed the dev version of sklearn, and I get an mkl error   ```  from .murmurhash import murmurhash3_32 .Intel MKL FATAL ERROR: Cannot load libmkl_avx.so or libmkl_def.so. ``` If I don't first call a sklearn function (e.g. call `linear_model.Ridge()` first prevents the error, but calling `linear_model.LogisticRegression()` doesn't)  
[2016-09-09T17:39:04.946Z] <55a36f535e0d51bd787b3400> Do you have an idea where I should look to track this error down?
[2016-09-09T19:03:03.299Z] <54d4a1d6db8155e6700f853b> update conda?
[2016-09-09T19:21:46.748Z] <56c625c3e610378809c22760> @amueller yep looking forward to your talk there!
[2016-09-12T08:35:32.192Z] <56f0af1085d51f252aba1606> Hi guys,  I meet a MemoryError problem when using minibatch k-means for clustering a data set with 1,700,000 rows and 5 cols. My desktop has 8G RAM and the scikit-learn version is 0.17.1. I searched google and found a same issue fixed by updating sklearn (https://github.com/scikit-learn/scikit-learn/issues/3048). Due to the algorithm of minibatch kmeans, I think 8G RAM should be enough. Anyone has ideas about this situation? Thanks! 
[2016-09-12T13:35:48.149Z] <53135b495e986b0712efc453> > @raghavrv can you maybe work at making the new grid-search docs render correctly?  @amueller Sorry I missed the chat. Where does it not render correctly? 
[2016-09-12T17:06:12.187Z] <54d4a1d6db8155e6700f853b> @raghavrv there are a bunch of errors when generating the sphinx doc
[2016-09-12T17:06:41.168Z] <54d4a1d6db8155e6700f853b> @CasiaFan have you tried ``init="random"``
[2016-09-12T23:37:29.251Z] <57d73afd40f3a6eec064e7a0> @amueller  dude tell me what are some cool things i can do with sci-kit learn and i promise i'll do them.
[2016-09-13T01:07:27.138Z] <56f0af1085d51f252aba1606> I tried it. Still running out all memory @amueller 
[2016-09-13T01:46:03.992Z] <56f0af1085d51f252aba1606> Sorry, I check the script again and find this error is caused by plotting cluster patterns after clustering using matplotlib. Thanks anyway! @amueller 
[2016-09-13T05:07:17.592Z] <5770330bc2f0db084a2008c6> hi
[2016-09-13T05:09:31.195Z] <5770330bc2f0db084a2008c6> i have a question
[2016-09-13T05:13:02.659Z] <57d4603540f3a6eec06494c4> So... you can ask :)
[2016-09-13T17:29:56.407Z] <541a528b163965c9bc2053de> @amueller I will push the 0.18rc tag soon
[2016-09-13T18:11:24.316Z] <54d4a1d6db8155e6700f853b> @ogrisel thanks :)
[2016-09-13T18:12:53.999Z] <57d83c7940f3a6eec0650f6e> If i am python programmer and no knowledge about Ml but i want to go in ML so how can i start with python ? 
[2016-09-13T18:15:12.124Z] <541a528b163965c9bc2053de> you can follow the tutorials on http://scikit-learn.org then read a book such as @amueller's and work the examples, then try a kaggle.com challenge then follow a class online.
[2016-09-13T18:15:34.305Z] <541a528b163965c9bc2053de> basically alternate between theory and practice
[2016-09-13T18:16:03.772Z] <541a528b163965c9bc2053de> to get the theory you need basic linear algebra and stats / proba
[2016-09-13T18:17:23.469Z] <57d83c7940f3a6eec0650f6e> I know AI theory and reading Modern approach but i am lacking to understand equations and expression in ML , for understanding those euations and expression what should i learn first??
[2016-09-13T18:17:41.905Z] <541a528b163965c9bc2053de> then you don't know theory ;)
[2016-09-13T18:18:02.393Z] <541a528b163965c9bc2053de> also AI is wider than ML
[2016-09-13T18:18:17.822Z] <541a528b163965c9bc2053de> but ML is a very very rich subfield of AI
[2016-09-13T18:18:28.608Z] <57d83c7940f3a6eec0650f6e> Ok for understand expressiona and equations what should i learn? 
[2016-09-13T18:19:33.209Z] <57d83c7940f3a6eec0650f6e> ok i see you mentioned Linear algebra ! Any good tutorial or blog or book for linear algebra ?
[2016-09-13T18:19:42.743Z] <541a528b163965c9bc2053de> what I said:  linear algebra and stats / proba + basic differential multivariate calculus (what is a continuous function, a differentiable function, a gradient...)
[2016-09-13T18:20:05.793Z] <57d83c7940f3a6eec0650f6e> And will i able to understand regression funtion after reading linear algenra ?
[2016-09-13T18:20:22.073Z] <541a528b163965c9bc2053de> I don't have any particular recommendation in mind but if you ask that question to google you will probably get answers
[2016-09-13T18:21:36.361Z] <541a528b163965c9bc2053de> regression is a stats / machine learning concept, not a linear algebra concept. But generally it is presented in terms of vector space with a euclidean metric so you need to know about vector spaces and norms and distances first
[2016-09-13T18:22:46.331Z] <57d83c7940f3a6eec0650f6e> which math course would you recommend for understanding regression (vector..etc)
[2016-09-13T18:23:05.899Z] <541a528b163965c9bc2053de> to apply ML you don't necessarily need to understand the underlying math in details though. It's good to start with a bit of ml practice (e.g. sklearn tutorials) then learn a bit about the underlying maths and then iterate
[2016-09-13T18:23:29.215Z] <57d83c7940f3a6eec0650f6e> I am working with tensor flow api
[2016-09-13T18:23:40.658Z] <57d83c7940f3a6eec0650f6e> but i want to work with SNN
[2016-09-13T18:24:19.811Z] <541a528b163965c9bc2053de> learning linear algebra + stats + proba is typically 1 or 2 semesters of BSc in a math related cursus. So learning on your own without application to ML will probably be too dry.
[2016-09-13T18:24:29.664Z] <541a528b163965c9bc2053de> alternate with practice to keep with the motivation.
[2016-09-13T18:25:31.302Z] <541a528b163965c9bc2053de> then go an read a tensorflow tutorial instead
[2016-09-13T18:25:42.771Z] <57d83c7940f3a6eec0650f6e> I am also undergraduate student and this is last year of my graduation !
[2016-09-13T18:26:09.473Z] <57d83c7940f3a6eec0650f6e> Ok , thanks :)
[2016-09-13T18:27:01.655Z] <541a528b163965c9bc2053de> you might be interested in this : https://www.youtube.com/watch?v=cKxRvEZd3Mw
[2016-09-13T18:27:50.548Z] <541a528b163965c9bc2053de> you did not take any linear algebra class?
[2016-09-13T18:28:36.653Z] <57d83c7940f3a6eec0650f6e> Yet now but i will self learn no prob.
[2016-09-13T18:35:31.669Z] <541a528b163965c9bc2053de> @amueller I pushed the 0.18rc tag. I also triggered the wheel builder.
[2016-09-13T18:36:12.725Z] <54d4a1d6db8155e6700f853b> sweet!
[2016-09-13T18:36:17.072Z] <541a528b163965c9bc2053de> I tried with Python 3.6.0b1 and we have broken tests because of int / str comparisons: need to look in details
[2016-09-13T18:36:21.987Z] <54d4a1d6db8155e6700f853b> i'll try to trigger the conda builder
[2016-09-13T18:36:22.482Z] <541a528b163965c9bc2053de> after the 0.18rc
[2016-09-13T18:37:15.973Z] <541a528b163965c9bc2053de> all numpy tests pass on Python 3.6.0b1, 8 errors for scipy.
[2016-09-13T18:38:48.073Z] <54d4a1d6db8155e6700f853b> @ogrisel err did you merge #7414 ?
[2016-09-13T18:40:07.210Z] <54d4a1d6db8155e6700f853b> shouldn't the version be 0.18rc1?
[2016-09-13T18:41:47.704Z] <541a528b163965c9bc2053de> no I did not merge #7414, let me review it quickly, we can merge it and then tag 0.18rc1 will be after 0.18rc and nobody will ever know ;)
[2016-09-13T18:42:04.515Z] <54d4a1d6db8155e6700f853b> ;)
[2016-09-13T18:44:07.368Z] <541a528b163965c9bc2053de> actually I am not sure about updating the website.
[2016-09-13T18:44:19.250Z] <541a528b163965c9bc2053de> I think we should wait for 0.18 final to update the nav
[2016-09-13T18:44:39.257Z] <541a528b163965c9bc2053de> BTW I think 0.18rc is equivalent to 0.18rc0
[2016-09-13T18:47:56.108Z] <54d4a1d6db8155e6700f853b> ok
[2016-09-13T18:48:15.363Z] <54d4a1d6db8155e6700f853b> it's not entirely impossible that we do manual builts of the stable website, which would be silly
[2016-09-13T18:48:25.075Z] <54d4a1d6db8155e6700f853b> also https://circleci.com/gh/scikit-learn/scikit-learn-feedstock
[2016-09-13T18:49:20.340Z] <54d4a1d6db8155e6700f853b> ugh test failures in the pickle test
[2016-09-13T18:49:26.390Z] <541a528b163965c9bc2053de> this is looking good: https://travis-ci.org/MacPython/scikit-learn-wheels / https://ci.appveyor.com/project/sklearn-wheels/scikit-learn-wheels (the Python 3.3 failure is known but we don't care for the RC)
[2016-09-13T18:49:53.866Z] <54d4a1d6db8155e6700f853b> on python three
[2016-09-13T18:49:58.611Z] <54d4a1d6db8155e6700f853b> travis is failing
[2016-09-13T18:50:16.640Z] <54d4a1d6db8155e6700f853b> like our normal travis https://travis-ci.org/scikit-learn/scikit-learn/builds/159677032
[2016-09-13T18:50:43.132Z] <541a528b163965c9bc2053de> what...
[2016-09-13T18:51:11.136Z] <54d4a1d6db8155e6700f853b> unicode stuff?
[2016-09-13T18:52:13.418Z] <54d4a1d6db8155e6700f853b> that's the built in the 0.18.X branch?
[2016-09-13T18:54:48.580Z] <54d4a1d6db8155e6700f853b> turns out that running a "replace" on a pickled string is not a good idea
[2016-09-13T18:54:51.396Z] <54d4a1d6db8155e6700f853b> who'd thought?
[2016-09-13T18:58:00.854Z] <54d4a1d6db8155e6700f853b> gimme a sec
[2016-09-13T18:58:39.401Z] <54d4a1d6db8155e6700f853b> @ogrisel https://github.com/scikit-learn/scikit-learn/pull/7415
[2016-09-13T18:58:52.011Z] <54d4a1d6db8155e6700f853b> let's wait for CI, then backport
[2016-09-13T19:02:24.041Z] <541a528b163965c9bc2053de> yeah
[2016-09-13T19:25:18.212Z] <541a528b163965c9bc2053de> travis is slow...
[2016-09-13T19:26:55.934Z] <54d4a1d6db8155e6700f853b> hm I'm having trouble with the feedstock
[2016-09-13T19:27:04.161Z] <54d4a1d6db8155e6700f853b> https://circleci.com/gh/scikit-learn/scikit-learn-feedstock/4
[2016-09-13T19:30:29.803Z] <541a528b163965c9bc2053de> Maybe @ jakirkham has an idea.
[2016-09-13T19:30:50.667Z] <541a528b163965c9bc2053de> hum that did not work
[2016-09-13T19:31:51.540Z] <54d4a1d6db8155e6700f853b> I opened an issue here: https://github.com/conda-forge/conda-smithy/issues/304
[2016-09-13T19:39:02.553Z] <54d4a1d6db8155e6700f853b> I tried setting conda-forge as source channel
[2016-09-13T19:39:06.042Z] <54d4a1d6db8155e6700f853b> not sure if that does anything
[2016-09-13T19:39:13.699Z] <54d4a1d6db8155e6700f853b> it'll take like half an hour to complete anyhow :-/
[2016-09-13T19:39:18.114Z] <54d4a1d6db8155e6700f853b> how are the wheels?
[2016-09-13T19:42:33.175Z] <541a528b163965c9bc2053de> travis must be completely overloaded by the californians...
[2016-09-13T19:43:02.634Z] <541a528b163965c9bc2053de> the wheels tests break because of the pickle issue under Python 3
[2016-09-13T19:43:17.196Z] <541a528b163965c9bc2053de> I cancelled them to wait for #7415
[2016-09-13T19:43:44.310Z] <541a528b163965c9bc2053de> The Python 2.7 wheels did work
[2016-09-13T20:39:02.952Z] <541a528b163965c9bc2053de> @amueller I merged, backported and pushed 0.18rc1
[2016-09-13T20:39:11.981Z] <541a528b163965c9bc2053de> the wheel builder is triggered
[2016-09-13T21:11:07.226Z] <541a528b163965c9bc2053de> @amueller the wheels are on their way. How are you doing with the conda-forge feedstock?
[2016-09-13T21:11:16.309Z] <54d4a1d6db8155e6700f853b> well, it's running
[2016-09-13T21:11:27.524Z] <541a528b163965c9bc2053de> coool
[2016-09-13T21:13:07.331Z] <54d4a1d6db8155e6700f853b> I mean "they haven't failed yet"
[2016-09-13T21:15:41.254Z] <541a528b163965c9bc2053de> :)
[2016-09-13T21:22:39.612Z] <541a528b163965c9bc2053de> wheel builder was going fine but no more travis workers at the moment unfortunately: https://travis-ci.org/MacPython/scikit-learn-wheels
[2016-09-13T21:23:01.243Z] <541a528b163965c9bc2053de> the windows wheels are almost all ready: https://ci.appveyor.com/project/sklearn-wheels/scikit-learn-wheels
[2016-09-13T21:23:35.336Z] <541a528b163965c9bc2053de> OSX travis workers are overloaded
[2016-09-13T21:24:27.327Z] <541a528b163965c9bc2053de> I have to wake up early tomorrow, I won't have time to wait for them, feel free to push everything to PyPI while I'm sleeping :)
[2016-09-13T21:25:14.846Z] <541a528b163965c9bc2053de> ``` git checkout 0.18rc1 pip install wheelhouse-uploader python setup.py sdist fetch_artifacts ```
[2016-09-13T21:25:55.820Z] <541a528b163965c9bc2053de> then `twine upload dist/`
[2016-09-13T21:29:11.658Z] <54d4a1d6db8155e6700f853b> hehe alright
[2016-09-13T21:29:19.345Z] <54d4a1d6db8155e6700f853b> hm I messed up the channel config somewhere
[2016-09-13T21:30:12.924Z] <541a528b163965c9bc2053de> ...
[2016-09-13T21:30:34.195Z] <541a528b163965c9bc2053de> I going AFK, see you tomorrow. Good luck with conda-forge.
[2016-09-13T21:31:26.247Z] <57d8575a40f3a6eec0651444> hi
[2016-09-13T21:53:57.486Z] <54d4a1d6db8155e6700f853b> thanks @ogrisel and good night :)
[2016-09-13T21:54:03.506Z] <54d4a1d6db8155e6700f853b> hi @canadadeer_twitter 
[2016-09-14T12:30:13.059Z] <541a528b163965c9bc2053de> @amueller how do you test the feedstock without issue PRs?
[2016-09-14T19:13:45.201Z] <54d4a1d6db8155e6700f853b> there is no real way to test the feedstock
[2016-09-14T19:13:50.100Z] <54d4a1d6db8155e6700f853b> as far as I can tell
[2016-09-14T19:14:00.874Z] <54d4a1d6db8155e6700f853b> @ogrisel have you see this https://circleci.com/gh/scikit-learn/scikit-learn/5456?utm_campaign=build-failed&utm_medium=email&utm_source=notification ?
[2016-09-14T19:15:58.179Z] <541a528b163965c9bc2053de> Indeed, I'm on it.
[2016-09-14T19:17:57.456Z] <541a528b163965c9bc2053de> done
[2016-09-14T19:19:16.175Z] <541a528b163965c9bc2053de> If travis is green after this fix, I think we can tag 0.18rc2 and trigger the wheel builders. How is the feedstock going?
[2016-09-14T19:40:26.481Z] <541a528b163965c9bc2053de> @amueller shall I tag 0.18rc2?
[2016-09-14T19:41:44.283Z] <54d4a1d6db8155e6700f853b> @ogrisel sure
[2016-09-14T19:41:59.166Z] <54d4a1d6db8155e6700f853b> @ogrisel feedstock is been running for like an hour to build the 0.18rc1
[2016-09-14T19:46:30.124Z] <541a528b163965c9bc2053de> 0.18rc2 is on the launch pad
[2016-09-14T19:47:09.700Z] <541a528b163965c9bc2053de> I believe the wheels will be ready by tomorrow ;)
[2016-09-14T19:47:46.198Z] <54d4a1d6db8155e6700f853b> cool
[2016-09-14T19:48:01.851Z] <54d4a1d6db8155e6700f853b> Hopefully the conda packages too
[2016-09-14T19:48:07.103Z] <54d4a1d6db8155e6700f853b> I expect they arrive here: https://anaconda.org/conda-forge/repo?label=rc
[2016-09-14T19:48:16.409Z] <54d4a1d6db8155e6700f853b> I'll update the feedstock for 0.18.2
[2016-09-14T19:48:20.412Z] <541a528b163965c9bc2053de> great
[2016-09-14T19:49:08.264Z] <541a528b163965c9bc2053de> as soon as the conda package is ready any of us can fetch the wheels + build the sdist and publish to PyPI + tweet
[2016-09-14T19:51:56.313Z] <54d4a1d6db8155e6700f853b> sounds good
[2016-09-14T19:52:04.007Z] <54d4a1d6db8155e6700f853b> I think the conda package takes about 3h to build
[2016-09-14T19:52:14.508Z] <54d4a1d6db8155e6700f853b> a single entry of the matrix takes 30 minutes, there are 6
[2016-09-14T19:52:28.110Z] <54d4a1d6db8155e6700f853b> and they all run in the same job
[2016-09-14T21:30:59.855Z] <54d4a1d6db8155e6700f853b> @ogrisel do you want to fix the lbgfs thing or should I?
[2016-09-14T21:31:06.077Z] <54d4a1d6db8155e6700f853b> rc3? ;)
[2016-09-14T23:07:23.969Z] <54d4a1d6db8155e6700f853b> YES!
[2016-09-14T23:07:24.720Z] <54d4a1d6db8155e6700f853b> https://anaconda.org/conda-forge/scikit-learn/labels
[2016-09-14T23:08:11.032Z] <56c4f19ae610378809c1f8ae> :clap: 
[2016-09-14T23:27:02.907Z] <54d4a1d6db8155e6700f853b> ugh so conda users can't update
[2016-09-14T23:27:08.169Z] <54d4a1d6db8155e6700f853b> unless they use conda-forge
[2016-09-14T23:27:32.560Z] <54d4a1d6db8155e6700f853b> eh
[2016-09-15T04:38:09.166Z] <56a34c16e610378809bdc988> Hi @amueller @nelson-liu  I am free for four days straight, and I can do a port to py.tests now. I'm afraid my PR may stay open for a long time and fast moving master would leave it outdated. I'm almost sure that I can port the whole framework from nose to pytests within four days. Are we ready for it ? :wink: 
[2016-09-15T04:39:27.206Z] <56a34c16e610378809bdc988> Meanwhile, Github announces Trello type support natively to all repositories ! http://venturebeat.com/2016/09/14/github-launches-a-trello-competitor-pull-request-reviews-redesigned-profile-pages/
[2016-09-15T04:41:54.840Z] <56a34c16e610378809bdc988> @karandesai-96 waits for a green signal
[2016-09-15T05:46:43.745Z] <56c4f19ae610378809c1f8ae> > I'm afraid my PR may stay open for a long time and fast moving master would leave it outdated.  unfortunately, this sort of thing happens a lot with scikit-learn considering we dont have a lot of people doing reviews. Im not sure we have the bandwidth to review and process this fix even if you do create a PR. Hence the idea for a GSoC, because then you can guarantee 1 or 2 people looking at it.
[2016-09-15T07:22:25.535Z] <56a34c16e610378809bdc988> Okay I'm happy with it
[2016-09-15T14:51:07.423Z] <54d4a1d6db8155e6700f853b> @ogrisel so fetch-artifacts didn't get me the OS X wheels. It should have, right?
[2016-09-15T19:50:13.414Z] <55a36f535e0d51bd787b3400> Is this a good place to ask a question about the design/API of sklearn-like object?  If not: disregard.  [we are trying to implement a meta-estimator](https://github.com/mne-tools/mne-python/pull/3502) `SearchLight` which iteratively distributes a subset of `X, shape(n_samples, n_features, n_estimators)` to a series of `n_estimators` (all identical), e.g.  ``` class SearchLight(BaseEstimator):         def __init__(self, base_estimator=LogisticRegression()):               ....         def fit(self, X, y):                 for ii in range(X.shape[2]):                        est = clone(self.base_estimator)                        est.fit(X[:, :, ii], y)                        .... ```  This is useful when we want to have a quick estimate of how much information we can extract as a function of a particular feature (e.g.  decode brain activity as a function of time, or as a function of brain locus)  I'm unclear however what this kind of object is/should be. The problem becomes clear when we try to pipe and cross validate it. e.g.  ``` est = make_pipeline(PCA(), Foo(), SearchLight(Bar(), LogisticRegression())) cross_val_score(est, X, y) ```  cross_val_score won't work because the SearchLight object has `n_estimators` and thus the score shape is `n_estimators`.  My question is, how do you think we should design this kind of objects? Is it an estimator? a sort of ensemble? shall we rather create a model_selection function?
[2016-09-15T21:52:27.748Z] <54d4a1d6db8155e6700f853b> @kingjr it is sometimes. Are you working with Alexandre? I'm a bit busy right now but might be able to read / answer later
[2016-09-15T22:40:33.185Z] <562a7da216b6c7089cb80965>   @kingjr this sounds *kind* of like the `score_func` type of object that feature_selection.SelectKBest might want, except your score shape is `n_estimators` rather than `n_features`
[2016-09-15T22:41:41.638Z] <562a7da216b6c7089cb80965> From your code snippet, though, I'm having a hard time understanding where `n_estimators` even comes in, since the `ii` loop is on the shape of `X`
[2016-09-15T22:44:30.528Z] <562a7da216b6c7089cb80965> You perhaps already know this, but the sklearn [API documentation](http://scikit-learn.org/stable/developers/contributing.html#apis-of-scikit-learn-objects) defines 4 types of objects, though it's not clear to me if `SearchLight` fits neatly into any of these buckets. What sort of behavior do you expect when chaining? Is this almost like [`iterables`](http://nipype.readthedocs.io/en/latest/users/mapnode_and_iterables.html#iterables) in nipype?
[2016-09-15T22:54:21.703Z] <562a7da216b6c7089cb80965> Again, apologies if this is old news, but given your gravatar, is this like [`SearchLight`](http://nilearn.github.io/modules/generated/nilearn.decoding.SearchLight.html) from nilearn?
[2016-09-16T13:19:14.623Z] <55a36f535e0d51bd787b3400> @amueller yes I do, at least I'm a contributor of the package; I'm a postdoc at nyu.
[2016-09-16T13:21:59.399Z] <55a36f535e0d51bd787b3400> @dankessler thanks for taking a look. So to clarify: `X` is 3D, e.g. `(n_samples, n_features, n_dimensions)` and we want to fit an estimator across all features for each dimension separately, such that we end up with `n_dimensions` estimators, and therefore `n_dimensions` scores.
[2016-09-16T13:29:05.679Z] <55a36f535e0d51bd787b3400> Our `SearchLight` is indeed similar to nilearn's, but nilearn's does everything at once (parametrize how to move across dimensions of an MRI scan, fit/predict estimators, do the whole thing within a cv etc); by contrast we  implemented a single-purpose object: i.e. fit different classifiers over different dimensions of the data, but don't summarize or combine these classifiers. We can thus pipeline the search light : e.g. `make_pipeline(PrepareData(), SearchLight(Regressiont()))` and cross_val_predict this estimator
[2016-09-16T13:35:09.748Z] <55a36f535e0d51bd787b3400> However, we can't apply `cross_val_score` because this functions requires that the score is a float, not an array.
[2016-09-16T13:37:23.435Z] <55a36f535e0d51bd787b3400> But perhaps there s a way in sklearn to get cross_val_score compatible with arrays? i.e. if one wants to retrieve the cross-validated confusion matrix , instead of the average score?
[2016-09-16T16:00:51.647Z] <54d4a1d6db8155e6700f853b> @kingjr have we met? Sorry If I forgot :(
[2016-09-16T16:01:23.287Z] <54d4a1d6db8155e6700f853b> @kingjr also check out https://github.com/scikit-learn/scikit-learn/pull/7388#issuecomment-247565362
[2016-09-16T16:37:18.754Z] <55a36f535e0d51bd787b3400> @amueller briefly at a meetup
[2016-09-16T16:41:04.271Z] <55a36f535e0d51bd787b3400> yes #7388 seems indeed relevant. If you allow `cross_val_score` to have scoring metrics that are not float but custom (e.g. numpy arrays), then our problem is solved at the sklearn level: we would directly do `cross_val_score(SearchLight())` where by default `SearchLight().score(X, y)`with `X` shape being `(n_samples, n_features, n_dimensions)` returns an array of `n_dimensions`
[2016-09-16T21:02:54.517Z] <54d4a1d6db8155e6700f853b> @kingjr I think that would be the best. We already want that for f1_scores without averaging for example, where you get one for each class.
[2016-09-19T16:24:07.159Z] <57dfed0240f3a6eec0660e8d> Hello, is this the right place to ask beginners ML questions?
[2016-09-19T17:05:42.740Z] <56c4f19ae610378809c1f8ae> I think crossvalidated or stackoverflow would be better
[2016-09-19T17:05:44.909Z] <56c4f19ae610378809c1f8ae> thank you for asking
[2016-09-19T18:00:51.672Z] <564a0e2916b6c7089cbaead6> As an intermediate ML practitioner still stinging from being a noob, I found both of those communities very off putting in getting assistance. On cross validated, I was literally told that the answers to a question I asked were "in any basic econometrics text". They are invaluable resources to be sure, but not the place to learn as a beginner. I would advise trying to find a community around one of the MOOCs - udacity, coursera, ... Perhaps even Reddit
[2016-09-19T18:01:41.581Z] <564a0e2916b6c7089cbaead6> I am biased in which I would choose as I got a lot out of the Udacity ML nanodegree and have found their slack community inviting and informative. 
[2016-09-19T18:30:23.537Z] <57a061aa40f3a6eec05d8d26> Hello, how would one extract decision paths from a decision tree classifier? I mean I would like to get something like, "if x < 1 and ... then class 1"
[2016-09-19T18:41:54.030Z] <57dfed0240f3a6eec0660e8d> Thank you @joshuacook and @nelson-liu 
[2016-09-20T12:42:10.507Z] <53fdba59163965c9bc200ba2> Hi. Reading the SVC doc(http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) has it `... may not work properly in a multithreaded context `  Is possible to execute SVC using all threads? how ? 
[2016-09-20T14:27:14.156Z] <56c625c3e610378809c22760> Hi, I'm trying to build an outlier detection system on textual data using the `EllipticEnvelope`. I was wondering if there's a better way to choose the optimal number of features out of a TFIDF vectorizer so as to not cause a memory error or a singular covariance matrix apart from repeatedly checking on the training or the cv set. Thanks a lot for the help and I apologise if this is a very noob-ish doubt!
[2016-09-20T19:07:07.298Z] <53fdba59163965c9bc200ba2> How can I see the most frequent word using a TfidfVectorizer instance? Is possible?
[2016-09-24T15:41:05.663Z] <55a361b55e0d51bd787b3315> Could anyone peep in to see how can I correct this issue? https://travis-ci.org/scikit-learn/scikit-learn/builds/162438563
[2016-09-26T04:42:01.610Z] <576f8ac4c2f0db084a1ff53e>  hello everyone i am new to machine learning and data science .Can anyone one tell me what are the skills and tools to know to get a job in machine learning
[2016-09-26T08:37:16.032Z] <57b3fd8640f3a6eec05fe0e8> Depends what kind of job  you want. It's like asking what you need to know to get a `science` job.
[2016-09-26T08:38:22.516Z] <57b3fd8640f3a6eec05fe0e8> Washing flasks in a chemistry lab is a `science job` as is cloning a sheep. 
[2016-09-26T08:40:25.411Z] <57b3fd8640f3a6eec05fe0e8> If you want jobs where Apple or Google is offering you $1mil, you probably will want to learn higher level math and be capable of creating algo's. 
[2016-09-26T14:21:39.774Z] <53135b495e986b0712efc453> @ogrisel I can't get my conda env to cache the compilation of unchanged cythonized files... Have you experience this before? Any way I could make it compile only the files that are changed?
[2016-09-26T19:07:26.140Z] <57b8c8a640f3a6eec0608028> For those interested in ImageNet, 2016 winners have been announced:  http://image-net.org/challenges/LSVRC/2016/results        Object Detection winner: CUImage with 4.2% lead over ResNet Object Localization Winner: Trimps-Soushen  
[2016-09-28T08:09:32.175Z] <57e4ea1140f3a6eec066d9b4> hello! I am Satya Prakash wanting to work with scikit package and as it involves ML stuff I am intrested in it so any one please give me location to start and also looking forward to contribute in GSOC2017 any guidance will be really helpful
[2016-09-28T11:44:07.681Z] <56ed0b8885d51f252ab9a1b8> Hello! I am new with this stuff, I intend extracting features from gray-scale images and then further do analysis using Decision Tree algorithm  but it doesn't seem working.I will appreciate any guidance. Below is a screenshot of my work. Thank you               
[2016-09-28T11:44:50.117Z] <56ed0b8885d51f252ab9a1b8> %matplotlib inline from matplotlib import pyplot as plt import numpy as np from skimage import io  count = 0  images = io.imread_collection('/home/data/Desktop/IMAGES/GRAY-SCALE/*.jpg')        x_images = np.vstack(images)   while count < len(images):      new_x = (x_images[count])     new_y =(images.files[count])             print(new_y)     print(new_x)      count = count + 1      
[2016-09-28T11:46:20.740Z] <56ed0b8885d51f252ab9a1b8>  %matplotlib inline from matplotlib import pyplot as plt import numpy as np from skimage import io  count = 0  images = io.imread_collection('/home/data/Desktop/IMAGES/GRAY-SCALE/*.jpg')        x_images = np.vstack(images)   while count < len(images):      new_x = (x_images[count])     new_y =(images.files[count])             print(new_y)     print(new_x)      count = count + 1  from sklearn.tree import DecisionTreeClassifier from sklearn.cross_validation import train_test_split from sklearn.metrics import confusion_matrix from sklearn.metrics import accuracy_score   features = x_images  targetVariable = new_y  featureTrain,featureTest,TargetTrain,TargerTest = train_test_split(features, targetVariable, test_size = 0.2)  model = DecisionTreeClassifier() fittedModel = fit.model(featureTrain,targetTrain) predictions = fittedModel.predict()  print(predictions) #print(TargetTest,predictions) #print(accuracy_score(TargetTest,predictions))    
[2016-09-28T11:48:35.245Z] <57b3fd8640f3a6eec05fe0e8> Doesn't seem to be working as in you get errors? if so what? or do you mean the code words but it's not doing wwhat you want it to do? 
[2016-09-28T11:50:34.375Z] <56ed0b8885d51f252ab9a1b8> I get an error when i run the algorithm...
[2016-09-28T11:52:24.077Z] <57b3fd8640f3a6eec05fe0e8> Did you paste the error as well?
[2016-09-28T11:53:52.684Z] <56ed0b8885d51f252ab9a1b8> This is the error am getting  --------------------------------------------------------------------------- NameError                                 Traceback (most recent call last) <ipython-input-1-b657a0ea1003> in <module>()       5        6  ----> 7 features = x_images       8        9 targetVariable = new_y  NameError: name 'x_images' is not defined
[2016-09-28T12:12:02.446Z] <56ed0b8885d51f252ab9a1b8> Is there any line of code that can help extract features from these images(gray-scale) so I can further do analysis using decision Tree algorithm...@ItchyJunk...??  
[2016-09-28T12:44:43.869Z] <57b3fd8640f3a6eec05fe0e8> Hmm, not sure. I'll let someone who know better answer you. but looks like it's just x_image variable being used without being declared? is x_image supposed to be an array or string or something? x_image = [] or x_image = ''  would be the needed step.
[2016-09-28T12:53:23.131Z] <56ed0b8885d51f252ab9a1b8> Thanks a lot
[2016-09-28T20:56:04.660Z] <56c4f19ae610378809c1f8ae> stable docs down, is this intended?
[2016-09-28T20:56:08.656Z] <56c4f19ae610378809c1f8ae> @amueller @ogrisel 
[2016-09-28T20:58:55.346Z] <54d4a1d6db8155e6700f853b> @nelson-liu typo, sorry about that!
[2016-09-28T20:59:09.731Z] <56c4f19ae610378809c1f8ae> nvm, just saw https://github.com/scikit-learn/scikit-learn.github.io/commit/d6c6bd03f4cabbce20a3ac579c243abe0c4f2235
[2016-09-28T20:59:12.177Z] <56c4f19ae610378809c1f8ae> ah ok
[2016-09-28T20:59:16.793Z] <56c4f19ae610378809c1f8ae> thanks :smile: 
[2016-09-28T21:06:10.329Z] <54d4a1d6db8155e6700f853b> should now be up as 0.18 :)
[2016-09-28T21:13:00.006Z] <56c4f19ae610378809c1f8ae> :fireworks: yay!
[2016-09-28T21:49:53.289Z] <56ed0b8885d51f252ab9a1b8> Hello! is there any simple way of extracting features from fifty  gray scale images for further analysis? few lines of code would be much appreciated.Thanks
[2016-09-28T22:03:20.021Z] <56ed0b8885d51f252ab9a1b8>  I tried using numerical matrix of each  Grayscale image as a feature for further analysis but it doesn't working. Any guidance would help.Thanks 
[2016-09-28T22:03:59.208Z] <56c4f19ae610378809c1f8ae> have you looked at something like [the mnist example](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)
[2016-09-29T01:01:13.777Z] <56ed0b8885d51f252ab9a1b8> In the mnist example only a single file is loaded but in my case am working with four distinct image files so i used the lines below to obtain a numerical matrix of each image before I apply a classifier.But I get this error message.   D_images = io.imread_collection('/home/data/Desktop/TEST-IMAGES/*.jpg')  x_images = np.vstack(D_images)      n_samples = len(D_images) data = D_images.reshape((n_samples, -1))   print(data)                             #### ERROR MESSAGE ### --------------------------------------------------------------------------- AttributeError                            Traceback (most recent call last) <ipython-input-23-825371324329> in <module>()       4        5 n_samples = len(D_images) ----> 6 data = D_images.reshape((n_samples, -1))       7 print(data)  AttributeError: 'ImageCollection' object has no attribute 'reshape'   
[2016-09-29T17:27:46.325Z] <57ed4d1c40f3a6eec0680da9> Hello everyone. 
[2016-09-29T17:28:32.506Z] <57decc9840f3a6eec065e9e2> Hi :smile: 
[2016-09-29T17:28:41.476Z] <57a5a74c40f3a6eec05e31c1> hello
[2016-09-29T17:30:50.100Z] <57ed4d1c40f3a6eec0680da9> I want some help on project based learning in Recommendation systems... I started with movielens dataset but now I'm stuck. can anyone help me please.
[2016-09-29T17:34:30.147Z] <562a7da216b6c7089cb80965> @Ben-Kobby are you sure you want to be reshaping `D_images` and not `x_images`?
[2016-09-29T19:31:32.547Z] <561a58f7d33f749381a8ff2f> Guys... I'm super confused about `DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.`
[2016-09-29T19:31:46.680Z] <561a58f7d33f749381a8ff2f> How can we make our modules compliant with older and newer versions?
[2016-09-29T20:37:23.485Z] <56c4f19ae610378809c1f8ae> @kootenpv by modules do you mean modules that interface with scikit-learn?
[2016-09-30T03:15:15.710Z] <56d587f0e610378809c46913> Hello everyone, I want to contribute to scikit-learn. Can someone please direct me towards the documentation to get started? Thanks.
[2016-09-30T03:18:13.143Z] <56c4f19ae610378809c1f8ae> have you read the contributing guide?
[2016-09-30T03:18:16.887Z] <56c4f19ae610378809c1f8ae> thats a good start.
[2016-09-30T03:33:01.137Z] <56d587f0e610378809c46913> Yes sir, I did give it a read. However, not having worked with such a huge library before, the code base seems a bit intimidating. Can you please tell me as to how long would it take to understand the code before I can make any contribution?
[2016-09-30T03:37:12.993Z] <56c4f19ae610378809c1f8ae> well you dont have to understand everything to begin contributing
[2016-09-30T03:37:34.599Z] <56c4f19ae610378809c1f8ae> the different methods implemented are largely independent of each other
[2016-09-30T04:06:24.704Z] <56d587f0e610378809c46913> Okay sir, thanks for letting me know. I'll try to solve any issue marked 'easy' to start-off as mentioned in the guide then.
[2016-09-30T04:19:26.605Z] <56ed0b8885d51f252ab9a1b8> @dankessler  thanks a lot for the correction,  Am suppose to reshape x_images instead...
[2016-09-30T10:55:42.382Z] <56c625c3e610378809c22760> Hi, this is one error that I always seem to encounter when I pull from upstream (using 0.19.dev0) even after executing `sudo make`: ``` ImportError: /home/devashish/EXPERIMENTATION/scikit-learn/sklearn/utils/sparsefuncs_fast.so: undefined symbol: PyFPE_jbuf ``` Any solutions to this?
[2016-09-30T10:56:20.648Z] <56c625c3e610378809c22760> I'm trying to import LogisticRegression here
[2016-09-30T11:06:15.495Z] <56c625c3e610378809c22760> This is the full traceback: ``` --------------------------------------------------------------------------- ImportError                               Traceback (most recent call last) <ipython-input-81-c84b03903d9e> in <module>() ----> 1 from sklearn.linear_model import LogisticRegression  /home/devashish/EXPERIMENTATION/scikit-learn/sklearn/linear_model/__init__.py in <module>()      10 # complete documentation.      11  ---> 12 from .base import LinearRegression      13       14 from .bayes import BayesianRidge, ARDRegression  /home/devashish/EXPERIMENTATION/scikit-learn/sklearn/linear_model/base.py in <module>()      30 from ..utils.validation import FLOAT_DTYPES      31 from ..utils import check_random_state ---> 32 from ..utils.extmath import safe_sparse_dot      33 from ..utils.sparsefuncs import mean_variance_axis, inplace_column_scale      34 from ..utils.fixes import sparse_lsqr  /home/devashish/EXPERIMENTATION/scikit-learn/sklearn/utils/extmath.py in <module>()      24 from ._logistic_sigmoid import _log_logistic_sigmoid      25 from ..externals.six.moves import xrange ---> 26 from .sparsefuncs_fast import csr_row_norms      27 from .validation import check_array      28 from ..exceptions import NonBLASDotWarning  ImportError: /home/devashish/EXPERIMENTATION/scikit-learn/sklearn/utils/sparsefuncs_fast.so: undefined symbol: PyFPE_jbuf ```
[2016-09-30T11:22:25.667Z] <56c625c3e610378809c22760> I'm getting pretty much the same error as reported [here](http://stackoverflow.com/questions/37577210/build-sklearn-error-cythonize-failed). 
[2016-09-30T11:23:46.101Z] <56c625c3e610378809c22760> I have cython installed however I still get this error :disappointed: 
[2016-09-30T12:05:27.718Z] <56c625c3e610378809c22760> reported it here: https://github.com/scikit-learn/scikit-learn/issues/7542
[2016-10-04T05:28:54.501Z] <57f33dd7d73408ce4f2b9adf> Hello everyone
[2016-10-04T05:29:52.258Z] <57f33dd7d73408ce4f2b9adf> I just started using scikit-learn few weeks back and I am loving every bit of it. 
[2016-10-04T05:30:22.366Z] <57f33dd7d73408ce4f2b9adf> I want to contribute to scikit-learn but not able to understand where to start
[2016-10-04T05:30:30.621Z] <57f33dd7d73408ce4f2b9adf> Can anyone guide me through
[2016-10-04T12:46:26.404Z] <5770c02dc2f0db084a2017bd> @vibrantabhi19 their website has some contribution guidelines : http://scikit-learn.org/stable/developers/index.html
[2016-10-04T14:18:40.807Z] <57f33dd7d73408ce4f2b9adf> Thanks @RohanVB. I went through these guidlines. Hope I can get over some issues and make my first PR.
[2016-10-04T15:08:09.198Z] <56c4f19ae610378809c1f8ae> theres a low hanging fruit @ https://github.com/scikit-learn/scikit-learn/issues/7521
[2016-10-04T16:13:31.154Z] <57f33dd7d73408ce4f2b9adf> Thank you @nelson-liu  I am up for it :)
[2016-10-04T16:45:43.862Z] <54ec8cb715522ed4b3dc693b> Scikit learn is amazing! I just had a question regarding what is the plan of scikitlearn as tensorflow has written something called sci flow, which is intended to be replacement for scikit-learn. Please be advised that I still do not totally understand tensorflow!
[2016-10-04T17:22:34.272Z] <57f33dd7d73408ce4f2b9adf> @nelson-liu The file testimonial.html is available only after we build the html docs.  And then in testimonials.html, even after fixing the issue we get 'working directory clean' So kindly help me with the file/code structure
[2016-10-04T17:23:00.347Z] <56c4f19ae610378809c1f8ae> you have to modify about.rst
[2016-10-04T17:23:07.762Z] <56c4f19ae610378809c1f8ae> thats the file name
[2016-10-04T17:23:17.836Z] <56c4f19ae610378809c1f8ae> the html files are built from rst source files, so modify the rst source
[2016-10-04T17:23:27.643Z] <56c4f19ae610378809c1f8ae> i bet you could grep rangespan and find wher eyou want it
[2016-10-04T17:23:53.507Z] <56c4f19ae610378809c1f8ae> @thewhitetulip if youre referring to skflow, I dont think its a replacement for scikit-learn
[2016-10-04T17:24:08.848Z] <56c4f19ae610378809c1f8ae> and i dont think its their intention to be a replacement
[2016-10-04T17:24:39.891Z] <56c4f19ae610378809c1f8ae> skflow is useful for providing a scikit-learn interface to the deep learning capabilities of tensorflow, because scikit-learn does not do deep learning
[2016-10-04T17:24:46.381Z] <56c4f19ae610378809c1f8ae> they occupy different roles
[2016-10-04T18:19:08.149Z] <57f33dd7d73408ce4f2b9adf> @nelson-liu Done, Kindly review my PR
[2016-10-05T04:17:46.215Z] <57f33dd7d73408ce4f2b9adf> I got through my first contribution, can anyone suggest few more issues that are easy to solve. I wanted to get some confidence before going to the core progamming structure. I also reviewed some fo  the 'Easy' labeled issues.  @nelson-liu any more low hanging fruit?
[2016-10-05T14:56:25.177Z] <54ec8cb715522ed4b3dc693b> @nelson-liu good to know!
[2016-10-05T16:18:45.775Z] <54d4a1d6db8155e6700f853b> @vibrantabhi19 @thewhitetulip one thing that's also very appreciated is going through old issues and seeing if they are still relevant.
[2016-10-05T16:19:45.559Z] <57f33dd7d73408ce4f2b9adf> @amueller Will surely look into it
[2016-10-05T16:43:08.920Z] <54d4a1d6db8155e6700f853b> @raghavrv you know that the ping on numpy was Travis, the creator of numpy and scipy and CEO of continuum? ;)
[2016-10-05T18:00:53.376Z] <53135b495e986b0712efc453> Wow. I didn't know that o.O
[2016-10-05T19:30:17.320Z] <57f553ebd73408ce4f2c1766> hello, may I ask a question about sk-learn here? 
[2016-10-05T19:30:45.000Z] <57f553ebd73408ce4f2c1766> It's related to the deprecation warning.
[2016-10-05T19:30:47.466Z] <57f553ebd73408ce4f2c1766> DeprecationWarning: Function residues_ is deprecated; ``residues_`` is deprecated and will be removed in 0.19
[2016-10-05T19:31:20.584Z] <57f553ebd73408ce4f2c1766> I'm wondering what should I use instead of 'residues_' to get residue values from LinearRegression (fitted) model.
[2016-10-07T23:48:11.143Z] <54d4a1d6db8155e6700f853b> wow this makes me shiver: https://github.com/scikit-learn/scikit-learn/pull/6348/files
[2016-10-07T23:49:19.206Z] <54d4a1d6db8155e6700f853b> @naokishibuya yes you should
[2016-10-07T23:51:12.026Z] <54d4a1d6db8155e6700f853b> err sorry use ``_residues`` or  just compute them from the predictions?
[2016-10-07T23:51:30.899Z] <54d4a1d6db8155e6700f853b> np.sum((y_train - lr.predict(X_train)) ** 2)
[2016-10-08T03:50:15.534Z] <54d4a1d6db8155e6700f853b> hm is there a way to see how many issues I closed today?
[2016-10-08T04:10:10.165Z] <57f553ebd73408ce4f2c1766> @amueller understood, thx!
[2016-10-08T15:31:31.404Z] <57f4f049d73408ce4f2bfae9> Is there anything to do discretization on scikilearn?
[2016-10-08T16:45:03.536Z] <54d4a1d6db8155e6700f853b> @Piperod__twitter not really right now. You can just use numpy though
[2016-10-08T16:45:13.340Z] <54d4a1d6db8155e6700f853b> numpy.digitize is the thing you want to look at iirc
[2016-10-09T05:32:48.704Z] <56a34c16e610378809bdc988> @amueller not sure, bu pulse can give really good insights
[2016-10-09T05:32:51.269Z] <56a34c16e610378809bdc988> https://github.com/scikit-learn/scikit-learn/pulse
[2016-10-09T05:35:56.323Z] <56a34c16e610378809bdc988> Hi, I had a feature request
[2016-10-09T05:36:20.214Z] <56a34c16e610378809bdc988> can we have a `mean_squared_log_error` or a `root_mean_squared_log_error` in `sklearn.metrics` ?
[2016-10-09T05:36:34.106Z] <56a34c16e610378809bdc988> former is preferred looking at the current set of metrics
[2016-10-09T05:37:41.060Z] <56a34c16e610378809bdc988> Frequent competitions on kaggle have this evaluation metric
[2016-10-09T05:37:42.735Z] <56a34c16e610378809bdc988> https://www.kaggle.com/competitions?sortBy=prize&group=all&page=1&site=main&eval=rmsle
[2016-10-09T05:38:58.056Z] <56a34c16e610378809bdc988> for now, i make a new column in my dataframe by taking `np.log(1 + x)` transformation, and then calculate `mean_squared_error` on it. Then while making a submission I reverse it as `np.exp(x) - 1`.
[2016-10-09T05:39:18.221Z] <56a34c16e610378809bdc988> Thoughts ?
[2016-10-09T05:40:48.999Z] <56a34c16e610378809bdc988> [![blob](https://files.gitter.im/scikit-learn/scikit-learn/VhqO/thumb/blob.png)](https://files.gitter.im/scikit-learn/scikit-learn/VhqO/blob)
[2016-10-10T10:24:04.546Z] <56333d0d16b6c7089cb8d5c7> hello, I was working on https://github.com/scikit-learn/scikit-learn/issues/6120. I am not sure I understand what needs to be exactly needs to be changed.
[2016-10-10T10:25:12.214Z] <56333d0d16b6c7089cb8d5c7> what do I need to do in order to use only 20 components?
[2016-10-10T15:53:38.900Z] <555687ea15522ed4b3e079c7> How would one submit a feature request on the documentation. With the addition of float elements to some hyper parameters it might be assumed that values can range from (0-1] , but in fact ranges often have a minimum i.e.( (0-1]*n_elements  must be greater than 2 , (0-.5] )
[2016-10-11T18:20:10.611Z] <54d4a1d6db8155e6700f853b> @dylanbstorey on the issue tracker
[2016-10-12T12:38:53.277Z] <57a061aa40f3a6eec05d8d26> Does mean_score_time in GridSearchCV.cv\_results_ mean time that it took to predict classes (in classification case) and calcuclate the relevant evaluation scores?
[2016-10-12T17:47:20.578Z] <564789be16b6c7089cbab8b7> if you fit randomforestclassifier with verbosity  =1, say and then pickle it
[2016-10-12T17:47:40.392Z] <564789be16b6c7089cbab8b7> it seems you are stuck with this verbosity level forever. Is that correct/wanted?
[2016-10-12T17:51:38.822Z] <564789be16b6c7089cbab8b7> unless you can secretly set the verbosity level when doing .predict_proba?
[2016-10-12T20:23:30.543Z] <56a34c16e610378809bdc988> > Hi, I had a feature request  #7655 :)
[2016-10-12T20:23:53.414Z] <56a34c16e610378809bdc988> I'll be waiting eagerly for the reviews
[2016-10-12T21:50:39.045Z] <55d213e50fc9f982beadaa87> has anyone successfully added sklearn to a requirements.txt with a specific version?
[2016-10-13T00:17:43.631Z] <56c4f19ae610378809c1f8ae> yes i have
[2016-10-13T00:17:58.665Z] <56c4f19ae610378809c1f8ae> by version do you mean release #? @alexbednarczyk 
[2016-10-13T00:18:21.870Z] <56c4f19ae610378809c1f8ae> whats the error you are getting right now?
[2016-10-13T02:23:27.510Z] <53135b495e986b0712efc453> > Does mean_score_time in GridSearchCV.cv\_results_ mean time that it took to predict classes (in classification case) and calcuclate the relevant evaluation scores?  @mkoske Yes. `mean_fit_time` corresponds to the training time...
[2016-10-13T09:16:30.222Z] <55d213e50fc9f982beadaa87> @nelson-liu what does your requirements.txt line for sklearn look like? I've tried scikit-learn==0.17 and sklearn==0.17 both give me errors
[2016-10-13T10:31:34.524Z] <55d213e50fc9f982beadaa87> it doesn't seem like sklearn interacts with pip3 freeze. when i use pip3 freeze it displays the version as 0.0 when im using 0.18
[2016-10-13T10:33:39.172Z] <55d213e50fc9f982beadaa87> Collecting sklearn==0.17 (from -r requirements.txt (line 3))  Could not find a version that satisfies the requirement sklearn==0.17 (from -r requirements.txt (line 3)) (from versions: 0.0) No matching distribution found for sklearn==0.17 (from -r requirements.txt (line 3))
[2016-10-13T13:38:12.100Z] <56c4f19ae610378809c1f8ae> hmm thats odd. my pip outputs `scikit-learn==0.18` perfectly fine
[2016-10-13T13:38:18.613Z] <56c4f19ae610378809c1f8ae> although i am on python 2, so ill try with 3
[2016-10-13T13:43:02.361Z] <56c4f19ae610378809c1f8ae> ``` conda create --name test python=3 source activate test pip install numpy scipy cython scikit-learn  $ pip --version pip 8.1.2 from /Users/nfliu/miniconda2/envs/test/lib/python3.5/site-packages (python 3.5)  $ pip freeze Cython==0.24.1 numpy==1.11.2 scikit-learn==0.18 scipy==0.18.1 ```  seemed to work for me
[2016-10-13T13:44:55.877Z] <56c4f19ae610378809c1f8ae> @alexbednarczyk 
[2016-10-13T14:03:15.087Z] <55d213e50fc9f982beadaa87> alright. im using pip 8.1.1, maybe i need to update
[2016-10-13T14:03:22.594Z] <55d213e50fc9f982beadaa87> did it work with 0.17?
[2016-10-13T14:08:17.343Z] <56c4f19ae610378809c1f8ae> yeah it did
[2016-10-13T14:17:53.559Z] <55d213e50fc9f982beadaa87> ok ill try updating pip, thanks 
[2016-10-14T04:47:36.897Z] <56a34c16e610378809bdc988> Hi, https://github.com/scikit-learn/scikit-learn/pull/7655 is ready. Can any core team member help me improve it ? :D
[2016-10-15T03:00:20.103Z] <55a36f535e0d51bd787b3400> Hi Sklearn community. Is there a way to do clustering with a constrain such that there is an equal number of training samples in each cluster?
[2016-10-17T14:23:56.055Z] <529c6e38ed5ab0b3bf04dde0> Hey Guys, I was going through the issues on github, so have a few  questions regarding  Neural Network modules(MLPclassifier/MLPregressor): 
[2016-10-17T14:24:23.203Z] <529c6e38ed5ab0b3bf04dde0> 1. I think Dropout has already been implemented, is the PR already merged with the 'master' branch
[2016-10-17T14:24:50.705Z] <529c6e38ed5ab0b3bf04dde0> 2. What are the other things in the pipeline related to neural networks
[2016-10-17T14:25:27.474Z] <529c6e38ed5ab0b3bf04dde0> Also, are there any plans for implementing Word Vectors in scikit-learn?
[2016-10-17T14:27:06.830Z] <529c6e38ed5ab0b3bf04dde0> @amueller ?
[2016-10-17T14:36:10.934Z] <56c4f19ae610378809c1f8ae> iirc there was a proposal to add word2vec awhile ago but it got dismantled pretty quickly since gensim is already a thing
[2016-10-17T14:37:40.213Z] <56c4f19ae610378809c1f8ae>  also i dont think dropout is implemented / merged, see https://github.com/scikit-learn/scikit-learn/pull/7407
[2016-10-17T14:38:32.446Z] <56c4f19ae610378809c1f8ae> heres the word2vec one https://github.com/scikit-learn/scikit-learn/issues/6247
[2016-10-17T14:39:23.353Z] <529c6e38ed5ab0b3bf04dde0> @nelson-liu true that. and although gensim is pretty straight forward to use, do you think that, if we had the word2vec module in scikit-learn itself, then one doesn't have to rely on two different libraries, besides, we already have couple of existing vectorization methods for text, in that way you can simply try word vectors instead of tfidf/count vectors etc.
[2016-10-17T14:40:18.059Z] <56c4f19ae610378809c1f8ae> i dont think thats worth implementing word2vec/glove in scikit-learn though; as gael said in the issue > Text modelling probably requires more than just machine learning, including specific rules. Thus I think that word2vec belongs more in gensim (where it already is) than in scikit-learn: it is a model very tuned to text.
[2016-10-17T14:40:56.951Z] <56c4f19ae610378809c1f8ae> and gensim does indeed have a scikit-learn interface (or should have one soon i believe)
[2016-10-17T14:41:32.721Z] <529c6e38ed5ab0b3bf04dde0> yeah right, just went through it. I think as @mblondel mentioned in this issue, I'd rather add it in https://github.com/scikit-learn/scikit-learn/wiki/Third-party-projects-and-code-snippets.
[2016-10-17T15:27:51.306Z] <56c4f19ae610378809c1f8ae> yup or perhaps https://github.com/scikit-learn-contrib
[2016-10-18T16:07:08.377Z] <57f4f049d73408ce4f2bfae9> Decision trees support categorical data or do I have to convert categorical data into numbers? 
[2016-10-18T17:22:13.426Z] <56c4f19ae610378809c1f8ae> you have to convert categorical data into numbers
[2016-10-19T01:11:37.221Z] <58011513d73408ce4f2e472f> Hello -- does anyone know what's the best way to serialize scikit learn models to string/bytes etc, which can be stored in a database?
[2016-10-19T01:12:13.818Z] <58011513d73408ce4f2e472f> I have tried pickle -- but many people seem to advice against it.
[2016-10-19T01:12:45.320Z] <58011513d73408ce4f2e472f> joblib is good for writing to a file, but does not provide support to converting to string.
[2016-10-19T16:21:26.633Z] <57a061aa40f3a6eec05d8d26> Hello, are the neighbors returned by NearestNeighbors.kneighbors() always sorted by distance?
[2016-10-19T16:28:46.908Z] <553d32d715522ed4b3df8b92> Hi, I suppose it is sorted by distance - nearest( least distance) being the first element.
[2016-10-19T21:08:49.797Z] <57a061aa40f3a6eec05d8d26> If I use same estimator in a loop but with different subset of data, should I always call .fit(X, y) with the new subset?
[2016-10-20T02:03:48.546Z] <553d32d715522ed4b3df8b92> Is partial_fit suitable for your purpose ?
[2016-10-20T02:07:21.864Z] <553d32d715522ed4b3df8b92> Though not all estimators support it. [This](http://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning) might be relevant. Hope I am understanding your use case right.
[2016-10-21T01:07:59.089Z] <561be13fd33f749381a91e6e> @rajhans  I'm curious, if you were to store it in a db, what would you want to do with the record
[2016-10-21T01:30:58.745Z] <56c4f19ae610378809c1f8ae> @rajhans you could write the joblib file to disk, get a hash, and then store the hash? That might be a bit too much space for your application, though.
[2016-10-21T01:31:40.284Z] <561be13fd33f749381a91e6e> @nelson-liu is that what you do?  
[2016-10-21T04:28:44.935Z] <56c4f19ae610378809c1f8ae> no, I dont work with scikit-learn and databases. Im just postulating a possible solution to his answer
[2016-10-21T16:59:01.221Z] <56d8cf14e610378809c4e7e9> Having issues with akka netty
[2016-10-21T17:00:49.156Z] <56d8cf14e610378809c4e7e9> I have two services in akka communicating over netty tcp. How can I dockerize them. I am as of now getting an error 
[2016-10-21T17:01:03.262Z] <56d8cf14e610378809c4e7e9> Can anyone help me on this?
[2016-10-21T17:02:28.097Z] <56c4f19ae610378809c1f8ae> i dont think this is the proper place to ask a question about akka, this gitter room is for scikit-learn
[2016-10-22T06:42:14.994Z] <5730c2dcc43b8c601971eca1> Hello, Just wondering, how can we setup path dependant input states for Random Forest ? This is similar to Recurrent Network,   where input Xt=(x0,...,xi,.. yt-1, yt-2) depends on past output states Yt.  If we could put the exact output states Yt, it creates a bias in the training. So, wondering how we can put  recurrent states in Random Forest training. Thanks   
[2016-10-24T12:18:35.348Z] <580cad1dd73408ce4f303424> hey everyone
[2016-10-24T12:18:49.244Z] <580cad1dd73408ce4f303424> i am new here and want to learn machine learning
[2016-10-25T14:32:42.491Z] <54d4a1d6db8155e6700f853b> @neerajwadhwa take andrew Ng's coursera course and by my book ;) https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413/ref=sr_1_1?ie=UTF8&qid=1477405931&sr=8-1&keywords=introduction+to+machine+learning+with+python
[2016-10-25T16:27:40.126Z] <53135b495e986b0712efc453> @amueller Do you have any issue that needs fixing or review for `0.18.1`?
[2016-10-25T16:28:31.920Z] <54d4a1d6db8155e6700f853b> @raghavrv  https://github.com/scikit-learn/scikit-learn/pulls?q=is%3Aopen+is%3Apr+milestone%3A0.18.1 ;)
[2016-10-25T16:30:27.625Z] <54d4a1d6db8155e6700f853b> and https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+is%3Aissue+milestone%3A0.18.1+label%3ABlocker
[2016-10-25T16:31:07.816Z] <54d4a1d6db8155e6700f853b> so two things that would be great are fixing this: https://github.com/scikit-learn/scikit-learn/issues/7563 (I'm investigating but getting no-where)
[2016-10-25T16:31:32.079Z] <54d4a1d6db8155e6700f853b> and a non-regression test for this: https://github.com/scikit-learn/scikit-learn/pull/7724
[2016-10-25T16:32:06.115Z] <53135b495e986b0712efc453> @amueller Okay! BTW for #7672, you can try `curl -Ls https://goo.gl/jhGwkV | git apply -v --index; git commit -m "NOMERGE recythonize all";` to clear up the cache and make tests pass... (Resetting the cache at travis seems to not work...)
[2016-10-25T16:58:23.948Z] <53135b495e986b0712efc453> Have addressed your comments at #5874
[2016-10-25T16:59:32.713Z] <53135b495e986b0712efc453> @amueller For #7724 do you want me to cherry-pick his commits and add a test or do we wait for him to add it?
[2016-10-25T16:59:48.635Z] <54d4a1d6db8155e6700f853b> either way. first find a test?
[2016-10-25T17:29:15.545Z] <562a7da216b6c7089cb80965> For `sklearn.svm.SVC` with a [callable kernel](http://scikit-learn.org/dev/modules/svm.html#using-python-functions-as-kernels), is there any way the callee knows if the outer estimator is in the midst of a `fit` or `predict` (or similar)?
[2016-10-25T17:30:00.281Z] <54d4a1d6db8155e6700f853b> whether the kernel knows? Well if X==Y it's probably fit
[2016-10-25T17:30:14.855Z] <562a7da216b6c7089cb80965> Yeah, that was first heuristic that came to mind
[2016-10-25T17:30:28.797Z] <54d4a1d6db8155e6700f853b> but no, there is no flag or anything. The kernel shoudn't know
[2016-10-25T17:30:42.345Z] <54d4a1d6db8155e6700f853b> why do you want that?
[2016-10-25T17:30:47.316Z] <562a7da216b6c7089cb80965> Ok. I know others have done work on this, but trying to implement MKL as a callable
[2016-10-25T17:31:09.714Z] <54d4a1d6db8155e6700f853b> use shogun if you want to do mkl ;)
[2016-10-25T17:31:22.101Z] <562a7da216b6c7089cb80965> Idea is that during outer `fit` call, there's an MKL class that computes the various kernels, learns the gamma weights and stores them, then returns the combined gram
[2016-10-25T17:31:30.460Z] <562a7da216b6c7089cb80965> but during `predict` it uses the stored weights
[2016-10-25T17:31:42.271Z] <562a7da216b6c7089cb80965> Yeah, I suppose I could go to shogun. I just like sklearn so dang much
[2016-10-25T17:31:53.487Z] <54d4a1d6db8155e6700f853b> I think I did implement mkl with sklearn at some point...
[2016-10-25T17:31:54.336Z] <54d4a1d6db8155e6700f853b> hm
[2016-10-25T17:32:14.795Z] <562a7da216b6c7089cb80965> I suppose so long as the weight learning is deterministic, it's effectively idempotent, so that heuristic would work
[2016-10-25T17:32:24.628Z] <562a7da216b6c7089cb80965> i.e., if you're predicting the training data, it works the same as fitting the training data
[2016-10-25T17:32:25.780Z] <54d4a1d6db8155e6700f853b> Well you should implement your own class that calls the kernels, I would say
[2016-10-25T17:32:40.403Z] <54d4a1d6db8155e6700f853b> you can always just nystroem it and use a liner model on the combined embedding ;)
[2016-10-25T17:32:53.928Z] <562a7da216b6c7089cb80965> Yeah, I previously built that, too, but trying to see if I can fit this within the `SVC` spec
[2016-10-25T17:33:01.149Z] <562a7da216b6c7089cb80965> nystroem it?
[2016-10-25T17:33:53.665Z] <562a7da216b6c7089cb80965> nvm, presume you're talking about the `Nystroem` class from kernel estimator family
[2016-10-25T17:34:07.272Z] <54d4a1d6db8155e6700f853b> compute the nystroem feature map (see Nystroem class), which makes the SVM problem a linear problem in that feature space. MKL is just doing a linear model on concatenated features
[2016-10-25T17:34:12.916Z] <54d4a1d6db8155e6700f853b> I guess it's a group lasso, though
[2016-10-25T17:34:40.088Z] <562a7da216b6c7089cb80965> ah, that makes sense
[2016-10-25T17:34:55.187Z] <562a7da216b6c7089cb80965> My motivating case is multiple kernels of same functional form but defined on non-overlapping subsets of the feature space
[2016-10-25T17:35:01.901Z] <562a7da216b6c7089cb80965> which is very group lasso-y
[2016-10-25T17:35:26.554Z] <562a7da216b6c7089cb80965> Thanks @amueller! If you come across your MKL code, would appreciate a link, but no worries if it's not close at hand
[2016-10-25T17:49:22.207Z] <562a7da216b6c7089cb80965> ah, but that callable isn't going to have access to `Y`, even if estimator is doing a fit, so that kind of sinks learning weights based on labels
[2016-10-25T17:49:47.592Z] <562a7da216b6c7089cb80965> Seems like feature xform is the way to go (if I'm going to fit this into sklearn)
[2016-10-25T22:15:50.429Z] <57a061aa40f3a6eec05d8d26> Hello, I am using NearestNeighbors.kneighbors. If there's some cases that are at equal distance from the query point, the number of neighbors might be larger than n_neighbors. Is there a way to find how many neighbors there actually were, i.e. counting the neighbors with equal distance.
[2016-10-26T01:17:46.369Z] <56ed0b8885d51f252ab9a1b8>  Hi guys can anyone help me with some lines of code on how to extract features from 400,000 images dateset using color histogram...in a vector form?? Thank you.
[2016-10-26T04:21:09.358Z] <561be13fd33f749381a91e6e> although joblib exists, I'm curious if people have experience using dill to pickle both arrays and models. 
[2016-10-26T04:23:48.977Z] <561be13fd33f749381a91e6e> as well as experience with cloudpickle
[2016-10-26T12:14:59.049Z] <58109daad73408ce4f30f654> Is there any algorithm to make understand the sentence in english.. Actually the meaning of sentence 
[2016-10-26T14:03:00.077Z] <57a061aa40f3a6eec05d8d26> My code takes about 4seconds to run when using just NearestNeighbors(), but if I use n_jobs=-1 argument, it takes 8.5 minutes. Why it does this?
[2016-10-26T16:23:59.455Z] <54d4a1d6db8155e6700f853b> @mkoske depending on how much data you have, parallelization might make it slower. Starting the jobs has some overhead. Try n_jobs=2
[2016-10-26T16:53:08.596Z] <57a061aa40f3a6eec05d8d26> @amueller I think it is 2, since I have 2 cores, right? I'm using the digits dataset for testing
[2016-10-26T17:02:15.736Z] <561be13fd33f749381a91e6e> @nilkanthshirodkar apologies, my native tongue is gibberish.  ^_^  Here's the meaning:  Lately, I've been using [dill](https://github.com/uqfoundation/dill) instead of `joblib.dump` to serialize models.  While dill can pickle the object itself,  it can also recursively pickle the object definition, which means you don't need to import the object's class(es) ahead of time.   Unfortunately, I get a variety of file handle errors when dumping some* scikit models using dill, and I'm not sure why.  I know there have been [thoughts to integrate dill into joblib itself](https://github.com/scikit-learn/scikit-learn/issues/5623).  And I'm curious to know if others have had similar experiences with dill or [cloudpickle](https://github.com/cloudpipe/cloudpickle).
[2016-10-27T06:44:05.589Z] <581195aed73408ce4f3124fe> @saket1192 can anyone help me out with NLTK python i got hindi POS tagger and Hindi parser ,but I am not able to excess it. m new to this so i need some help for my in-house project 
[2016-10-27T15:28:55.901Z] <53135b495e986b0712efc453> Andy, for #7724, do you want me to send a PR to his branch to speed up the process?
[2016-10-27T15:28:57.579Z] <53135b495e986b0712efc453> @amueller 
[2016-10-27T15:29:48.321Z] <54d4a1d6db8155e6700f853b> @raghavrv hm not sure. I mean I'd like to finish up this week, but there is no super rush
[2016-10-27T15:51:58.639Z] <53135b495e986b0712efc453> Okie so I'll clean up that as a test, comment there and wait for him to make the changes. If it still remains at the end of the week unaddressed, ping me so I can carry forward the work...
[2016-10-27T15:52:09.749Z] <54d4a1d6db8155e6700f853b> ok cool
[2016-10-27T22:24:24.693Z] <53135b495e986b0712efc453> Anyone here wants to pick up an easy doc issue? - #7772 
[2016-10-28T05:01:27.076Z] <56a34c16e610378809bdc988> @raghavrv Please have a look at #7776 :)
[2016-10-28T05:03:40.253Z] <56a34c16e610378809bdc988> Oops, #7775 was submitted just seven minutes before mine and it solves the same issue :sweat_smile: Feel free to close mine if it works out well !
[2016-10-28T11:58:07.722Z] <53135b495e986b0712efc453> @karandesai-96 Thanks for the PR :)
[2016-10-28T13:15:44.043Z] <56a34c16e610378809bdc988> @raghavrv my pleasure :) on a similar note, i have one more PR which needs review ( #7655 )
[2016-10-30T13:35:41.156Z] <53135b495e986b0712efc453> Have done some review. Let me know once you address them! 
[2016-10-30T17:35:02.108Z] <56a34c16e610378809bdc988> @raghavrv thanks, also I just checked out - #7775 was closed for some reason. Let me know if #7776 needs to be reopened again :smile: 
[2016-10-31T04:48:59.088Z] <56c4f19ae610378809c1f8ae> hi everyone
[2016-10-31T04:49:26.542Z] <56c4f19ae610378809c1f8ae> I want to apply the elastic net to do sparse feature selection on my data, but I only want a subset of the features to be regularized (and the rest of the features to be unregularized)
[2016-10-31T04:49:39.426Z] <56c4f19ae610378809c1f8ae> theres probably nothing that supports this right now in scikit-learn, right?
[2016-10-31T04:49:52.568Z] <56c4f19ae610378809c1f8ae> not too keen on re-implementing the algorithms myself haha, so Id figure Id ask.
[2016-10-31T04:55:58.361Z] <56c4f19ae610378809c1f8ae> I also find it interesting that the elastic net is not mentioned anywhere on the [feature selection page](http://scikit-learn.org/stable/modules/feature_selection.html), since it tends to avoid the problem that the lasso has of selecting an individual variable out of a group of highly correlated features...
[2016-10-31T09:39:50.565Z] <5626239616b6c7089cb79f22> #7659 and #7671 sould be closed
[2016-10-31T14:35:22.285Z] <56c4f19ae610378809c1f8ae> @waterponey you should comment that on the original PRs, gitter is fairly low-visibility
[2016-10-31T15:37:28.176Z] <55d21ee30fc9f982beadabb8> @amueller I wonder if you could give a look to #6509
[2016-10-31T15:38:05.836Z] <54d4a1d6db8155e6700f853b> @glemaitre I'm crazy busy today and tomorrow (ending a job today, starting a new tomorrow). I'll try to catch up with the issue tracker soon but feel free to ping me again.
[2016-10-31T15:39:23.661Z] <55d21ee30fc9f982beadabb8> ok np
[2016-10-31T15:39:55.790Z] <5759dd0dc2f0db084a1d128d> @amueller what's the convention when two PR are opened for the same bug?
[2016-10-31T15:40:37.983Z] <5759dd0dc2f0db084a1d128d> It's a minor one... very very very minor documentation issue.
[2016-10-31T15:40:42.840Z] <54d4a1d6db8155e6700f853b> @NelleV you tell them both and maybe give a recommendation on which offers a better solution?
[2016-10-31T15:41:06.706Z] <54d4a1d6db8155e6700f853b> @NelleV if they are both ready to merge, merge one and explain / apologize to the other?
[2016-10-31T15:41:11.501Z] <5759dd0dc2f0db084a1d128d> :D
[2016-10-31T15:41:30.789Z] <54d4a1d6db8155e6700f853b> If you have a better idea, I'm all ears
[2016-10-31T15:41:32.753Z] <5759dd0dc2f0db084a1d128d> well, there is a second reviewer needed, if you'd like to review two 2-liners documentation change
[2016-10-31T15:41:44.414Z] <54d4a1d6db8155e6700f853b> sure
[2016-10-31T15:42:03.169Z] <5759dd0dc2f0db084a1d128d> #7783 and #7784
[2016-10-31T15:42:17.624Z] <5759dd0dc2f0db084a1d128d> The first one is better.
[2016-10-31T15:45:05.775Z] <54d4a1d6db8155e6700f853b> the first one is also first.  this can be merged with one review as minor docs.
[2016-10-31T15:48:13.586Z] <54d4a1d6db8155e6700f853b> I think we try a mixture of nice and pragmatic
[2016-10-31T15:48:46.570Z] <5759dd0dc2f0db084a1d128d> That's what I figured
[2016-10-31T19:43:08.754Z] <54d4a1d6db8155e6700f853b> are the scipy docs down or is it just me? https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html
[2016-10-31T20:09:03.357Z] <55d21ee30fc9f982beadabb8> @amueller It is down
[2016-11-01T00:19:33.995Z] <57ca533e40f3a6eec0631e0c> what is the best  external  PCIe Box where i can use titan X. I have mac book pro 2009 model. 
[2016-11-01T15:41:11.003Z] <574454a0c43b8c601974a563> @amueller Today the docs are back online.
[2016-11-01T15:56:07.075Z] <574454a0c43b8c601974a563> <unconvertable> Transpile trained scikit-learn models to a low-level programming language like C, Java, JavaScript or Go with https://github.com/nok/sklearn-porter :smile:
[2016-11-01T18:07:50.727Z] <54dea33315522ed4b3dc0092> Hello, Need some help with this:  I'm working on a project where I'm creating a spam classifier (instagram photos) I have features from the user and features from the content, would you combine all data knowing that there are multiple photos from the same users. Thank you! 
[2016-11-02T12:21:49.463Z] <53135b495e986b0712efc453> @amueller Could we just have the `return self` fix refactored out of #6141 for 0.18.1?
[2016-11-02T17:54:06.411Z] <5761eefbc2f0db084a1e1a53> @nok  something I've been looking for!
[2016-11-02T22:14:56.891Z] <574454a0c43b8c601974a563> @tonnamb Ty!
[2016-11-02T22:59:39.002Z] <57fed465d73408ce4f2dd5f6> Hey everyone, with sklearn.metrics.roc_curve, is there a way to manually specify the thresholds/cutoffs I want to test at?
[2016-11-03T12:22:06.339Z] <5770c02dc2f0db084a2017bd> Hey guys. Can someone help with this error I get
[2016-11-03T12:22:10.915Z] <5770c02dc2f0db084a2017bd>  when I do : `>>> dataset = fetch_mldata('MNIST original'` any idea why I get this error: OSError: could not read bytes the .mat file downloaded, it has 1498112 lines
[2016-11-03T12:22:35.848Z] <5770c02dc2f0db084a2017bd> The error itself is : `OSError: could not read bytes`
[2016-11-03T12:29:10.226Z] <5770c02dc2f0db084a2017bd> I tried : ```dataset = fetch_mldata('MNIST original', data_home='/Users/myname/Virtualenv/virt1/lib/python3.5/site-packages/sklearn/datasets/')``` aswell
[2016-11-03T17:16:40.143Z] <56c4f19ae610378809c1f8ae> the cached data might be corrupted
[2016-11-03T17:16:54.181Z] <56c4f19ae610378809c1f8ae> try removing downloaded files and trying again
[2016-11-03T19:03:17.297Z] <57475b90c43b8c601975254f> Are Pandas dataframes supported for use in scikit-neuralnetwork?  It appears so, via the Lasagne implementation according to https://recordnotfound.com/scikit-neuralnetwork-aigamedev-8422   but I keep getting errors when using a Pandas dataframe in sknn.
[2016-11-03T23:05:32.849Z] <56c4f19ae610378809c1f8ae> @cpoptic this room is for scikit-learn, and the developers of scikit-learn arent involved in scikit-neuralnetwork. youd probably be better off asking your question in the scikit-neuralnetwork gitter (if there is one) or raising an issue on their github repo / posting to stackoverflow
[2016-11-04T23:29:04.335Z] <57475b90c43b8c601975254f> @nelson-liu  Thanks, I checked and there is no scikit-neuralnetwork gitter channel, and haven't gotten an answer to this issue when I asked on the github, but I'll post to StackOverflow.  Thanks
[2016-11-07T13:13:06.741Z] <53135b495e986b0712efc453> @amueller Do you want #7812 into 0.18.1?
[2016-11-07T14:26:51.227Z] <53135b495e986b0712efc453> Also should we move #7627 out of 0.18.1 into 0.19?
[2016-11-07T14:38:09.640Z] <53135b495e986b0712efc453> Also #7544 and #7173?
[2016-11-09T07:41:22.383Z] <55e7596f0fc9f982beaf75b6> Hello, I've proposed a project for chromosomes segmentation : https://github.com/jeanpat/DeepFISH . Up to now there are datasets (82146 images+ground-truth labels) and python notebooks (way to generate datasets, scikit-image based). The notebooks could be better:  the size of the datasets are limited by the amount of RAM. The datasets are waiting to train a classifier.
[2016-11-10T08:55:56.275Z] <56b38569e610378809bfe274> Completely new to contributing to sklearn. Is there a recommended contributions guide? Considering fixing the memory issues with bh-tsne.
[2016-11-10T18:12:26.227Z] <56c4f19ae610378809c1f8ae> @hvaara http://scikit-learn.org/dev/developers/contributing.html#contributing
[2016-11-10T19:17:07.054Z] <5824bf65d73408ce4f350625> Hi, I'm new with machine learning, do you can help me for information?
[2016-11-11T11:16:56.773Z] <55d054b70fc9f982bead8af7> Hi forks, I am trying import ```from sklearn.model_selection import cross_val_score``` but it had an error ```ImportError: No module named 'sklearn.model_selection'``` and I installed scikit-learn package but I don't know what matter for me , I cannot import this module to my project. I am using python 3.5. Can you help me ? Many thanks :D 
[2016-11-12T16:50:15.767Z] <576e76e2c2f0db084a1fdb14> @khanhnguyenneka you have to update your `scikit-learn` installation to 0.18.x version
[2016-11-14T03:07:56.191Z] <5827d866d73408ce4f3575e6> @VictorArias24 Hi, Victor! For some basics you can refer to: http://scikit-learn.org/stable/tutorial/basic/tutorial.html hope it helps!
[2016-11-14T10:16:47.152Z] <5730c2dcc43b8c601971eca1> Just wondering if anybody in Scikit Community has already worked on Recurrent Decision Tree implementation ?
[2016-11-17T11:12:41.621Z] <564789be16b6c7089cbab8b7> Does https://github.com/scikit-learn/scikit-learn/milestone/22 need updating?
[2016-11-17T11:46:16.189Z] <54c80b5ddb8155e6700f2708> Hi! Does anyone know how to show percentage of similarity of predicted data to one of train data?
[2016-11-17T11:46:53.117Z] <54c80b5ddb8155e6700f2708> And how to group train data by labels?
[2016-11-17T11:46:56.222Z] <54c80b5ddb8155e6700f2708> thanks
[2016-11-18T05:49:09.682Z] <580500d6d73408ce4f2ee055> Hi
[2016-11-18T16:11:27.979Z] <55a36aae5e0d51bd787b33cd> Hello, I'm not sure what metric my cross_val_score uses. The estimator is a RF regressor, and I leave the scorer for cross_val_score at None. Does that mean I get R^2? Because I somehow have an R^2 of minus 300 then ...
[2016-11-21T20:01:27.158Z] <543d7fd1db8155e6700cb700> I'm also running into an issue downloading datasets with `datasets.fetch_mldata()` (cc @RohanVB)
[2016-11-21T20:02:06.572Z] <543d7fd1db8155e6700cb700> urlopen() fails with a "Connection reset by peer", though downloading the same URL with curl works (but curl --verbose shows a warning)
[2016-11-21T20:02:31.430Z] <543d7fd1db8155e6700cb700> Did mldata.org change their server, and it now does something weird with HTTP that Python's urllib2 can't handle?
[2016-11-21T20:04:19.134Z] <543d7fd1db8155e6700cb700> ``` $ curl -LI -X GET http://mldata.org/repository/data/download/matlab/mnist-original HTTP/1.0 301 MOVED PERMANENTLY Date: Mon, 21 Nov 2016 20:03:05 GMT Content-Type: text/html; charset=utf-8 Location: http://mldata.org/repository/data/download/matlab/mnist-original/ Server: fapws3/0.9  HTTP/1.0 200 OK Content-Length: 55440440 Content-Disposition: attachment; filename=mnist-original.mat Vary: Cookie Server: fapws3/0.9 Date: Mon, 21 Nov 2016 20:03:05 GMT Content-Type: application/x-matlab  $ python -c 'import sklearn.datasets; sklearn.datasets.fetch_mldata("MNIST original")' Traceback (most recent call last):   File "<string>", line 1, in <module>   File "/home/vagrant/.virtualenvs/digits-sklearn-opencv/local/lib/python2.7/site-packages/sklearn/datasets/mldata.py", line 143, in fetch_mldata     mldata_url = urlopen(urlname)   File "/usr/lib/python2.7/urllib2.py", line 154, in urlopen     return opener.open(url, data, timeout)   File "/usr/lib/python2.7/urllib2.py", line 435, in open     response = meth(req, response)   File "/usr/lib/python2.7/urllib2.py", line 548, in http_response     'http', request, response, code, msg, hdrs)   File "/usr/lib/python2.7/urllib2.py", line 467, in error     result = self._call_chain(*args)   File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain     result = func(*args)   File "/usr/lib/python2.7/urllib2.py", line 651, in http_error_302     fp.read()   File "/usr/lib/python2.7/socket.py", line 355, in read     data = self._sock.recv(rbufsize)   File "/usr/lib/python2.7/httplib.py", line 612, in read     s = self.fp.read(amt)   File "/usr/lib/python2.7/socket.py", line 384, in read     data = self._sock.recv(left) socket.error: [Errno 104] Connection reset by peer ```
[2016-11-21T20:14:15.610Z] <543d7fd1db8155e6700cb700> Wow now I'm seeing "Connection reset by peer" from curl as well. I'll just try and self-host that somewhere, if I can ever grab it
[2016-11-21T20:22:33.916Z] <543d7fd1db8155e6700cb700> There is no way to load a MATLAB mldata file from a different URL though, is there?
[2016-11-21T21:25:35.135Z] <574454a0c43b8c601974a563> Today I found https://github.com/scikit-learn-contrib/scikit-learn-contrib , is it possible to add https://github.com/nok/sklearn-porter ? But it isn't an estimator like one of the listed examples. Who can help me?
[2016-11-23T00:14:05.344Z] <574c6042c43b8c601975bcdb> Hi guys. I'm a beginning undergrad researcher in data science and trying to run scikits svm model on 500k models.
[2016-11-23T00:14:08.440Z] <574c6042c43b8c601975bcdb> rows*
[2016-11-23T00:14:28.026Z] <574c6042c43b8c601975bcdb> It's taking 5 terms of life to complete. Can someone help point me in the right direction for how I should apporoach this?
[2016-11-23T01:58:17.125Z] <54dea33315522ed4b3dc0092> @Schachte Try using linearSVM instead of SVC, you can see in the documentation the following  The implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples. 
[2016-11-23T03:20:07.811Z] <574c6042c43b8c601975bcdb> hi @firetix , thanks a lot. I ran this and it completes very quickly now. Can you explain how the testing works with the clf-score?
[2016-11-23T03:20:23.729Z] <574c6042c43b8c601975bcdb> @firetix does it automatically just split the input data into test/train for me?
[2016-11-23T18:41:31.173Z] <54dea33315522ed4b3dc0092> @Schachte it works the same way as an SVC you will have to do the split yourself and then call .score or run f1 evaluation 
[2016-11-27T05:27:14.829Z] <583a6e71d73408ce4f38e30d> I'm a newbie, so please pardon what might be a very simple / silly question.  I'm wondering whether the example code for various sample problems posted on the scikit-learn website are done in Python 2 or Python 3?
[2016-11-27T20:00:50.493Z] <56c4f19ae610378809c1f8ae> @FLalani should be compatible with both 
[2016-11-27T20:02:13.458Z] <56c4f19ae610378809c1f8ae> @nok contact the scikit-learn contrib folks about that. I think the proper procedure is to raise an issue on their repo, but I'm not sure.
[2016-11-27T20:04:01.009Z] <574454a0c43b8c601974a563> Thanks @nelson-liu 
[2016-11-27T23:07:04.786Z] <583a6e71d73408ce4f38e30d> @nelson-liu:  Thanks!  It did indeed run with no exceptions on Python 2.7 after my comment so I can at least verify Python 2.  Thanks again.
[2016-11-29T07:59:12.269Z] <583d3402d73408ce4f3962b6> Hi, i am running into some really wierd behavior on gridsearchCV on an ESXI host. Although number of jobs is set to a fixed number, the spawned pythonw.exe will claim all available cores after the 2nd-3th task iteration and run into some sort of infinite loop
[2016-11-30T16:35:51.894Z] <56ed0b8885d51f252ab9a1b8> Hi everyone,please is it possible to join two image feature vectors as a vector and use it to train a model for classification (example is raw pixel feature vector and color histogram feature vector of an image).I would appreciate your help, thank you.
[2016-12-02T20:26:15.303Z] <55901c1b15522ed4b3e2f949> @Ben-Kobby can't you just concatenate the two vectors together?
[2016-12-04T05:10:21.998Z] <5770c02dc2f0db084a2017bd> @remram44 I attained a fix if its still required.
[2016-12-04T05:10:40.637Z] <5770c02dc2f0db084a2017bd> I'll have to look into my code to see exactly what I did, ping me if you need it.
[2016-12-06T14:34:53.956Z] <57a061aa40f3a6eec05d8d26> Is there any post-pruning implementation in scikit for decision trees? 
[2016-12-06T16:20:19.339Z] <57781008c2f0db084a211eda> Any suggestions for how to implement handwriitten signature verification in Python ?
[2016-12-06T17:13:23.056Z] <530c03e25e986b0712efafb8> General question, why haven't tensor factorizations (like Parafac, Tucker) become more widely adopted?  (or, are they widely adopted and I'm not aware?)
[2016-12-06T17:43:43.096Z] <530c03e25e986b0712efafb8> (I apologize for being somewhat off topic here)
[2016-12-07T17:23:09.244Z] <54d4a1d6db8155e6700f853b> @mrocklin they will be. For what application were you thinking?
[2016-12-07T17:24:08.398Z] <54d4a1d6db8155e6700f853b> wow I haven't been here in a while.. whoops
[2016-12-07T17:42:36.150Z] <530c03e25e986b0712efafb8> They've been around for a long while, why the delay?  And more importantly, why the optimism?
[2016-12-07T17:43:09.841Z] <54d4a1d6db8155e6700f853b> in the context of machine learning they haven't been around that long, and I think for topic modeling for example they are only now becoming popular
[2016-12-07T17:43:15.274Z] <54d4a1d6db8155e6700f853b> they've been around for CRFs for a while
[2016-12-07T17:43:25.810Z] <54d4a1d6db8155e6700f853b> which applications / algorithms did you have in mind?
[2016-12-07T17:44:18.007Z] <530c03e25e986b0712efafb8> I've had a request to build implementations on top of dask.array.  I'm polling to see how much value there is to the general community.
[2016-12-07T17:45:04.387Z] <530c03e25e986b0712efafb8> If you happen to have strong opinions about the value of various algorithms I'd enjoy getting your thoughts.
[2016-12-08T11:25:10.066Z] <57a061aa40f3a6eec05d8d26> What does it mean, when I do grid search and in ther cv_results_ there's param_n_estimators, for example, and it's type is masked_array and then next to it, there's mask which is full of boolean false values?
[2016-12-09T16:04:41.521Z] <54d4a1d6db8155e6700f853b> @mrocklin can you share your application domain?
[2016-12-09T16:06:13.398Z] <54d4a1d6db8155e6700f853b> @mkoske it means none of the values is masked out
[2016-12-09T16:06:18.942Z] <54d4a1d6db8155e6700f853b> i.e. it's a normal full array
[2016-12-09T17:10:33.490Z] <530c03e25e986b0712efafb8> @amueller I genuinely don't know the application domain.  Government types are asking for a general library for tensor decompositions in Python.
[2016-12-09T17:11:28.189Z] <530c03e25e986b0712efafb8> Which, while that ignorance is somewhat suboptimal, also means that we get to build software for the common case.
[2016-12-09T17:11:40.890Z] <530c03e25e986b0712efafb8> (this is somewhat typical in my world)
[2016-12-09T17:11:57.580Z] <54d4a1d6db8155e6700f853b> huh alright
[2016-12-09T17:12:08.822Z] <54d4a1d6db8155e6700f853b> well in machine learning, tensor decomposition applications are somewhat "new"
[2016-12-09T17:14:53.963Z] <530c03e25e986b0712efafb8> Given the wiggle room, how would you direct my time to best benefit the community if other people were paying for it?
[2016-12-10T13:50:50.966Z] <57a061aa40f3a6eec05d8d26> In RandomForestClassifier, if the max_features is sqrt or log2, does it round it to nearest int or what?
[2016-12-11T13:48:47.188Z] <55d21ee30fc9f982beadabb8> @mkoske This is casted to an integer. Refer to [here](https://github.com/scikit-learn/scikit-learn/blob/b7e370244795c291fc8ac10686ce5867adde988e/sklearn/tree/tree.py#L211) for details.
[2016-12-11T18:35:58.116Z] <584d9ad9d73408ce4f3c4b46>  am asked to only stimulate a smart device in c++ that could belong to the IOT. Although, I am not entirely sure what to choose. I have been given an example such as a weather device, also it is to produced data by 3 (simulated) sensors. For example the weather device, may register data from temperature, air pressure and wind speed sensors. Any ideas on a device i could choose?
[2016-12-11T18:58:29.192Z] <57a061aa40f3a6eec05d8d26> @glemaitre, thanks
[2016-12-12T16:37:35.694Z] <54d4a1d6db8155e6700f853b> @mrocklin I talked to the person working on tensor factorization for LDA. That woudl be nice but I think they said it's not really ready yet. So I'm not sure there is a killer application. Maybe check out http://www.cs.columbia.edu/~djhsu/papers/power-jmlr.pdf
[2016-12-13T13:16:33.057Z] <57a061aa40f3a6eec05d8d26> Hello, what's the difference between mean_test_score and mean_train_score in GridSearchCV.cv\_results_?
[2016-12-13T15:32:20.618Z] <54d4a1d6db8155e6700f853b> they are the mean of the score on the training folds vs the hold-out folds
[2016-12-13T15:32:28.001Z] <54d4a1d6db8155e6700f853b> @mkoske 
[2016-12-13T15:46:43.726Z] <57a061aa40f3a6eec05d8d26> @amueller So hold-out folds means, that if I use e.g. 10-fold cross validation, there's 10 hold-out folds, i.e. dataset is split into 10 and then the model is trained on 9 of those and one is used for testing . And this is repeated until every one of those 10 is used as testing. Right?
[2016-12-13T15:46:56.389Z] <54d4a1d6db8155e6700f853b> yes
[2016-12-13T15:48:49.729Z] <57a061aa40f3a6eec05d8d26> ok, so that part I understood
[2016-12-13T15:49:16.825Z] <57a061aa40f3a6eec05d8d26> what is the training score then? 
[2016-12-13T15:49:31.158Z] <54d4a1d6db8155e6700f853b> scores are computed for each of the 10 iterations
[2016-12-13T15:49:49.982Z] <54d4a1d6db8155e6700f853b> and each iteration has a 9 folds that the model is trained on and one that it is tested on
[2016-12-13T15:50:01.437Z] <54d4a1d6db8155e6700f853b> the training score is the score on the training set, i.e. the 9 folds
[2016-12-13T15:53:56.798Z] <57a061aa40f3a6eec05d8d26> So, is the model is evaluated on those 9 folds too, at same iteration?
[2016-12-13T15:54:24.761Z] <54d4a1d6db8155e6700f853b> yes. training score meaning the data it was trained on
[2016-12-13T16:01:41.410Z] <57a061aa40f3a6eec05d8d26> Ok, I'll recap so I make sure I understood correctly :) In my example, one iteration consists of building the model on 9 folds and testing it with both those 9 folds and hold-out data. Is this correct?
[2016-12-13T16:01:54.066Z] <54d4a1d6db8155e6700f853b> yes
[2016-12-13T16:02:00.960Z] <54d4a1d6db8155e6700f853b> only the hold-out test score is used to select the model
[2016-12-13T16:02:15.262Z] <54d4a1d6db8155e6700f853b> the training score is good monitor overfitting / underfitting
[2016-12-13T16:02:48.596Z] <57a061aa40f3a6eec05d8d26> Ok, thanks for help
[2016-12-13T16:03:28.844Z] <57a061aa40f3a6eec05d8d26> Hm, you mean that if training score is high and test score is much smaller, then it overfits?
[2016-12-13T16:04:10.503Z] <54d4a1d6db8155e6700f853b> well if there is a large gap then you might want to regularize more. if there is a very small gap you might want to try a more complex model
[2016-12-13T16:14:01.518Z] <57a061aa40f3a6eec05d8d26> One more question. When I run my script, Parallel reported that it took almost 3hours to complete. But when I sum all the fit and score times from GridSearchCV.cv\_results\_, the sum is significantly lower. Why? Is it that Parallel reports the total time my script was running and GridSearchCV exact times that scoring and fitting took?
[2016-12-13T16:16:19.398Z] <54d4a1d6db8155e6700f853b> can't say without looking at your script
[2016-12-13T17:13:25.593Z] <57a061aa40f3a6eec05d8d26> @amueller nothing special, something like this: https://gist.github.com/mkoske/1f9b92b3f214260278ea115507cea72d
[2016-12-13T17:13:49.845Z] <57a061aa40f3a6eec05d8d26> I use Jupyter Notebook and it shows some timing information on red background
[2016-12-13T17:19:44.541Z] <57a061aa40f3a6eec05d8d26> I updated that gist to contain example similar to my use case.
[2016-12-13T17:22:14.962Z] <57a061aa40f3a6eec05d8d26> I also updated my comment on that gist to explain
[2016-12-13T18:33:47.225Z] <54d4a1d6db8155e6700f853b> sorry not sure
[2016-12-13T18:33:57.639Z] <54d4a1d6db8155e6700f853b> I don't have time to look into it right now
[2016-12-13T20:11:47.632Z] <57a061aa40f3a6eec05d8d26> @amueller ok, thanks anyway
[2016-12-16T18:35:53.704Z] <544906e2db8155e6700cdd16> Hi everyone! I'm doing some research on hyperparameter optimization and I felt very impressed by the technique shown in this tutorial by @ogrisel  https://www.youtube.com/watch?v=iFkRt3BCctg Do you recommend any similar package or any library that implement that technique? I was playing with GridSearchCV and RandomizedSearchCV optimizers but those seem to be less interactive versions of the one in the tutorial (more "blackbox")
[2016-12-20T05:08:41.079Z] <5634e15116b6c7089cb8f9f2> Hi all, how would I do knowledge representation in SKL?
[2016-12-20T05:11:20.034Z] <57714f9ec2f0db084a203010> Can someone explain what hyperparameter optimization? 
[2016-12-20T11:17:42.135Z] <584ae429d73408ce4f3bed37> Hello everyone I wanted to contribute. Can anybody help me how to do so????
[2016-12-20T11:28:16.171Z] <584ae429d73408ce4f3bed37> I have knowledge of ML and R but am completely new to scikit-learn
[2016-12-20T17:42:08.241Z] <54d4a1d6db8155e6700f853b> Abinash check out the contributor docs on the website
[2016-12-21T02:10:57.555Z] <562a7da216b6c7089cb80965> I apologize for a rather naive python question, but I've forked sklearn, made some local changes introducing new functinoality, committed them, and now want to use my modified sklearn in a test project. Should I manipulate sys.path to import my modified sklearn? Do I need to run `make` in it first? Do I need to re-run `make` if I edit sklearn again? Or should I be running `make` as in [here](http://scikit-learn.org/stable/developers/advanced_installation.html#testing-scikit-learn-from-within-the-source-folder)?
[2016-12-21T02:16:23.071Z] <553d32d715522ed4b3df8b92> Hi, I suppose the last link would be better in case you are okay to use dev version for all purposes. I 
[2016-12-21T02:18:55.448Z] <553d32d715522ed4b3df8b92> Sorry sent message early. I use ``python setup.py develop``. In case you want both stable and dev versions, it would be better to use virtualenv to create a virtual environment for working on dev. hope it helps.
[2016-12-21T02:24:03.070Z] <562a7da216b6c7089cb80965> Ah, great idea RE virtualenv; thanks!
[2016-12-21T02:25:13.830Z] <553d32d715522ed4b3df8b92> Sure Anytime :+1: 
[2016-12-21T02:45:49.562Z] <584ae429d73408ce4f3bed37> Thanks  @amueller  :smile: 
[2016-12-21T04:58:33.103Z] <578b5ed1c2f0db084a235992> I am having some trouble getting an MLPRegressor sample to work. Any hints or pointers appreciated. Thank you. 
[2016-12-21T04:59:32.395Z] <578b5ed1c2f0db084a235992> P
[2016-12-21T05:05:14.942Z] <578b5ed1c2f0db084a235992> http://stackoverflow.com/questions/41069905/trouble-fitting-simple-data-with-mlpregressor
[2016-12-23T11:09:40.086Z] <5757de1ec43b8c6019787b6c> Is it possible to write wrapper on python code to use it in Java , for NER Purpose ?
[2016-12-24T11:34:58.029Z] <585e5cecd73408ce4f3f162e> I am using a decision tree to classify my data. Using scikit-learn, how do i load my own dataset? Unable to understand it in scikit-learn.org where they talk about loading from external datasets. Any help would be appreciated
[2016-12-24T12:32:31.489Z] <585e5cecd73408ce4f3f162e> Anyoone?? My dataset is this format:  Day Outlook Temp Humidity Wind Play 1 Sunny Hot High Weak No 2 Sunny Hot High Strong No 3 Overcast Hot High Weak Yes 4 Rain Mild High Weak Yes 5 Rain Cool Normal Weak Yes 6 Rain Cool Normal Strong No 7 Overcast Cool Normal Strong Yes 8 Sunny Mild High Weak No 9 Sunny Cool Normal Weak Yes 10 Rain Mild Normal Weak Yes 11 Sunny Mild Normal Strong Yes 12 Overcast Mild High Strong Yes 13 Overcast Hot Normal Weak Yes 14 Rain Mild High Strong No
[2016-12-24T12:56:40.011Z] <553d32d715522ed4b3df8b92> Hi, in case your data is in a CSV or test file, you can use [`numpy.load_txt`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) and [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) and then use the scikit learn DecisionTreeClassifier for classification. Hope it helps.
[2016-12-27T13:34:00.296Z] <5808a180d73408ce4f2f919f> Hey guys, I hope you can help me out
[2016-12-27T13:34:34.294Z] <5808a180d73408ce4f2f919f> I want to train a random forest regressor, and my features are mainly categorical
[2016-12-27T13:35:10.075Z] <5808a180d73408ce4f2f919f> The thing is, the amount of possible labels per example is variable, so I can't easily dump it in a CSV
[2016-12-27T13:35:26.483Z] <5808a180d73408ce4f2f919f> I tried creating a 1-hot encoded CSV but that would result in a ~50GB file
[2016-12-27T13:36:02.076Z] <5808a180d73408ce4f2f919f> So what I want is saving my label-encoded values in some data format (maybe JSON, which supports arrays), and one-hot encoding on the fly during training
[2016-12-27T13:36:23.650Z] <5808a180d73408ce4f2f919f> I'm not sure where to start though, any clues?
[2016-12-27T14:09:23.597Z] <5808a180d73408ce4f2f919f> Hmm I guess scipy sparse matrices could help me here, then I just need to find a good file format
[2016-12-27T15:50:47.065Z] <572cc82bc43b8c6019718138> Hello everyone! My name is Samriddhi Sinha. I am interested in contributing to this project. I have been working with various Machine Learning algorithms an have participated in a few Data Analytics competitions. Can some one help me getting started?
[2016-12-29T11:22:58.263Z] <55d21ee30fc9f982beadabb8> @djokester You can check out the [contributors guide](http://scikit-learn.org/stable/developers/contributing.html)
[2016-12-30T17:25:36.519Z] <57a061aa40f3a6eec05d8d26> Hello, what's the feature importance implemented in trees / ensembles? Is it Gini-importance or what?
[2016-12-30T17:38:18.846Z] <57a061aa40f3a6eec05d8d26> At least DecisionTreeClassifier documentation says Gini importance
[2017-01-03T18:31:56.269Z] <54d4a1d6db8155e6700f853b> @mkoske depends on the criterion ;)
[2017-01-03T18:32:43.045Z] <54d4a1d6db8155e6700f853b> hm I can't build master because of some C++ linking issues :-/
[2017-01-03T18:38:21.939Z] <54d4a1d6db8155e6700f853b> ah right, I had that issue before on another box https://github.com/scikit-learn/scikit-learn/issues/7869
[2017-01-04T03:32:54.971Z] <58183b57d73408ce4f323e33> Does anyone know what is the precision used in metrics calculation in sklearn. I'm asking because I see significant differences in calculated metrics between sklearn and xgboost which might be occuring due to precision issues.
[2017-01-05T04:32:00.770Z] <56a34c16e610378809bdc988> Hi, is #7319 (Move to py.test) still under consideration as gsoc '17 project ? I pinged there earlier to work on it but realised that it is not that small to do within a week or two. I migrated joblib's testing framework from nose to py.test and am willing to take up the same here :smile: 
[2017-01-06T15:05:51.639Z] <55a36f535e0d51bd787b3400> Hi all. Is there a plan for making `cross_val_score` accept multidimensional scoring metrics (i.e. a scorer that returns an array rather than a float)? I see that #7388 may be related, but IIUC it mainly to compare different metrics.
[2017-01-10T20:14:40.792Z] <54d4a1d6db8155e6700f853b> @kingjr There is an intend. I'm not sure I'd say there is a plan. I haven't caught up with #7388 and I'm not sure whether it will include returning arrays, probably not
[2017-01-10T20:15:15.026Z] <54d4a1d6db8155e6700f853b> @karandesai-96 yes, it's still a possible project. I'm not sure who would be mentoring, though.
[2017-01-10T20:15:34.190Z] <54d4a1d6db8155e6700f853b> @nareshshah139 which metric?
[2017-01-11T20:45:10.676Z] <57ab24e040f3a6eec05ec701> I posted a question on Stack Overflow related to preprocessing-scaling my features taking the logarithm but column-based as with the `MaxAbsScaler` -- Question: http://stackoverflow.com/questions/41600349/scale-apply-function-sparse-matrix-logarithmically
[2017-01-11T20:45:29.135Z] <57ab24e040f3a6eec05ec701> Any help is much appreciated <unconvertable>
[2017-01-12T03:54:14.736Z] <56a34c16e610378809bdc988> @amueller Loic Esteve reviewed 20 of my PRs on joblib. :) We would probably complete by this weekend.
[2017-01-12T10:01:23.562Z] <57ab24e040f3a6eec05ec701> Thank you to scikit-learn contributors -- It seems to be a great community
[2017-01-16T15:09:45.419Z] <54d4a1d6db8155e6700f853b> @karandesai-96 sweet! Good you two!
[2017-01-16T16:47:07.693Z] <55a36f535e0d51bd787b3400> @amueller ok thanks
[2017-01-16T16:48:21.547Z] <5874edafd73408ce4f428857> Anybody recommend any starter guides for scikit-learn?
[2017-01-16T16:48:33.173Z] <5874edafd73408ce4f428857> Whats the best way to get into this?
[2017-01-16T16:48:33.950Z] <54d4a1d6db8155e6700f853b> @aquan9 my book ;)
[2017-01-16T16:48:44.989Z] <5874edafd73408ce4f428857> lol. What book?
[2017-01-16T16:48:49.956Z] <54d4a1d6db8155e6700f853b> or sebastians book?
[2017-01-16T16:49:03.664Z] <54d4a1d6db8155e6700f853b> https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413/ref=sr_1_1?ie=UTF8&qid=1479485017&sr=8-1&keywords=introduction+to+machine+learning+with+python
[2017-01-16T16:49:13.205Z] <54d4a1d6db8155e6700f853b> https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=pd_bxgy_14_img_2?_encoding=UTF8&psc=1&refRID=HA8X4W6W4KAK3RCZ7G85
[2017-01-16T16:49:22.605Z] <54d4a1d6db8155e6700f853b> (if you get mine, make sure it's the second print that just came out)
[2017-01-16T16:49:31.876Z] <54d4a1d6db8155e6700f853b> There's also a bunch of free tutorials linked on the website:
[2017-01-16T16:49:58.791Z] <5874edafd73408ce4f428857> Ok awesome thanks. 
[2017-01-16T16:50:00.193Z] <54d4a1d6db8155e6700f853b> http://scikit-learn.org/stable/presentations.html
[2017-01-16T16:50:26.510Z] <54d4a1d6db8155e6700f853b> what's your background?
[2017-01-16T16:50:28.392Z] <54d4a1d6db8155e6700f853b> my book is "no math". sebastians is "some math"
[2017-01-16T16:50:47.356Z] <54d4a1d6db8155e6700f853b> I recommend reading mine alongside bishops book or elements of statistical learning if your math-minded
[2017-01-16T16:50:47.570Z] <5874edafd73408ce4f428857> CS
[2017-01-16T16:50:57.481Z] <57ec309f40f3a6eec067e511> Just saw your update on the book. Congrats  @amueller 
[2017-01-16T16:51:13.065Z] <54d4a1d6db8155e6700f853b> thanks. it's mostly all the worst typos. 
[2017-01-16T16:51:24.774Z] <54d4a1d6db8155e6700f853b> And obviously someone pointed out something real bad just after it got finished lol
[2017-01-16T16:51:35.854Z] <57ec309f40f3a6eec067e511> :)
[2017-01-16T16:52:37.253Z] <54d4a1d6db8155e6700f853b> @aquan9 there's also a bunch of free tutorials on my website: amueller.github.io
[2017-01-16T16:58:56.255Z] <5874edafd73408ce4f428857> @amueller Thanks for the advice
[2017-01-16T17:02:21.914Z] <57ec309f40f3a6eec067e511> In the past I have also found the following book to be very helpful "Machine Learning- The Art and Science of Algorithms that Make Sense of Data". @amueller . Whats your opinion about the same @amueller ?
[2017-01-16T17:06:19.496Z] <54d4a1d6db8155e6700f853b> @pramitchoudhary haven't read that one. I like Max Kuhn's book though
[2017-01-17T06:24:35.427Z] <55b8f4510fc9f982beab69f3> **\[shubham4060\]** Hi,
[2017-01-17T06:27:53.857Z] <55b8f4510fc9f982beab69f3> **\[shubham4060\]** I am a 3rd year engineering currently pursuing Computer Science and Engineering department, IIT Kharagpur. i am really interested in this project and i really want to contribute. it would be very helpful if i could get some guidance on how to start. really looking forward to hearing from you.
[2017-01-17T09:37:43.781Z] <587de5b8d73408ce4f441152> hello, everybody, i'm coming
[2017-01-18T05:53:24.605Z] <55b8f4510fc9f982beab69f3> **\[madan96\]** Can anyone please explain me the reason for this error? Ref: https://travis-ci.org/sympy/sympy/jobs/192867768
[2017-01-18T06:31:17.633Z] <539f11a8a9176b500d1ce23e> @yhaddad, why are you echoing chats in the sympy room here?
[2017-01-18T07:23:59.333Z] <55b8f4510fc9f982beab69f3> **\[madan96\]** @jksuom I think the `elif` condition might resolve the issue.
[2017-01-26T10:04:12.588Z] <58033d49d73408ce4f2e92ba> Hi all ! I have some trouble with the MinMaxScaler, I m using it together with a keras model with input with 3 features and 1 output . my xdate is of shape (XX, 3) and output (XX,1) , I dont have any issue when calling scaler.fit_transform on both input and output training data
[2017-01-26T10:05:58.830Z] <58033d49d73408ce4f2e92ba> but when I try to call inverse_transform on my predictions I get errors like this : ValueError: non-broadcastable output operand with shape (18,1) doesn't match the broadcast shape (18,3) or ValueError: operands could not be broadcast together with shapes (18,) (3,) (18,) or ValueError: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,3)  (I tried so many reshape but nothing works as excepted :( )
[2017-01-26T10:10:20.489Z] <58033d49d73408ce4f2e92ba> Using a different scaler for input and output fixes the issue but is it the only solution? 
[2017-01-27T16:11:05.933Z] <588b6fe9d73408ce4f467366> @amueller is there  a reason that the new gaussian process classifier doesn't provide an error estimate on the fitted probability, similar to the gaussian process regressor?  I believe this can be done, similar as to how one would use the covariance matrix/Fisher information of logistic regression model to confidence bounds upon the fitted probabilities?  Thx in advance. 
[2017-01-28T08:10:56.652Z] <5729ef37c43b8c60197119b1> @amueller Are there any immediate plans on inproving clustering performance?  Thanks!
[2017-01-29T13:14:53.191Z] <580cd140d73408ce4f3039f6> Hi, is there any one with experience with Gaussian processes. Are 20 data points enough to fit a GP? Is there any way to overfit a GP?
[2017-01-29T15:49:45.049Z] <588b76ccd73408ce4f4674e7> iirc, I thought the "magic minimum" for gaussian  distributions was a sample of 30
[2017-01-31T11:16:20.030Z] <57a061aa40f3a6eec05d8d26> How fast or slow is SpasePCA? I have a dataset of size about 15000 x 500 and it seems to take quite a while
[2017-01-31T13:44:52.243Z] <54b4f2d1db8155e6700e99c0> Hey Folks, [Core question], is there a specific reason why `RandomForests` dont inherit from `BaseBagging`?
[2017-02-01T11:40:22.431Z] <5891ba54d73408ce4f476005> Does scikit have any ideas page for gsoc 2017?
[2017-02-01T18:33:45.907Z] <54d4a1d6db8155e6700f853b> not yet
[2017-02-01T18:34:14.269Z] <54d4a1d6db8155e6700f853b> @Djabbz things inherit when there's shared functionality. if there's not, there's no reason to inherit
[2017-02-01T19:31:18.857Z] <54b4f2d1db8155e6700e99c0> Thanks @amueller. But if you compare the code, there are a lot of similarities (not surprising given that RF are bagged random trees). My question is: is it done on purpose or is it a consequence of different persons working on different algorithms?
[2017-02-02T14:45:09.795Z] <579618a040f3a6eec05c5e42> Hey guys, I have a question regarding Gaussian process. It seems to me that is taking for ever to converge even with the n_jobs=-1 option. The data is very high dimensional. Any suggestions to speed up the convergence? Any tricks I should be aware of? Last but not least I've noticed that the option of `n_jobs=-1`is included only in a number of algorithms. Why was that the case? What is the logic behind it to include it only in a subset of the algorithms that scikit offers?
[2017-02-02T20:21:03.861Z] <5891ba54d73408ce4f476005> are there no newcomer issues to solve at https://github.com/scikit-learn/scikit-learn/issues
[2017-02-02T20:21:26.899Z] <5891ba54d73408ce4f476005> i want to start contributing here
[2017-02-07T22:26:21.385Z] <54d4a1d6db8155e6700f853b> check the "easy" tag
[2017-02-10T14:07:02.410Z] <589dc0e0d73408ce4f4968ce> Hi guys 
[2017-02-10T14:07:12.396Z] <589dc0e0d73408ce4f4968ce> is there anyone know C# ?
[2017-02-12T10:02:47.844Z] <5869f3ded73408ce4f4098f2> Are there any 13 year olds on
[2017-02-13T16:51:39.328Z] <56bb7a56e610378809c0cb2c> `@ThatGeoGuy:matrix.org` Hey all, was wondering if anyone had any thoughts regarding https://github.com/scikit-learn/scikit-learn/issues/4682. I've been thinking about  the issue more and the more I think about it, it seems the appropriate choice would be to change the covariance scaling in `MinCovDet` from `n` to `n-1`
[2017-02-13T16:52:17.984Z] <56bb7a56e610378809c0cb2c> `@ThatGeoGuy:matrix.org` Or, barring that, rename `mcd.covariance_` to `mcd.scatter_`, since covariance usually implies that you did `n-1` scaling
[2017-02-18T18:58:25.038Z] <570d67cb187bb6f0eadf268b> hey! quick question about LSTMs if someone has a minute 
[2017-02-19T13:52:40.885Z] <58a9a221d73408ce4f4b6740> Hello friends, first time on gitter so introduction: I am Shubham Bhardwaj 2nd year computer science undergrad from VIT Vellore. I mostly contributed on back end tasks using python in Google Developers Group-VIT. But I made a transition to Machine Learning this Winter after taking a course on UDACITY. Looking forward to working and learning from all. Thanks.
[2017-02-21T13:13:24.116Z] <58ab8421d73408ce4f4bbbb2> Hello everybody, I am new here! It is nice to be here ! Cheers
[2017-02-21T13:16:49.615Z] <58ab8421d73408ce4f4bbbb2> I have a question regarding applying the standardaization of the training set to a test set , for classification procedures. Do we repeat this 10 times for 10CV ? 
[2017-02-21T15:08:17.741Z] <58a9a221d73408ce4f4b6740> @faprz  5CV is also fine but 10CV feels like standard. You can claim your accuracy better. Lets dive in: If you have k=5. that is 5 folds what you do is to divide the data set into 5 sets of equal length say s1,s2.....s5. Now you take s1 as test s2...s5 as training set and check accuracy. Each of the set gets a chance to become a test set.Now you would get 5 accuracies- average it and get the mean accuracy. Usage: sometimes using a particular split you can get better results but in real world you model doesn't performs good. So try some splits and get the average it helps you see the truth.  
[2017-02-21T15:09:50.702Z] <58a9a221d73408ce4f4b6740> Yes 10 times.
[2017-02-21T16:14:31.176Z] <58ab8421d73408ce4f4bbbb2> @shubham0704 Thank you, do we apply the mean/std of the train set to the test for each fold ?
[2017-02-21T17:41:45.241Z] <58a9a221d73408ce4f4b6740> cannot get what you are trying to ask @faprz  can you describe what you are trying to say a little more elaborately.
[2017-02-21T19:20:19.135Z] <58ab8421d73408ce4f4bbbb2> Sure, I read that a prefered practise in pre processing is to standardize the train set and apply the configuration used for standardization to the test set before we test with the classifier. I wonder if we need to do this for each fold in 10CV.
[2017-02-22T18:01:52.352Z] <5759dd0dc2f0db084a1d128d> @amueller I was reading the docstring of the f-regression and I am wondering if what is written is not very misleading
[2017-02-22T18:03:46.781Z] <5759dd0dc2f0db084a1d128d> @amueller I would have to read the code to check, but I was very confused with the docstring, so I googled and I arrived on stack exchange: http://stats.stackexchange.com/questions/204141/difference-between-selecting-features-based-on-f-regression-and-based-on-r2
[2017-02-22T18:10:18.189Z] <5759dd0dc2f0db084a1d128d> @amueller To me, the docstring suggests that the code actually does p linear regressions, and looks for the significance of the parameter (usually, this is done by converting the  t-score/t-test), but it mentions and f-score and f-test which is usually used to compare nested models
[2017-02-22T18:10:29.892Z] <5759dd0dc2f0db084a1d128d> disclaimer: I have no clue what I talking about :D
[2017-02-22T18:25:17.766Z] <5759dd0dc2f0db084a1d128d> So I think the stack exchange link is misleading as well.
[2017-02-22T18:27:11.727Z] <5759dd0dc2f0db084a1d128d> In the specific case of scikit-learn's implementation, the f-score and t-score are identical (as we are comparing one model to the null), so it indeed boils down to selecting the features that are significantly correlated with the target. If the K-top features are selected, it is exactly what sure independance screening is about
[2017-02-22T23:01:54.999Z] <54bd5965db8155e6700ed583> Hi everyone. I have a problem that I would love to solve with scikit-learn, but cant seem to figure out how to crack it. Im hoping someone who knows a bit more about the package might have a quick answer.  I have a matrix $$X$$ that I want to factorize with sparse NMF as $$X = WH$$. I would like to use cross-validation to tune the hyperparameters (to wit, level of sparsity and # of components). Since the only place that $$X$$ shows up in the objective function for NMF is $$||X-WH||_F$$, I would imagine doing the cross validation in random folds, each time leaving out a random subset of the elements of  $$X$$ from the Forbenius norm, fitting the model, and then computing the reconstruction error on those elements. However I cant seem to find any way or think of a trick to do the fit on just a subset of the matrix (scikit-learns NMF algorithm doesnt seem to like it when I try to <unconvertable> leave out <unconvertable> some of the elements by setting them to `nan` :-P ). Is there any other route to accomplishing this within the package? 
[2017-02-24T21:16:02.637Z] <54d4a1d6db8155e6700f853b> @NelleV I'm probably not the right person to ask this either.  It's just an F-test, right? https://en.wikipedia.org/wiki/F-test
[2017-02-24T21:17:00.585Z] <54d4a1d6db8155e6700f853b> @jwittenbach have you checked out GridSearchCV? that does that automatically
[2017-02-24T21:17:15.452Z] <54d4a1d6db8155e6700f853b> you can use ShuffleSplit if you want random splits of the data
[2017-02-24T21:17:25.180Z] <54d4a1d6db8155e6700f853b> What's the objective that you want to use for selection?
[2017-02-24T21:17:59.999Z] <54d4a1d6db8155e6700f853b> If you want to do it manually, you shouldn't leave them out by setting them to NaN but by just subsetting the data and throwing out those rows.
[2017-02-24T21:23:36.655Z] <5759dd0dc2f0db084a1d128d> @amueller I am definitely not the right person to ask this, but f-tests are used to compare different models, while t-tests used for significance testing
[2017-02-24T21:24:22.455Z] <5759dd0dc2f0db084a1d128d> @amueller I *think* that in that specific case, the code compares 1 model (univariate regression model) versus the null (mean == 0), and thus it is identical
[2017-02-24T21:25:12.925Z] <5759dd0dc2f0db084a1d128d> @amueller now, as f-tests are often use to compare models, they can be use for feature selection by comparing linear models with covariate X1 and linear models with covariate X1 and X2.
[2017-02-24T21:26:22.795Z] <5759dd0dc2f0db084a1d128d> @amueller in practice, our f-regression does not do this, and thus I think the Stack exchange answer is wrong (though I would have to look at the code): our f-regression just fit univariate linear models, and rank them with the significance of the regression parameter (with is computed with a t-test)
[2017-02-24T21:26:28.117Z] <5759dd0dc2f0db084a1d128d> am I making any sense?
[2017-02-24T21:27:20.589Z] <5759dd0dc2f0db084a1d128d> now, I have recently realized that sure independance screening and our f-regression is the same. I think that might be worth mentioning somewhere, considering how widely used SIS is.
[2017-02-24T21:27:48.194Z] <54d4a1d6db8155e6700f853b> yes that makes sense. I haven't checked the code but sounds plausible
[2017-02-24T21:28:00.179Z] <54d4a1d6db8155e6700f853b> the f_regression and f_classif docs are pretty bad imho
[2017-02-24T21:28:23.558Z] <54d4a1d6db8155e6700f853b> I have not heard of SIS but that means nothing
[2017-02-24T21:28:29.755Z] <5759dd0dc2f0db084a1d128d> yep... I might work on that during the docathon :)
[2017-02-24T21:28:37.268Z] <54d4a1d6db8155e6700f853b> cool :)
[2017-02-24T21:29:52.288Z] <5759dd0dc2f0db084a1d128d> the sure independence screening paper is quite interesting. They don't make the link between the cross correlation and the significance of the linear regression of X on y (but it might be just that it is trivial for this community), but it gives a good intuition on why this works better for feature selection than lasso
[2017-02-24T21:30:06.911Z] <5759dd0dc2f0db084a1d128d> it has over 1000 citations
[2017-02-24T21:30:36.374Z] <54bd5965db8155e6700ed583> @amueller I guess my issue  is that I dont want to throw out entire rows, because that will change the shape of the factors ($$X = WH$$). I just want to hold out random elements during the fit (analogous to k-fold CV for regression) and then use the reconstruction error, i.e. $$\sum_{i, j \in S} (X_{ij} - (WH)_{ij})^2$$ (where $$S$$ is the subset of held-out elements), for the cross-validation
[2017-02-25T16:06:09.125Z] <54d4a1d6db8155e6700f853b> That's matrix completion with is not really easily supported by sklearn, because the algorithm doesn't deal with missing values. You could try fancyimpute or any from this list: https://www.quora.com/What-is-the-best-open-source-package-to-build-a-recommender-system-in-Python/answer/Xavier-Amatriain?srid=cgo
[2017-02-25T18:47:24.510Z] <54bd5965db8155e6700ed583> @amueller ok, thanks; that answers my question. I was just curious as to whether it  might be straightforward to do this in `scikit-learn` but I was just missing something obvious :)
[2017-02-27T11:10:26.257Z] <564789be16b6c7089cbab8b7> I noticed scikit-learn is taking part in GSoC. I was wondering if https://github.com/scikit-learn/scikit-learn/issues/5736 would make a nice projecet?
[2017-02-27T11:10:38.663Z] <564789be16b6c7089cbab8b7> it has the advantage not being too technical I think
[2017-02-27T12:49:06.271Z] <55d21ee30fc9f982beadabb8> @lesshaste The projects should be in line with the proposals specified there: https://github.com/scikit-learn/scikit-learn/wiki/Google-summer-of-code-(GSOC)-2017
[2017-02-27T20:13:22.152Z] <564789be16b6c7089cbab8b7> @glemaitre  OK thanks
[2017-02-28T01:36:31.192Z] <58a9a221d73408ce4f4b6740> @glemaitre  I have implemented a DecisionTree version in order to gain some insight regarding your fix #8458 .My approach during split is to remove the feature we split on and each child node doesn't contain that feature. But again we are going to have to look at say n-1 features .How did you overcome that. Your help can go a long way into helping me. Also I can make the code available to you. its actually from a book. Thanks.
[2017-02-28T16:06:32.526Z] <55d21ee30fc9f982beadabb8> @shubham0704 The idea is to keep a list of splitter and when scanning a feature, each sample is distributed to the given splitter to evaluate if this is a best split. Once the feature is scanned, all the potential splits have been evaluated with a single scan.
[2017-02-28T23:33:21.691Z] <58a9a221d73408ce4f4b6740> thanks @glemaitre .
[2017-03-01T12:55:40.769Z] <57a061aa40f3a6eec05d8d26> how much memory I need with PolynomialFeatures?
[2017-03-01T12:59:03.130Z] <57a061aa40f3a6eec05d8d26> I have data with shape (10374, 500) and I use interaction_only=True, but it gives me memory error
[2017-03-01T12:59:22.732Z] <57a061aa40f3a6eec05d8d26> I  think I have 8G limit for memory on that machine where I'm running it
[2017-03-01T15:24:38.516Z] <589b9e0fd73408ce4f490ba4> @mkoske Well, `PolynomialFeatures(degree=2, interaction_only=True).fit_transform(np.ones((1, 500)))`  generates an array with 125251 features, so if you do that for all of your 10374 rows, it would produce a ~10.4 GB array (64 bit floats) and 8 GB RAM wont be enough..
[2017-03-01T15:25:59.878Z] <57a061aa40f3a6eec05d8d26> @rth ok, thanks :) 
[2017-03-01T15:35:43.771Z] <57a061aa40f3a6eec05d8d26> if I use 32 bit floats, would that be half of it? like ~5GB?
[2017-03-01T16:14:29.280Z] <589b9e0fd73408ce4f490ba4> @mkoske True that could work..
[2017-03-02T14:37:23.423Z] <5634e15116b6c7089cb8f9f2> Hi all, I am having issues installing scipy for scikit-learn. Is winPython a good workaround?
[2017-03-02T15:55:12.252Z] <55d21ee30fc9f982beadabb8> @Ij888 I personally opted for conda.
[2017-03-02T15:57:00.849Z] <5634e15116b6c7089cb8f9f2> Okay thanks @glemaitre! Can I safely use pip and conda side by side?
[2017-03-02T15:57:18.431Z] <55d21ee30fc9f982beadabb8> pip is included in conda
[2017-03-02T15:57:33.177Z] <55d21ee30fc9f982beadabb8> I never add problem with up to now
[2017-03-02T16:24:03.839Z] <5634e15116b6c7089cb8f9f2> *thumbsUp
[2017-03-02T16:24:15.898Z] <5634e15116b6c7089cb8f9f2> Thanks a million
[2017-03-02T20:07:09.589Z] <5633b77d16b6c7089cb8e50e> I'm persisting a random forest classifier using joblib, and in another process loading it. If I use sample_weights in fit, when I load the model it produces all 0 predictions. If I turn off sample_weights and train, everything is fine. During kfold validation, both settings produce expected results. Any ideas?
[2017-03-02T20:11:15.384Z] <55d21ee30fc9f982beadabb8> @ccarter-cs If this is something that you can reproduce with a simple snippet
[2017-03-02T20:11:20.876Z] <55d21ee30fc9f982beadabb8> you can open an issue
[2017-03-02T20:12:12.843Z] <5633b77d16b6c7089cb8e50e> @glemaitre Alright, I'll try to minimize. Was just wanting a spot check. 
[2017-03-02T20:12:47.635Z] <55d21ee30fc9f982beadabb8> you can use a simple `iris` dataset or something like that.
[2017-03-02T20:13:05.487Z] <55d21ee30fc9f982beadabb8> it always easier to find out when there is code to check.
[2017-03-02T20:13:23.612Z] <55d21ee30fc9f982beadabb8> if this is really a bug, this is a win-win :D
[2017-03-02T20:14:25.124Z] <5633b77d16b6c7089cb8e50e> ty for your help
[2017-03-03T00:31:32.334Z] <5633b77d16b6c7089cb8e50e> @glemaitre It was a problem with my predict code. I was not imputing values for a feature that doesn't matter in the non sample weighted case, but apparently does with the weighted samples. I've learned my lesson on using the same processing on both sides. =) 
[2017-03-03T08:47:48.340Z] <55d21ee30fc9f982beadabb8> @ccarter-cs :+1: 
[2017-03-03T15:03:56.018Z] <57e4ea1140f3a6eec066d9b4> Hey is sklearn not in GSOC 2017?
[2017-03-03T15:17:14.545Z] <5634e15116b6c7089cb8f9f2> Please all, what DIY level apps can I build with scikit-learn? So far I feel as if I have answers but no problems!
[2017-03-03T21:52:24.338Z] <54d4a1d6db8155e6700f853b> @SatyaPrakashDwibedi it is if we find good students ;)
[2017-03-03T21:52:53.100Z] <54d4a1d6db8155e6700f853b> @NelleV have you opened an issue on the f_regression issue we discussed? Could be good for the sprint tomorrow.
[2017-03-04T00:14:11.511Z] <57e4ea1140f3a6eec066d9b4> @amueller  after attending your talk I was really looking forward to it.
[2017-03-04T00:14:28.109Z] <54d4a1d6db8155e6700f853b> Which one? Yesterday?
[2017-03-04T00:14:43.821Z] <54d4a1d6db8155e6700f853b> Or PyCon India?
[2017-03-04T00:15:27.982Z] <54d4a1d6db8155e6700f853b> We expect students to having contributed before applying for doing a GSoC with us. I haven't been around much the last two month, have you contributed so far?
[2017-03-04T00:16:13.962Z] <5759dd0dc2f0db084a1d128d> @amueller I have not yet
[2017-03-04T00:16:47.549Z] <54d4a1d6db8155e6700f853b> If you don't mind and don't want to do it yourself next week, it would be great if you could open one.
[2017-03-04T00:18:56.332Z] <5759dd0dc2f0db084a1d128d> doing it right now
[2017-03-04T00:19:17.145Z] <5759dd0dc2f0db084a1d128d> if it is not done by next week, I'll try to tackle this during the docathon
[2017-03-04T00:19:47.801Z] <54d4a1d6db8155e6700f853b> thanks :)
[2017-03-04T00:58:25.564Z] <5759dd0dc2f0db084a1d128d> I'll try to review some of the pull requests of the sprint btw
[2017-03-04T00:58:40.360Z] <5759dd0dc2f0db084a1d128d> so don't hesitate to ping me on PR that you think I could help review
[2017-03-04T00:58:40.521Z] <54d4a1d6db8155e6700f853b> thanks, that would be great :)
[2017-03-04T00:58:50.480Z] <54d4a1d6db8155e6700f853b> it will mostly be "easy fix" issues, I think
[2017-03-04T00:58:55.575Z] <54d4a1d6db8155e6700f853b> I tagged a bunch of stuff "sprint"
[2017-03-04T00:59:07.777Z] <54d4a1d6db8155e6700f853b> as you might have seen on the right here lol
[2017-03-04T01:00:00.803Z] <5759dd0dc2f0db084a1d128d> yep, I saw
[2017-03-04T01:01:59.652Z] <54d4a1d6db8155e6700f853b> FYI thanks for being in the top 100 scikit-learn contributors and not making us look like the worst possible ;) For an article about the sprint tomorrow I was asked about the state of women contributing to sklearn. Since counting contributors in a meaningful way is hard, I settled for the top 100 reported by github..... which has a 99:1 ration men:women unless I miscounted :-/ well let's hope we can do something about that tomorrow
[2017-03-04T01:05:20.426Z] <5759dd0dc2f0db084a1d128d> using an infinite timeframe?
[2017-03-04T01:05:33.505Z] <54d4a1d6db8155e6700f853b> I think that's what the default is.
[2017-03-04T01:05:47.072Z] <5759dd0dc2f0db084a1d128d> yep, I am surprisingly still in the top 20 :)
[2017-03-04T01:07:17.069Z] <5759dd0dc2f0db084a1d128d> I'm hoping to contribute more, but matplotlib is still taking a lot of my time
[2017-03-04T01:07:38.161Z] <54d4a1d6db8155e6700f853b> 2013 till now you are still in the top 20 ;) I'm not sure any other timeframe makes us look more diverse
[2017-03-04T01:08:33.132Z] <54d4a1d6db8155e6700f853b> matplotlib might need contributors even more, somehow it's not as "cool" as sklearn I fear. I wish I could contribute more there, but I can't even keep up with sklearn
[2017-03-04T16:00:48.626Z] <55e7596f0fc9f982beaf75b6> Hi, If interested, there's a semantic segmentation problem waiting to be solved here : https://github.com/chromosome-seg/DeepFISH
[2017-03-04T16:29:00.636Z] <54d4a1d6db8155e6700f853b> Started the sprint :) as you might have notices ;)
[2017-03-06T17:47:29.753Z] <58bd932cd73408ce4f4ec329> Hi, I am new to the community.. and still a beginner. I would appreciate if you could share with me any documentation on the development process and ways to involve.. that information would be very helpful
[2017-03-06T17:47:49.565Z] <54d4a1d6db8155e6700f853b> http://scikit-learn.org/dev/developers/contributing.html
[2017-03-06T17:48:49.331Z] <58bd932cd73408ce4f4ec329> thanks Andreas :)
[2017-03-07T16:39:16.019Z] <54d4a1d6db8155e6700f853b> is codecov still commenting?
[2017-03-08T15:03:55.765Z] <58beb8b7d73408ce4f4ef904> hello
[2017-03-08T15:05:44.032Z] <58beb8b7d73408ce4f4ef904> while I am trying to fix an issue using the the inspect.signature method with python3, I am getting this error: /sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8
[2017-03-08T15:06:42.141Z] <58beb8b7d73408ce4f4ef904> Have I built something wrong , or do you know how I can build again so as to be python3 compatible?
[2017-03-08T15:13:11.295Z] <54d4a1d6db8155e6700f853b> do you want to use the development version? Otherwise I'd suggest you just use anaconda or the wheels provided by pip
[2017-03-08T15:13:30.742Z] <54d4a1d6db8155e6700f853b> What's the error you're trying to fix?
[2017-03-08T15:14:07.247Z] <58beb8b7d73408ce4f4ef904> https://github.com/scikit-learn/scikit-learn/issues/8194 
[2017-03-08T15:14:33.150Z] <58beb8b7d73408ce4f4ef904> I am running the rcheck.py to scan the modules
[2017-03-08T15:16:35.483Z] <54d4a1d6db8155e6700f853b> how did you build scikit-learn?
[2017-03-08T15:16:44.571Z] <54d4a1d6db8155e6700f853b> and how are you running rcheck.py?
[2017-03-08T15:16:55.794Z] <54d4a1d6db8155e6700f853b> Make the installation procedure matches the python environment you are running
[2017-03-08T16:26:04.527Z] <58beb8b7d73408ce4f4ef904> I managed to build successfully with make using python3. Everything looks good now, I 'll get on with the fix
[2017-03-08T16:26:21.526Z] <58beb8b7d73408ce4f4ef904> Thank you Andreas!
[2017-03-10T16:52:44.289Z] <530c03e25e986b0712efafb8> Question: how large are typical parameter sets to `GridSearchCV`? 
[2017-03-10T16:53:01.805Z] <530c03e25e986b0712efafb8> And how large are larger-than-typical parameter sets?
[2017-03-10T16:55:17.594Z] <530c03e25e986b0712efafb8> @jcrist and I are trying to decide how much we should care about overheads in Dask+sklearn work
[2017-03-11T18:11:39.802Z] <58a26882d73408ce4f4a2f0d> @amueller Any idea on when this pull request can be accepted:  https://github.com/ja9harper/scikit-learn/pull/1/files
[2017-03-12T12:34:14.988Z] <53135b495e986b0712efc453> @reshama You have made a pull request to your fork... You should instead [raise one at the scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn/compare/master...ja9harper:crossdecompostionmethods)...
[2017-03-16T05:26:30.817Z] <5891ba54d73408ce4f476005> Hello! how many slots does scikit-learn usually gets every year?
[2017-03-16T10:14:47.691Z] <589af8c1d73408ce4f48e81f> Reinforcement learning 
[2017-03-17T15:00:45.513Z] <56ef431a85d51f252ab9e16d> hi would this room fall under wanting to learn about neural networks?
[2017-03-18T05:01:44.342Z] <58ccbc04d73408ce4f51be85> Hello I am new to machine learning 
[2017-03-18T06:58:39.134Z] <58ccd9ead73408ce4f51c219> hello world
[2017-03-20T16:31:12.487Z] <5841ea1ed73408ce4f3a543e> Hi guys i'm new to scikit learning
[2017-03-20T16:31:19.238Z] <5841ea1ed73408ce4f3a543e> i want to learn more about data science
[2017-03-20T16:31:26.065Z] <5841ea1ed73408ce4f3a543e> i hope you can help me with that.
[2017-03-21T04:57:22.083Z] <5657989e16b6c7089cbc5309> @El-moro hi there! A first step is to take a look at the [tutorial](http://scikit-learn.org/stable/tutorial/basic/tutorial.html) for scikit-learn. [This GitHub repo](https://github.com/hangtwenty/dive-into-machine-learning) might also be a good start for places to get your hands on data science and machine learning.
[2017-03-21T12:10:26.223Z] <58cea98cd73408ce4f5208c2> hello guys
[2017-03-21T18:18:23.850Z] <57f68cf5d73408ce4f2c567d> Hey!!  Would implementing dropout in current Neural Network module count as proposal for GSOC?   "https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf"
[2017-03-22T12:58:00.794Z] <55d21ee30fc9f982beadabb8> @geekSiddharth You should probably address your proposal to the mailing list instead of the gitter. You have more chance to get the attention of the core developer.
[2017-03-22T12:58:30.672Z] <55d21ee30fc9f982beadabb8> Check the wiki page also regarding the topic which have an higher chance for the GSOC
[2017-03-24T18:57:44.998Z] <571e7c86659847a7aff47954> 
[2017-03-24T22:36:28.247Z] <5717ab2f659847a7aff3b583> Hi
[2017-03-24T22:38:03.016Z] <5717ab2f659847a7aff3b583> I have answered it
[2017-03-25T16:17:46.935Z] <58d6965fd73408ce4f539cff> Hello guys ! I'm a beginner in Machine Learning, do you recommend me a tutorial for  working on a dataset with sikit-learn ? 
[2017-03-25T16:18:24.406Z] <54d4a1d6db8155e6700f853b> @aniked we have two tutorials on our website, there is some on kaggle.com and there's videos on my website
[2017-03-25T16:18:29.385Z] <54d4a1d6db8155e6700f853b> amueller.io
[2017-03-25T20:22:23.677Z] <57f68cf5d73408ce4f2c567d> @aniked Try intro to ML by udacity. 
[2017-03-26T07:09:13.203Z] <55d21ee30fc9f982beadabb8> @aniked You can also got with the [book](http://shop.oreilly.com/product/0636920030515.do) of @amueller 
[2017-03-26T13:46:59.923Z] <58d7c559d73408ce4f53c7d3> Do you guys have any online courses/ bootcamp recommendation for someone that have been learning the basics of machine learning?
[2017-03-26T13:47:52.338Z] <58d7c559d73408ce4f53c7d3> I just finished the Machine Learning Coursera course and I would like to learn more deeply about the more advanced topics in machine learning.
[2017-03-26T15:25:24.933Z] <58d6965fd73408ce4f539cff> @amueller  @geekSiddharth @glemaitre  thank you so much guys :) 
[2017-03-26T18:42:24.689Z] <54d4a1d6db8155e6700f853b> @tonyvanhain check out the replies to @aniked above.
[2017-03-26T18:43:43.754Z] <54d4a1d6db8155e6700f853b> I would rather not recommend bootcamps, as you'd have to pay for them usually, and some of them give me money ;)
[2017-03-26T18:44:11.240Z] <54d4a1d6db8155e6700f853b> There's really a whole bunch of good free material online, though
[2017-03-27T11:44:28.925Z] <564789be16b6c7089cbab8b7> The docs for StratifiedShuffleSplit and StratifiedKFold are very similar. One says "This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class." and the other says "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class."   I might not be the only person who finds this confusing
[2017-03-27T11:45:08.084Z] <564789be16b6c7089cbab8b7> what is the difference?
[2017-03-27T12:49:55.345Z] <564789be16b6c7089cbab8b7> is the only difference that the first one is randomized?
[2017-03-27T18:15:13.981Z] <54d4a1d6db8155e6700f853b> there are no folds in StratifiedShuffleSplit
[2017-03-27T18:15:30.822Z] <54d4a1d6db8155e6700f853b> the number of iterations is independent of the training set size
[2017-03-30T02:04:49.345Z] <551c051b15522ed4b3de2fea> hi all :)
[2017-03-31T08:00:48.164Z] <564789be16b6c7089cbab8b7> does sklearn have tests that you can run?
[2017-03-31T09:08:14.460Z] <55d21ee30fc9f982beadabb8> @lesshaste Do you mean https://github.com/scikit-learn/scikit-learn#testing
[2017-03-31T09:54:03.994Z] <564789be16b6c7089cbab8b7> yes thanks
[2017-03-31T09:57:48.310Z] <564789be16b6c7089cbab8b7> are some errors expected? For example "bagging.py:747: RuntimeWarning: divide by zero encountered in log "
[2017-03-31T11:02:11.756Z] <55d21ee30fc9f982beadabb8> Sometimes, you can have error or warning raised by scipy and numpy which will be catch I think
[2017-03-31T11:02:27.653Z] <55d21ee30fc9f982beadabb8> the important things is that you get no output as
[2017-03-31T11:02:54.166Z] <55d21ee30fc9f982beadabb8> ``` Ran 20 tests in 0.238s  FAILED (errors=2) ```
[2017-03-31T11:03:02.430Z] <55d21ee30fc9f982beadabb8> or with failure
[2017-03-31T11:04:03.159Z] <564789be16b6c7089cbab8b7> @glemaitre  OK
[2017-03-31T11:04:41.514Z] <564789be16b6c7089cbab8b7> I think it is all works fine. I was trying to get TPOT to work which stalls mysteriously on OS X and I wanted to check it wasn't a scikit learn problem. It isn't.
[2017-03-31T11:04:54.429Z] <55d21ee30fc9f982beadabb8> Then if you fill this is a bug you probably want to put it back in the issue tracker in github
[2017-03-31T11:05:24.470Z] <564789be16b6c7089cbab8b7> it's a TPOT bug I think, not a scikit-learn one
[2017-03-31T11:05:45.114Z] <564789be16b6c7089cbab8b7> probably in fact a pathos bug
[2017-03-31T21:31:51.946Z] <58cd4780d73408ce4f51d3cb> Hello, I am willing to get the frequency of keywords + ngrams over a Russian text. I am having troubles using the CountVectorizer, here is what I did so far:  ```python corpus = open("russian-text-file").read() corpus = nltk.regexp_tokenize(corpus, r'(?u)\\b\\w+\\b', gaps=True) cv = CountVectorizer(ngram_range=(1, 10), vocabulary=["list of russian keywords + ngrams"], token_pattern='(?u)\\b\\w+\\b') results = pd.DataFrame(cv.fit_transform(corpus).toarray(), columns=cv.get_feature_names()) results_sum = results.sum() ```  `results_sum` shows that none of the keywords or ngrams are present in the text. However when I searched manually I could find them. Also, this code snippet worked with english text. Any help is appreciated, thanks!
[2017-03-31T22:06:53.703Z] <551c051b15522ed4b3de2fea> would someone mind interpreting a learning curve for me? Im not quite sure whether this represents an issue with my data.
[2017-03-31T22:07:14.703Z] <551c051b15522ed4b3de2fea> [![Screen Shot 2017-03-31 at 15.06.27.png](https://files.gitter.im/scikit-learn/scikit-learn/QgsH/thumb/Screen-Shot-2017-03-31-at-15.06.27.png)](https://files.gitter.im/scikit-learn/scikit-learn/QgsH/Screen-Shot-2017-03-31-at-15.06.27.png)
[2017-03-31T22:08:09.720Z] <551c051b15522ed4b3de2fea> it looks like were getting a 7% CV error, which is a bit high, but tolerable for this use case?
[2017-03-31T22:11:08.387Z] <551c051b15522ed4b3de2fea> my p/r values sort of suck
[2017-04-01T10:37:03.482Z] <58cd4780d73408ce4f51d3cb> @sbromberger You can read more about bias and variance at http://cs229.stanford.edu/materials/ML-advice.pdf
[2017-04-01T23:16:36.335Z] <551c051b15522ed4b3de2fea> I understand (or at least I think I do) about bias and variance. What I dont quite have down is whether or not my actual results above indicate excessive variance.
[2017-04-02T06:43:58.638Z] <588f320bd73408ce4f46ee3d> The overlap of the shaded curve hulls around 150 an 175 training samples would bring doubt to me, if wether this presentation is useful to judge the parameters impact - but I am alien to machine learning ;-)
[2017-04-02T09:19:05.085Z] <55476cb515522ed4b3dfe7eb> Hy guys, I'm trying to learn scikit clustering, but can not get into final step before giving data into clustering algorithms, hope someone will be able to point me out direction of next step to get two dimmensional array from dataframe so it can be used by algorithms like MeanShift or may be DBSCAN or something else  ``` import pandas as pd df = pd.read_csv('http://sandbox.mac-blog.org.ua/sample.csv') # C1..C5 - categorical, D1..D10 - dates, B1..B28 - binary, 100K rows df = df.drop(['D1','D2','D3','D4','D5','D6','D7','D8','D9','D10'], 1) # do not understand how to deal with this df = df.fillna(False) # looking around, all categorical data has values, treating NaN for all binaries as false  # going to convert all binaries into 0..1 ints for c in df.columns:     if c.startswith('B'):         df[c] = df[c].astype('int')  # totally not sure should such things be done print('Before:', len(df)) # 100000 df = df.drop_duplicates() print('After:', len(df)) # 35944  # not sure is it good idea at all # but after that I have reduced number of columns from 33 to 12 from sklearn.feature_selection import VarianceThreshold sel = VarianceThreshold(threshold=(.8 * (1 - .8))) sel.fit(df) labels = [df.columns[x] for x in sel.get_support(indices=True)] print('Before:', len(df.columns)) # 33 df = pd.DataFrame(sel.fit_transform(df), columns=labels) print('After:', len(df.columns)) # 12  # not sure do I need something like StandardScaler or LabelEncoder?  # every example of clustering algorithms like https://www.youtube.com/watch?v=EQZaSuK-PHs expect 2 dimensional array - kind of stuck here  df.head() ```
[2017-04-02T12:11:50.013Z] <55476cb515522ed4b3dfe7eb> Seems that have found one way:  step 1 looking around on data   ``` from sklearn.decomposition import PCA      pca = PCA(n_components=2) pca.fit(df) existing_2d = pca.transform(df) plt.scatter(existing_2d.T[0], existing_2d.T[1], c='b') ```  step 2 clustering  in my case i definitely see 4 clusters so using kmeans  ``` from sklearn.cluster import KMeans km = KMeans(n_clusters=4) km.fit(df) df['Cluster'] = pd.Series(clusters, index=df.index) # append cluster column to dataframe ```  step 3 get usefull data  ``` desired = [] for col in df.columns:     if col != 'Cluster':         vals = [] # will contain top 1 value from each cluster         for cluster in list(set(km.labels_)):             vals.append(df[df['Cluster']==cluster][col].value_counts().head(h).reset_index().rename(columns={'index': col, col: 'Count'}).iloc[0][col])         if len(np.unique(vals)) > 1:             desired.append(col) # we are looking only for columns that are changing between clusters  xx = [] for cluster in list(set(km.labels_)):     x = {'Cluster': cluster}     for col in desired:         h=1         z = df[df['Cluster']==cluster][col].value_counts().head(h).reset_index().rename(columns={'index': col, col: 'Count'})         x[col] = z.iloc[0][col]     xx.append(x)      pd.DataFrame(xx) ```  not sure if this is a right way but got answer dataframe with 6 columns (5 categorical and 1 binary) describing top1 from each cluster (4 rows)  hope that may be helpful
[2017-04-04T01:47:03.808Z] <578a5e75c2f0db084a23470c> Looking at the digits dataset, the `DESCR` says ":Number of Instances: 5620" but when I examine the shape of the `data`, `target`, and `images`,  they all have 1797 instances.  Is this a documentation error or could I be missing something when I loaded the data?
[2017-04-04T10:29:36.950Z] <5495ae8fdb8155e6700e17c8> A curious observation: ``` from sklearn.feature_extraction.text import HashingVectorizer v = HashingVectorizer() v.transform(["a","b","c"]) ``` The result is  ``` <3x1048576 sparse matrix of type '<class 'numpy.float64'>' 	with 0 stored elements in Compressed Sparse Row format> ``` It seems that HashingVectorizer will transform any single word into zero vector. Do I miss anything? 
[2017-04-04T11:06:51.235Z] <5495ae8fdb8155e6700e17c8> look like the default "word" analyzer will transform single character into empty list ``` analyzer = v.build_analyzer() analyzer("a") ```  ``` [] ``` 
[2017-04-04T11:29:14.378Z] <58e381c1d73408ce4f55fa94> Hi any good book for Keras 
[2017-04-04T11:35:52.357Z] <5729ef37c43b8c60197119b1> Folks, whats the easiest way to figure out the top features used by RandomForestClassifier for prediction?  Im using DictVectorizer to extract features. 
[2017-04-04T22:20:41.197Z] <551c051b15522ed4b3de2fea> so, `class_weight` doesnt do what I expected it to do.
[2017-04-06T08:56:57.523Z] <561a58f7d33f749381a8ff2f> OHE makes me feel like a handicapped person
[2017-04-06T17:46:47.336Z] <57f1894dd73408ce4f2b2588> is there a sklearn preprocessing function/class that removes data points (examples) with values that are out of range? here is a snippet, i.e. remove all data x<lo or x>up. here is an example https://gist.github.com/ulf1/6810883a985ef464ae9d26833966b4fa
[2017-04-06T20:23:35.259Z] <55d21ee30fc9f982beadabb8> @ulf1 you can use [`numpy.clip`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.clip.html)
[2017-04-07T08:09:22.368Z] <57f1894dd73408ce4f2b2588> @glemaitre thank you for the tip. however it isnt exactly what i was searching for. numpy.clip substitute values that are out of range. my plan is to remove the row (or column) that contain out-of-range values.
[2017-04-07T10:03:04.998Z] <55d21ee30fc9f982beadabb8> There is not transformer which remove samples in scikit-learn I think
[2017-04-07T10:06:10.426Z] <55d21ee30fc9f982beadabb8> you could probably use the [`pandas.query`](http://pandas.pydata.org/pandas-docs/version/0.13.1/generated/pandas.DataFrame.query.html) to make such request
[2017-04-08T06:25:09.805Z] <58e381c1d73408ce4f55fa94> welcome to sonnet from DeepMind
[2017-04-08T06:25:15.696Z] <58e381c1d73408ce4f55fa94>         https://gitter.im/TF_Sonnet/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link
[2017-04-09T22:56:29.373Z] <561a58f7d33f749381a8ff2f> I think Ridge normalized=True is broken
[2017-04-09T23:00:19.409Z] <561a58f7d33f749381a8ff2f> In [44]: Ridge(normalize=True).fit([[1000],[1], [500]], [1000,1,500]).predict([[1000],[1], [500]]) Out[44]: array([ 750.16666667,  250.66666667,  500.16666667])
[2017-04-09T23:00:23.929Z] <561a58f7d33f749381a8ff2f> In [45]: Ridge(normalize=False).fit([[1000],[1], [500]], [1000,1,500]).predict([[1000],[1], [500]]) Out[45]: array([ 999.99899867,    1.00100066,  500.00000067]) 
[2017-04-09T23:00:59.138Z] <561a58f7d33f749381a8ff2f> 'scikit-learn==0.19.dev0'
[2017-04-10T04:55:11.941Z] <55d21ee30fc9f982beadabb8> @kootenpv Use the issue tracker from GitHub if you have a bug report
[2017-04-11T13:00:50.119Z] <5845699ed73408ce4f3ad4e7> I am getting a major error in Dictionary Learning.  The error is Segmentation fault (core dumped).
[2017-04-11T13:02:08.342Z] <5845699ed73408ce4f3ad4e7> It is working fine for 100 Images to train a Dictionary but If I use 200 Images to train a Dictionary then I am  getting Segmentation fault (core dumped).
[2017-04-11T13:02:54.130Z] <5845699ed73408ce4f3ad4e7> I debuged my code and got this one : :0x00007ffff3059f50 in ATL_dJIK0x0x48NN0x0x0_aX_bX () from /usr/lib/libblas.so.3
[2017-04-14T08:27:20.204Z] <58e88d54d73408ce4f56ee47> hello, i am trying to use sklearn.svm.svc with l1 or l2 regularization and can't seem to find how to, can anyone please help with me some pointers? please see stackoverflow question  http://stackoverflow.com/questions/43407896/python-sklearn-non-linear-svm-penalty
[2017-04-15T01:53:00.964Z] <589856bdd73408ce4f4866a2> Guys need some advice on Networkx. What's the best way to learn it. Need to perform some clustering on stackoverflow dump.
[2017-04-15T15:16:10.661Z] <551c051b15522ed4b3de2fea> @Pratyush3196_twitter the networkx docs are really good, but be aware that its not memory efficient AT ALL so youre not going to be able to use it at scale.
[2017-04-15T15:25:46.975Z] <589856bdd73408ce4f4866a2> Should I prefer Gephi over Networkx? @sbromberger 
[2017-04-15T15:29:43.307Z] <551c051b15522ed4b3de2fea> @Pratyush3196_twitter networkx is good. How big are your graphs?
[2017-04-16T04:47:54.768Z] <589856bdd73408ce4f4866a2> @sbromberger. I am using it on the 200gb stackexchange dump.
[2017-04-16T04:48:09.322Z] <551c051b15522ed4b3de2fea> how many nodes/edges?
[2017-04-16T04:48:25.946Z] <589856bdd73408ce4f4866a2> Around 180345
[2017-04-16T04:50:19.460Z] <551c051b15522ed4b3de2fea> nodes?
[2017-04-16T04:50:39.451Z] <551c051b15522ed4b3de2fea> how many edges? and have you tried loading this into networkx?
[2017-04-16T04:50:55.678Z] <589856bdd73408ce4f4866a2> But all of them won't be mapped. Lots of tags contain null so wont map them. Networkx has pretty straightforward documentaion. I read through it but gephi looks quite exquisite.
[2017-04-16T04:55:02.922Z] <589856bdd73408ce4f4866a2> @sbromberger It's my first DS project. Learning by doing so could use some good advice.
[2017-04-16T04:55:49.675Z] <551c051b15522ed4b3de2fea> gephi is a different package with different goals. It really depends on what you want to do.
[2017-04-16T04:56:22.538Z] <551c051b15522ed4b3de2fea> if you want to visualize data and play around with it in a gui, gephi is better suited. If you want to run advanced graph analysis, networkx is probably better.
[2017-04-16T04:56:28.691Z] <551c051b15522ed4b3de2fea> but both have limitations.
[2017-04-16T04:59:34.186Z] <589856bdd73408ce4f4866a2> Can I apply kmeans on the data on the gephi graphs? 
[2017-04-16T04:59:45.380Z] <551c051b15522ed4b3de2fea> I dont know.
[2017-04-16T05:00:30.500Z] <589856bdd73408ce4f4866a2> Okay. It can be done in Networkx. Isn't it?
[2017-04-16T05:06:15.200Z] <551c051b15522ed4b3de2fea> I dont believe it can.
[2017-04-16T05:07:06.072Z] <551c051b15522ed4b3de2fea> but there are many clustering algorithms available for each.
[2017-04-16T05:08:31.348Z] <551c051b15522ed4b3de2fea> http://stackoverflow.com/questions/40602158/how-to-draw-networkx-graph-based-on-k-means-cluster-label may help you.
[2017-04-16T05:10:40.590Z] <589856bdd73408ce4f4866a2> Thanks! That was a great help. Is this feature also available in Gephi in some way?
[2017-04-16T05:15:19.805Z] <551c051b15522ed4b3de2fea> I dont know.
[2017-04-17T04:49:43.820Z] <58e46e92d73408ce4f562b3b> Is there a way to combine LevenbergMarquardt algorithm with Stochastic Gradient Descent?
[2017-04-19T06:49:30.847Z] <585cd30bd73408ce4f3ee4d2> ~~~ Testing ~~~
[2017-04-19T13:36:03.792Z] <5586719a15522ed4b3e23add> Hi everyone,  (it seems that this channel changed its purpose...? anyway)  I don't want to bother the group but I recently posted [an issue when running kNN's](http://stackoverflow.com/questions/43284115/sklearn-knn-sklearn-neighbors-kneighbors-function-producing-unexpected-result)? It is in stackoverflow with the suggested changes by other users - still downgraded though.  Does anyone can have a look? If not, which other place would be the best one to post my question? Also: what other tests should I try before posting anywhere else to be sure I did all I could to verify the problem was completely evaluated?
[2017-04-20T09:21:26.974Z] <5586719a15522ed4b3e23add> ^^^  --- Problem above was solve. Thanks for the help.
[2017-04-22T20:50:35.736Z] <58fbc160d73408ce4f5a4648> Can i talk C# in here?
[2017-04-22T20:50:43.106Z] <58fbc160d73408ce4f5a4648> I am new to here
[2017-04-22T22:00:24.256Z] <55d21ee30fc9f982beadabb8> @HamunSunga It does not seem the right gitter room since this is a scikit-learn room
[2017-04-24T13:59:16.330Z] <58af2e9dd73408ce4f4c72db> Can i use datetime variable as independent variable in case of building a classification model like Random Forest.? I'm a new to data science. Great if someone can help. Thanks
[2017-04-24T14:22:37.443Z] <551c051b15522ed4b3de2fea> since your datetime variable will be unique per observation, what do you expect to gain by making it a feature?
[2017-04-25T00:14:39.853Z] <58af2e9dd73408ce4f4c72db> I agree to with ur point. In my training dataset i see a relationship among the transactions happened with in a less span of time and in morning & evening are classified as suspicious . 
[2017-04-25T00:22:15.629Z] <551c051b15522ed4b3de2fea> so you want to create a set of features based on the timestamp: perhaps the hour of the timestamp only (to determine morning/evening), and then some duration engineered from the rest of the data.
[2017-04-25T00:28:38.977Z] <58af2e9dd73408ce4f4c72db> Ok. So new features like hour and minute bin like 5 or 10 minute size will have to create.
[2017-04-26T09:50:02.934Z] <59006cdfd73408ce4f5b1a27> Hi I need to implement a multiclass text classification using python
[2017-04-26T09:50:04.523Z] <59006cdfd73408ce4f5b1a27> How?
[2017-04-27T21:49:32.647Z] <5832567dd73408ce4f376bd8> what sites do you recomend for learning c or c++
[2017-04-29T04:41:46.535Z] <58d7cfdad73408ce4f53c9b6> Is CountVectorizer's vocabulary_ attribute sorted by their occurences in the documents?
[2017-04-30T02:10:38.926Z] <58c984f9d73408ce4f50e4cb> hi everyone, i was tasked with setting up a dev environment for our teams projects and I accidentally installed the latest version of sklearn instead of .17      is there a way to downgrade myself? or do I have to uninstall and reinstall?
[2017-05-01T18:13:08.757Z] <54d4a1d6db8155e6700f853b> @kaufmak2 with pip or conda or how?
[2017-05-03T12:04:08.397Z] <57430fe4c43b8c60197476d9> It says on the PyParis page that the scikit-learn dev sprint is going to happen during the conference - but this [link](https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events) mentions it happening a week before. Will there be 2 sprints in Paris?
[2017-05-03T20:28:17.243Z] <547efb1fdb8155e6700dad1a> DataScience Digest, Issue #7 - http://bit.ly/2p9NaRc  Please share;)
[2017-05-04T10:26:58.382Z] <58ca7db4d73408ce4f51357f> Hi
[2017-05-04T14:48:48.407Z] <590a3126d73408ce4f5cbbf3> @b0bcup_twitter  hello
[2017-05-04T20:02:33.323Z] <55d21ee30fc9f982beadabb8> @bhargavvader The sprint will be the week before as mentioned in the wiki.
[2017-05-05T18:06:20.374Z] <58e6bdf2d73408ce4f56a831> Hello @theslothhermit  you may consider the new boston tutorial in youtube. 
[2017-05-05T18:06:23.127Z] <58e6bdf2d73408ce4f56a831> C++ Programming Tutorials Playlist: http://www.youtube.com/playlist?list=PLAE85DE8440AA6B83
[2017-05-05T18:06:59.485Z] <58e6bdf2d73408ce4f56a831> C Programming Tutorials: http://www.youtube.com/playlist?list=PL6gx4Cwl9DGAKIXv8Yr6nhGJ9Vlcjyymq
[2017-05-06T20:59:52.678Z] <590e05cdd73408ce4f5d769b> hi all, i'm trying to run n_jobs>1 with a OneVsRestClassifier(LinearSVC()) and am seeing the following... is this due to lambda's creeping in somewhere recently? ``` Traceback (most recent call last):   File "main.py", line 24, in <module>     train(df, Y)   File "/home/ubuntu/model.py", line 90, in train     mod.fit(docs_train, labels_train) #mod to use grid search or "model" for the pipeline only   File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py", line 216, in fit     for i, column in enumerate(columns))   File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__     self.retrieve()   File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve     raise exception   File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve     self._output.extend(job.get(timeout=self.timeout))   File "/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get     raise self._value   File "/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py", line 385, in _handle_tasks     put(task)   File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py", line 371, in send     CustomizablePickler(buffer, self._reducers).dump(obj) AttributeError: Can't pickle local object 'train.<locals>.<lambda>' ```
[2017-05-06T21:00:37.155Z] <590e05cdd73408ce4f5d769b> is there a way to set dill or some other serializer instead?
[2017-05-06T21:06:00.373Z] <590e05cdd73408ce4f5d769b> nm, found a lambda hidden away in my code somewhere... :)
[2017-05-07T04:49:51.265Z] <58da7f70d73408ce4f545382> I need some help 
[2017-05-07T04:49:53.586Z] <58da7f70d73408ce4f545382> Means I write codes in pycharm and it will execute in Windows cmd prompt
[2017-05-07T04:49:56.626Z] <58da7f70d73408ce4f545382> Plzzzzzzzzz
[2017-05-07T04:50:01.353Z] <58da7f70d73408ce4f545382> Help me
[2017-05-08T03:37:32.046Z] <58847c11d73408ce4f452e18> hello
[2017-05-10T15:49:41.249Z] <58fd3abed73408ce4f5a7b40> anybody here with experience handling EEG data ?  I'll be very grateful if you could answer a few questions
[2017-05-10T17:54:56.578Z] <55d21ee30fc9f982beadabb8> @fel-mazo You have maybe more chance to find people on the mailing list of MNE: http://martinos.org/mne/stable/index.html
[2017-05-11T07:41:34.111Z] <591414ffd73408ce4f5eaf83> from sklearn.decomposition import PCA  pca = PCA(n_components=2) pca.fit(df) existing_2d = pca.transform(df) plt.scatter(existing_2d.T[0], existing_2d.T[1], c='b')
[2017-05-11T07:42:32.970Z] <591414ffd73408ce4f5eaf83> After doing the pca now I want to know which are the columns that have been selected by pca and only use those in my dataset df Any idea how to get the column names selected by pca?
[2017-05-11T07:43:11.123Z] <591414ffd73408ce4f5eaf83> *pca = PCA(n_components=29)
[2017-05-11T07:43:53.033Z] <591414ffd73408ce4f5eaf83> say I have a large value of columns 400 and I want only 29 of them but I want the name of those 29 columns selected by pca
[2017-05-11T07:44:00.323Z] <591414ffd73408ce4f5eaf83> from df
[2017-05-11T07:44:13.911Z] <591414ffd73408ce4f5eaf83> can anybody help please?
[2017-05-11T09:37:24.084Z] <553d32d715522ed4b3df8b92> Hi, in case I understood the use case right, you might want to look at feature_selection http://scikit-learn.org/stable/modules/feature_selection.html for selecting features since PCA doesnt select particular features but converts to n_components dimensions where each component is a weighted sum of the features. Hope it helps.
[2017-05-11T09:41:28.145Z] <55d21ee30fc9f982beadabb8> @maniteja123 :+1:  @puneetmathurDS each component is a "bit of all columns"
[2017-05-11T10:46:43.140Z] <58fd3abed73408ce4f5a7b40> @glemaitre thanks !
[2017-05-11T16:30:15.294Z] <591414ffd73408ce4f5eaf83> Thanks
[2017-05-12T06:23:16.107Z] <5910079ed73408ce4f5dc467> I have a doubt  in my code ``` from sklearn.tree import DecisionTreeClassifier from sklearn.datasets import load_breast_cancer from sklearn.cross_validation import train_test_split cancer = load_breast_cancer() X_train, X_test, y_train, y_test = train_test_split( cancer.data, cancer.target, stratify=cancer.target, random_state=42) tree = DecisionTreeClassifier(random_state=0) tree.fit(X_train, y_train) print(tree.score(X_train, y_train)) print(tree.score(X_test, y_test)) ``` The first random_state is in test_train_split is used for  getting the same result next time when we are gonna run the code. But I don't get why is there a random_state in DecisionTreeClassifier line ? And how does that work ? @amueller  ..    
[2017-05-12T08:24:06.695Z] <55d21ee30fc9f982beadabb8> @ashiskriz There is some randomness in the decision tree. For instance a subset of feature can be taken at each note with a randomization. Having this in mind the random_state allows to have this part deterministic as well
[2017-05-12T11:57:21.984Z] <5910079ed73408ce4f5dc467> @glemaitre  - Thank you very much . Thats helpful  And I  want to add that the book I was following  written by @amueller  had a sentence saying "We fix the random_state in the tree, which is used for tiebreaking internally"  . I was wondering about the mechanism of tie breaking thing . How is the tie breaking thing happens internally?
[2017-05-12T13:39:14.896Z] <56ed9a8885d51f252ab9b33f> 
[2017-05-12T14:21:41.840Z] <58e46e92d73408ce4f562b3b> @punitaojha you have posted the exact same message in https://gitter.im/Machine-Learning-Group/chat too. That's I believe a spammy behavior...
[2017-05-12T14:41:49.050Z] <590c8ffdd73408ce4f5d352d> Hey Guys, I am planning to build a ML and probabilistic modelling libray in Python. Would like to know if anybody is interested to start the project with me?
[2017-05-12T22:00:40.261Z] <55d21ee30fc9f982beadabb8> @ashiskriz at each node, a random set of feature will be used to find a best split. If there two features leading to a split with the same impurity improvement, you get a tie. Therefore, the first feature which was randomly picked up will be selected.
[2017-05-12T22:01:48.489Z] <55d21ee30fc9f982beadabb8> If you try multiple times, you will select one feature or the other which will lead to different trees architectures. Therefore, random_state allows you to pick up always the same feature in case of a tie.
[2017-05-12T23:35:48.217Z] <55901c1b15522ed4b3e2f949> @anisnouri how will it be different from current existing libraries?
[2017-05-12T23:41:24.718Z] <590c8ffdd73408ce4f5d352d> @jmschrei  would be much focused on quantifying uncertainty.
[2017-05-12T23:42:03.612Z] <55901c1b15522ed4b3e2f949> Have you looked into PyMC3 and PyStan, and the libraries built on top of those?
[2017-05-12T23:44:23.519Z] <590c8ffdd73408ce4f5d352d> @jmschrei  yeah. I find them a bit compound and complex to use. Would be nice to have something with the same APIs design as sklearn 
[2017-05-12T23:55:12.424Z] <55901c1b15522ed4b3e2f949> You should probably reach out in those communities then, if you'll be building on top of it. I think that learning Bayesian models like that is much more niche than classical machine learning.
[2017-05-13T19:04:52.386Z] <5910079ed73408ce4f5dc467> @glemaitre   Thank you very much  .Really appreciate your help. Great explanation there
[2017-05-14T07:15:24.958Z] <56ed9a8885d51f252ab9b33f> 
[2017-05-14T08:23:26.293Z] <55d21ee30fc9f982beadabb8> @punitaojha spamming is merely annoying
[2017-05-17T06:05:04.452Z] <590d97a3d73408ce4f5d6441> @punitaojha <unconvertable> You know why we are here. 
[2017-05-21T03:32:54.197Z] <5864997ad73408ce4f3fe96c> pbppppppppppapoppppp
[2017-05-21T19:21:00.289Z] <5921d334d73408ce4f612e46> Hello, I'm looking for some help with a code I wrote. It seems straightforward enough but it takes forever (its not even run it yet and I've had it running for hours) to perform a 5-fold cross validation bit on an 800 x 18 dataframe. 
[2017-05-21T19:40:12.829Z] <5921d334d73408ce4f612e46> This seems to be where my code hangs:
[2017-05-21T19:41:28.133Z] <5921d334d73408ce4f612e46> ``` kf = KFold(800,5) score = [] for i in range(1,1001):      clf = SVC(C=i/100, kernel='linear')      error = []      for train_index, test_index in kf:           X_train, X_test = train_data[train_index], train_data[test_index]           y_train, y_test = train_label[train_index], train_label[test_index]           clf.fit(X_train,y_train)           error.append(1 - clf.score(X_test, y_test))      score.append(sum(error)/5) ``` 
[2017-05-21T19:49:16.278Z] <55d21ee30fc9f982beadabb8> you can use the [`cross_val_score`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function to do what you try to do
[2017-05-21T19:51:17.340Z] <55d21ee30fc9f982beadabb8> Also I think that you are using the `cross_validation` module which you should move away from since it is deprecated
[2017-05-21T19:51:45.585Z] <55d21ee30fc9f982beadabb8> Use the `model_selection` where you have the refactored cross-validation classes
[2017-05-21T19:52:01.678Z] <55d21ee30fc9f982beadabb8> long story short, you can write your code as
[2017-05-21T19:54:39.119Z] <55d21ee30fc9f982beadabb8> ```python from sklearn.model_selection import KFold from sklearn.model_selection cross_val_score from sklearn.svm import SVC  clf = SVC(kernel='linear') print(cross_val_score(clf, X, y))  ```
[2017-05-21T19:55:45.929Z] <55d21ee30fc9f982beadabb8> Then it seems that you try to actually find the best `C` parameter probably. To do that you should use the [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class.
[2017-05-21T19:59:01.193Z] <55d21ee30fc9f982beadabb8> ```python from sklearn import svm, datasets from sklearn.model_selection import GridSearchCV  parameters = {'C': [1, 10, 100, 1000]} svr = svm.SVC(kernel='linear') clf = GridSearchCV(svr, parameters) clf.fit(X, y) ```  
[2017-05-21T19:59:21.683Z] <55d21ee30fc9f982beadabb8> It will search and select the best `C` parameter
[2017-05-21T20:00:38.842Z] <5921d334d73408ce4f612e46> OK. Thank you so much @glemaitre. I'd try that Yes, I am trying to find the best C parameter  
[2017-05-21T20:00:43.944Z] <55d21ee30fc9f982beadabb8> In your example you are trying all the 1000 possible `C` values and it could be pretty slow. You can also use `n_jobs=-1` to take advantages of all the CPU cores
[2017-05-21T20:02:58.661Z] <5921d334d73408ce4f612e46> Oh. Sorry, I'm still new at it so, I don't know how to use the n_jobs yet
[2017-05-21T20:03:32.923Z] <55d21ee30fc9f982beadabb8> `clf = GridSearchCV(svr, parameters, n_jobs=-1)`
[2017-05-21T20:03:36.037Z] <55d21ee30fc9f982beadabb8> is enough
[2017-05-21T20:03:36.584Z] <5921d334d73408ce4f612e46> The task was to check for the best C value between 0.01 and 10
[2017-05-21T20:03:38.870Z] <55d21ee30fc9f982beadabb8> clf = GridSearchCV(svr, parameters)
[2017-05-21T20:03:45.814Z] <55d21ee30fc9f982beadabb8> you can check the examples in the doc
[2017-05-21T20:03:52.180Z] <5921d334d73408ce4f612e46> OK. Thanks a lot!
[2017-05-21T20:03:58.253Z] <55d21ee30fc9f982beadabb8> this is actually related to an SVM with different kernel and C values
[2017-05-21T20:13:51.576Z] <5921d334d73408ce4f612e46> `GridSearchCV(cv=None, error_score='raise',        estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',   max_iter=-1, probability=False, random_state=None, shrinking=True,   tol=0.001, verbose=False),        fit_params={}, iid=True, n_jobs=1,        param_grid={'C': [1, 10, 100, 1000]}, pre_dispatch='2*n_jobs',        refit=True, return_train_score=True, scoring=None, verbose=0)`
[2017-05-21T20:14:08.712Z] <5921d334d73408ce4f612e46> I guess this implies the best estimator is C = 1.0 ?
[2017-05-21T20:14:19.261Z] <55d21ee30fc9f982beadabb8> yep
[2017-05-21T20:14:29.928Z] <5921d334d73408ce4f612e46> Wow! Thank you. You are a life saver!
[2017-05-21T20:14:36.935Z] <55d21ee30fc9f982beadabb8> the returned classifier is this one
[2017-05-21T20:15:09.152Z] <5921d334d73408ce4f612e46> I've been trying to do this for days!
[2017-05-21T20:15:10.360Z] <55d21ee30fc9f982beadabb8> you can increase the number of C to visit if you want as well
[2017-05-21T20:15:17.468Z] <5921d334d73408ce4f612e46> OK
[2017-05-21T20:15:32.855Z] <5921d334d73408ce4f612e46> How do I do that?
[2017-05-21T20:15:41.136Z] <5921d334d73408ce4f612e46> By changing param_grid?
[2017-05-21T20:15:59.370Z] <55d21ee30fc9f982beadabb8> yep
[2017-05-21T20:16:05.717Z] <5921d334d73408ce4f612e46> Cool
[2017-05-21T20:17:42.014Z] <55d21ee30fc9f982beadabb8> `parameters = {'C': np.logspace(-1, 2, num=20)}`
[2017-05-21T20:18:12.881Z] <55d21ee30fc9f982beadabb8> Don't hesitate sometimes to check the tutorial
[2017-05-21T20:18:13.314Z] <55d21ee30fc9f982beadabb8> http://scikit-learn.org/stable/tutorial/
[2017-05-21T20:18:31.179Z] <5921d334d73408ce4f612e46> Ok. Thank you
[2017-05-21T20:18:40.793Z] <55d21ee30fc9f982beadabb8> http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html
[2017-05-21T20:18:48.783Z] <55d21ee30fc9f982beadabb8> was actually the one you wanted ;)
[2017-05-21T20:19:04.763Z] <5921d334d73408ce4f612e46> I'm new at sci-kit and machine learning. So sometimes, my solutions are not optimal and my system is rather slow
[2017-05-21T20:19:10.677Z] <5921d334d73408ce4f612e46> Awesome. I'd go through it
[2017-05-21T20:19:27.980Z] <5921d334d73408ce4f612e46> Yes, it is :D
[2017-05-22T11:14:32.255Z] <5921d334d73408ce4f612e46> Please does it make sense to find the optimal gamma for a polynomial kernel? 
[2017-05-22T11:15:05.180Z] <5921d334d73408ce4f612e46> Most of the examples I've seen searching for gamma have the kernel as linear or rbf
[2017-05-22T11:16:27.037Z] <5921d334d73408ce4f612e46> I tried using grid search, but it doesn't seem to be the right function for getting the gamma in this case (it seems slow in processing)
[2017-05-22T15:02:11.019Z] <56ed9a8885d51f252ab9b33f> 
[2017-05-25T12:16:21.042Z] <5910079ed73408ce4f5dc467>  Hi all,  Can I get some indepth resource on RFE(Recursive features elimination) ? I have went through the documentation but it will be good if I could get any detailed  example which uses RFE. 
[2017-05-29T19:15:30.100Z] <574454a0c43b8c601974a563> [sklearn-porter 0.5.0](https://github.com/nok/sklearn-porter) has been released :sparkles:. The [MLPRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) is the first supported regressor! That's one small step for a man, one giant leap for scientists. :smile: 
[2017-05-30T21:31:57.138Z] <551c051b15522ed4b3de2fea> thats pretty cool, @nok 
[2017-05-30T21:35:52.037Z] <574454a0c43b8c601974a563> Thanks :smile: 
[2017-05-30T22:30:54.016Z] <551c051b15522ed4b3de2fea> Itd be nice to get Julia support into this :)
[2017-05-31T06:43:23.005Z] <56c4f19ae610378809c1f8ae> does anyone happen to know if scikit-learns implementation of coordinate descent (for stuff like Lasso, ElasticNet, etc.) is stochastic?
[2017-05-31T06:43:27.841Z] <56c4f19ae610378809c1f8ae> i.e., does sample order matter?
[2017-05-31T06:43:38.044Z] <56c4f19ae610378809c1f8ae> (assuming random seeds are set and all that other stuff)
[2017-05-31T08:54:50.635Z] <56aba3aee610378809bedf43> I have been trying SVC and have a doubt. C is referred to the penalty term, therefore with increase in the value of C, the algorithm try's to reduce the number of wrong classified and with very high value of C it may overfit the data. Can we say that with overfitting, the number of support vectors would increase. And if we use a lower value of C the number of support vectors will be less ? 
[2017-05-31T08:55:25.990Z] <56aba3aee610378809bedf43> But the results I got were different, with small value of C, the model was underfit and the number of support vectors were huge  
[2017-05-31T09:03:28.088Z] <56aba3aee610378809bedf43> Can anyone explain, what is wrong with my thinking :P  
[2017-05-31T18:42:10.771Z] <592f0e7ad73408ce4f63b1dd> no
[2017-05-31T18:42:24.919Z] <592f0e7ad73408ce4f63b1dd> don't you know anything?
[2017-05-31T23:26:44.315Z] <574454a0c43b8c601974a563> @sbromberger Currently Im not familiar with Julia, but it seems to be easy. I will have a look at the necessary parts.
[2017-05-31T23:33:06.495Z] <574454a0c43b8c601974a563> @amitmanchanda1995 https://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel
[2017-05-31T23:37:20.323Z] <574454a0c43b8c601974a563> @amitmanchanda1995 Furthermore  the parameter `n_support_`  of an estimator gives you the number of used support vectors for each class: https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/svm/classes.py#L484-L485
[2017-06-01T00:23:49.052Z] <551c051b15522ed4b3de2fea> @nok - its a very cool language, and it has bindings to sklearn :)
[2017-06-01T07:23:17.978Z] <56aba3aee610378809bedf43> @nok thanks. Previously I thought only the vectors present on the boundary lines were only considered to be support vectors, but all the misclassified and the vectors on the boundary lines are support vector so if we increase C the number of support vectors will decrease. 
[2017-06-03T02:01:38.830Z] <590709b7d73408ce4f5c2454> S
[2017-06-03T10:53:23.788Z] <54d4a1d6db8155e6700f853b> @nelson-liu sample order shouldn't matter but feature order. Some pick the coordinates at random, I think.
[2017-06-03T10:54:47.739Z] <54d4a1d6db8155e6700f853b> @amitmanchanda1995 C is an upper bound on the dual coefficents, and if you restrict the dual coefficients more (make C smaller) you'll have less zero alphas, i.e. more support vectors
[2017-06-05T07:14:32.319Z] <56aba3aee610378809bedf43> Thanks @amueller. Can you also help me the following *In predict_proba of SVC* > Notes > The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.  What do we mean by cross validation in case of prediction, what I get by cross validation is that the training data is divided into K sets, and K-1 is used for training while the 1 set is used for testing.
[2017-06-05T07:15:13.695Z] <56aba3aee610378809bedf43> And it is repeated K times
[2017-06-05T07:15:21.515Z] <54d4a1d6db8155e6700f853b> check out the paper by platt
[2017-06-05T07:15:31.127Z] <54d4a1d6db8155e6700f853b> it's linked to in the description
[2017-06-05T07:15:53.586Z] <54d4a1d6db8155e6700f853b> predict_proba uses platt scaling internally
[2017-06-05T07:22:44.272Z] <54d4a1d6db8155e6700f853b> Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods, J. Platt, (1999)
[2017-06-05T07:22:54.133Z] <56aba3aee610378809bedf43> Thanks 
[2017-06-05T07:23:01.757Z] <54d4a1d6db8155e6700f853b> maybe also Predicting Good Probabilities with Supervised Learning, A. Niculescu-Mizil & R. Caruana, ICML 2005 
[2017-06-05T21:49:37.528Z] <551c051b15522ed4b3de2fea> `DBSCAN` takes a long time relative to K-means.
[2017-06-06T11:34:48.605Z] <593679b8d73408ce4f65082e> Hello!   Am I right that https://github.com/scikit-learn/scikit-learn/pull/6015 is also within the sprint scope? Can I take it?
[2017-06-06T11:35:16.567Z] <54d4a1d6db8155e6700f853b> @n0mad review it you mean?
[2017-06-06T11:39:02.555Z] <54e47f0815522ed4b3dc2640> Anyone tackling this already https://github.com/scikit-learn/scikit-learn/issues/8899 ? Seems easy and would be useful for hmmlearn as well.
[2017-06-06T11:39:29.689Z] <593679b8d73408ce4f65082e> @amueller I had impression it did not fully address https://github.com/scikit-learn/scikit-learn/issues/5879  so I thought I could continue working on it?
[2017-06-06T11:45:05.546Z] <55d21ee30fc9f982beadabb8> @superbobry You can go ahead if there is not PR yet
[2017-06-07T10:33:55.103Z] <54e07d0815522ed4b3dc0850> @jnothman : do you want to do a video hangout at some point, mostly to say hi and join the excitement?
[2017-06-07T10:34:47.075Z] <54e07d0815522ed4b3dc0850> @jnothman I believe that it's 8:30PM your time. We are currently having the lunch break. So maybe in a little while will be good. We can put you on a big screen
[2017-06-07T10:35:27.151Z] <54b2524adb8155e6700e8a8e> I'm okay with small screens. Sounds like fun. I'm currently having my dinner too.
[2017-06-07T10:41:51.564Z] <54e07d0815522ed4b3dc0850> OK, after dinner? Or will you be busy?
[2017-06-07T10:42:17.648Z] <54e07d0815522ed4b3dc0850> If you want: ping me on google hangout
[2017-06-07T10:49:22.976Z] <54b2524adb8155e6700e8a8e> Should be alright when all the feasting is 
[2017-06-07T10:49:24.465Z] <54b2524adb8155e6700e8a8e> over
[2017-06-07T10:50:35.055Z] <54e07d0815522ed4b3dc0850> Everybody is gone to take a break outside now :)
[2017-06-07T11:08:04.145Z] <54b2524adb8155e6700e8a8e> No hurry on my part! There's washing up to do.
[2017-06-07T11:08:44.274Z] <54e07d0815522ed4b3dc0850> When you want, everybody is back
[2017-06-07T11:22:43.327Z] <54b2524adb8155e6700e8a8e> Child calls. 
[2017-06-07T11:23:06.204Z] <54b2524adb8155e6700e8a8e> I'll be with you in a couple of mins
[2017-06-07T11:23:43.917Z] <54d4a1d6db8155e6700f853b> @tguillemot also https://github.com/scikit-learn/scikit-learn/pull/9030 https://github.com/scikit-learn/scikit-learn/pull/9029
[2017-06-07T11:23:45.483Z] <54d4a1d6db8155e6700f853b> ;)
[2017-06-07T11:35:23.548Z] <541a528b163965c9bc2053de> @jnothman I think @mblondel is going to ICML
[2017-06-07T11:35:50.385Z] <54b2524adb8155e6700e8a8e> Haha I think
[2017-06-07T12:29:19.364Z] <54e07d0815522ed4b3dc0850> All sprinters: we are having a sample-props discussion from 15:00 to 16:00, and a group picture at 16:00 hopefully on the roof
[2017-06-07T12:38:50.858Z] <56b0a775e610378809bf7a7c> if you want you can find a spec for sample-props  I have done several month ago to launch the discussion : https://github.com/tguillemot/sample_props_spec/blob/master/sample_props_spec_v2.md
[2017-06-07T12:39:14.949Z] <54d4a1d6db8155e6700f853b> thanks @tguillemot, I'll reread
[2017-06-07T12:41:23.891Z] <54e07d0815522ed4b3dc0850> Update: group picture: 16:30 sharp: Ibrahim will be there to bring us up to the roof
[2017-06-07T12:51:04.836Z] <54d4a1d6db8155e6700f853b> simple fix for making BaseSearchCV (more) API compatible: https://github.com/scikit-learn/scikit-learn/pull/9038
[2017-06-07T19:06:11.347Z] <55502d0c15522ed4b3e03330> hi all, I wish to calculate the confidence of an `SVC` prediction, but I have a hard time understanding the result I have fitting data like this ```python X = np.array([ 		[0, 0, 0, 0], 		[1, 1, 1, 1], 		[2, 2, 2, 2], 		[3, 3, 3, 3] 	])  y = np.array([ 	0, 1, 2, 3 	])  clf = svm.SVC(C=1, kernel='rbf', probability=True) clf.fit(X, y) ``` Then I predict the class for input `x = np.array([1, 2, 3, 4])`, and I the output makes sence ```python clf.predict([x]) # array([1]) ```  But the probability does not make sense at all ```python clf.predict_proba([x]) # array([[ 0.2550524 ,  0.16488868,  0.25497241,  0.3250865 ]]) ```  According to the probabilities, class `1` has the lowest possibility. Why is that?
[2017-06-07T19:10:15.663Z] <54d4a1d6db8155e6700f853b> what's x?
[2017-06-07T19:10:45.283Z] <54d4a1d6db8155e6700f853b> @nlhkh check out the docs, it tells you that there can be inconsistencies between the probability estimate and the prediction, because of the platt scaling that is used to create the predictions
[2017-06-07T19:11:49.391Z] <54d4a1d6db8155e6700f853b> you can also look at decision_function and that should be consistent
[2017-06-07T19:12:29.877Z] <55502d0c15522ed4b3e03330> oh, sorry
[2017-06-07T19:13:07.491Z] <55502d0c15522ed4b3e03330> ```python x = np.array([1, 1, 1, 1]) ``` 
[2017-06-07T19:13:36.811Z] <55502d0c15522ed4b3e03330> I tried the `decision_function` too
[2017-06-07T19:13:46.326Z] <55502d0c15522ed4b3e03330> Could you tell me a bit more what it means?
[2017-06-07T19:14:21.345Z] <54d4a1d6db8155e6700f853b> I can explain to you what happens: the probability estimate uses cross-validation to create the probability estimates, but there's only one data point for each class, so the models will be pretty useless
[2017-06-07T19:14:37.289Z] <54d4a1d6db8155e6700f853b> because as soon as you leave out some points you leave out the whole class
[2017-06-07T19:15:06.560Z] <54d4a1d6db8155e6700f853b> if you're trying to understand the svm algorithm, don't look at the probabilities
[2017-06-07T19:15:10.552Z] <54d4a1d6db8155e6700f853b> what is your goal?
[2017-06-07T19:15:21.998Z] <55502d0c15522ed4b3e03330> my goal is to determine how confident a prediction is
[2017-06-07T19:15:30.145Z] <54d4a1d6db8155e6700f853b> on this dataset?
[2017-06-07T19:15:31.147Z] <55502d0c15522ed4b3e03330> so as to declare that a prediction is not reliable
[2017-06-07T19:15:33.110Z] <55502d0c15522ed4b3e03330> no
[2017-06-07T19:15:42.129Z] <55502d0c15522ed4b3e03330> on a much bigger dataset
[2017-06-07T19:15:46.775Z] <55502d0c15522ed4b3e03330> this is just for example
[2017-06-07T19:15:48.438Z] <54d4a1d6db8155e6700f853b> ok. well then it will work
[2017-06-07T19:16:00.152Z] <55502d0c15522ed4b3e03330> so when I do this `clf.decision_function([x])`, I get this  ``` array([[-0.0296443 , -0.22257708, -0.22257708, -0.19293278, -0.19293278,         0.        ]]) ```
[2017-06-07T19:16:03.887Z] <54d4a1d6db8155e6700f853b> well the example is done in a way that breaks the method that is used to get the uncertainty
[2017-06-07T19:16:54.857Z] <55502d0c15522ed4b3e03330> how should I interprete these numbers?
[2017-06-07T19:17:19.886Z] <54d4a1d6db8155e6700f853b> predict_proba they are estimated probabilities of the classes
[2017-06-07T19:17:35.585Z] <54d4a1d6db8155e6700f853b> for decision_function they are unnormalized, so higher means better but there is no absolute scale
[2017-06-07T19:19:10.777Z] <54d4a1d6db8155e6700f853b> ```python import numpy as np from sklearn import svm X = np.array([         [0, 0, 0, 0],         [1, 1, 1, 1],         [2, 2, 2, 2],         [3, 3, 3, 3]     ]) X = np.repeat(X, 10, axis=0)  y = np.array([     0, 1, 2, 3     ]) y = np.repeat(y, 10)  clf = svm.SVC(C=1, kernel='rbf', probability=True) clf.fit(X, y) print(clf.predict([[1, 1, 1, 1]])) print(clf.predict_proba([[1, 1, 1, 1]])) ```
[2017-06-07T19:22:04.371Z] <55502d0c15522ed4b3e03330> ohhh, now it makes better sense
[2017-06-07T19:22:49.986Z] <55502d0c15522ed4b3e03330> so I do not have enough data for cross-validation
[2017-06-07T19:23:10.655Z] <54d4a1d6db8155e6700f853b> in your example, yes
[2017-06-07T19:23:19.585Z] <55502d0c15522ed4b3e03330> so in this case
[2017-06-07T19:23:30.609Z] <55502d0c15522ed4b3e03330> the decision_function is `array([[-1.00000001,  0.        ,  0.3495638 ,  1.00000001,  1.        ,         0.5530018 ]])`
[2017-06-07T19:23:43.221Z] <55502d0c15522ed4b3e03330> the evaluation for class 1 is 0
[2017-06-07T19:23:54.497Z] <55502d0c15522ed4b3e03330> so close to 0 is better?
[2017-06-07T19:24:03.179Z] <55502d0c15522ed4b3e03330> isnt that the distance to the hyperplane?
[2017-06-07T19:24:09.920Z] <54d4a1d6db8155e6700f853b> no
[2017-06-07T19:24:13.971Z] <54d4a1d6db8155e6700f853b> with this code I get
[2017-06-07T19:24:25.050Z] <54d4a1d6db8155e6700f853b> [[ 1.89159397  3.5         0.9255003  -0.31709426]] In [ ]: 
[2017-06-07T19:24:34.896Z] <54d4a1d6db8155e6700f853b> print(clf.decision_function([[1, 1, 1, 1]]))
[2017-06-07T19:24:56.857Z] <54d4a1d6db8155e6700f853b> higher is better
[2017-06-07T19:25:06.843Z] <54d4a1d6db8155e6700f853b> there's a 3.5 for class 1, that's why class 1 is predicted
[2017-06-07T19:25:13.297Z] <54d4a1d6db8155e6700f853b> it's always the argmax of the decision function
[2017-06-07T19:25:15.746Z] <55502d0c15522ed4b3e03330> I dont get the same output as yours
[2017-06-07T19:25:25.449Z] <54d4a1d6db8155e6700f853b> you're running different code then ;)
[2017-06-07T19:25:30.766Z] <55502d0c15522ed4b3e03330> no no
[2017-06-07T19:25:33.452Z] <55502d0c15522ed4b3e03330> I copied your code
[2017-06-07T19:25:52.504Z] <55502d0c15522ed4b3e03330> it returns an array of 6 elements
[2017-06-07T19:26:01.230Z] <54d4a1d6db8155e6700f853b> then you didn't copy my code
[2017-06-07T19:26:15.260Z] <54d4a1d6db8155e6700f853b> ohhh wait
[2017-06-07T19:26:16.164Z] <54d4a1d6db8155e6700f853b> sorry
[2017-06-07T19:26:23.627Z] <54d4a1d6db8155e6700f853b> set decision_function_shape='ovr'
[2017-06-07T19:26:29.961Z] <54d4a1d6db8155e6700f853b> if you have scikit-learn 0.17
[2017-06-07T19:26:38.717Z] <54d4a1d6db8155e6700f853b> you should upgrade to 0.18
[2017-06-07T19:26:53.148Z] <54d4a1d6db8155e6700f853b> SVC.decision_function is / was really weird as well
[2017-06-07T19:27:06.415Z] <55502d0c15522ed4b3e03330> it does say this "The decision_function_shape default value will change from 'ovo' to 'ovr' in 0.19. This will change the shape of the decision function returned by SVC. <unconvertable> :)
[2017-06-07T19:27:23.400Z] <54d4a1d6db8155e6700f853b> yeah
[2017-06-07T19:27:26.198Z] <54d4a1d6db8155e6700f853b> I wrote this ;)
[2017-06-07T19:27:34.714Z] <54d4a1d6db8155e6700f853b> make it ovr
[2017-06-07T19:27:45.213Z] <54d4a1d6db8155e6700f853b> then it'll have 4 elements
[2017-06-07T19:27:48.974Z] <54d4a1d6db8155e6700f853b> I'm on 0.19-dev
[2017-06-07T19:27:51.131Z] <54d4a1d6db8155e6700f853b> sorry about that
[2017-06-07T19:27:55.258Z] <55502d0c15522ed4b3e03330> I see :)
[2017-06-07T19:27:59.148Z] <55502d0c15522ed4b3e03330> it is an honor
[2017-06-07T19:28:00.703Z] <54d4a1d6db8155e6700f853b> ok starbucks is closing and I have to write a keynote
[2017-06-07T19:28:01.939Z] <54d4a1d6db8155e6700f853b> good luck
[2017-06-07T19:28:11.024Z] <55502d0c15522ed4b3e03330> have fun!
[2017-06-08T05:16:30.800Z] <584bec30d73408ce4f3c127e> Hello, I need some help with C++ Coding
[2017-06-08T09:15:37.999Z] <54d4a1d6db8155e6700f853b> @MoreToDo have you tried stackoverflow?
[2017-06-08T10:04:59.560Z] <54b2524adb8155e6700e8a8e> I've requested some very minor changes at #8096 and gather that @dalmia won't complete it. A volunteer to take it over?
[2017-06-08T11:54:52.422Z] <53135b495e986b0712efc453> Need any reviews anyone?
[2017-06-08T12:12:50.821Z] <547d8325db8155e6700da60b> @jnothman  do you still need someone for #8096 ??
[2017-06-08T12:13:51.195Z] <54b2524adb8155e6700e8a8e> Yes
[2017-06-08T12:20:43.474Z] <55d21ee30fc9f982beadabb8> @raghavrv I will need one soon
[2017-06-08T12:22:09.371Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/9058 he it goes
[2017-06-08T12:28:07.210Z] <53135b495e986b0712efc453> Aye master on it :)
[2017-06-08T12:54:56.763Z] <547d8325db8155e6700da60b> @jnothman see #9059 
[2017-06-08T13:57:05.826Z] <5634e15116b6c7089cb8f9f2> hey all, please point me to a "Definitive g"
[2017-06-08T13:58:57.944Z] <5634e15116b6c7089cb8f9f2> hey all, don't mean to bother but please I'd appreciate if I could be pointed to a "Definitive guide to using Scikit-Learn" -style tutorial walkthrough. Peace <unconvertable>
[2017-06-09T12:02:17.770Z] <59366dabd73408ce4f6504fd> Did you miss this http://scikit-learn.org/stable/ ?
[2017-06-09T17:34:30.483Z] <541a528b163965c9bc2053de> @Ij888  There is http://scikit-learn.org/stable/tutorial/index.html or you can buy a book such as: http://shop.oreilly.com/product/0636920030515.do
[2017-06-10T07:16:05.110Z] <5634e15116b6c7089cb8f9f2> thanks @dohmatob and @ogrisel . I tried working through the docs on  http://scikit-learn.org/stable/tutorial/basic/tutorial.html but it got rather dense at the **Learning and predicting** section especially at `clf.fit(digits.data[:-1], digits.target[:-1])`. I am at a loss to what some of the parameters in `SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)` represent. 
[2017-06-10T09:41:59.402Z] <541a528b163965c9bc2053de> you don't need to know the meaning of them all at first but you should check the API documentation of the SVC class at some point
[2017-06-10T10:05:41.965Z] <541a528b163965c9bc2053de> http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
[2017-06-10T11:11:51.066Z] <5634e15116b6c7089cb8f9f2> thanks for the tip @ogrisel  <unconvertable>
[2017-06-10T12:08:12.958Z] <5784d86dc2f0db084a229ae0> Hey guys! I have an idea for an app and I was hoping i could find rediculously passionate people who could come work with me. it has machine learning integrated to bring progress to mankind.
[2017-06-10T17:11:48.531Z] <541a528b163965c9bc2053de> I think people in this room are ridiculously passionate (and incredibly busy) in building tools for other people to build apps to bring progress to mankind.
[2017-06-10T17:12:00.460Z] <541a528b163965c9bc2053de> ;)
[2017-06-10T17:12:16.815Z] <547d8325db8155e6700da60b> ajajajajaaj
[2017-06-10T19:00:45.352Z] <5784d86dc2f0db084a229ae0> @ogrisel Haha yeah that's pretty evident :') so you wouldn't be able to help me?
[2017-06-10T19:06:46.245Z] <541a528b163965c9bc2053de> I am sorry, no. You should probably setup a proof of concept of your own if you want to recruit others to join your project.
[2017-06-10T19:32:48.073Z] <593c448fd73408ce4f66554c> Hi, I am a veteran R/Rcpp developer wanting to transition to being a sklearn contributor. There are a lot of classes and I think a consistent coding style in the sklearn code base - I'm wondering if there are any docs or presentations on the overall architecture (class hierarchy, the way helper functions should be organized, etc) that could help me understand the flow and be able to contribute?
[2017-06-10T20:19:45.038Z] <55d21ee30fc9f982beadabb8> @jeffwong I would check the tutorial http://scikit-learn.org/stable/tutorial/index.html The introduction will give you the convention and bases regarding the estimator
[2017-06-11T10:59:19.791Z] <541a528b163965c9bc2053de> @jeffwong and the contributors doc: http://scikit-learn.org/stable/developers/contributing.html
[2017-06-12T12:04:33.504Z] <54908b42db8155e6700dfe2d> Is there any way to incorporate cost matrix in SVM classification as is available in weka https://weka.wikispaces.com/CostSensitiveClassifier
[2017-06-12T16:00:07.855Z] <54d4a1d6db8155e6700f853b> @axay possibly the class_weight parameter, though that doesn't allow specifying a full matrix, only relative weights
[2017-06-12T16:00:53.537Z] <54d4a1d6db8155e6700f853b> It also depends a bit on whether you want to do that for training or for predicting with a trained model or both. It looks like weka influences the training.
[2017-06-12T16:03:11.291Z] <54908b42db8155e6700dfe2d> weka supports both afaik. My aim is to prevent misclassification of other labels as a target label
[2017-06-12T16:03:39.418Z] <54908b42db8155e6700dfe2d> for example if i have 3 labels A, B and C, I don't want A and C to be predicted as B
[2017-06-12T16:03:42.856Z] <54d4a1d6db8155e6700f853b> false positives for that label?
[2017-06-12T16:03:52.637Z] <54908b42db8155e6700dfe2d> yeah
[2017-06-12T16:04:25.805Z] <54d4a1d6db8155e6700f853b> I think it would make most sense to calibrate the prediction thresholds for that, but scikit-learn doesn't have tools for that yet.
[2017-06-12T16:04:54.655Z] <54d4a1d6db8155e6700f853b> you can try to change the class-weights, but the control they give is a bit indirect
[2017-06-12T16:05:33.735Z] <54d4a1d6db8155e6700f853b> do you know how weka implements this?
[2017-06-12T16:06:05.709Z] <54d4a1d6db8155e6700f853b> the scikit-learn class_weights for SVC are multipliers to C so that you get one C per class, as described in the libsvm paper
[2017-06-12T16:06:11.417Z] <54908b42db8155e6700dfe2d> no, haven't gone through their code yet.
[2017-06-13T07:35:52.745Z] <593f94a1d73408ce4f66e9df> Hi, this is probably not the right forum to ask it, but not sure where else to go: How do I get permission to use the scikit-learn machine learning map (ML-map.png) in a published document? Obviously with full citation!  Thanks. Available from this link: http://scikit-learn.org/stable/tutorial/machine_learning_map/
[2017-06-13T09:45:06.243Z] <56aba3aee610378809bedf43> Hi, is there any way to incorporate self-learning in SVC. By self-learning I mean if a datapoint is being predicted class A with accurary 0.7, then if I add same datapoint again in the corpus, then the prediction accurary should increase from 0.7 like in case of Neural Nets. But looking at the mathematics, if the datapoint is not a support vector then it is not considered in cost function. Then what should I do to increase the accuracy?
[2017-06-13T09:46:29.653Z] <54d4a1d6db8155e6700f853b> Self learning is a meta-algorithm for semi-supervised learning and should work with any supervised model.
[2017-06-13T09:46:56.760Z] <54d4a1d6db8155e6700f853b> I'm not sure what you mean by a point being predicted with accuracy 0.7
[2017-06-13T09:48:27.265Z] <56aba3aee610378809bedf43> predict_proba of SVC gives me a confidence score of 0.7. Can I seed it back into your model and hope that the next time confidence score for the same datapoint increase  
[2017-06-13T09:50:26.949Z] <54d4a1d6db8155e6700f853b> that's not the same as accuracy. and SVC is not probabilistic. And was it in the original training set? self-learning is for semi-supervised learning
[2017-06-13T09:50:48.735Z] <54d4a1d6db8155e6700f853b> I think SVC uses sample_weight that you can increase
[2017-06-13T09:50:53.170Z] <54d4a1d6db8155e6700f853b> hm...
[2017-06-13T09:53:52.585Z] <56aba3aee610378809bedf43> yeah sorry that was a mistake. what I want is once I deploy a model in production, it somehow keeps on improving. I was thinking that if the confidence score of an unseen data point is above a certain threshold (say 0.7) i add it to the training set and retrain . Is it a good idea to use this with SVC ?
[2017-06-13T12:09:18.342Z] <54d4a1d6db8155e6700f853b> yeah that can work. self learning can have problems with concept drift
[2017-06-14T01:31:20.800Z] <584bec30d73408ce4f3c127e> Hello, I need some assistance with C++ homework.  let me know if anyone can assist!
[2017-06-14T02:03:18.572Z] <57379367c43b8c601972f35d> hey
[2017-06-14T15:28:52.125Z] <55e777330fc9f982beaf78c9> anyone seen an error like this when building from source? I get this with conda Cython but not pip Cython (0.25.2 in both cases, Python 3.6.1) ``` [ 2/39] Cythonizing sklearn/_isotonic.pyx Traceback (most recent call last):   File "setup.py", line 267, in <module>     setup_package() ... "/Users/brettnaul/miniconda3/envs/py361/lib/python3.6/copy.py", line 169, in deepcopy     rv = reductor(4) TypeError: can't pickle Cython.Compiler.FlowControl.NameAssignment objects ```
[2017-06-15T11:03:58.681Z] <58e53928d73408ce4f565aa3> hi guys ,i m coding in c ,and i want to store values from a txt file to an array any idea ?
[2017-06-15T11:11:45.869Z] <55d21ee30fc9f982beadabb8> @Krikbov  Bad chance that scikit-learn is in Python
[2017-06-16T01:11:30.706Z] <5941c1b4d73408ce4f6764d6> Hello my name is priyam and i am interested in contributing to scikit-learn.Can anyone help me i am completely new in open source world.
[2017-06-16T07:55:34.178Z] <541a528b163965c9bc2053de> @bnaul that's really weird. Do you have the full Traceback? It seems that the interesting part is under the setup_package function.
[2017-06-16T15:19:35.458Z] <57433a8cc43b8c6019747d9e> @satishjasthi Hi all, Anyone knows how to visualize high dimensional data in 2d image
[2017-06-16T15:20:23.867Z] <57433a8cc43b8c6019747d9e> We have 25 instances each of dimension 1800. We want to visualize each instance separately and then build a classifier on it.
[2017-06-16T15:20:28.569Z] <57433a8cc43b8c6019747d9e> Please help
[2017-06-16T15:21:57.784Z] <541a528b163965c9bc2053de> You can do a scatter plot of a t-SNE embedding to get some intuition on the structure of your data.  But you should not train the classifier on the 2D project. It's very likely that you will get much higher predictive accuracy by training the classifier on the original high dimensional data.
[2017-06-16T15:23:25.563Z] <57433a8cc43b8c6019747d9e> can We visualize each instance separately in t-SNE
[2017-06-16T15:23:47.126Z] <541a528b163965c9bc2053de> There is a TSNE class in scikit-learn but it has many bugs. We would like to solve them for the next release but it's not ready yet. I would advise to have a look at https://github.com/lvdmaaten/bhtsne .
[2017-06-16T15:24:11.771Z] <541a528b163965c9bc2053de> The scatter plot will put on dot in the 2D plane for each instance.
[2017-06-16T15:24:36.494Z] <541a528b163965c9bc2053de> What you visualize is the neighborhood structure of your data.
[2017-06-16T15:24:56.453Z] <541a528b163965c9bc2053de> http://distill.pub/2016/misread-tsne/
[2017-06-16T15:25:18.743Z] <57433a8cc43b8c6019747d9e> No. We dont want a dot for each instance. We want an altogether different 2D image for each instance
[2017-06-16T15:25:47.946Z] <541a528b163965c9bc2053de> You should also try with 2D PCA of your data. This is much faster to compute alhough generally the neighborhood structure can be much blurier.
[2017-06-16T15:27:11.274Z] <541a528b163965c9bc2053de> I don't understand what it means to "visualize a 2D image or a single 1800 dimensional vector".
[2017-06-16T15:27:24.212Z] <541a528b163965c9bc2053de> what are you features ? which data types ? what is the physical meaning of each of them ?
[2017-06-16T15:28:40.271Z] <57433a8cc43b8c6019747d9e> We have 1800 features for each instance. We then need to visualize these 1800 features in a single image. Repeat this process for each instance. And then build a classifier on it
[2017-06-16T15:29:39.741Z] <541a528b163965c9bc2053de> you already said that, please answer my question if you want me to be able to help you.
[2017-06-16T15:29:40.539Z] <57433a8cc43b8c6019747d9e> we got these 1800 features after doing CNN on the image
[2017-06-16T15:30:30.510Z] <57433a8cc43b8c6019747d9e> RGB image, we performed CNN, and then extracted features are of dimension 1800
[2017-06-16T15:30:53.248Z] <541a528b163965c9bc2053de> There is no generic way to visualize a single feature vector of a CNN.
[2017-06-16T15:31:19.479Z] <57433a8cc43b8c6019747d9e> We have 25 such images
[2017-06-16T15:31:32.833Z] <57433a8cc43b8c6019747d9e> so it becomes 25X1800
[2017-06-16T15:32:58.675Z] <541a528b163965c9bc2053de> If you want to visualize the distribution of your 25 images embedded in the 1800 dimensional CNN space,  then you can use PCA or TSNE, for instance using http://projector.tensorflow.org/ (online web interface) or https://github.com/lvdmaaten/bhtsne to do that programmatically.
[2017-06-16T15:36:25.444Z] <541a528b163965c9bc2053de> Also if you want to train an image classifier, I would advise you to build a training set with at list 100 images per class. 25 is probably far too few even if you do binary classification.
[2017-06-17T03:12:03.859Z] <5634e8e116b6c7089cb8fa99> Hi all, has anyone in scikit-learn tried to import some of the surrogate model methods used by pyKriging or inspyred?
[2017-06-17T06:40:22.872Z] <57433a8cc43b8c6019747d9e> Hi all, So we have 25 images of dimension 400X488. We have labels assigned to each image as 1/0 . There are 14 1s and 11 0s. What we need to do is we need to find pixels that differentiates 1 from 0. Also along with these differentiating pixels we also need to allot ranking to them based on their frequency in images with label 1.  Any thoughts on how to do it?
[2017-06-17T06:50:05.370Z] <57433a8cc43b8c6019747d9e> @ogrisel Thank you
[2017-06-17T06:50:07.206Z] <57433a8cc43b8c6019747d9e> Hi all, So we have 25 images of dimension 400X488. We have labels assigned to each image as 1/0 . There are 14 1s and 11 0s. What we need to do is we need to find pixels that differentiates 1 from 0. Also along with these differentiating pixels we also need to allot ranking to them based on their frequency in images with label 1.  Any thoughts on how to do it?
[2017-06-21T09:05:32.498Z] <541a528b163965c9bc2053de> @satishjasthi please do not spam this channel with repeated questions. The way you pose your image classification problem is very non standard. What does ranking pixels mean? Why do you want to do that in the first place? Is this a natural image classification problem? In that case you will need much more than 25 labeled images to do anything useful as I already told you earlier. If those are not natural images then you should probably give more details on the nature of the images. Which objects are in the images? What are the two labels 0 and 1 (what do they mean)? Have the images been recorded with a traditional camera with three color channels or is it a very specific recording device?
[2017-06-26T09:43:18.784Z] <55502d0c15522ed4b3e03330> Hi all, I want to revisit the question regarding how to interpret the output of `decision_function`into something meaningful. With the output from `decision_function`, how can I determine if a prediction is trust worthy or not, given some threshold `alpha`?
[2017-06-26T09:45:16.030Z] <541a528b163965c9bc2053de> There is no generic method, it depends on your estimator and the kind of multiclass reduction used by the underlying model (e.g. One vs One for SVC, One vs All for most other models such as LinearSVC).
[2017-06-26T09:48:50.939Z] <541a528b163965c9bc2053de> You might also have heteroschedastic prediction errors: some regions of your feature space might lead to a higher error rate and this heteroschedasticity might not be part of the model assumptions (or maybe cannot be handled properly by the model capacity).
[2017-06-26T09:51:15.737Z] <541a528b163965c9bc2053de> Which model family are you interested in? One interesting thing to consider is using a calibrated classifier (especially for binary classification): http://scikit-learn.org/stable/modules/calibration.html This way you can better interpret the output of `clf.predict_proba`. This won't solve any heteroschedasticity issues though.
[2017-06-26T09:53:48.149Z] <541a528b163965c9bc2053de> What you can also do is plot the precision / recall curve, select an admissible precision level (e.g. 0.8) according to business considerations and select the model and threshold that maximizes the recall at that precision level. We currently don't have a high level API to do this but the http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html function of scikit-learn returns the thresholds for each point along the PR curve.
[2017-06-26T09:57:08.202Z] <541a528b163965c9bc2053de> Once you have fitted your best model, you can compute its precision and recall on a held out test set to check that this is still fine, and further analyse that you don't have strong heteroschedasticity in your precision / recall metrics. For instance if you use your classifier to build a recommender systems for users, you can check that you get approximately similar performance for various ways to split your user base, e.g.: male vs female users, age groups, geography, very engaged users vs casual users...
[2017-06-26T12:23:20.553Z] <55502d0c15522ed4b3e03330> @ogrisel thanks Olivier :smile: I'll give it a try
[2017-06-26T12:23:37.235Z] <55502d0c15522ed4b3e03330> I am doing facial recognition, so it's multiclass
[2017-06-26T12:25:50.281Z] <541a528b163965c9bc2053de> you should definitely try to label your test dataset with additional info such as facial hair, glasses, long hair vs short air, gender, maybe ethnicity so as to compare the accuracy of your model for different groups of people.
[2017-06-28T05:15:41.973Z] <59533ac5d73408ce4f6a9616> i have  some customers data what information can i get from there using machine learning
[2017-06-28T06:51:28.827Z] <59533ac5d73408ce4f6a9616> hi there
[2017-06-28T08:52:50.214Z] <59533ac5d73408ce4f6a9616> @ogrisel  hi there
[2017-06-28T13:39:42.137Z] <58bf9a31d73408ce4f4f2137> Lol wut 
[2017-06-29T13:00:58.017Z] <55502d0c15522ed4b3e03330> when I use `GridSearchCV`, how can I find the actual parameters being used for a classifier?
[2017-06-29T13:01:22.205Z] <55502d0c15522ed4b3e03330> the `get_params` method seems to print everything in the search grid
[2017-06-29T13:01:25.266Z] <541a528b163965c9bc2053de> `grid_search.best_params_` after fit
[2017-06-29T13:01:42.406Z] <55502d0c15522ed4b3e03330> ah ok
[2017-06-29T13:01:49.133Z] <55502d0c15522ed4b3e03330> thanks Olivier :)
[2017-06-29T14:09:48.369Z] <54d4a1d6db8155e6700f853b> test #9032
[2017-06-29T22:35:25.893Z] <5572219415522ed4b3e17f0c> I'm using sklearn '0.15.0b1'.  I think I found a bug - when using lm.Ridge, if XtX is singular, the problem is still solved but sample_weight is ignored.  Is this worth filing an issue for?  I tried searching to see if this has been reported/resolved but I didn't find anything
[2017-06-29T22:36:02.177Z] <54d4a1d6db8155e6700f853b> @hhuuggoo that's a *really* old version and a beta release. Can you please update to master and see if the problem persists?
[2017-06-29T22:36:11.024Z] <5572219415522ed4b3e17f0c> yea I'll check
[2017-06-29T22:48:15.741Z] <5572219415522ed4b3e17f0c> ok cool looks like it's correct in sklearn 0.18.2
[2017-06-29T22:48:27.255Z] <54d4a1d6db8155e6700f853b> great :)
[2017-06-29T23:43:53.819Z] <54d4a1d6db8155e6700f853b> I'm close to defeating my arch enemy, dot: https://user-images.githubusercontent.com/449558/27715089-d81ef462-5d02-11e7-806b-87ac0753ecbe.png
[2017-06-29T23:44:04.335Z] <54d4a1d6db8155e6700f853b> (pure matplotlib)
[2017-06-30T06:01:24.767Z] <541a528b163965c9bc2053de> :)
[2017-06-30T06:04:25.726Z] <541a528b163965c9bc2053de> Maybe you should make all boxes have the same width and left align the content:  ```text petal width(cm) split: <= 1.65 entropy: 0.041 samples: 48 value: 0, 47, 1 class:  versicolor ```
[2017-07-01T02:32:06.749Z] <5864997ad73408ce4f3fe96c> cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccp
[2017-07-02T02:09:09.823Z] <558ca3d015522ed4b3e2cf85> Hello
[2017-07-03T07:32:46.581Z] <536ba85d048862e761fa0abb> l
[2017-07-04T08:46:12.766Z] <5799ed1c40f3a6eec05ce0b3> Hello good people! If I may enquire,  is there any advantage for using one-hot encoding over label encoding with GradientBoosting algorithm?
[2017-07-04T16:14:45.316Z] <590c8ffdd73408ce4f5d352d> Hi, Is there a particular clustering algorithm that works best with time series? 
[2017-07-05T04:53:25.359Z] <54b2524adb8155e6700e8a8e> @arnawldo, LabelEncoder is not intended for features.
[2017-07-05T06:02:41.978Z] <5799ed1c40f3a6eec05ce0b3> @jnothman so given my feature is categorical,  should I just replace the levels with integers, or spread it across columns?
[2017-07-05T06:44:31.887Z] <54b2524adb8155e6700e8a8e> We have had discussions on this topic on the mailing list. Either should work alright with trees. Integers will require deeper trees to select for (or against) a single category. So the model parameters need to be tuned to whichever approach you take.
[2017-07-05T06:56:12.704Z] <5799ed1c40f3a6eec05ce0b3> @jnothman great. How can I see this discussion and learn more. I'm not on this list
[2017-07-05T07:00:00.463Z] <54b2524adb8155e6700e8a8e> https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/ suggests you are better off with integers, fwiw
[2017-07-05T07:06:43.317Z] <5799ed1c40f3a6eec05ce0b3> @jnothman Thanks a lot
[2017-07-05T10:33:27.248Z] <57a061aa40f3a6eec05d8d26> Hello
[2017-07-05T10:35:01.610Z] <57a061aa40f3a6eec05d8d26> Docs for nearest neighbors says "The most naive neighbor search implementation involves the brute-force computation of distances between all pairs of points in the dataset...". Why it is so?
[2017-07-05T10:47:07.403Z] <54b2524adb8155e6700e8a8e> Because BallTree and KDTree require true metrics and dense data; and because brute force pairwise distances may be faster for small datasets.
[2017-07-05T10:49:22.343Z] <57a061aa40f3a6eec05d8d26> I mean, why it is pairwise (O(dn^2))? Why you have to compute distances between all pairs of points? I'm trying to understand the time complexity of the kNN, that's why I ask.
[2017-07-05T10:50:18.772Z] <5683764a16b6c7089cc092dc> hmm, it is hard to say. it is the nature of kNN. you can find some visualization of kNN on the Internet and you will understand
[2017-07-05T10:50:47.337Z] <5683764a16b6c7089cc092dc> well, let's say for  one new data point
[2017-07-05T10:51:03.002Z] <5683764a16b6c7089cc092dc> how do you know the k-nearest neighbors of this new one?
[2017-07-05T10:51:52.107Z] <57a061aa40f3a6eec05d8d26> calculate distance from this new point to all training points and keep k closest?
[2017-07-05T10:51:58.601Z] <5683764a16b6c7089cc092dc> yep
[2017-07-05T10:52:01.267Z] <5683764a16b6c7089cc092dc> exactly
[2017-07-05T10:52:11.988Z] <5683764a16b6c7089cc092dc> so for one data point you need n calculation
[2017-07-05T10:52:35.862Z] <57a061aa40f3a6eec05d8d26> yes
[2017-07-05T10:52:43.963Z] <5683764a16b6c7089cc092dc> so ?
[2017-07-05T10:53:15.016Z] <57a061aa40f3a6eec05d8d26> isn't it then like O(knd), not O(dn^2) ?
[2017-07-05T10:54:29.140Z] <5683764a16b6c7089cc092dc> :D
[2017-07-05T10:54:30.317Z] <5683764a16b6c7089cc092dc> cool
[2017-07-05T10:54:32.755Z] <5683764a16b6c7089cc092dc> let me check again
[2017-07-05T10:54:33.112Z] <5683764a16b6c7089cc092dc> :D
[2017-07-05T10:55:33.581Z] <5683764a16b6c7089cc092dc> I suppose it means you find kNN for all N
[2017-07-05T10:55:59.416Z] <57a061aa40f3a6eec05d8d26> I can understand that, but why I would like to do that?
[2017-07-05T10:57:35.047Z] <5683764a16b6c7089cc092dc> hmm, I have no answer for this in fact
[2017-07-05T10:57:35.546Z] <5683764a16b6c7089cc092dc> :D
[2017-07-05T10:58:06.716Z] <5683764a16b6c7089cc092dc> https://stats.stackexchange.com/questions/219655/k-nn-computational-complexity
[2017-07-05T10:58:46.756Z] <5683764a16b6c7089cc092dc> https://nlp.stanford.edu/IR-book/html/htmledition/time-complexity-and-optimality-of-knn-1.html
[2017-07-05T10:58:50.575Z] <57a061aa40f3a6eec05d8d26> Yes, I was just reading that... the example I gave was from that 
[2017-07-05T10:59:00.494Z] <57a061aa40f3a6eec05d8d26> (crossvalidated I mean)
[2017-07-05T10:59:07.089Z] <5683764a16b6c7089cc092dc> yep, they say the same thing
[2017-07-05T11:00:58.482Z] <57a061aa40f3a6eec05d8d26> It seems that people just think it different ways. And probably different implementations.
[2017-07-05T11:01:02.853Z] <57a061aa40f3a6eec05d8d26> That's why they differ
[2017-07-05T11:01:30.966Z] <5683764a16b6c7089cc092dc> I wouldnt say so. brute-force kNN is very straightforward
[2017-07-05T11:02:38.985Z] <57a061aa40f3a6eec05d8d26> Well, the answer at the Cross Validated says it depends on "algorithmic choices"
[2017-07-05T11:02:49.997Z] <57a061aa40f3a6eec05d8d26> Doesn't it mean different implementations?
[2017-07-05T11:07:06.156Z] <54b2524adb8155e6700e8a8e> O(knd) is referring to the cost *per query*. If you have n queries, then the cost is O(kn^2d)
[2017-07-05T11:09:29.713Z] <54b2524adb8155e6700e8a8e> and by per query I mean per instance in your query
[2017-07-05T11:09:49.142Z] <54b2524adb8155e6700e8a8e> With a binary tree index, the k neighbor search should be O(k log n) *per query* (ignoring some factor related to d)
[2017-07-05T11:15:59.804Z] <57a061aa40f3a6eec05d8d26> Ok, it's just confusing when the complexity of brute force is stated to be O(DN^2) i.e. N queries in O(DN) time but for KD-tree it's stated to be O(log N) i.e. only for one query. Or am I missing something here?
[2017-07-05T11:18:18.049Z] <57a061aa40f3a6eec05d8d26> Should it be made more clear in the docs that it refers to computing nearest neighbors for N query points?
[2017-07-05T11:37:30.037Z] <57a061aa40f3a6eec05d8d26> Also, I looked at code and if I'm not mistaken, it  calculates pairwise distances between query points and training points using pairwise_distances() function. In this case, if there's M query points, it would be O(DMN) and only if M is close to N in size, then it's O(DN^2), right?
[2017-07-05T11:40:55.606Z] <54b2524adb8155e6700e8a8e> sure. a pull request is welcome which removes the ^2. I think the current implementation is actually something like O(knd log k)...
[2017-07-05T11:52:39.840Z] <57a061aa40f3a6eec05d8d26> Ok. Where does the log k come from?
[2017-07-05T12:15:40.856Z] <54b2524adb8155e6700e8a8e> we sort the k neighbors so nearest is output first. which we perhaps need not be doing.
[2017-07-05T12:17:39.293Z] <57a061aa40f3a6eec05d8d26> Oh, I saw that on the code... thanks for helping
[2017-07-06T13:02:32.048Z] <55f3c8020fc9f982beb0733a> Hi All! Is there an option to run k-median incremental algorithm with the library? Thanks
[2017-07-06T13:39:15.772Z] <54b2524adb8155e6700e8a8e> It is not provided in the library, but there might be a compatible implementation outside. There is an implementation of K Medoids under review, but this is not the same thing.
[2017-07-06T14:57:19.531Z] <55f3c8020fc9f982beb0733a> thanks
[2017-07-07T09:32:31.055Z] <5938174cd73408ce4f656da8> Hi all, I have a program to run pipeline with featureunion infinitely by putting into fit_transform function and training data. So may I know how to know program running status? I am using anaconda Jupiter notebook to run that python script. Million thanks
[2017-07-07T09:33:13.634Z] <5938174cd73408ce4f656da8> Any verbose features available on fit transform and pipeline?
[2017-07-07T14:51:16.079Z] <54d4a1d6db8155e6700f853b> @bryanleekw it depends on the models in the pipeline
[2017-07-07T14:51:46.525Z] <54d4a1d6db8155e6700f853b> there is a pull request for verbosity in pipelines, but I don't think it's merged yet
[2017-07-07T21:30:50.394Z] <55366f4c15522ed4b3df5040> Hi, does anybody know how should I go if I want to work on an open PR from another person?
[2017-07-07T21:51:35.663Z] <54d4a1d6db8155e6700f853b> you can add them as a remote and pull their branch and open your own pr
[2017-07-07T21:52:21.311Z] <54d4a1d6db8155e6700f853b> @gsmafra 
[2017-07-08T02:58:10.665Z] <5938174cd73408ce4f656da8> Thanks Andreas, may I know any links in sklearn that i can know detail?
[2017-07-08T13:12:10.234Z] <5960d940d73408ce4f6c33f4> hi guys, i am new to gitter. Not sure if this is right way and channel to post the doubt. but if it is, here is my doubt: I have to create a model to assign sales representatives in like 105 territories across united states based on sales-and other business rules like geo location - in each territory. But i am having hard time finding a solution to limit the size of each cluster based on sales, vicinity and few other parameters. So my question is how do i stop the cluster from growing when it meets a certain defined criteria/conditions.
[2017-07-11T13:29:54.028Z] <54e07d6515522ed4b3dc0858> If you truly want to dynamically "stop growing a cluster" based on custom criteria, I don't think any of the scikit-learn algorithms have an API for that. Moreover, it would only apply to algorithms that incrementally grow clusters, e.g. hierarchical clustering. If your dataset is not huge and you don't need to fit many different models, you could try implementing your own hierarchical clustering with simple python logic, and add your own constraints. It's a fairly straightforward algorithm.
[2017-07-12T01:52:41.046Z] <54b2524adb8155e6700e8a8e> As its agglomerative, you dont lose a great deal by not stopping. You should just process the output of linkage_tree to adhere to your criteria.
[2017-07-12T10:01:39.990Z] <5581814615522ed4b3e20c6a> Its is possible to retrain a Sklearn classifier once loaded back from a pickled filed
[2017-07-12T10:02:16.987Z] <541a528b163965c9bc2053de> Yes but it will forget everything from the previous training set.
[2017-07-12T10:02:32.910Z] <5581814615522ed4b3e20c6a> So its again a fresh training?
[2017-07-12T10:02:46.171Z] <541a528b163965c9bc2053de> Yes.
[2017-07-12T10:02:56.381Z] <5581814615522ed4b3e20c6a> Is there a way to persist that memory
[2017-07-12T10:07:05.058Z] <541a528b163965c9bc2053de> There is no generic way, it depends on the model. Some models have a `partial_fit` method, it might or might not do want you want. Read the documentation, the reference papers of the literature (usually referenced in the docstring of the class) and the source code of the model to determine that whether it can help accomplish what you are looking for.
[2017-07-12T10:07:46.206Z] <5581814615522ed4b3e20c6a> @ogrisel thank you for this information
[2017-07-12T10:08:56.835Z] <541a528b163965c9bc2053de> My advice would be to always snapshot the training sets of your models so that you can retrain later, possibly with an extended / enriched training set.
[2017-07-12T10:10:07.419Z] <5581814615522ed4b3e20c6a> So you mean to keep the training set as a back up and letter merge the new dataset with old and fit
[2017-07-12T10:10:27.059Z] <541a528b163965c9bc2053de> yes, that's the safest thing to do.
[2017-07-12T10:10:37.166Z] <5581814615522ed4b3e20c6a> Perfect
[2017-07-12T10:11:07.930Z] <541a528b163965c9bc2053de> you can discard or down weight older samples if you think that the distribution of the data drifts over time.
[2017-07-12T10:11:29.803Z] <5581814615522ed4b3e20c6a> Ok that sounds good
[2017-07-12T14:39:21.341Z] <54d4a1d6db8155e6700f853b> @ogrisel did you tag at some point?
[2017-07-12T14:39:38.390Z] <54d4a1d6db8155e6700f853b> We should definitely tag before the sprint
[2017-07-12T14:40:07.978Z] <54d4a1d6db8155e6700f853b> looks like no branch yet
[2017-07-12T16:01:15.592Z] <59533ac5d73408ce4f6a9616> sir can i ask You something
[2017-07-12T16:02:05.137Z] <59533ac5d73408ce4f6a9616> hi there
[2017-07-12T16:02:14.382Z] <54d4a1d6db8155e6700f853b> hi
[2017-07-12T16:02:18.572Z] <59533ac5d73408ce4f6a9616> if i have few doubt
[2017-07-12T16:02:20.290Z] <541a528b163965c9bc2053de> @amueller no, not yet I got busy on other thing and now I am back at trying to debug a precision issue in the error computation of the TSNE model that has an impact on the stopping criterion.
[2017-07-12T16:02:25.273Z] <59533ac5d73408ce4f6a9616> for interviw
[2017-07-12T16:02:33.273Z] <59533ac5d73408ce4f6a9616> can any one help me
[2017-07-12T16:02:57.436Z] <54d4a1d6db8155e6700f853b> @ogrisel so branch now and backport TSNE once it's merged?
[2017-07-12T16:02:58.988Z] <541a528b163965c9bc2053de> @amueller  In any case, if I cannot find the bug before tomorrow, I will cut the branch 0.19.X anyway.
[2017-07-12T16:03:11.895Z] <54d4a1d6db8155e6700f853b> ok that
[2017-07-12T16:03:16.942Z] <54d4a1d6db8155e6700f853b> also good with me @ogrisel 
[2017-07-12T16:03:29.907Z] <59533ac5d73408ce4f6a9616> @amueller can i ask u something
[2017-07-12T16:03:38.145Z] <54d4a1d6db8155e6700f853b> sure
[2017-07-12T16:04:19.191Z] <59533ac5d73408ce4f6a9616> @amueller  I have an interviw  in a startup
[2017-07-12T16:05:11.009Z] <59533ac5d73408ce4f6a9616> @amueller I clear technical part but if somebody ask about is there any questions for me  what should i ask
[2017-07-12T16:05:40.412Z] <54d4a1d6db8155e6700f853b> This is not really a forum to discuss interview practices
[2017-07-13T12:08:40.416Z] <5964e3b4d73408ce4f6c9e02> Hey! Did someone deal with this preprocessing dilemma when working with timeseries? https://stackoverflow.com/questions/45080001/how-to-preprocess-timeseries-test-data-to-make-a-classification-prediction
[2017-07-13T15:42:20.798Z] <54d4a1d6db8155e6700f853b> if anyone wants to help the sprints run smoothly, please help tag issues appropriately with "easy" "need contributor" and "sprint"
[2017-07-13T15:52:19.710Z] <54d4a1d6db8155e6700f853b> looks like all "easy" "need contributor" issues already have PRs awaiting review...
[2017-07-13T15:52:22.506Z] <54d4a1d6db8155e6700f853b> so review sprint?
[2017-07-13T15:52:24.811Z] <54d4a1d6db8155e6700f853b> ;)
[2017-07-13T16:24:47.039Z] <541a528b163965c9bc2053de> If you have experienced macOS users who know a thing or two about numerical stability, clang, Accelerate / OpenBLAS.
[2017-07-13T16:24:50.294Z] <541a528b163965c9bc2053de> https://github.com/scikit-learn/scikit-learn/issues/9351
[2017-07-13T16:25:24.059Z] <541a528b163965c9bc2053de> this is blocking the 0.19b1 wheels on macOS
[2017-07-13T16:25:35.753Z] <54d4a1d6db8155e6700f853b> sprint will be on saturday ;)
[2017-07-13T16:26:23.267Z] <541a528b163965c9bc2053de> there is also a 32 bit linux issue in the feature importance test
[2017-07-13T16:26:41.244Z] <541a528b163965c9bc2053de> the test is probably too strict, I am currently investigating with docker
[2017-07-13T16:27:30.799Z] <541a528b163965c9bc2053de> the saga solver on  macOS is a real bug but it's probably not easy to debug.
[2017-07-13T16:28:27.038Z] <54d4a1d6db8155e6700f853b> hm yeah it would be cool to have some easy issues but it looks like the issue tracker doesn't really have a lot right now :-/
[2017-07-13T16:29:05.047Z] <541a528b163965c9bc2053de> I will add one to improve CI on master to test 32 bit linux and another to test macOS
[2017-07-13T16:29:42.206Z] <54d4a1d6db8155e6700f853b> "easy"
[2017-07-13T16:29:42.780Z] <54d4a1d6db8155e6700f853b> ;)
[2017-07-13T16:30:23.905Z] <541a528b163965c9bc2053de> it's easy in the sense that you don't need to know python programming or machine learning
[2017-07-13T16:30:48.284Z] <541a528b163965c9bc2053de> but you need to know system and travis stuff
[2017-07-13T16:32:15.456Z] <541a528b163965c9bc2053de> I won't have time to work on those tomorrow, I need to review a long journal paper... + other admin stuff to do over the WE
[2017-07-13T16:46:04.950Z] <541a528b163965c9bc2053de> https://github.com/scikit-learn/scikit-learn/issues/9352
[2017-07-13T16:46:38.315Z] <541a528b163965c9bc2053de> I gave some boilerplate docker commands and scripts + references to docs to get started
[2017-07-13T18:18:17.050Z] <57ec309f40f3a6eec067e511> Hi @amueller just saw your tweet about advocating the need for fair and un-biased prediction. We at datascience.com have been looking into this topic and open sourced our first step in that direction. https://github.com/datascienceinc/Skater. If possible checkout our roadmap. How do others feel about the idea ? 
[2017-07-13T18:31:10.044Z] <54d4a1d6db8155e6700f853b> @pramitchoudhary so that builds upon lime? what functionality are you adding to it?
[2017-07-13T18:34:42.294Z] <57ec309f40f3a6eec067e511> @amueller so the idea is to balance between global and local interpretation. At global level: model agnostic pdp, model agnostic variable importance as of now(one flavor of it, work is in progress to add other flavors); local level: its currently our forked version of LIME(_some improvements in the way local samples are generated_). There is also support for InMemoryModel(_one has access to the environment in which model is build_) and DeployedModel(_model is deployed in the wild_)
[2017-07-13T18:37:39.807Z] <57ec309f40f3a6eec067e511> here is a nice example of DeployedModel to evaluate third part models  https://github.com/datascienceinc/Skater/blob/master/examples/third_party_model/algorithmia_indico.ipynb.
[2017-07-13T18:39:16.636Z] <57ec309f40f3a6eec067e511> InMemoryModel example: https://github.com/datascienceinc/Skater/blob/master/examples/credit_analysis/Credit%20Analysis.ipynb
[2017-07-13T18:49:05.383Z] <54d4a1d6db8155e6700f853b> @ogrisel did you break master ;)
[2017-07-13T18:52:13.045Z] <541a528b163965c9bc2053de> @amueller it's green: https://travis-ci.org/scikit-learn/scikit-learn/branches
[2017-07-13T18:52:35.206Z] <54d4a1d6db8155e6700f853b> @ogrisel https://circleci.com/gh/scikit-learn/scikit-learn/12068?utm_campaign=build-failed&utm_medium=email&utm_source=notification
[2017-07-13T18:54:07.338Z] <541a528b163965c9bc2053de> it's plot_stock_market
[2017-07-13T18:54:17.038Z] <54d4a1d6db8155e6700f853b> ugh
[2017-07-13T18:54:17.077Z] <541a528b163965c9bc2053de> random failure I think
[2017-07-13T18:54:19.601Z] <54d4a1d6db8155e6700f853b> yeah true
[2017-07-14T22:48:33.124Z] <574454a0c43b8c601974a563> Then couldt we start the rebuild again?
[2017-07-15T03:08:03.694Z] <54d4a1d6db8155e6700f853b> @nok yeah but it doesn't matter
[2017-07-15T03:08:12.124Z] <54d4a1d6db8155e6700f853b> it will restart with the next commit
[2017-07-15T06:48:40.436Z] <574454a0c43b8c601974a563> Okay :smile: 
[2017-07-17T14:29:32.117Z] <5581814615522ed4b3e20c6a> Consider if i am having a column of integers is there any strong suggestion whether to do classification or regression. @ogrisel @amueller 
[2017-07-17T14:30:43.099Z] <5581814615522ed4b3e20c6a> normally i use pandas dtypes to differentiate the problem
[2017-07-17T14:30:56.666Z] <5581814615522ed4b3e20c6a> if its object or int64 - classification
[2017-07-17T14:31:04.924Z] <5581814615522ed4b3e20c6a> if its float64 - regression
[2017-07-17T14:31:10.550Z] <5581814615522ed4b3e20c6a> is that right?
[2017-07-17T14:31:28.650Z] <541a528b163965c9bc2053de> it depends : if the integers encodes target classes / categories, then classification, if they represent a target quantity (e.g. ratings, prices...),  then a regression model should work
[2017-07-17T14:31:51.940Z] <541a528b163965c9bc2053de> it depends on what they mean, not their physical types
[2017-07-17T14:32:32.716Z] <5581814615522ed4b3e20c6a> @ogrisel i can understand. Is there any specific automation in such cases
[2017-07-17T14:34:04.011Z] <5581814615522ed4b3e20c6a> I wrote a function to see uniques of integer columns counts if its above 75% then i consider is regression
[2017-07-17T14:34:07.408Z] <5581814615522ed4b3e20c6a> is it a right thing
[2017-07-17T14:35:23.706Z] <541a528b163965c9bc2053de> pandas has a categorical datatype that you could use to make the distinction instead of using ambiguous integers.
[2017-07-17T14:35:43.956Z] <5581814615522ed4b3e20c6a> Perfect
[2017-07-17T14:35:53.661Z] <541a528b163965c9bc2053de> your heuristic should work most of the time, but then it can fail
[2017-07-17T14:36:40.502Z] <541a528b163965c9bc2053de> e.g. predicting ratings, you might get 80% of "4" in your training set and treat the probleme as classification instead of regression.
[2017-07-17T14:36:59.400Z] <5581814615522ed4b3e20c6a> Exactly
[2017-07-17T14:37:02.936Z] <5581814615522ed4b3e20c6a> Thank you @ogrisel 
[2017-07-17T14:37:10.791Z] <541a528b163965c9bc2053de> but that should work well enough anyway. But using classification metrics might not be the best metric.
[2017-07-17T14:51:34.035Z] <57ab46cf40f3a6eec05eccac> Hi, I have a quick question for you experts: I'm trying to use the function "model_selection.train_test_split()" but I need to make sure that only there are no transactions whose "coreID" appears both in the test and in the train set.  I generally have 100 transactions per core and I have a coreID for every transaction.  I basically want each "core" (I have thousands of them) to be either in train or in test. Any ideas to help?
[2017-07-17T14:51:36.966Z] <57ab46cf40f3a6eec05eccac> Thanks!!
[2017-07-17T14:53:33.127Z] <57ab46cf40f3a6eec05eccac> (my dataset is at the single transaction level though)
[2017-07-17T16:55:48.479Z] <547d8325db8155e6700da60b> @mario_avevo_twitter can you make it with the parameter **group** of split ?
[2017-07-17T16:55:50.127Z] <547d8325db8155e6700da60b> http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html
[2017-07-17T16:57:14.364Z] <547d8325db8155e6700da60b> http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html
[2017-07-17T18:49:30.146Z] <57ab46cf40f3a6eec05eccac> thank you @massich I'll look into it!!
[2017-07-18T07:11:16.830Z] <5910079ed73408ce4f5dc467> If after 6th epoch of perceptron ,  our perceptron is getting converged but I have set n_iter parameter as 10 , will the  values of weights that are obtained at 6th epoch as well as 10th epoch  be optimal or Is it like the weight values at 6th epoch be more optimal than 10th epoch? Need some clarifications .
[2017-07-18T08:05:23.392Z] <596d505dd73408ce4f6d9602> I don't know the perceptron implementation of scikit-learn but convergence with Delta rule is guaranteed only for linearly separable problem
[2017-07-18T08:18:12.440Z] <5910079ed73408ce4f5dc467> Ok I'll share the code soon... 
[2017-07-18T08:25:24.918Z] <596d505dd73408ce4f6d9602> <unconvertable> I will take a look, I'm dev a perceptron in go (on github) and I want also to implement a multilevel + backprop framework (so guys, if you are interested, please join :D :D)
[2017-07-18T08:27:51.482Z] <596d505dd73408ce4f6d9602> About convergence: I don't remember maths related to "is monotonous descent or not"
[2017-07-18T08:29:27.393Z] <596d505dd73408ce4f6d9602> But definitely is guaranteed under the assumption of linearly separability (I have demonstration, if you want)
[2017-07-18T16:56:15.985Z] <5581814615522ed4b3e20c6a> @ogrisel I have pickled my model using Joblib. Now i am pickling the LabelEncoder used to build the dataset also. So i can use it when prediction. Is it a right path? 
[2017-07-18T17:18:35.037Z] <541a528b163965c9bc2053de> How did you use the LabelEncder? To transform input features or the target variable? Most scikit-learn classifiers will automatically use a label encoder internally so you don't need to do it externally.
[2017-07-18T17:19:00.530Z] <541a528b163965c9bc2053de> If it's used to transform  input features it's better to use a pipeline.
[2017-07-18T17:19:07.930Z] <5581814615522ed4b3e20c6a> Only for couple of categorical variables
[2017-07-18T17:19:12.326Z] <541a528b163965c9bc2053de> an pickle the full pipeline
[2017-07-18T17:19:14.487Z] <5581814615522ed4b3e20c6a> like State
[2017-07-18T17:19:28.583Z] <541a528b163965c9bc2053de> there is a PR for a ColumnTransformer under way.
[2017-07-18T17:20:14.251Z] <5581814615522ed4b3e20c6a> @ogrisel i dont get u
[2017-07-18T17:20:22.364Z] <541a528b163965c9bc2053de> You can copy the code in your own project if you want it to be compatible with sklearn 0.18.2 and the future 0.19. ColumnTransformer will be part of 0.20.
[2017-07-18T17:20:44.622Z] <5581814615522ed4b3e20c6a> oh thats great
[2017-07-18T17:21:49.135Z] <541a528b163965c9bc2053de> you can follow progress at: https://github.com/scikit-learn/scikit-learn/pull/9012
[2017-07-18T17:23:04.463Z] <5581814615522ed4b3e20c6a> I am currently planning serving prediction via RESTapi 
[2017-07-18T17:23:16.556Z] <5581814615522ed4b3e20c6a> So mostly ppl will upload their dataset
[2017-07-18T17:23:57.452Z] <5581814615522ed4b3e20c6a> my models automatically are preprocessed (imputing, labelEncoding for Object types, Scaling)
[2017-07-18T17:24:49.009Z] <5581814615522ed4b3e20c6a> as its encoded i need to have those encoding instance for cross validating my new predictions right
[2017-07-18T17:25:32.300Z] <541a528b163965c9bc2053de> Then write all the preprocessing logics in a transformer (as done in ColumnTransformer for instance) and use a pipeline: http://scikit-learn.org/stable/modules/pipeline.html to combine it with the supervised classification or regression model.
[2017-07-18T17:25:48.256Z] <541a528b163965c9bc2053de> Then you can pickle the full pipeline for deployment.
[2017-07-18T17:26:00.950Z] <5581814615522ed4b3e20c6a> Thats perfect
[2017-07-18T17:26:33.873Z] <5581814615522ed4b3e20c6a> Thank you @ogrisel  for instant reply :)
[2017-07-18T17:26:57.017Z] <541a528b163965c9bc2053de> Don't forget to snapshot the training for a given version of the model to be deployed. This way you can make sure you can retrain a similar model from the same data when you decide to upgrade the scikit-learn version.
[2017-07-18T17:27:16.346Z] <5581814615522ed4b3e20c6a> Yes i do remember it :)
[2017-07-18T17:27:20.521Z] <541a528b163965c9bc2053de> model pickles are not guaranteed to work across different scikit-learn versions.
[2017-07-18T17:27:41.073Z] <5581814615522ed4b3e20c6a> exactly.. thank u :)
[2017-07-18T17:32:07.467Z] <541a528b163965c9bc2053de> @BastinRobin BTW if you deploy your model with several python processes running on the same host (e.g. gunicorn workers), you should use `joblib.dump(pipeline, '/path/to/store/model.pkl')` to save the model and `joblib.load('/path/to/store/model.pkl', mmap_mode='r')` to load the model parameters in read-only shared memory and save memory usage on your production servers.
[2017-07-18T17:34:36.503Z] <5581814615522ed4b3e20c6a> Yes i am doing the same
[2017-07-18T17:34:50.256Z] <5581814615522ed4b3e20c6a> its a perfect suggestion
[2017-07-18T18:36:39.385Z] <56f4f5b885d51f252ababa4e> @amueller Noticing your latest issue, there is another malformed class at: http://scikit-learn.org/stable/modules/cross_validation.html#group-k-fold
[2017-07-23T18:22:52.489Z] <5910079ed73408ce4f5dc467> @made2591  .. Thanks for the help . I did the maths manually and got it cleared .. 
[2017-07-23T19:30:52.750Z] <596d505dd73408ce4f6d9602> @ashiskriz actually I didn't anything ^^ u r welcome!
[2017-07-25T07:58:51.657Z] <541a528b163965c9bc2053de> @SebastinSanty it's fixed in the master branch: http://scikit-learn.org/dev/modules/cross_validation.html#group-k-fold
[2017-07-25T09:29:04.479Z] <56f4f5b885d51f252ababa4e> @ogrisel Yes, I fixed it! :-)
[2017-07-25T09:30:03.808Z] <541a528b163965c9bc2053de> :)
[2017-07-27T07:28:49.118Z] <5948fba7d73408ce4f68b048> Hi guys are there any c++ projects I can get involved in
[2017-07-27T07:28:59.155Z] <5948fba7d73408ce4f68b048> if yes please link me below
[2017-07-27T15:44:46.660Z] <54d4a1d6db8155e6700f853b> @PriyaChincholikar lol this is a python package. We have a bunch of Cython though. But you can check out Shogun or MLPack
[2017-07-27T15:44:52.805Z] <54d4a1d6db8155e6700f853b> or xgboost
[2017-07-28T08:12:20.612Z] <5581814615522ed4b3e20c6a> @ogrisel  Is there a better recommendation on using timeseries data in realtime. Is it good to store it or use any tools to get realtime inputs
[2017-07-30T14:41:53.929Z] <5695d48216b6c7089cc24ae7> Hi all, any open easy issues need to be solved?
[2017-07-30T22:36:03.295Z] <582cbfc5d73408ce4f365e2b> Hello does anyone know if there are any plans to add factor rotation to FA ?
[2017-07-31T04:03:29.125Z] <54b2524adb8155e6700e8a8e> @ibrahimsharaf, https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+label%3A%22Need+Contributor%22+label%3AEasy includes: #9341, #9336, #9325. #4458, among other stalled pull requests, should not take much work to finish up...
[2017-08-02T18:52:54.012Z] <56f8122085d51f252abb1414> Hi all, I was wondering if it is somehow possible to include a model into the mean of a Gaussian Process Regressor (just like one can choose a kernel) a fit for the mean as well? 
[2017-08-02T18:53:51.450Z] <54d4a1d6db8155e6700f853b> No, I don't think so. That's rarely done in GPs afaik
[2017-08-02T18:54:01.770Z] <54d4a1d6db8155e6700f853b> you can remove the global mean beforehand if you like
[2017-08-02T19:08:33.288Z] <56f8122085d51f252abb1414> Oh ok, thanks for the quick reply. I dont want to subtract the mean because sometimes subtracting things out of a dataset somehow changes its random nature...
[2017-08-04T00:01:38.824Z] <54b2524adb8155e6700e8a8e> A toy for anyone who uses grid search, and particularly @amueller: https://github.com/jnothman/searchgrid
[2017-08-04T00:02:32.446Z] <54b2524adb8155e6700e8a8e> very much in alpha status
[2017-08-04T14:37:01.517Z] <54d4a1d6db8155e6700f853b> @jnothman nice!
[2017-08-04T14:38:26.765Z] <54d4a1d6db8155e6700f853b> What I'm thinking about right now / talking about with some people is to make it easier to implement ask/tell interfaces with BaseGridSearch. Maybe not in sklearn, but I think it should be possible to use a coroutine approach that allows implementing arbitrary parallel search strategies with a common interface
[2017-08-05T08:09:57.743Z] <54b2524adb8155e6700e8a8e> I implemented a callback-based parameter search variety of grid search years ago. It wasn't hard then, but it might be now ;) Not sure if that's all you mean...
[2017-08-07T17:46:39.798Z] <5759dd0dc2f0db084a1d128d> I'm looking at our GMM and the BIC derivation looks weird
[2017-08-07T17:50:27.214Z] <5759dd0dc2f0db084a1d128d> never mind... It's the score that is weird, and the BIC function corrects for that.
[2017-08-08T01:37:40.260Z] <54b2524adb8155e6700e8a8e> I hope thats a good thing ;)
[2017-08-09T06:11:41.039Z] <598aa547d73408ce4f70a1d1> I recently built a rudimentary classifier that identifies the news topic of a given article. I scraped lots of news articles - as training data - off a website, with their labels. In terms of text-processing, I removed stopwords, punctuations, lemmatized all words, then computed the tf-idf values of the remaining words. I represented each article as a doc of its 25 words with the highest tf-idf values. Then I decided on adopting a knn approach to the problem: upon getting the input article and determining its most frequent words (after the text-processing), I find the 5 articles that have most words in common with the input article - and then I perform a majority vote. If a majority of the 5 articles are tech, then the input article is tech. What are some ways I can improve upon this approach?
[2017-08-11T15:54:14.457Z] <553d0d7b15522ed4b3df8a67> would there be a way to include some of the changes suggested by https://stackoverflow.com/questions/26851553/sklearn-agglomerative-clustering-linkage-matrix into agglomerative clustering to plot dendrograms of the model?
[2017-08-11T15:55:33.109Z] <54d4a1d6db8155e6700f853b> @jzf2101 can you open an issue, or check if there's already one? I think there were previous requests to draw dendrograms, which I think would be a great feature
[2017-08-11T15:55:47.705Z] <54d4a1d6db8155e6700f853b> I haven't read the question in full but there were some issues in supporting this in the past
[2017-08-12T04:47:11.288Z] <54c084dbdb8155e6700eed4c> Hey all, chipping away at #5653 and was wondering if there's any places in the codebase that check if fitted on any input estimator (where the est type is unknown) ?
[2017-08-12T04:50:23.751Z] <54c084dbdb8155e6700eed4c> https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/partial_dependence.py#L125 from #7464 is a little tricky to generalise 
[2017-08-12T05:13:05.897Z] <54c084dbdb8155e6700eed4c> hrmm. i think i can sneak it into the logic for ensembles and then check for other estimators in the fit stage. never mind!
[2017-08-12T11:13:09.318Z] <57afd94d40f3a6eec05f5ad7> hi
[2017-08-12T15:06:26.895Z] <5986271dd73408ce4f703d62> Hi, I've generated a big set of very high-dimensional embeddings (7300 verbs with 1700 dimensions each) from a QnA dataset. I'm trying to visualize them and what I do is to apply [`truncatedSVD`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) (a PCA which centers the data) to obtain 50 dimensions and then pass those to [`TSNE`](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) in order to visualize them in 2d. The problem is that those embeddings include lots of verb conjugations and synonyms, so I would like to apply some type of algorithm to those high-dimensional embeddings (like kNN or cosine similarity) in order to obtain clusters or groups of similar embeddings represented by a single vector for each of those groups (without reducing their dimensionality since that is done later through SVD and TSNE). Does anybody know how to obtain that?
[2017-08-12T20:17:42.215Z] <553d0d7b15522ed4b3df8a67> @amueller issue already exists but pr is still left open
[2017-08-14T15:03:18.230Z] <584e0ea7d73408ce4f3c6163> Can anyone help me with a calculus issue using the SVM lost function
[2017-08-15T09:22:47.238Z] <5683764a16b6c7089cc092dc> hi everyone
[2017-08-15T09:22:52.705Z] <5683764a16b6c7089cc092dc> in SGDClassifier
[2017-08-15T09:22:53.104Z] <5683764a16b6c7089cc092dc> http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html
[2017-08-15T09:23:28.612Z] <5683764a16b6c7089cc092dc> how can I determine the baseline model?
[2017-08-15T09:23:45.660Z] <5683764a16b6c7089cc092dc> the doc said: "Linear classifiers (SVM, logistic regression, a.o.) with SGD training."
[2017-08-15T09:23:56.962Z] <5683764a16b6c7089cc092dc> how can I choose between SVM and logistic regression?
[2017-08-15T10:45:54.996Z] <5717ab2f659847a7aff3b583> it depends in your data 
[2017-08-15T10:46:02.100Z] <5717ab2f659847a7aff3b583> and what you want to predict
[2017-08-15T10:46:06.715Z] <5683764a16b6c7089cc092dc> hi
[2017-08-15T10:46:07.669Z] <5717ab2f659847a7aff3b583> continous data 
[2017-08-15T10:46:08.145Z] <5683764a16b6c7089cc092dc> I mean
[2017-08-15T10:46:09.744Z] <5683764a16b6c7089cc092dc> in the code
[2017-08-15T10:46:12.061Z] <5683764a16b6c7089cc092dc> how can I choose
[2017-08-15T10:46:24.190Z] <5717ab2f659847a7aff3b583> check the documentation :D
[2017-08-15T10:46:33.108Z] <5683764a16b6c7089cc092dc> yes, but I couldn't find
[2017-08-15T10:46:36.798Z] <5683764a16b6c7089cc092dc> that's why I ask here
[2017-08-15T10:47:21.046Z] <5717ab2f659847a7aff3b583> http://scikit-learn.org/stable/modules/svm.html
[2017-08-15T10:47:34.809Z] <5717ab2f659847a7aff3b583> http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
[2017-08-15T10:47:37.456Z] <5717ab2f659847a7aff3b583> now ?
[2017-08-15T10:47:48.862Z] <5683764a16b6c7089cc092dc> it is SVM?
[2017-08-15T10:47:59.996Z] <5683764a16b6c7089cc092dc> but how can I use SVM as a base model with SGDClassifier?
[2017-08-15T10:49:15.308Z] <5683764a16b6c7089cc092dc> or suppose SVM is by default, how can I switch to logistic regression?
[2017-08-15T10:51:33.733Z] <5717ab2f659847a7aff3b583> or sorry , i didn't have depth knowledge in machine learning
[2017-08-15T10:51:44.057Z] <5683764a16b6c7089cc092dc> no problem, thanks for your help
[2017-08-15T10:51:44.506Z] <5717ab2f659847a7aff3b583> how to choose the algorithm
[2017-08-15T10:51:55.221Z] <5717ab2f659847a7aff3b583> i'am begineer
[2017-08-15T10:52:03.023Z] <5717ab2f659847a7aff3b583> i just follow some moocs
[2017-08-15T10:52:17.196Z] <5717ab2f659847a7aff3b583> @vinhqdang tell me your experience with machine learning ?
[2017-08-15T10:55:03.919Z] <55d21ee30fc9f982beadabb8> http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier
[2017-08-15T10:55:20.981Z] <55d21ee30fc9f982beadabb8> @vinhqdang you have to set the `loss` properly
[2017-08-15T10:56:17.218Z] <55d21ee30fc9f982beadabb8> `loss=hinge` correspond to the SVM while `loss=log` to logistic regression
[2017-08-15T10:56:46.580Z] <5683764a16b6c7089cc092dc> great, thanks
[2017-08-15T10:56:56.800Z] <5683764a16b6c7089cc092dc> do you know what functions correspond to other loss
[2017-08-15T10:57:06.254Z] <5683764a16b6c7089cc092dc> say, "modified_huber"
[2017-08-15T10:58:19.126Z] <55d21ee30fc9f982beadabb8> modified_huber is a smooth hinge loss
[2017-08-15T10:59:21.203Z] <5683764a16b6c7089cc092dc> is it possible to pass a custom loss to SGDClassifier
[2017-08-15T10:59:22.792Z] <5683764a16b6c7089cc092dc> ?
[2017-08-15T10:59:51.522Z] <55d21ee30fc9f982beadabb8> it does not seems so since it does not accept callable
[2017-08-15T10:59:55.992Z] <5717ab2f659847a7aff3b583> @glemaitre hi can you contact you in private
[2017-08-15T10:59:57.045Z] <5717ab2f659847a7aff3b583> ?
[2017-08-15T11:00:54.199Z] <5683764a16b6c7089cc092dc> great thanks
[2017-08-15T11:03:55.798Z] <5717ab2f659847a7aff3b583> @vinhqdang 
[2017-08-15T11:03:57.110Z] <55d21ee30fc9f982beadabb8> @vinhqdang If really you want to play with the loss
[2017-08-15T11:04:09.404Z] <55d21ee30fc9f982beadabb8> they are defined there https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a805efbe4bb06516670a9b8c690992bd7/sklearn/linear_model/sgd_fast.pyx
[2017-08-15T11:04:32.814Z] <55d21ee30fc9f982beadabb8> in case that you want to implement your own
[2017-08-15T11:04:44.261Z] <5683764a16b6c7089cc092dc> yes, thanks
[2017-08-15T11:05:16.653Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/linear_model/stochastic_gradient.py#L901
[2017-08-15T11:05:22.639Z] <55d21ee30fc9f982beadabb8> then you can register it there
[2017-08-15T11:05:38.819Z] <5683764a16b6c7089cc092dc> I see
[2017-08-15T21:11:42.041Z] <54d4a1d6db8155e6700f853b> @vinhqdang I wouldn't use SGDClassifier for custom loss functions for learning. Just implement your own in pure python. It will not be fast but it's a good learning experience and much easier to understand
[2017-08-24T07:35:01.015Z] <58176b11d73408ce4f321426> Anyone have experience predicting multiple time series with similar inputs and outputs? My problem is as follows: I have a bunch of products, and a bunch of locations at which the products are sold. Each of these locations has a sales history, so essentially I have a time series for each product at each location. My goal is to forecast future sales of each product at each location. I have tried approaching this problem as a time-series forecasting problem however I can't wrap my head around how to build a generalized single model from multiple time series. Would love to chat with someone if they've had experience with this before. thanks!
[2017-08-24T09:09:47.754Z] <56652eda16b6c7089cbdb710> @tblazina you should probably consider it as a time series data for each location. that way you will be only considering sales as a function of time and thus make your initial model simple.
[2017-08-24T09:11:04.709Z] <56652eda16b6c7089cbdb710> once you are able to make predictions on that  model and are able to understand it probably you can scale this model to encompass addtional dimensions like geography. point is to take only one location at a time. that should help you
[2017-08-24T09:14:06.263Z] <58176b11d73408ce4f321426> @infinite-Joy  thanks for the feedback, yes that was my general approach before having a model for each location but unfortunately then I'm reducing the amount of data significantly,  from >300,000 data points in all for all locations, versus having sometimes <<1000 for newer locations, I was wondering if there was somehow a way to reframe the problem so as to only have one model which generalizes to all locations. 
[2017-08-24T09:32:35.723Z] <56652eda16b6c7089cbdb710> this one seems a close match. not sure if this will help though. also not in python https://stats.stackexchange.com/questions/23036/estimating-same-model-over-multiple-time-series
[2017-08-24T10:22:10.271Z] <58176b11d73408ce4f321426> cool, i'll have a look at it
[2017-08-24T10:22:12.544Z] <58176b11d73408ce4f321426> thanks!
[2017-09-01T11:27:25.534Z] <54c084dbdb8155e6700eed4c> The #9551 merge seems to be causing fails in a lot of new PRs
[2017-09-01T11:28:42.032Z] <5571fe1015522ed4b3e17d90> Hmmm really do you have examples?
[2017-09-01T11:32:55.260Z] <54c084dbdb8155e6700eed4c> #4197 https://travis-ci.org/scikit-learn/scikit-learn/builds/270779099?utm_source=github_status&utm_medium=notification
[2017-09-01T11:33:35.042Z] <54c084dbdb8155e6700eed4c> #9147 sorry... feeling dlysexic this evening 
[2017-09-01T11:36:36.236Z] <54c084dbdb8155e6700eed4c> #5653 will fail shortly too I'm guessing (for a variety of reasons lol... but this complex check will be one of them)
[2017-09-01T12:07:46.602Z] <5571fe1015522ed4b3e17d90> :confused: #9147 has not been merged yet, right?
[2017-09-01T12:13:55.517Z] <5571fe1015522ed4b3e17d90> I think I understand what you are saying. I'll fix it.
[2017-09-01T12:14:53.320Z] <54c084dbdb8155e6700eed4c> the fails aren't related to the PRs that are failing... #9551 seems to be the source unrelated to the new code
[2017-09-01T12:21:19.318Z] <5571fe1015522ed4b3e17d90> Should be fixed now: https://github.com/scikit-learn/scikit-learn/commit/deaa96452a981e3e54dc302fc14cb1c83cb2e399
[2017-09-02T02:11:28.194Z] <54c084dbdb8155e6700eed4c> Looking good now  @lesteve  :beers: 
[2017-09-03T18:50:36.992Z] <564789be16b6c7089cbab8b7> hi.. I want to do cross-validation but my data comes in groups. I have 10,000,000 rows in total and the sizes of the groups vary a lot. So I would really like to sample 100,000 rows first in proportion to the group sizes and then do the group cross-validation.  Is that possible?
[2017-09-03T19:43:53.889Z] <56f8122085d51f252abb1414> Is scikit-learn taking part on the Google Summer of Code this year? (I couldnt find anything for this year)
[2017-09-03T20:02:01.427Z] <55d21ee30fc9f982beadabb8> @mirca not this year
[2017-09-04T11:57:04.681Z] <58b47262d73408ce4f4d4113> @glemaitre  And what about next year? Is scikit-learn taking part next year? 
[2017-09-04T12:24:44.454Z] <55d21ee30fc9f982beadabb8> @thechargedneutron no idea. I think that the core devs will keep the community informed.
[2017-09-04T12:27:01.588Z] <58b47262d73408ce4f4d4113> @glemaitre Thanks :)
[2017-09-04T18:16:12.148Z] <56f8122085d51f252abb1414> @glemaitre thanks
[2017-09-05T07:41:30.063Z] <564789be16b6c7089cbab8b7> I am confused by scikit-learn's support for pandas dataframes.  Can you just use them like 2n numpy arrays in scikit learn and if so, is there still any need for sklearn-pandas?
[2017-09-05T07:51:53.831Z] <541a528b163965c9bc2053de> @lesshaste you can use pandas dataframes with numeric values as input to most scikit-learn estimators and model selection tools (e.g. cross_val_score and parameter search tools). sklearn-pandas can still be useful to do per-column feature preprocessing although this also should be improved by default in future scikit-learn versions.
[2017-09-05T07:53:08.976Z] <564789be16b6c7089cbab8b7> @ogrisel  thanks!  I can't tell by looking at the docs which parts of sklearn will work with dataframes and which won't. For example http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
[2017-09-05T07:54:16.591Z] <564789be16b6c7089cbab8b7> should I just assume all classifier and regression functions will work?
[2017-09-05T07:55:33.478Z] <541a528b163965c9bc2053de> yes, whenever there is `array-like` as the type for X in fit and predict, numerical dataframes should work.
[2017-09-05T07:55:45.120Z] <564789be16b6c7089cbab8b7> thanks so much
[2017-09-05T10:55:40.267Z] <564789be16b6c7089cbab8b7> Is there any way to get feature importance (for a random forest classifier) based on auc (area under the curve)?
[2017-09-05T18:49:22.282Z] <584778b4d73408ce4f3b440c> why is auc important?
[2017-09-05T18:50:09.815Z] <54d4a1d6db8155e6700f853b> @lesshaste what do you mean by that? you could do sequential feature selection for any arbitrary metric, but that requires fitting multiple models
[2017-09-05T20:13:37.405Z] <564789be16b6c7089cbab8b7> @ian-flores  It's the only sensible way I know to measure a classification  where the number of items in each class is very different
[2017-09-05T20:14:17.291Z] <564789be16b6c7089cbab8b7> @amueller  I would like to know how much each feature contributes to the auc . Does that make sense?
[2017-09-05T20:14:41.414Z] <564789be16b6c7089cbab8b7> It would also be great if sklearn had multi-class auc but that PR seems to have stalled a while ago
[2017-09-05T20:14:59.616Z] <54d4a1d6db8155e6700f853b> @lesshaste feel free to pick it up ;)
[2017-09-05T20:15:10.570Z] <54d4a1d6db8155e6700f853b> it makes sense if you can define it? ;)
[2017-09-05T20:15:13.237Z] <564789be16b6c7089cbab8b7> @amueller  I wish I had the skills!
[2017-09-05T20:15:31.850Z] <564789be16b6c7089cbab8b7> @amueller  what do you mean by "it makes sense if you can define it"? 
[2017-09-05T20:17:16.403Z] <564789be16b6c7089cbab8b7> if you mean the multi-class AUC, isn't there a more or less standard definition by Hand and Till?
[2017-09-05T20:18:32.358Z] <54d4a1d6db8155e6700f853b> there are two standard definitions
[2017-09-05T20:18:41.174Z] <54d4a1d6db8155e6700f853b> I'm not sure what's currently to do
[2017-09-05T20:19:03.675Z] <564789be16b6c7089cbab8b7> ah ok.  Looks like it just stalled on that observation https://github.com/scikit-learn/scikit-learn/pull/7663#issuecomment-307566895
[2017-09-05T20:19:19.009Z] <54d4a1d6db8155e6700f853b> What does it mean for a feature to contribute to the auc? how much will AUC change if you leave it out? That is just one step of sequential forward selection
[2017-09-05T20:20:16.422Z] <564789be16b6c7089cbab8b7> yes I think that makes sense. You just want to avoid rebuilding the model n times when you have n features
[2017-09-05T20:20:21.287Z] <564789be16b6c7089cbab8b7> I often have 10,000 features
[2017-09-05T20:24:18.245Z] <564789be16b6c7089cbab8b7> is there a more efficient way of doing this?
[2017-09-07T11:05:57.087Z] <59ad481bd73408ce4f743eb0> Hey I am a newbie. Would love to contribute to the organization. Can anyone guide me on this?
[2017-09-07T11:16:59.851Z] <58b47262d73408ce4f4d4113> You may start by solving easy issues. Its available at https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aissue+is%3Aopen+label%3AEasy
[2017-09-07T11:17:49.283Z] <58b47262d73408ce4f4d4113> Solve the ones which is not currently being attempted by anyone else. (I'm a newbie too :P )
[2017-09-07T13:34:54.184Z] <59ad481bd73408ce4f743eb0> Alright. Thanks :smile: 
[2017-09-11T04:47:25.042Z] <59b56a87d73408ce4f751f7b> hi i am new here can anyone guide me..!
[2017-09-11T15:23:16.053Z] <58db7784d73408ce4f5484eb> Hi, i am quite new to machine learning and am thinking about a good approach for my ML analysis. I have several tables with data in a DB. Some of this data are name, adresses and email and so on and some are 'other' data, mostly numbers and configuration data. Both kind of data can be in the same table. What I want to analyse now is, has a column address like data or number/config data. As I undersatand it with most ML examples you have a number of test data in tables and each table row is a data point. When I want to predict something, I take data that has the data structure of one table row and see that I predict the wanted data based on the test data training. In my case I have the table + column metadata (column name, length, etc) plus the actual content of the table column. My first idea is now to create a new table with (table name, colunm name, length, ctable column content as a string ,lets say) and then copy the column content column by column into this structture. This would give me individual rows to analyse. It just feels a bit clonky as the meta data (table/comuln name, ..) would be naturally the same for a whole column and only the column content differs and so there is not much variation in this table. Is there a more clever way of prepading the data ?
[2017-09-13T07:05:06.618Z] <5967287ad73408ce4f6cf2a7> Could I have Kmeans example convert data frame and output cluster prediction with Plot visualization?
[2017-09-13T14:41:23.262Z] <59b94206d73408ce4f7598d4> like this? https://beta.gryd.us/notebook/published/fJevxtDmjFfo5nGYs4A4bC/
[2017-09-13T15:23:22.996Z] <5967287ad73408ce4f6cf2a7> and how about convert string data frame to vector? Thanks anyway
[2017-09-14T11:29:04.258Z] <564789be16b6c7089cbab8b7> anyone here have authority to update the topic in the IRC channel? (#scikit-learn on freenode)
[2017-09-15T08:43:29.093Z] <5571fe1015522ed4b3e17d90> @mirca @thechargedneutron aboug Google Summer of Code, the consensus amongst the core developers seems to be that we need all of the three conditions: a good student, a good focussed project with accomplishable goals that will produce something within the time constraints, and one mentor (ideally two mentors actually) who has enough spare bandwidth during this time. It just was not the case last year. It's hard to tell what will happen next year for sure. Potentially interested GSoC students are more than encouraged to get involved in scikit-learn so they get to know the project and we get to know them. 
[2017-09-15T08:44:12.729Z] <564789be16b6c7089cbab8b7> @lesteve  maybe add something to the scikit front page about this?  
[2017-09-15T08:44:18.938Z] <564789be16b6c7089cbab8b7> It's always good to advertise :)
[2017-09-15T08:48:04.446Z] <58b47262d73408ce4f4d4113> @lesteve  Thanks for the information. I am continuously trying to understand the codebase by solving bugs. It's more comfortable for me now. Thanks :) 
[2017-09-18T14:19:26.503Z] <54d4a1d6db8155e6700f853b> @lesshaste yeah I could update the topic if I find the time. Maybe the update should be "check gitter instead"
[2017-09-29T17:14:01.361Z] <5717ab2f659847a7aff3b583> hi
[2017-09-29T17:28:38.326Z] <54d4a1d6db8155e6700f853b> @Rebaiahmed hi
[2017-09-29T17:28:49.572Z] <5717ab2f659847a7aff3b583> i need some help
[2017-09-29T17:29:05.390Z] <5717ab2f659847a7aff3b583> for scholarship project
[2017-09-29T17:29:08.292Z] <54d4a1d6db8155e6700f853b> you can post your question here, but I recommend going to stackexchange and tag it with sklearn
[2017-09-29T17:29:19.876Z] <5717ab2f659847a7aff3b583> wait
[2017-09-29T17:29:26.937Z] <54d4a1d6db8155e6700f853b> see http://scikit-learn.org/dev/faq.html#what-s-the-best-way-to-get-help-on-scikit-learn-usage
[2017-09-29T17:29:32.951Z] <5717ab2f659847a7aff3b583> just i'm searching about
[2017-09-29T17:29:38.619Z] <5717ab2f659847a7aff3b583> sickit learn
[2017-09-29T17:29:42.977Z] <5717ab2f659847a7aff3b583> with django
[2017-09-29T17:29:51.033Z] <5717ab2f659847a7aff3b583> i want to implement machine learning
[2017-09-29T17:29:56.153Z] <5717ab2f659847a7aff3b583> into web project
[2017-09-29T17:30:07.116Z] <5717ab2f659847a7aff3b583> but i didn"t have any idea
[2017-09-29T17:30:14.121Z] <5717ab2f659847a7aff3b583> for the application 
[2017-09-29T17:30:19.863Z] <5717ab2f659847a7aff3b583> or the avalaible dataset
[2017-09-29T17:30:59.880Z] <54d4a1d6db8155e6700f853b> for an introduction, check out @jakevdp's free book: https://github.com/jakevdp/PythonDataScienceHandbook
[2017-09-29T17:31:59.330Z] <5717ab2f659847a7aff3b583> i have an experience with django and sickit-learn
[2017-09-29T17:32:08.286Z] <5717ab2f659847a7aff3b583> they are separated 
[2017-09-29T17:32:20.296Z] <5717ab2f659847a7aff3b583> i want an idea o combine them
[2017-09-29T17:33:22.011Z] <541a528b163965c9bc2053de> Build a recommender system for suggesting movies based on the movie lens data as a web application
[2017-09-29T17:33:49.277Z] <541a528b163965c9bc2053de> or a book recommender system using https://www.kaggle.com/zygmunt/goodbooks-10k
[2017-09-29T17:34:39.936Z] <5717ab2f659847a7aff3b583> good idea ;)
[2017-09-29T17:34:48.083Z] <541a528b163965c9bc2053de> I would recommend you to use [lightfm](https://github.com/lyst/lightfm) or [spotlight](https://github.com/maciejkula/spotlight) instead of scikit-learn though :)
[2017-09-29T17:35:35.758Z] <5717ab2f659847a7aff3b583> why ?
[2017-09-29T17:35:40.715Z] <5717ab2f659847a7aff3b583> what are the advantages ?
[2017-09-29T17:36:48.678Z] <541a528b163965c9bc2053de> Those libraries are dedicated to building recommender systems. Factorization machines and neural networks with categorical embeddings are known to be very good for building recommender systems but are not implemented in scikit-learn.
[2017-09-29T17:36:51.762Z] <541a528b163965c9bc2053de> (yet)
[2017-09-29T17:37:06.704Z] <5717ab2f659847a7aff3b583> ok good :D
[2017-09-29T17:37:22.426Z] <5717ab2f659847a7aff3b583> there is any other suggestion for other dataset
[2017-09-29T17:37:26.186Z] <5717ab2f659847a7aff3b583> for example
[2017-09-29T17:37:37.881Z] <5717ab2f659847a7aff3b583> client -ecommerce dataset 
[2017-09-29T17:37:41.813Z] <5717ab2f659847a7aff3b583> something ike this
[2017-09-29T17:38:10.416Z] <5717ab2f659847a7aff3b583> what do you think about Twitter Sentiment Analysis ?
[2017-09-29T17:39:03.700Z] <541a528b163965c9bc2053de> e-commerce: I don't know any out the time of my mind. For twitter you can use the sentiment140 dataset but I find sentiment analysis pretty useless personally.
[2017-09-29T17:39:26.427Z] <541a528b163965c9bc2053de> I have to go. Good luck for your project.
[2017-09-30T11:27:20.188Z] <59bacd63d73408ce4f75cb22> > Build a recommender system for suggesting movies based on the movie lens data as a web applicationLove  this one!
[2017-10-04T20:27:24.221Z] <59d4936ed73408ce4f7883b1> @Rebaiahmed Sentiment analysis is iffy at best. Twitter is particularly bad. Training data is typically nice and clean, but Twitter users are are an insanely sarcastic bunch which makes this so unreliable. Plus it's pretty worthless. The move to 280 characters might improve this in the future but we'll need to get new training data.  What could be interesting is to do questionaries, and demographics and other data, then build a model that predicts opinions and responses based on that data. You could through in sentiment analysis here for longer paragraph answers if it really interests you.
[2017-10-06T21:04:54.213Z] <564789be16b6c7089cbab8b7> is it possible to use  the pearson correlation coefficient as the loss function when doing regression in scikit-learn?
[2017-10-08T23:13:15.061Z] <59146cabd73408ce4f5ec527> To look at feature importance, I extract it from the `feature_importance_` attribute, sort, and visualize. Is there a way to pretty print / plot automatically? In R, `plot(random_forest)` does the trick
[2017-10-08T23:13:32.175Z] <59146cabd73408ce4f5ec527> If there's not a way to do this in scikit-learn, is there a reason why and does the community welcome PR in this regard?
[2017-10-09T06:02:55.034Z] <59d187cfd73408ce4f782f22> @LaDilettante you need to use matplotlib to plot your results
[2017-10-09T06:04:25.880Z] <59d187cfd73408ce4f782f22> Sentiment analysis is good for articles, but yes I do agree it's bad for Twitter.
[2017-10-10T13:18:47.962Z] <595a8627d73408ce4f6b61ba> perhaps use bayesian classifier if predicting something from tweets 
[2017-10-10T13:18:57.981Z] <595a8627d73408ce4f6b61ba> it worked in some works ive come across
[2017-10-11T06:46:41.800Z] <5757de1ec43b8c6019787b6c> @rishavroy1264bitmesra Hey guys ! Can someone help me to find a way to find similar meaning sentences sentence-A is known and I have to develop an implementation to find all sentences meaning same to sentence-A in coming input data(paragraphs)
[2017-10-12T17:49:37.071Z] <577ebc96c2f0db084a21f545> @rishavroy1264bitmesra  I am not sure how you can exactly achieve this but what you are trying to achieve is a very hard problem. I feel WordNet shall be used for calculating the word distances for similarity/dissimilarity and even use tf-idf for sentence scoring. I know this is very vague for you've got some work to do..
[2017-10-12T23:43:41.825Z] <58d98495d73408ce4f5421c4> Does someone have experience with using SE(3) poses as inputs? I am trying to find a good representation for the orientations. Some pros/cons, along with usage guidelines would be much appreciated as well. Thanks in advance
[2017-10-16T04:54:53.127Z] <59d187cfd73408ce4f782f22> Hey guys anyone here familiar with University of Edinburgh's grad school program?
[2017-10-16T04:55:15.323Z] <59d187cfd73408ce4f782f22> Looking for recommendations for European graduate schools
[2017-10-16T16:21:03.956Z] <59e0d687d73408ce4f79e8c1> Hi. Was wondering if anyone knows of any academic papers on marketing attribution modelling with offline source (assigning a website visitor a probability of having come to the site due to a TV ad)? 
[2017-10-17T14:45:36.636Z] <59c93e97d73408ce4f774b70> HI, I am trying to prepare training data for hand written recognition for Tibetan language. As i have to prepare thousand of it. I want to make sure i am making the correct format of pixel values for Tibetan character for machine learning. I tried a single Tibetan alphabet image of size 32*32 pixel. I got the pixel values but i am not able to plot its back in python using matplotlib.pyplot.
[2017-10-17T16:51:00.009Z] <59d187cfd73408ce4f782f22> hey guys I have X_test and X_train data. Does anyone know how I can divide it so I can have two different two of each for two different models? 
[2017-10-17T16:51:04.535Z] <59d187cfd73408ce4f782f22> trying to make a pipeline
[2017-10-17T16:52:06.649Z] <59c93e97d73408ce4f774b70> @angelotc  you got one data file ?
[2017-10-17T17:00:59.098Z] <59d187cfd73408ce4f782f22> nope I didn't use test_train_split to make X_test and X_train 
[2017-10-20T15:55:28.925Z] <56d2f977e610378809c40828> Hi, a recent ML enthusiast trying to contribute. I just forked the scikit-learn repo and got a very easy PR merged. 
[2017-10-20T16:00:42.278Z] <56d2f977e610378809c40828> I set up a dev environment using virtualenv, so that it does not interfere with my existing scikit-learn installation. But I see that the docs does not mention it at all. Is there any particular reason? Or am I missing something obvious here?
[2017-10-20T17:26:42.973Z] <59ea3107d73408ce4f7af81c> @angelotc  : First import  from sklearn.model_selection import train_test_split then  X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42) X is a dataframe having only features and y is a dataframe having only target from your original dataset
[2017-10-21T00:49:41.609Z] <58a5767cd73408ce4f4abd3f> Are you guys familiar with C++? I need some help...
[2017-10-22T18:19:08.150Z] <5910079ed73408ce4f5dc467> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/yuhz/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/yuhz/image.png)
[2017-10-22T18:19:15.371Z] <5910079ed73408ce4f5dc467> Hello everybody , I have a doubt - Why is the number of nodes in hidden layer always 1 more than number of nodes in input layer ?  
[2017-10-22T18:21:29.660Z] <5910079ed73408ce4f5dc467> How do we set that number of nodes in hidden layer . In most cases I see this type of representation as shown in diagram 
[2017-10-22T18:21:38.535Z] <55a487245e0d51bd787b4e45> @CaptainAshis "Always"?
[2017-10-22T18:21:57.322Z] <5910079ed73408ce4f5dc467> I mean in most cases that I came across   @mikegraham 
[2017-10-22T18:23:29.598Z] <55a487245e0d51bd787b4e45> @CaptainAshis I am not aware of this being a standard practice. Do you mean in actual cases or just diagramatically?
[2017-10-22T18:25:10.981Z] <5910079ed73408ce4f5dc467> I mean diagrammatically .In most youtube videos I see this type of representation @mikegraham 
[2017-10-22T18:26:06.959Z] <55a487245e0d51bd787b4e45> @CaptainAshis It's probably what's convenient for the creator to draw.
[2017-10-22T18:27:26.076Z] <5910079ed73408ce4f5dc467> @mikegraham  . So is there any standard rule to know how many nodes we can set for the hidden layer ? 
[2017-10-22T18:36:18.826Z] <55a487245e0d51bd787b4e45> @CaptainAshis It varies wildly what ends up working well. There is an old rule of thumb for single-hidden-layer models of 'mean of input nodes and output nodes', but that is even rougher than most rules of thumb.
[2017-10-22T18:37:33.345Z] <5910079ed73408ce4f5dc467> ok , Thank you @mikegraham 
[2017-10-24T12:16:55.021Z] <5634e15116b6c7089cb8f9f2> @CaptainAshis hot damn! How can I implement a hello world style for this ![alt](https://files.gitter.im/scikit-learn/scikit-learn/yuhz/image.png)...
[2017-10-24T13:22:49.689Z] <595a8627d73408ce4f6b61ba> https://www.youtube.com/watch?v=bxe2T-V8XRs
[2017-10-24T14:25:56.877Z] <595a8627d73408ce4f6b61ba> @Ij888 
[2017-10-24T15:48:24.084Z] <5634e15116b6c7089cb8f9f2> yo @tms1337 woot woot
[2017-10-24T18:20:14.760Z] <574454a0c43b8c601974a563> @Ij888 e.g. https://github.com/rushter/MLAlgorithms
[2017-10-27T17:07:00.257Z] <54ea6b6b15522ed4b3dc55a2> `<SPAM>` In case someone is interested in visiting Colombia and presenting something, or maybe just attending ;-)  https://www.pycon.co And sorry for the spam `</SPAM>`
[2017-10-29T11:47:25.256Z] <5910079ed73408ce4f5dc467> @lj888 hope you got your answer  .. :) 
[2017-10-30T16:39:22.807Z] <53eb987c107e137846baa89d> I am doing this ``` In [1]: from sklearn.datasets import fetch_olivetti_faces In [2]: import pandas as pd In [3]: ol_faces = fetch_olivetti_faces() In [4]: ol_faces_df = pd.DataFrame(ol_faces.data) In [5]: pd.tools.plotting.scatter_matrix(ol_faces_df, c=ol_faces.target, figsize=(8, 8)) ``` But this programs tends to keep increasing memory usage, is something wrong that I am doing? I am not trying to do anything in particular on my own. I was just trying to 'replicate' (on self exercise type question) for what Alexandre Gram tried to do in SciPy 2017 tutorial.
[2017-10-30T16:44:56.142Z] <53eb987c107e137846baa89d> I am doing this on pandas version 0.19. I think we have `pd.plotting.scatter_matrix` in versions higher than 0.19 (i.e. development version I guess)
[2017-11-04T17:25:23.548Z] <58b47262d73408ce4f4d4113> Hello, I am quite free after my semester ending examinations. I want to contribute more to scikit-learn. Apart from solving bugs (which currently I am doing with 6-8 merged PRs), how else can I contribute to scikit-learn? 
[2017-11-07T15:26:32.279Z] <598c6a46d73408ce4f70da78> Hi, is there a way to remove samples using a pipeline? I was looking at FunctionTransformer but I don't see how it will modify the y values
[2017-11-07T15:45:08.847Z] <576e76e2c2f0db084a1fdb14> @cs_hanes_twitter  `imbalanced-learn` has a `Pipeline` object that lets you remove samples. Also, there is WIP for a `FunctionSampler` that lets you use arbitrary functions confirming the `scikit-learn`'s object oriented API.
[2017-11-08T14:05:32.162Z] <53eb987c107e137846baa89d> How do I run tests (unit tests) locally after making some changes?
[2017-11-08T14:09:10.847Z] <53eb987c107e137846baa89d> Would running `make` at the top-level directory be sufficient?
[2017-11-08T14:43:15.405Z] <53eb987c107e137846baa89d> Though I did that now. But I would still like to know how to do it cleanly.
[2017-11-08T21:08:23.545Z] <55d21ee30fc9f982beadabb8> make test
[2017-11-08T21:27:25.458Z] <564106cd16b6c7089cba16c7> Hi all, could you tell what you think of this approach  : https://www.kaggle.com/jankoch/scikit-learn-pipelines-and-pandas/notebook ? 
[2017-11-08T22:28:34.048Z] <53232ac75e986b0712efe3af> @ncouturier I didn't go through your notebook in detail, but I think you might be interested in looking at https://github.com/scikit-learn/scikit-learn/pull/9012/
[2017-11-08T22:29:11.846Z] <53232ac75e986b0712efe3af> That certainly relates to those transformers you implemented to apply certain transformers to certain columns
[2017-11-08T22:29:44.079Z] <53232ac75e986b0712efe3af> (you call it DataFrameFeatureUnion)
[2017-11-08T22:30:25.380Z] <53232ac75e986b0712efe3af> Regarding the dummy encoder transformer, you also might want to look at https://github.com/scikit-learn/scikit-learn/pull/9151 that implements a CategoricalEncoder
[2017-11-08T22:32:10.098Z] <53232ac75e986b0712efe3af> Further, you might be interested in https://github.com/scikit-learn-contrib/sklearn-pandas (but I am also not very familiar with that, so not sure how the functionality there relates to the transformers you implemented)
[2017-11-08T22:35:22.232Z] <53232ac75e986b0712efe3af> (so as a summary, I agree with you that it currently is hard to do pandas-like preprocessing in sklearn pipelines, but we are working to improve that. Feedback on those linked PRs / project is always welcome!)
[2017-11-08T22:36:15.668Z] <564106cd16b6c7089cba16c7> ok. Thx for your answer. 
[2017-11-09T08:52:19.044Z] <5a04163fd73408ce4f7dd6f7> <unconvertable> Hi, this is the link to my blog: http://dhrubajitdas44.blogspot.in/ <unconvertable>  It contains my machine learning/ deep learning projects, few as of now. More coming. Any kind of criticism/suggestions/corrections are very much welcome, as it will help me learn. I am a beginner. If any experts/instructors would like to give a review on the projects, that would be great. And the students, follow the blog if you find it useful and for future updates. Thank you
[2017-11-12T00:54:17.289Z] <58b46af0d73408ce4f4d3f2c> Hi everyone.
[2017-11-12T00:54:36.501Z] <58b46af0d73408ce4f4d3f2c> I'm a statistics graduate student and I'm interested getting some FOSS (and programming) experience.
[2017-11-12T00:55:08.478Z] <58b46af0d73408ce4f4d3f2c> Would it be a worthwhile endeavor to implement Dirichlet Process mixture models in sklearn?
[2017-11-12T00:56:09.232Z] <58b46af0d73408ce4f4d3f2c> Yikes, sorry just noticed it's already implemented!
[2017-11-12T16:19:58.903Z] <58ec2bf4d73408ce4f577ca0> what would probably be useful on the other hand is a python framework for generalized finite mixture models
[2017-11-12T16:20:33.276Z] <58ec2bf4d73408ce4f577ca0> eg. where you specify a set of distributions and parameters to estimate and run the model without hardcoding the maximum likelihood equation yourself
[2017-11-14T20:03:02.224Z] <58b46af0d73408ce4f4d3f2c> @VHRanger as an extension to sklearn?
[2017-11-17T16:37:55.015Z] <54d4a1d6db8155e6700f853b> @VHRanger you mean pomegranate?
[2017-11-17T16:38:51.089Z] <54d4a1d6db8155e6700f853b> @ssequeira if your interested in DPs, maybe check out our LDA? I feel it could use some love, and I also think having a gibbs sampling version would be nice
[2017-11-17T16:39:01.950Z] <54d4a1d6db8155e6700f853b> not sure if we also want a gibbs sampling version of the GMM
[2017-11-19T09:19:10.926Z] <53eb987c107e137846baa89d> Are the tags 'help wanted' tagged issues for beginners? How do they differ from 'Easy' tags on issues?
[2017-11-20T16:59:45.314Z] <5a05409fd73408ce4f7dfdd9> Ok
[2017-11-21T14:30:10.505Z] <564789be16b6c7089cbab8b7> if you use minmaxscaler like this: scaler = MinMaxScaler(feature_range=(0, 1)) train = scaler.fit_transform(train) test = scaler.transform(test)
[2017-11-21T14:30:21.646Z] <564789be16b6c7089cbab8b7> are we guaranteed that test is in the range 0 to 1?
[2017-11-21T15:11:14.586Z] <54d4a1d6db8155e6700f853b> @lesshaste the training set yes, the test-set  not.
[2017-11-21T15:11:30.397Z] <564789be16b6c7089cbab8b7> @amueller  ah right.. so what is the right thing to do here?
[2017-11-21T15:11:38.889Z] <54d4a1d6db8155e6700f853b> the right thing to do for what?
[2017-11-21T15:12:07.551Z] <564789be16b6c7089cbab8b7> I need to scale the data to use keras (LSTM)
[2017-11-21T15:12:16.878Z] <564789be16b6c7089cbab8b7> so I train on some set and the test on another 
[2017-11-21T15:12:22.160Z] <564789be16b6c7089cbab8b7> how should I scale the test set?
[2017-11-21T15:12:45.094Z] <564789be16b6c7089cbab8b7> if this method doesn't guarantee it will be in the right range
[2017-11-21T15:12:59.069Z] <54d4a1d6db8155e6700f853b> is there a technical reason why it needs to be in this range?
[2017-11-21T15:13:25.349Z] <54d4a1d6db8155e6700f853b> it will be in this range unless there are samples in the test set that are outside of the range of the training set
[2017-11-21T15:13:53.901Z] <564789be16b6c7089cbab8b7> hmm.. I don't actually know.. it's just that all the docs says you should scale everything to be in the range 0 to 1
[2017-11-21T15:14:21.479Z] <54d4a1d6db8155e6700f853b> yeah, then Using MinMaxScaler in this way is exactly the right thing to do.
[2017-11-21T15:14:54.523Z] <564789be16b6c7089cbab8b7> ok thanks.. It occurred to me that you could just scale the test set independently too
[2017-11-21T15:15:05.326Z] <564789be16b6c7089cbab8b7> which wouldn't be "cheating" but would give you the guarantee
[2017-11-21T15:15:09.222Z] <564789be16b6c7089cbab8b7> but maybe that is wrong
[2017-11-21T15:15:34.911Z] <54d4a1d6db8155e6700f853b> that will make it harder for the algorithm to generalize, because the meaning of the values in the training and test set will be different
[2017-11-21T15:15:52.577Z] <564789be16b6c7089cbab8b7> true and good point
[2017-11-21T15:15:54.002Z] <564789be16b6c7089cbab8b7> thank you
[2017-11-21T15:29:16.414Z] <564789be16b6c7089cbab8b7> in a related question.. how would you do CV for time series data?  The only obvious method that I can think of is to randomly split the data into the first x% of samples and the last (100-x)% of samples and train and test accordingly. But that clearly has much less randomness than a normal CV and the different folds overlap hugely
[2017-11-21T17:02:12.090Z] <564789be16b6c7089cbab8b7> I am confused by this example to visualize a decision tree. http://scikit-learn.org/stable/modules/tree.html#tree In a script, how do you get to see the picture? The example just finishes with >>> graph = graphviz.Source(dot_data)   >>> graph 
[2017-11-21T20:05:46.056Z] <54d4a1d6db8155e6700f853b> in jupyter you can just put the graph object in a cell
[2017-11-21T20:05:56.385Z] <54d4a1d6db8155e6700f853b> it'll show as image
[2017-11-22T09:11:32.465Z] <564789be16b6c7089cbab8b7> @amueller  right.. it would be nice to have an example that worked in a script though as many newbie people will just copy and paste into their code
[2017-11-22T09:12:02.734Z] <564789be16b6c7089cbab8b7> @amueller  I got it work myself so this is a suggestion for others
[2017-11-22T14:59:22.525Z] <54d4a1d6db8155e6700f853b> @lesshaste you mean for the tree plotting? The real solution is here: https://github.com/scikit-learn/scikit-learn/pull/9251
[2017-11-22T17:22:15.512Z] <564789be16b6c7089cbab8b7> @amueller  Thanks. Should this work for regression trees too?  
[2017-11-22T17:22:21.443Z] <54d4a1d6db8155e6700f853b> yes
[2017-11-22T17:34:26.443Z] <564789be16b6c7089cbab8b7> great! I look forward to it's being merged
[2017-11-23T14:45:09.058Z] <5a09a93cd73408ce4f7e626f> @amueller  When i ingest data, set sharing to true, what is shared?
[2017-11-23T14:49:43.632Z] <5a09a93cd73408ce4f7e626f> @amueller The distributed ingest data in geomesa is the MapReduce method, why not use spark?
[2017-11-23T20:45:02.643Z] <53eb987c107e137846baa89d> Ah, never mind. I found about 'help wanted' here: http://scikit-learn.org/stable/developers/contributing.html#issue-tracker-tags
[2017-11-24T09:12:40.084Z] <53eb987c107e137846baa89d> Using `make html` in the `doc` directory I get the following error (on master branch) ``` Exception occurred:   File "/home/gxyd/anaconda3/lib/python3.6/site-packages/sphinx_gallery/gen_gallery.py", line 322, in sumarize_failing_examples     "\n" + "-" * 79) ValueError: Here is a summary of the problems encountered when running the examples  Unexpected failing examples: /home/gxyd/dev/scikit-learn/examples/ensemble/plot_feature_transformation.py failed leaving traceback: Traceback (most recent call last):   File "/home/gxyd/anaconda3/lib/python3.6/site-packages/sphinx_gallery/gen_rst.py", line 450, in execute_code_block     exec(code_block, example_globals)   File "<string>", line 15, in <module> ImportError: cannot import name 'CategoricalEncoder'   /home/gxyd/dev/scikit-learn/examples/ensemble/plot_gradient_boosting_early_stopping.py failed leaving traceback: Traceback (most recent call last):   File "/home/gxyd/anaconda3/lib/python3.6/site-packages/sphinx_gallery/gen_rst.py", line 450, in execute_code_block     exec(code_block, example_globals)   File "<string>", line 40, in <module> TypeError: __init__() got an unexpected keyword argument 'validation_fraction' ```
[2017-11-24T09:13:46.329Z] <53232ac75e986b0712efe3af> Are you sure you installed the development version?
[2017-11-24T09:14:18.195Z] <53232ac75e986b0712efe3af> It seems as you are building the master docs but with a released version of sklearn for running the examples
[2017-11-24T09:14:33.041Z] <53eb987c107e137846baa89d> Well that is what I thought initially.
[2017-11-24T09:15:17.174Z] <53eb987c107e137846baa89d> But how can I force I make it to use the development version.
[2017-11-24T09:15:48.496Z] <53eb987c107e137846baa89d> Would I need to modify the `PATH` variable?
[2017-11-24T09:17:29.144Z] <53eb987c107e137846baa89d> I get things like ``` /home/gxyd/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:docstring of sklearn.model_selection.GridSearchCV:166: WARNING: Undefined substitution referenced: "param_kernel|param_gamma|param_degree|split0_test_score". /home/gxyd/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:docstring of sklearn.model_selection.GridSearchCV:166: WARNING: Undefined substitution referenced: "...". ``` While running `make html` which made me inclined towards the thing you are saying.
[2017-11-24T11:12:55.548Z] <53232ac75e986b0712efe3af> @gxyd I typically have a 'development' environment in which I install the master version (with `pip install -e .`)
[2017-11-24T11:16:55.723Z] <53eb987c107e137846baa89d> As I can see for `-e` option: ``` Install  a  project  in editable mode (i.e.  setuptools "develop               mode") from a local project path or a VCS url. ```
[2017-11-24T11:58:02.742Z] <53eb987c107e137846baa89d> @jorisvandenbossche thanks. That seems to be working just fine for me right now.
[2017-11-24T16:27:11.534Z] <5a1847bed73408ce4f801f28> hello
[2017-11-25T06:40:57.042Z] <53eb987c107e137846baa89d> Does running tests using `make test` differs from tests run using `pytest`?
[2017-11-25T12:41:50.625Z] <55d21ee30fc9f982beadabb8> @gxyd Check the Makefile: https://github.com/scikit-learn/scikit-learn/blob/master/Makefile#L39
[2017-11-25T13:05:37.743Z] <53eb987c107e137846baa89d> So that would mean `make test` actually runs `pytest` with different parameters (or options)?
[2017-11-25T15:23:00.603Z] <55d21ee30fc9f982beadabb8> `make test` run `make test-code` `make test-sphinxext` `make test-doc 
[2017-11-25T15:23:13.132Z] <55d21ee30fc9f982beadabb8> therefore it is equivalent to
[2017-11-25T15:24:07.771Z] <55d21ee30fc9f982beadabb8> ``` pytest --showlocals -v sklearn pytest --showlocals -v doc/sphinxext/ pytest $(shell find doc -name '*.rst' | sort) ```
[2017-11-25T16:04:57.763Z] <53eb987c107e137846baa89d> Yup, I understand now. Thanks.
[2017-11-26T14:15:53.244Z] <570d14d6187bb6f0eadf1582> Hi, I want to pickup https://github.com/scikit-learn/scikit-learn/pull/7694 again - which branch should I merge to the my code -  0.19.X, master ?
[2017-11-26T14:22:51.489Z] <53eb987c107e137846baa89d> I think 'master' branch should be the one to go with.
[2017-11-26T20:20:12.800Z] <570d14d6187bb6f0eadf1582> That's what I try, but make seems to fail: https://gist.github.com/Kornel/11e69ef9fd2e9380a21991029fbecaf9#file-gistfile1-txt-L9473
[2017-11-26T20:21:34.420Z] <570d14d6187bb6f0eadf1582> I'm using python 3.6.3, 
[2017-11-26T20:21:37.289Z] <570d14d6187bb6f0eadf1582> ``` python -c "import numpy as np; import scipy as sp; print(np.__version__); print(sp.__version__)" 1.13.3 1.0.0```
[2017-11-26T20:21:46.719Z] <570d14d6187bb6f0eadf1582> and running simply make
[2017-11-26T21:53:51.642Z] <56f8122085d51f252abb1414> Hi everyone, simple question here: is the prior in, e.g., Ridge Regression, also applied to the intercept? See here: http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression 
[2017-11-26T21:54:30.065Z] <56f8122085d51f252abb1414> By "prior" I mean the L2 regularization term. 
[2017-12-01T17:57:33.760Z] <58b47262d73408ce4f4d4113> Hello all, I want to take up a moder
[2017-12-01T17:58:49.176Z] <58b47262d73408ce4f4d4113> Hello all, I want to take up a moderate issue or something significant not currently being worked upon by anyone. Is there an issue or feature which needs quick attention?
[2017-12-01T18:01:29.006Z] <54d4a1d6db8155e6700f853b> @thechargedneutron have you worked on anything before? if not, go with those that say "good first issue"
[2017-12-01T18:01:55.164Z] <54d4a1d6db8155e6700f853b> oh actually you did, sorry
[2017-12-01T18:02:10.262Z] <54d4a1d6db8155e6700f853b> your name looked familiar lol
[2017-12-01T18:02:35.522Z] <58b47262d73408ce4f4d4113> Yeah, I have like 8-9 issues solved. And currently working on a moderate, but almost done. Hence looking for something more than just a bug
[2017-12-01T18:02:49.440Z] <54d4a1d6db8155e6700f853b> sorry I gotta run, I'll think about it
[2017-12-01T18:03:00.352Z] <54d4a1d6db8155e6700f853b> feature additions are usually pretty long-term
[2017-12-01T18:03:37.988Z] <58b47262d73408ce4f4d4113> I am like free for a month. So willing to take if there's a need
[2017-12-03T00:58:51.608Z] <5a234aead73408ce4f816c50> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/7foy/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/7foy/image.png)
[2017-12-03T00:59:15.697Z] <5a234aead73408ce4f816c50> Does anyone know if you need to be a repo owner to access CircleCI artifacts? Supposedly you should be able to access the full documentation built by CircleCI, but I don't see the tab in the build results...
[2017-12-03T13:06:15.566Z] <5a23f69dd73408ce4f81799e> need some help please
[2017-12-03T13:06:18.741Z] <5a23f69dd73408ce4f81799e> Hi,  Have you used Sklearn TImeSeriesSplit before?  I was wondering how you'd actually implement it?  # Splitting Time-series dataset into Training set and Test set using TimeSeriesSplit from sklearn.model_selection import TimeSeriesSplit tscv = TimeSeriesSplit(n_splits=10) print(tscv) for train_index, test_index in tscv.split(X):     print("TRAIN:", train_index, "TEST:", test_index)          X_train =     X_test =     y_train =     y_test =  So after you have the indexes built, how do you actually use this to get your X_train/test and y_train/test? From this point onwards, do you fit it to your model the same way?  Thanks, Joe
[2017-12-03T13:21:16.685Z] <5a23f69dd73408ce4f81799e> ahh no worries, solved it
[2017-12-03T13:21:21.645Z] <5a23f69dd73408ce4f81799e> misread documentation
[2017-12-03T17:33:14.130Z] <564e507e16b6c7089cbb6551> Hi everyone, I'm classifying an 8Million of pixels image using supervised classifiers in scikit-learn. I observed that SGD is that only classifier that converges in a reasonable time; the other classifiers tend to either run endlessly or to get stuck somehow. Is it true what's stated in this page (https://datascience.stackexchange.com/a/996/19222) that above 200.000 observations, one should stick with linear learning (i.e. those that implement partial_fit, although I'm really using it and the SGD is still working correctly)?
[2017-12-04T20:13:16.186Z] <54d4a1d6db8155e6700f853b> quick poll: did you all notice the conda compiler package update and have you trashed all your legacy environments? Am I the only one that didn't hear about that?
[2017-12-04T20:16:04.341Z] <53232ac75e986b0712efe3af> I have had a lot of problems lately with conda, but I don't know if they are related to the new compiler packages. Basically whatever small change I want to do, it wants to downgrade/upgrade a whole set of other packages (eg it always wants to downgrade my conda-forge numpy 1.13 to defaults numpy 1.11 when installing a package that is in no way depending (also no through its deps) on numpy)
[2017-12-04T20:16:19.826Z] <54d4a1d6db8155e6700f853b> huh
[2017-12-04T20:16:41.420Z] <53232ac75e986b0712efe3af> at a certain point it even just wanted to remove numpy
[2017-12-04T20:16:42.084Z] <53232ac75e986b0712efe3af> https://github.com/conda/conda/issues/6283
[2017-12-04T20:17:02.899Z] <54d4a1d6db8155e6700f853b> are you mixing old and new packages by any chance?
[2017-12-04T20:17:37.573Z] <53232ac75e986b0712efe3af> possibly, but as a user I should not be needed to be aware of that
[2017-12-04T20:17:39.456Z] <54d4a1d6db8155e6700f853b> these are all "old" packages. I guess conda-forge only uses old packages?
[2017-12-04T20:18:14.189Z] <54d4a1d6db8155e6700f853b> that's what I though, but I was just told in the conda issue tracker that I need to discard any old environment
[2017-12-04T20:18:31.812Z] <54d4a1d6db8155e6700f853b> or at least not try to upgrade anything or compile anything
[2017-12-04T20:19:46.477Z] <53232ac75e986b0712efe3af> they can say that maybe for environments that depend on defaults, but I have environments that are mainly conda-forge (because they eg depend on geospatial things that are (or were) broken on defaults), and there just updating a conda-forge package should still work, without having it pull in defaults (conda-forge should take priority)
[2017-12-04T20:20:25.172Z] <54d4a1d6db8155e6700f853b> yeah, true
[2017-12-04T20:20:40.775Z] <54d4a1d6db8155e6700f853b> that sounds possibly unrelated ;)
[2017-12-05T16:29:32.170Z] <564789be16b6c7089cbab8b7>  I am trying (X,y) = make_classification(n_features=20, n_samples=1000, n_classes=3) but it says ValueError: n_classes * n_clusters_per_class must be smaller or equal 2 ** n_informative
[2017-12-05T16:29:43.747Z] <564789be16b6c7089cbab8b7> I just want to make a random classification problem with 3 classes. How can I do that?
[2017-12-05T16:42:25.499Z] <53eb987c107e137846baa89d> How about ``` make_classification(n_classes=3, n_redundant=0, n_informative=20) ``` (I am also a beginner, but just trying here. You can ignore if you want someone more experienced to comment)
[2017-12-05T16:43:06.916Z] <53eb987c107e137846baa89d> There are quite a few other (default)arguments which probably would need to be changed. See http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
[2017-12-05T16:43:41.310Z] <564789be16b6c7089cbab8b7> thanks.. (trainX, trainY) = make_classification(n_informative=20, n_redundant=0, n_samples=50000, n_classes=120) works!
[2017-12-05T16:43:56.292Z] <564789be16b6c7089cbab8b7> this is slightly less intuitive than normal for scikit learn
[2017-12-05T16:44:18.650Z] <564789be16b6c7089cbab8b7> because (trainX, trainY) = make_classification(n_informative=20, n_samples=50000, n_classes=120)  does not work
[2017-12-05T16:46:51.295Z] <53eb987c107e137846baa89d> To be true, I am new to scikit-learn and to machine learning as well. This is what intrigues me a lot that for every function we find a lot (a lot) of arguments. I would have thought to simply use `**kwargs` and extract out the important information from it. But I think may be developers would have already given a good thought into this.
[2017-12-05T17:00:47.866Z] <55d21ee30fc9f982beadabb8> Even if scikit-learn is intuitive, @lesshaste do not forget to read the doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
[2017-12-05T17:09:28.381Z] <55d21ee30fc9f982beadabb8> so if we still wish to have 2 clusters per classes
[2017-12-05T17:09:54.799Z] <55d21ee30fc9f982beadabb8> you need at least `n_informative=6` minimum
[2017-12-05T17:12:43.632Z] <564789be16b6c7089cbab8b7> I really want 120
[2017-12-05T17:12:50.513Z] <564789be16b6c7089cbab8b7> thanks
[2017-12-05T17:17:19.986Z] <55d21ee30fc9f982beadabb8> > To be true, I am new to scikit-learn and to machine learning as well. This is what intrigues me a lot that for every function we find a lot (a lot) of arguments. I would have thought to simply use `**kwargs` and extract out the important information from it. But I think may be developers would have already given a good thought into this.  You can refer to [this talk](https://www.youtube.com/watch?v=MQMbnhSthZQ) to see ONE of the problem of the kwarg :).
[2017-12-05T17:24:38.401Z] <53eb987c107e137846baa89d> I haven't seen the video completely (but in between I liked to point out). But I have spent quite sometime with SymPy, and I definitely agree I used a lot of `*args, **kwargs`.
[2017-12-05T17:48:29.257Z] <53eb987c107e137846baa89d> I think I could say, that for a library having other libraries as dependencies it is better to use hard-coded arguments instead of `*args, **kwargs`.
[2017-12-05T17:52:33.674Z] <53eb987c107e137846baa89d> Thanks for the video, I can sleep tight now :)
[2017-12-06T15:40:23.366Z] <564789be16b6c7089cbab8b7> Apologies for being slightly OT but...does anyone know what I am doing wrong with xgboost? It seems amazingly slow when you have a large number of classes.  https://bpaste.net/show/ef817a256658 shows the problem
[2017-12-06T15:40:40.082Z] <564789be16b6c7089cbab8b7> thanks to the wonderful scikit-learn make_classification
[2017-12-06T15:40:56.215Z] <564789be16b6c7089cbab8b7> whereas as RandomForestClassifier is still super fast
[2017-12-06T16:51:49.019Z] <5623dda816b6c7089cb76c0f> Hi all. First of all sorry this question since it is not a sci-kit learn related, but I thought someone can help me out. I have some pet projects that Id like to start, but I am having some troubles to start. Can anyone point me out? or bring some ideas? Both involve unsupervised learning.  1. Id like to classify students using some economic information such as income, number of family members, etc. The classification should the economic status, e.g. low resources, medium, rich. The problem is that I dont have any labeled data. Can I approach this problem in a unsupervised way? (I tried with k-means)  2. I want classify academic papers using a taxonomy. Many librarians tag their documents in a specific way. In most cases, this tagging is different for each library. Tagging documents with a specific taxonomy will help search engines to retrieve documents. However, I found a taxonomy called Unesco nomenclature, but I dont know a way to match a document with an element/elements of the taxonomy. 
[2017-12-07T23:00:43.263Z] <56f8122085d51f252abb1414> Hello everyone. Anyone can point me to a mathematical proof of the objective function used in sklearn for the logistic regression? http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression Im trying to demonstrate it starting from the Bernoulli likelihood in which the probability of a success is a sigmoid function, however, the final likelihood expression that I arrive is not equivalent to sklearns.
[2017-12-07T23:01:48.352Z] <54d4a1d6db8155e6700f853b> @mirca there's nothing sklearn specific about this, this is *the* objective for binary logistic regression (with penalty)
[2017-12-07T23:02:36.872Z] <54d4a1d6db8155e6700f853b> Elements of statistical learning, chapter 4.4
[2017-12-07T23:02:54.029Z] <54d4a1d6db8155e6700f853b> https://web.stanford.edu/~hastie/ElemStatLearn/
[2017-12-07T23:05:15.222Z] <541a528b163965c9bc2053de> The objective function for binary classification logistic regression stems from the negative log likelihood of a linear parametrization the log odd ratio of the Bernoulli model.
[2017-12-07T23:07:06.416Z] <541a528b163965c9bc2053de> the linear parametrization (w.T . x + b)  is for the log odd ratio log(p / (1 - p)) instead of p directly, where p is the parameter of the Bernoulli function.
[2017-12-07T23:07:49.357Z] <541a528b163965c9bc2053de> I edited my comment as I made a mistake :)
[2017-12-07T23:09:56.579Z] <56f8122085d51f252abb1414> @amueller Im arriving exactly at expression (4.20) of the book you mention. Am I mistaken or (4.20) is different from http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression ? (disconsider the regularization/prior term)
[2017-12-07T23:14:02.842Z] <56f8122085d51f252abb1414> @ogrisel exactly, through these assumptions I arrive at (4.20) ^, which, to me, looks a little different from http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression . Perhaps I am missing out something?
[2017-12-07T23:17:24.830Z] <54d4a1d6db8155e6700f853b> I think you can simplify the 2 class case further.  let me catch up with the notation
[2017-12-07T23:20:10.347Z] <541a528b163965c9bc2053de> IIRC y_i take values in {-1, 1} for the negative and positive classes respectively. This is not clear in the scikit-learn doc.
[2017-12-07T23:20:11.382Z] <54d4a1d6db8155e6700f853b> why do you need to sum up the y_i and 1 - y_i cases? in 4.19 we are only looking at the probability of gi
[2017-12-07T23:20:59.041Z] <54d4a1d6db8155e6700f853b> ah right one of them is always zero... hm yeah could be the different encoding of y_i
[2017-12-07T23:23:58.237Z] <54d4a1d6db8155e6700f853b> did they use p(x, theta) as the top of 4.18 or the bottom of 4.18? I guess if they are consistent, they use the top, but we might use the bottom one
[2017-12-07T23:24:29.993Z] <54d4a1d6db8155e6700f853b> but that just replaces classes 0 and 1 I guess
[2017-12-07T23:25:10.810Z] <54d4a1d6db8155e6700f853b> Eh, I should be grading
[2017-12-07T23:25:21.584Z] <541a528b163965c9bc2053de> :)
[2017-12-07T23:36:53.657Z] <56f8122085d51f252abb1414> its not clear to me how (4.20) and sklearns docs are equivalent
[2017-12-07T23:37:22.579Z] <54d4a1d6db8155e6700f853b> have you tried replacing y by -1 and 1 like ogrisel said?
[2017-12-07T23:38:46.747Z] <54d4a1d6db8155e6700f853b> or maybe easier, try to expand sklearns doc for  y=-1 and y=1 and then try to match that to the two terms in 4.20
[2017-12-07T23:39:01.795Z] <56f8122085d51f252abb1414> Hum, ok! That looks to be the answer
[2017-12-07T23:39:06.750Z] <56f8122085d51f252abb1414> thank you!
[2017-12-07T23:39:24.827Z] <541a528b163965c9bc2053de> Feel free to submit a pull request to improve the doc :)
[2017-12-07T23:40:34.952Z] <541a528b163965c9bc2053de> https://github.com/scikit-learn/scikit-learn/blob/master/doc/modules/linear_model.rst?utf8=%E2%9C%93#logistic-regression
[2017-12-07T23:41:03.798Z] <56f8122085d51f252abb1414> Will do! =)
[2017-12-07T23:41:15.816Z] <541a528b163965c9bc2053de> Just mentioning explicitly the -1 and +1 values for y_i might be enough.
[2017-12-09T22:36:46.009Z] <5a2c58c8d73408ce4f8294ba> I am new to open source development but have worked with python for many year. I have found an issue I would like to solve. https://github.com/scikit-learn/scikit-learn/issues/10279 I have read a fair bit on how to submit pull requests but I hesitate to do so because of my inexperience. Is anybody interested in doing a review of my code before I submit so that I do not burden the community at large?
[2017-12-09T22:46:12.050Z] <55d21ee30fc9f982beadabb8> @DrEhrfurchtgebietend until your are fixing the issue and try to follow the contributing guide as much as possible, you can submit the PR. The community will review the code such that it follows the scikit-learn standard :)
[2017-12-09T22:49:39.948Z] <5a2c58c8d73408ce4f8294ba> OK thanks. I will do my best. I am trying to get up to speed on something small then I plan to tackle the more complex issue I discussed with you before https://github.com/scikit-learn/scikit-learn/issues/9947
[2017-12-11T11:33:27.040Z] <58bd4178d73408ce4f4eaf1e> Hello Everyone,I am new to scikit-learn.I followed the advanced install instructions but when I run pytest sklearn. I get module not found error.So can anyone help me.
[2017-12-11T16:11:10.320Z] <54d4a1d6db8155e6700f853b> @DrEhrfurchtgebietend omg that name lol
[2017-12-11T16:46:01.143Z] <5a2c58c8d73408ce4f8294ba>  By far my favorite word. German
[2017-12-11T16:46:31.527Z] <5a2c58c8d73408ce4f8294ba> has most of my favorite words
[2017-12-11T16:46:34.435Z] <54d4a1d6db8155e6700f853b> @DrEhrfurchtgebietend I know, I'm german ;)
[2017-12-11T16:49:19.350Z] <5a2c58c8d73408ce4f8294ba> @amueller I had guessed based on your name. I use it in place of "awesome" just to get a reaction
[2017-12-12T15:54:31.644Z] <5a1450bed73408ce4f7fa504> Hello from Berlin! 
[2017-12-12T18:50:02.608Z] <53eb987c107e137846baa89d> How can I debug using the simple 'print' commands? This is what I tried:, I first put a `print( (blaaa, bllllaaaa))` in my code. Then if I run the tests using `pytest path/to/file.py` then I don't get output from the `print` statement, I get whatever was expected without the `print` statements. (I'm sure that running those test would definitely reach those `print` statements).  Has this got something to do with `*.pyx` files?
[2017-12-12T19:19:08.054Z] <59d4f81ed73408ce4f789336> Hello developers! Am a newbie. Can someone provide me instructions link to build & run scikit-learn from source code. Am messing up with things.
[2017-12-12T19:25:30.825Z] <53eb987c107e137846baa89d> I guess this http://scikit-learn.org/stable/developers/advanced_installation.html should probably work.
[2017-12-12T20:02:42.840Z] <59d4f81ed73408ce4f789336> Am not getting how to put the cloned code to work. Help
[2017-12-12T20:17:54.355Z] <53eb987c107e137846baa89d> are you able to do `make test` (without errors) on root scikit-learn directory?
[2017-12-12T20:23:59.569Z] <59d4f81ed73408ce4f789336> nope
[2017-12-12T20:24:10.065Z] <59d4f81ed73408ce4f789336> sklearn/tests/test_docstring_parameters.py:150: AssertionError
[2017-12-12T20:24:37.677Z] <59d4f81ed73408ce4f789336> ``1 failed, 8361 passed, 16 skipped, 5024 warnings in 293.63 seconds``
[2017-12-12T20:24:44.044Z] <53eb987c107e137846baa89d> if you could paste into a pastebin or somrthing that might help
[2017-12-12T20:29:22.381Z] <59d4f81ed73408ce4f789336> https://pastebin.com/raw/1Q8PfyRf
[2017-12-12T20:34:31.873Z] <54d4a1d6db8155e6700f853b> @ai-coder don't worry about that, that looks like ups messing up.
[2017-12-12T20:34:35.419Z] <54d4a1d6db8155e6700f853b> we need to fix that, though
[2017-12-12T20:34:47.750Z] <54d4a1d6db8155e6700f853b> though master if working
[2017-12-12T20:34:48.777Z] <54d4a1d6db8155e6700f853b> hm...
[2017-12-12T20:34:54.570Z] <54d4a1d6db8155e6700f853b> so might be that you're mixing different installations?
[2017-12-12T20:36:15.228Z] <59d4f81ed73408ce4f789336> working now
[2017-12-12T20:36:24.151Z] <53eb987c107e137846baa89d> It says: `1 failed, 8361 passed, 16 skipped, 5024 warnings in 293.63 seconds`, it does contain 'passed' non-zero value, does it indicate ruling out mixing installations?
[2017-12-12T20:36:24.202Z] <54d4a1d6db8155e6700f853b> lol
[2017-12-12T20:36:30.520Z] <53eb987c107e137846baa89d> Oh cool.
[2017-12-12T20:36:58.524Z] <53eb987c107e137846baa89d> What is 'ups messing up'?
[2017-12-12T20:37:27.366Z] <54d4a1d6db8155e6700f853b> meant "us messing up" though I double checked, and it's correct
[2017-12-12T20:43:01.216Z] <59d4f81ed73408ce4f789336> what time will it take to get familiar with things over here?
[2017-12-12T20:43:11.074Z] <54d4a1d6db8155e6700f853b> ?
[2017-12-12T20:44:59.093Z] <59d4f81ed73408ce4f789336> m newbie. understanding issues and working is still tough despite working in python for long
[2017-12-12T20:45:36.583Z] <54d4a1d6db8155e6700f853b> well depends on what you mean with "getting familiar with things over here"... I've been doing machine learning for err.. 8 years and learn new stuff most days ;)
[2017-12-12T20:46:47.887Z] <59d4f81ed73408ce4f789336> I meant the open-source terms :smile: 
[2017-12-12T20:48:20.120Z] <53eb987c107e137846baa89d> @amueller since you are here. Can you please answer this query of mine https://gitter.im/scikit-learn/scikit-learn?at=5a3024da540c78242db7aaaf ? (I think otherwise it might get lost upward)
[2017-12-12T20:48:21.722Z] <54d4a1d6db8155e6700f853b> same applies, I guess?
[2017-12-12T20:48:42.984Z] <54d4a1d6db8155e6700f853b> @gxyd how do you run pytest?
[2017-12-12T20:48:43.225Z] <59d4f81ed73408ce4f789336> yeah, sure. doing my best
[2017-12-12T20:49:07.624Z] <54d4a1d6db8155e6700f853b> I think you need -s -v ?
[2017-12-12T20:49:12.503Z] <53eb987c107e137846baa89d> `pytest path/to/file.py`
[2017-12-12T20:49:14.447Z] <54d4a1d6db8155e6700f853b> but I'm relatively new to pytest ;)
[2017-12-12T20:49:27.525Z] <53eb987c107e137846baa89d> Nope I don't use `-s -v` arguments.
[2017-12-12T20:50:26.727Z] <53eb987c107e137846baa89d> Aah.
[2017-12-12T20:50:44.251Z] <53eb987c107e137846baa89d> It does work accordingly to what is expected.
[2017-12-12T20:50:57.043Z] <53eb987c107e137846baa89d> passing arguments is important I guess.
[2017-12-12T20:52:05.575Z] <53eb987c107e137846baa89d> I'm sure, I am even new (newer?) than you on pytest.
[2017-12-13T02:54:43.763Z] <56f8122085d51f252abb1414> pytest -s -v name-of-file-to-test.py should be enough
[2017-12-13T07:26:48.460Z] <57224267659847a7aff4ffce> Is this page for development using scikit or contributing to the project or both?
[2017-12-13T07:31:03.148Z] <58b47262d73408ce4f4d4113> For any type of queries and suggestions related to scikit-learn.
[2017-12-13T07:31:42.687Z] <58b47262d73408ce4f4d4113> There's a special dev room for developers of the project.
[2017-12-13T07:32:10.403Z] <57224267659847a7aff4ffce> Can I get a link for the room?
[2017-12-13T07:32:46.240Z] <57224267659847a7aff4ffce> Never mind
[2017-12-13T07:32:48.884Z] <57224267659847a7aff4ffce> Got it
[2017-12-13T07:33:01.509Z] <57224267659847a7aff4ffce> Thanks for the response though
[2017-12-13T07:37:50.533Z] <58b47262d73408ce4f4d4113> :smile: 
[2017-12-14T08:48:30.048Z] <5a1450bed73408ce4f7fa504> Hi guys! I want to contribute to the scikit learn open source. I am new to this. Can anyone give me any direction as to where to start with?
[2017-12-14T08:49:21.441Z] <541a528b163965c9bc2053de> @ashish-ram have a look at the contributors guide: http://scikit-learn.org/stable/developers/contributing.html
[2017-12-14T08:50:21.265Z] <5a1450bed73408ce4f7fa504> nice! a lot of information!! thanks  @ogrisel  !
[2017-12-14T08:50:26.008Z] <541a528b163965c9bc2053de> The best way to contribute is to actually use scikit-learn for a project of yours to identify which part needs improving from your users point of view.
[2017-12-14T08:50:59.704Z] <5a1450bed73408ce4f7fa504> I have been reading the documentation and want to use it for kaggle projects. 
[2017-12-14T08:51:43.355Z] <5a1450bed73408ce4f7fa504> have not used it extensively besides from some classification and regression tasks
[2017-12-14T17:58:38.693Z] <55d21ee30fc9f982beadabb8> @gxyd  `pytest  -s -v ` will display something only if the test fail. You can always put a `raise`after your printing :) or use a proper debugger maybe
[2017-12-14T17:59:39.321Z] <53eb987c107e137846baa89d> No, I think it worked. None of the test failed, but I simply put a `print` statement and it worked just fine.
[2017-12-14T18:01:08.292Z] <53eb987c107e137846baa89d> I am thinking you confuse that with something else.
[2017-12-14T18:04:13.182Z] <55d21ee30fc9f982beadabb8> ups right, this is `-l` that does show only at `raise`
[2017-12-14T18:05:43.458Z] <53eb987c107e137846baa89d> Seeing in documentation? (Refer me to it if you are).
[2017-12-14T18:07:13.564Z] <55d21ee30fc9f982beadabb8> `-l, --showlocals      show locals in tracebacks (disabled by default).`
[2017-12-14T18:10:17.371Z] <53eb987c107e137846baa89d> That's also seems useful, thanks @glemaitre .
[2017-12-15T21:05:46.368Z] <53eb987c107e137846baa89d> How can I run just doctests using pytest? Searching over the web I reached https://github.com/scikit-learn/scikit-learn/pull/9697, but still it isn't clear as how to do that.
[2017-12-15T21:12:19.842Z] <53eb987c107e137846baa89d> Perhaps it is better if documented in http://scikit-learn.org/stable/developers/advanced_installation.html#testing  also?
[2017-12-16T20:20:09.047Z] <564789be16b6c7089cbab8b7> is there  a suggested replacement for the deprecated http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLogisticRegression.html ?
[2017-12-16T20:20:40.599Z] <564789be16b6c7089cbab8b7> or http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLasso.html ?
[2017-12-19T13:24:58.768Z] <55d21ee30fc9f982beadabb8> @lesshaste I think that you can check the discussion: https://github.com/scikit-learn/scikit-learn/issues/9657
[2017-12-20T04:13:47.422Z] <5a37fc62d73408ce4f83e015> Hello everyone, how can I help with this project?
[2017-12-20T10:37:56.830Z] <53eb987c107e137846baa89d> Here in `make_blobs` http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html , what is centers? It says: ``` centers : int or array of shape [n_centers, n_features], optional      (default=3) The number of centers to generate, or the fixed center locations. ``` The number of centers to generate. I don't understand this.
[2017-12-20T10:39:17.094Z] <53eb987c107e137846baa89d> @MartinEliasQ see http://scikit-learn.org/stable/developers/contributing.html
[2017-12-20T12:00:35.864Z] <53eb987c107e137846baa89d> I think I got some idea using its different values in plots. (centers of normal distribution)
[2017-12-20T22:14:19.004Z] <5a2c58c8d73408ce4f8294ba> Yep. The center of each blob (cluster)
[2017-12-20T22:14:51.960Z] <53eb987c107e137846baa89d> Thanks @DrEhrfurchtgebietend 
[2017-12-21T21:09:55.459Z] <54d4a1d6db8155e6700f853b> @jorisvandenbossche can you do me a favor and explain https://github.com/pandas-dev/pandas/issues/18801 to me?
[2017-12-21T21:10:58.153Z] <54d4a1d6db8155e6700f853b> or maybe @jnothman understands and can enlighten me
[2017-12-21T21:12:20.050Z] <53eb987c107e137846baa89d> I wonder if Joel ever comes here, always busy with issues/PR. :)
[2017-12-22T07:25:06.372Z] <54b2524adb8155e6700e8a8e> I sometimes forget to open gitter and dont see its notifications...
[2017-12-24T15:55:16.791Z] <57379367c43b8c601972f35d> hey
[2018-01-01T06:50:14.470Z] <58b46af0d73408ce4f4d3f2c> Does scikit learn have support for sparse Gaussian processes, like with variational learning?
[2018-01-01T06:50:38.698Z] <58b46af0d73408ce4f4d3f2c> Is that a feature that's on the list?
[2018-01-01T06:50:47.478Z] <58b46af0d73408ce4f4d3f2c> *to be implemented list
[2018-01-02T07:50:43.523Z] <595a4f26d73408ce4f6b5a31> Hi everyone.  I joined this room first time today,  nice to meet you all
[2018-01-04T12:04:13.253Z] <5a4e181cd73408ce4f8611a6> hi,
[2018-01-06T03:46:02.274Z] <57379367c43b8c601972f35d> Hello
[2018-01-08T07:50:54.145Z] <58faf245d73408ce4f5a2675> hey,
[2018-01-08T07:51:14.097Z] <58faf245d73408ce4f5a2675> i have some doubt in estimator_check can anyone plz explain the purpose of that file
[2018-01-08T12:26:53.439Z] <53eb987c107e137846baa89d> I think it contains various routines to check the correctness of input to the various estimators. In particular see: http://scikit-learn.org/stable/modules/generated/sklearn.utils.estimator_checks.check_estimator.html 
[2018-01-09T01:26:29.897Z] <54b2524adb8155e6700e8a8e> sklearn/utils/estimator_checks.py includes assertions run on each estimator to check that it behaves according to Scikit-learns conventions.
[2018-01-09T02:55:02.324Z] <54b2524adb8155e6700e8a8e> @ssequeira, I dont think we have any planned enhancements to gaussian processes except for easier access to a linear kernel in #8373
[2018-01-09T06:37:20.211Z] <53eb987c107e137846baa89d> @jnothman (as you are aware) I'm currently working on https://github.com/scikit-learn/scikit-learn/pull/10083 and the other remaining PR is https://github.com/scikit-learn/scikit-learn/pull/10273 (has been inactive for sometime, but I'll get to that), do you think this would be a good time for me to get to medium-level issues?  If the answer to above question is somwhat yes, then, I've been searching for a medium-level issue (non-documentation issue), one which will require a few months of work. Better if there are a series of medium-level issues on the same topic that you guys need someone to contribute on?
[2018-01-10T06:08:15.954Z] <54b2524adb8155e6700e8a8e> Sorry, I cant think of anything right now. I think you would benefit from a few more easy issues. https://github.com/scikit-learn/scikit-learn/issues?utf8=%E2%9C%93&q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22+-label%3A%22good+first+issue%22+ might help, but as you know, were much better at adding the <unconvertable> help wanted <unconvertable> tag than removing it. Do you want to help me build a bot to manage that?? I have ideas...
[2018-01-10T10:17:44.537Z] <54b2524adb8155e6700e8a8e> Ping @gxyd 
[2018-01-10T10:18:05.554Z] <53eb987c107e137846baa89d> Yes, I'll am willing to work on that.
[2018-01-10T10:18:33.062Z] <53eb987c107e137846baa89d> Will you open an issue for that?
[2018-01-10T15:53:56.863Z] <55fc44590fc9f982beb11bbf> Please let me know if any assistance is needed 
[2018-01-10T15:54:35.572Z] <53eb987c107e137846baa89d> Sure. Thanks.
[2018-01-10T19:37:08.188Z] <55fc44590fc9f982beb11bbf> https://travis-ci.org/scikit-learn/scikit-learn/jobs/327310192
[2018-01-10T19:37:24.352Z] <55fc44590fc9f982beb11bbf> Why can't I use scipy.sparse.random?
[2018-01-10T19:37:34.720Z] <55fc44590fc9f982beb11bbf> Works fine locally
[2018-01-10T20:15:11.288Z] <55d21ee30fc9f982beadabb8> scipy.sparse.random was not there in scipy 0.13.3 which is the minimal version required by scikit-learn
[2018-01-11T03:09:52.309Z] <55fc44590fc9f982beb11bbf> Alroght thanks I'll change it with something else
[2018-01-11T03:10:00.257Z] <55fc44590fc9f982beb11bbf> Alright *
[2018-01-11T05:42:10.360Z] <54b2524adb8155e6700e8a8e> #9099 is also a fairly large, non-core project... Designing a better way to print out estimators.
[2018-01-11T15:29:24.969Z] <55fc44590fc9f982beb11bbf> Is github down?
[2018-01-11T15:51:25.103Z] <58faf245d73408ce4f5a2675>  @maykulkarni nope
[2018-01-11T15:52:02.278Z] <55fc44590fc9f982beb11bbf> It's working now, it was d os n
[2018-01-11T15:52:58.666Z] <55fc44590fc9f982beb11bbf> It was down a while ago
[2018-01-11T16:09:14.304Z] <5a477efed73408ce4f85632f> @maykulkarni - Were you trying to access using Jio internet because I faved the same problem
[2018-01-11T16:09:34.961Z] <5a477efed73408ce4f85632f> *faced 
[2018-01-11T16:09:46.937Z] <55fc44590fc9f982beb11bbf> No github was down https://status.github.com/messages
[2018-01-11T17:10:55.707Z] <5a429497d73408ce4f84e60d> guys does anyone have a cool idea for a simple machine learning project?
[2018-01-11T17:11:31.637Z] <5a429497d73408ce4f84e60d> using sciket-learn which is never done before?
[2018-01-12T05:44:54.636Z] <5a2c58c8d73408ce4f8294ba> Do you mean something which has never been done with scikit-learn or something that has never been done in general? If the former then just look for feature request. If the latter I think it is safe to say all simple things have been done long ago.
[2018-01-12T05:45:48.564Z] <5a429497d73408ce4f84e60d> Yeah its all done
[2018-01-12T05:49:33.688Z] <5a2c58c8d73408ce4f8294ba> Well the intersection of novel and simple is nearly nonexistant in most developed fields
[2018-01-12T12:13:00.724Z] <58bd1933d73408ce4f4ea7d6> am i supposed to know the internal functioning of all the scikit learn models?
[2018-01-12T12:14:32.568Z] <58bd1933d73408ce4f4ea7d6> because there are too many models
[2018-01-12T12:14:43.348Z] <58bd1933d73408ce4f4ea7d6> i just did the andrew ng course on coursera
[2018-01-12T12:14:58.671Z] <58bd1933d73408ce4f4ea7d6> he taught a few basic things.
[2018-01-13T05:28:34.373Z] <5a2c58c8d73408ce4f8294ba> Supposed to by who?
[2018-01-13T05:49:42.689Z] <53eb987c107e137846baa89d> I'm currently getting some errors in my scikit-learn branch (made some changes). Running tests via pytest, produces some output on terminal, but since numpy arrays contains large number of elements, they are printed with a threshold. ``` $ pytest sklearn/metrics/tests/test_common.py ============================================================= test session starts =============================================================  sklearn/metrics/tests/test_common.py:917: in check_averaging     y_pred_binarize, is_multilabel) sklearn/utils/testing.py:311: in wrapper     return fn(*args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  metric = <functools.partial object at 0x7fa62c5d5b50> y_true = array([0, 1, 0, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0,   ...0, 2, 0, 1, 1, 2, 0, 1, 1, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0,        1, 1, 2, 0]) y_pred = array([0, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 0, 2,   ...0, 0, 0, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 0, 1, 2, 0,        2, 0, 1, 2]) y_true_binarize = array([[1, 0, 0],        [0, 1, 0],        [1, 0, 0],        [0, 1, 0],       ...0, 0],        [0, 1, 0],        [0, 1, 0],        [0, 0, 1],        [1, 0, 0]]) ``` Now the problem is how can I print the complete array's (i.e with `threshold=np.nan`).  I tried to put `np.set_printoptions(threshold=np.nan)` in concerned test file as well as in skearn/utils/testing.py but with no success. Do I need some pytest option?
[2018-01-13T05:50:26.322Z] <53eb987c107e137846baa89d> See here `y_true` is printed with some threshold size.
[2018-01-13T06:10:42.466Z] <53eb987c107e137846baa89d> Well, one thing I can do is, use the `print` statement and then use `pytest` with `-s - v` option. But I don't think this is a good solution.
[2018-01-13T12:21:21.381Z] <5717ab2f659847a7aff3b583> hi
[2018-01-13T14:51:29.212Z] <55fc44590fc9f982beb11bbf> #10443 Ready to MRG, needs review. 
[2018-01-13T17:22:06.885Z] <58b47262d73408ce4f4d4113> Is scikit-learn going to take part in GSoC 2018? If yes, I saw a couple of projects in GSoC 2017 wiki. Since, there were no participant last year, is that project list still valid or are you guys going to come up with some other projects? I would be willing to explore available/possible projects.
[2018-01-15T00:19:25.958Z] <54b2524adb8155e6700e8a8e> @gxyd, try `np.set_printoptions(threshold=np.inf)` rather than `np.nan`, or perhaps `np.set_printoptions(threshold=np.iinfo(np.int).max)`
[2018-01-15T00:24:38.086Z] <54b2524adb8155e6700e8a8e> @thechargedneutron, our problem with GSoC is assuring mentor availability, as well as developing well-defined projects and students we are confident will complete the work without too much hand-holding. We have much less core dev availability than a few years ago, and many fewer well-defined, coherent project options that do not require substantial expertise. For example, we have a few big API things that could do with attention (see https://github.com/scikit-learn/scikit-learn/projects/9), but they mostly require a lot of familiarity with Scikit-learn API design issues. At this stage of maturity we have less need for an <unconvertable> implement this kind of algorithm <unconvertable> or <unconvertable> optimise that <unconvertable> kind of project. If a compelling student/project candidate approached, I think we would consider it.
[2018-01-15T05:51:31.967Z] <58b47262d73408ce4f4d4113> @jnothman  Thanks for the reply. I am indeed interested in working in API things but need a good understanding of it. Since there's some time before the GSoC, I would like to orient myself in the direction of the current requirements. Can you advise me on how to acquaint me with the current issues and possible solutions. Thanks :smile: 
[2018-01-16T08:56:36.631Z] <53eb987c107e137846baa89d> @jnothman neither of them work for me. BTW, which files should I put them in? I tried to put it both files sklearn/utils/testing.py and sklearn/metrics/tests/test_common.py.
[2018-01-16T09:36:02.543Z] <54b2524adb8155e6700e8a8e> Modify conftest.py if youre doing this for testing??
[2018-01-16T12:34:01.021Z] <54b2524adb8155e6700e8a8e> Is there a contributor who wants to work on an Easy issue with a moderate amount of work? #9726: create a new sklearn.impute module for imputation
[2018-01-16T12:36:43.948Z] <58b47262d73408ce4f4d4113> I am relatively free. I have currently #10206 which may get completed by the end of this week. So, I am willing to take it.
[2018-01-16T12:54:54.833Z] <54b2524adb8155e6700e8a8e> For a longer project (potentially a GSoC), contributors might be interested in resampling API: https://github.com/scikit-learn/scikit-learn/issues/3855#issuecomment-357949997
[2018-01-16T14:05:59.177Z] <56333d0d16b6c7089cb8d5c7> @jnothman I can work on #9726.
[2018-01-17T22:49:24.978Z] <589208e2d73408ce4f4770c4> [![Screenshot from 2018-01-17 22-43-24.png](https://files.gitter.im/scikit-learn/scikit-learn/aUpR/thumb/Screenshot-from-2018-01-17-22-43-24.png)](https://files.gitter.im/scikit-learn/scikit-learn/aUpR/Screenshot-from-2018-01-17-22-43-24.png)
[2018-01-17T22:50:19.980Z] <589208e2d73408ce4f4770c4> Hi everyone. an SVM model i created returns an error when i fit with my x and y data. below is a print out of my x and y values and the error message. I transformed the y values to onehotencoder values as well.  
[2018-01-17T22:53:23.376Z] <589208e2d73408ce4f4770c4> the same error is generated when i use random forest and naive bayes
[2018-01-17T23:22:55.351Z] <55d21ee30fc9f982beadabb8> Don't OneHotEncode `y`
[2018-01-17T23:22:59.433Z] <55d21ee30fc9f982beadabb8> and it will work
[2018-01-18T04:09:30.294Z] <55fc44590fc9f982beb11bbf> Just curious, 
[2018-01-18T04:09:47.516Z] <55fc44590fc9f982beb11bbf> Should every bug fix / enhancement go into what's new?
[2018-01-18T08:51:00.821Z] <589208e2d73408ce4f4770c4> @glemaitre: i the data is a multiclass data so i labeled the classes 0,1 ,2. will is it okay to use them as it is without onehotencoding?
[2018-01-18T09:34:49.485Z] <589208e2d73408ce4f4770c4> i encoded them as [001],[010] and [100] and that is what generated the error
[2018-01-19T13:14:06.763Z] <55d21ee30fc9f982beadabb8> http://scikit-learn.org/stable/modules/multiclass.html
[2018-01-19T13:14:25.195Z] <55d21ee30fc9f982beadabb8> @maykulkarni most of the time yes
[2018-01-19T13:15:48.077Z] <55d21ee30fc9f982beadabb8> @jotes35 SVM does not handle multi-label. But I am not sure that you have to hot one encode
[2018-01-19T13:17:53.235Z] <55fc44590fc9f982beb11bbf> #10478 #10443 completed, needs review
[2018-01-19T13:39:40.839Z] <55d21ee30fc9f982beadabb8> @maykulkarni I put 2 additional tests to do because I am almost sure that the solution in #10443 is not working if we don't introduce a dtype to the transformer as proposed [here](https://github.com/glemaitre/scikit-learn/commit/4e5e1f06ed1b90c0ffb00584db81a4e8c77e1dff)
[2018-01-19T13:40:24.740Z] <55fc44590fc9f982beb11bbf> Thanks, will check it out
[2018-01-22T20:25:17.760Z] <5a2c58c8d73408ce4f8294ba> Anybody know if there is a wrapper or python equivalent to RankLib
[2018-01-22T20:25:39.786Z] <5a2c58c8d73408ce4f8294ba> ?
[2018-01-24T22:12:35.665Z] <59afadccd73408ce4f748432> @DrEhrfurchtgebietend  It seems to be LEROT in Python. You have more details here : https://www.quora.com/What-are-the-alternatives-to-RankLib
[2018-01-26T15:14:08.800Z] <551d48fa15522ed4b3de4121> Guys, the GaussianMixture model's score_samples() method return log-probabilities, I'm not sure how to calculate regular/percentage-wise probabilities from these, can anyone enlighten me?
[2018-01-27T08:19:52.975Z] <57af6d0540f3a6eec05f5297> how to make spacemacs work behind https_proxy?
[2018-01-27T08:26:25.254Z] <57af6d0540f3a6eec05f5297> I tried `(setq url-proxy-services         '(("no_proxy" . "^\\(localhost\\|127.*\\)")           ("http" . "127.0.0.1:1087")           ("https" . "127.0.0.1:1087")))   )`,but it didnt work
[2018-01-27T08:41:41.935Z] <57af6d0540f3a6eec05f5297> Sorry,i send my message to wrong room,sorry again
[2018-01-27T08:43:15.294Z] <598e3be6d73408ce4f710e38> hi what are you doing now
[2018-01-28T10:19:29.589Z] <54b2524adb8155e6700e8a8e> @JVanloofsvelt np.exp is the inverse of np.log... Just apply that to get probabilities.
[2018-01-28T23:45:17.390Z] <5a6e6050d73408ce4f8a8f8b> hello world
[2018-01-30T09:39:35.658Z] <551d48fa15522ed4b3de4121> @jnothman thanks! 
[2018-01-30T09:40:54.588Z] <551d48fa15522ed4b3de4121> using GaussianMixtureModel.predict I'm able to guess what cluster/distribution the sample(s) belong(s) to, but how do I get the probability of the given sample occurring given that distribution (not a weighted average of all clusters)? 
[2018-01-31T19:59:44.898Z] <59e7b052d73408ce4f7aa075> I would like to include data loading/augmentation as the first step of a pipeline, so I can optimize parameters. But I see no way of doing so because of the signature of TransformerMixin (no place for class labels to be returned) . Any ideas?
[2018-02-01T18:59:00.882Z] <5a314ce4d73408ce4f83281f> Hi, anyone replicated IDL SMOOTH function in python successfully ? I infact want to use smooth2 function adopted by JHUAPL (https://github.com/callumenator/idl/blob/master/external/JHUAPL/SMOOTH2.PRO) which uses smooth function of IDL. Eagerly waiting ! 
[2018-02-02T01:00:39.463Z] <58b46af0d73408ce4f4d3f2c> As  a statistics graduate student, I'd love to add inferential tools to scikit-learn.
[2018-02-02T01:58:21.469Z] <58b46af0d73408ce4f4d3f2c> Would it be a worthwhile effort to implement conformal inference (http://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf) ?
[2018-02-03T03:16:06.674Z] <5921d334d73408ce4f612e46> Hello, I'm trying to understand the RCV1 dataset, so I can run some analysis on it. Please has anyone worked with it before? 
[2018-02-03T03:16:47.425Z] <5921d334d73408ce4f612e46> I'd also be grateful to receive help in understanding how to work with CSR
[2018-02-03T23:27:18.426Z] <5a764508d73408ce4f8b90d6> Any good book for machine learning with python?
[2018-02-04T17:55:43.520Z] <5a774845d73408ce4f8ba7bb> hello 
[2018-02-04T17:56:36.998Z] <5a774845d73408ce4f8ba7bb> i want to ask which is more advantageous to use dummy variables or one hot encoding?
[2018-02-09T08:02:21.007Z] <59b159b1d73408ce4f74c00d> @itsmegaurav check out https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn
[2018-02-10T17:30:01.693Z] <55a487245e0d51bd787b4e45> @xidorn5 I can't speak for the sklearn team, but generally sklearn is intended to target the most widespread, widely-cited, well-established methods for the core package, and to allow third-party packages a lot of freedom in implementing less-established advancements from the literature.
[2018-02-13T09:23:28.237Z] <58dabed4d73408ce4f5463b2> @Pimp_Fada_twitter https://books.google.com/books/about/Introduction_to_Machine_Learning_with_Py.html
[2018-02-13T09:25:58.789Z] <58dabed4d73408ce4f5463b2> Introduction to Machine Learning with Python: A Guide for Data Scientists https://www.amazon.com/dp/1449369413/ref=cm_sw_r_cp_apa_47QGAbZNXX58Z
[2018-02-16T06:43:17.680Z] <5a867bd5d73408ce4f8d6091> hi i am working on ml that determine the emergency situation in vehicle(cars) by getting the input from the sensors of the vehicle . so i need a real time OBD2 logged csv file for training in the ml. any help ?
[2018-02-20T10:18:45.162Z] <57a061aa40f3a6eec05d8d26> Hello, I tried to use PredefinedSplit as CV for GridSearchCV. I have two sets, first is for training and second is for validation. I made indices array so that for training set indices I put -1 and 0 for testing set. I get reasonable results to grid.cv_results_, but when I test it with the second (testing) set, I get .99 which is clearly not correct. Why is that?
[2018-02-22T00:02:20.281Z] <57a061aa40f3a6eec05d8d26> I get warning that some columns are collinear. Is there any utility to find out which columns they are?
[2018-02-26T09:19:41.744Z] <572f08a2c43b8c601971bc45> Hello, I am considering applying for a [GSoC project](https://github.com/rstats-gsoc/gsoc2018/wiki/SAGA-sparse-linear-models) with the aim of adapting the SAGA algorithm for R, possibly by porting existing code from scitkit-learn. The project, however, needs another co-mentor and I am wondering if there is any scitkit-developer here that would interested in participating? You can message me directly or contact Toby, who is signed up as mentor.
[2018-02-26T23:01:04.443Z] <56d53608e610378809c45c8c> Hello, I want to use the http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html but with the decision boundary always going through the origin. The API doesn't allow this so I wonder if there is a way around this. 
[2018-02-27T04:14:29.775Z] <56d53608e610378809c45c8c> I guess I can just use the normal SVM and mirror one example along the origin. 
[2018-03-03T19:40:30.164Z] <564789be16b6c7089cbab8b7> I would like to cluster about 100,000  vectors according to the Pearson distance https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#Pearson's_distance  . Which clustering method would support that?
[2018-03-03T19:40:49.703Z] <564789be16b6c7089cbab8b7> many of them seem to want the Euclidean distance
[2018-03-03T19:48:42.756Z] <59afadccd73408ce4f748432> @lesshaste 
[2018-03-03T19:48:55.161Z] <564789be16b6c7089cbab8b7> hi
[2018-03-03T19:50:02.377Z] <564789be16b6c7089cbab8b7> @guyome80  I am hoping you might be about to tell me about clustering...
[2018-03-03T19:50:22.632Z] <59afadccd73408ce4f748432> Oups, sorry, wrong message...
[2018-03-03T19:53:04.275Z] <570d14d6187bb6f0eadf1582> You can try k-medoids 
[2018-03-03T19:53:04.384Z] <59afadccd73408ce4f748432> I was thinking about a preprocessing method (Standardscaler) instead of clustering...
[2018-03-03T19:54:21.576Z] <570d14d6187bb6f0eadf1582> K-medoids isnt released yet, but it support any distance metric you wish. you might copy paste the class or build from the branch. The complexity is worse then k means, for 100k should be good 
[2018-03-03T23:01:09.869Z] <57379367c43b8c601972f35d> hi
[2018-03-05T11:53:00.934Z] <5a70791bd73408ce4f8ad6e1> Hi, further on my spell correct algo: Is there a function that gives you the number of occurences of a word (BoW-style)? I would expect that frequent words (preposition) are often in the neighbourhood of other words (nouns)
[2018-03-05T13:07:36.372Z] <5a70791bd73408ce4f8ad6e1> @aph61 Further to my question  before, can you also work with word vectors, like, count the number of vectors for a given word? Makes actually more sense
[2018-03-06T17:53:53.339Z] <59ff9cd4d73408ce4f7d44f2> Hi guys
[2018-03-06T17:54:51.696Z] <59ff9cd4d73408ce4f7d44f2> What's the... eh, correct way to test C extensions without exposing the original class?
[2018-03-06T17:57:03.227Z] <59ff9cd4d73408ce4f7d44f2> oops, wrong room, sorry :worried: 
[2018-03-07T05:27:38.233Z] <5a895aedd73408ce4f8da2b8> Hello all! I just finished compiling a survey with more than 350 open source software project members which, together with some communication theory, we used to define a set of **best practices and guidelines for using Gitter** (in fact, it probably applies to *any chat-like platform*).  If anybody would be interest on it, or in applying them in this community, or your other projects, there is a [small survey](http://bit.ly/survey-and-guidelines) you can fill to get the guidelines. The survey takes something between just *10 seconds to a maximum of 2 minutes to fill* and it is intended to help us validate the guidelines in the future.  There is also a small [article](https://medium.com/@fabiomolinar/validating-chat-communication-tools-guidelines-and-best-practices-fb8852f319da) I wrote with a really short description about the study; in case you would be curious about it.  Of course, feel free to send the [survey link](http://bit.ly/survey-and-guidelines) to anyone you would like to share these guidelines with.
[2018-03-07T12:04:20.330Z] <57433a8cc43b8c6019747d9e> Guys I'm new to contributing to open source projects and I'm trying to resolve issue #10689, the issue is about replacing a depreciated function with new function But when I try to replace the depreciated issue with new issue, and create a PR, my commits are facing merge conflicts because of circle ci and lgtome tools  Can anyone please help me?
[2018-03-09T17:53:43.474Z] <57007657187bb6f0eadd96e8> try a rebase
[2018-03-13T16:35:13.944Z] <5a2c58c8d73408ce4f8294ba> Why are partial dependence plots not in the units of the prediction variable? https://stackoverflow.com/questions/49247796/understanding-partial-dependence-for-gradient-boosted-regression-trees
[2018-03-20T17:56:46.171Z] <58412a9ed73408ce4f3a3004> Hi everyone! I have been looking in to multi-output regression the last few days. I know that the scikit-learn package offers a class called multioutput regressor. This class will give every algorithm multi-output support by fitting model for every variable. My questions : Does this package take the relationship between the input variables into account? Which algorithm would work better , a model with a multi-output regression or without (some models support it natively ?
[2018-03-21T17:53:58.932Z] <5796009e40f3a6eec05c5aa0> @satishjasthi , I would use Pycharm if the command line version of git is giving you trouble.  Then, do the [visual merge conflict resolution](https://www.jetbrains.com/help/idea/resolving-conflicts.html).    
[2018-03-22T12:14:34.098Z] <57e0cda740f3a6eec0662f30> How many documents scikit k means clustering can process at a time? 
[2018-03-22T21:44:18.748Z] <5ab421aad73408ce4f92b961> Just discover gitter. Nice room to join :-)
[2018-03-23T22:09:48.425Z] <59e7b052d73408ce4f7aa075> Do "train" and "fit" mean exactly the same thing or do they have different connotations?
[2018-03-23T22:10:44.219Z] <54d4a1d6db8155e6700f853b> @bsheline they mean the same. I think train mostly comes from the neural net community, while fit comes more from statistics
[2018-03-23T22:10:55.576Z] <54d4a1d6db8155e6700f853b> but I'm not sure
[2018-03-24T02:24:11.149Z] <58f51045d73408ce4f5906f0> i know this is python but does anyone know how to do C#? 
[2018-03-24T20:12:37.010Z] <57cdefdf40f3a6eec063af10> hi all
[2018-03-25T12:15:26.619Z] <5ab7916ad73408ce4f93091f> hi
[2018-03-25T12:15:34.207Z] <5ab7916ad73408ce4f93091f> send help
[2018-03-26T12:23:20.829Z] <5ab8e610d73408ce4f9327af> Hi guys
[2018-03-26T18:36:46.475Z] <5842913cd73408ce4f3a6993> <unconvertable> <unconvertable> <unconvertable> <unconvertable>
[2018-03-29T17:39:44.592Z] <58b72049d73408ce4f4dc16c> Hey there
[2018-03-30T01:54:50.830Z] <5abd978cd73408ce4f93b55a> Hey there
[2018-03-30T22:09:37.878Z] <5abeb33fd73408ce4f93d1a6> hello guys im new in data science can any one please guide me with some books or anything that i should learn 
[2018-03-31T14:03:09.325Z] <57c1cad340f3a6eec061a142> hi guys, I got some question about dimensional reduction using LDA
[2018-03-31T14:10:29.350Z] <5ab421aad73408ce4f92b961> @idahmed One of my latest favourites is Hands on machine learning with Scikit-Learn and Tensor flow by Aurelien Geron
[2018-03-31T14:12:10.936Z] <5ab421aad73408ce4f92b961> @hndr91 there is an issue opened at Github with some info to take into account
[2018-04-01T14:15:29.458Z] <5a873b5fd73408ce4f8d784b> @idahmed : also try this https://developers.google.com/machine-learning/crash-course/
[2018-04-02T05:17:30.839Z] <57e0cda740f3a6eec0662f30> I have to classify docs into two categories and if the docs does not belong to these two, then i have to identify them in other category i have training data for two. Classes What algo or approach i can use?
[2018-04-03T08:33:32.583Z] <570665ba187bb6f0eade50c8> Hi , I am a beginner and I try to predict an anomaly in different systems, I have different parameters, which I can use to do more precise prediction. I have a general question, is there a way to do prediction without know with parameters should I use ? sometimes, I don't have all parameters values, so I am thinking if there is a away to do prediction with a minimum parameters
[2018-04-03T18:14:46.584Z] <5a2c58c8d73408ce4f8294ba> Google feature selection
[2018-04-03T19:37:08.601Z] <54d4a1d6db8155e6700f853b> @naaioa @DrEhrfurchtgebietend more like imputation?
[2018-04-03T19:39:42.191Z] <54d4a1d6db8155e6700f853b> @idahmed the "python data science handbook" is a great introduction and available online for free and in notebook format.
[2018-04-03T19:40:25.701Z] <54d4a1d6db8155e6700f853b> @mcasl if I may ask, have you looked at mine as well? I feel the two are somewhat similar in scope, but tbh I haven't looked into Aurelien's book in that much detail
[2018-04-05T19:35:04.530Z] <5ab421aad73408ce4f92b961> @amueller 
[2018-04-05T19:37:01.982Z] <5ab421aad73408ce4f92b961> @amueller Sure! I have it on my to do list. Just browsed it and seems an impressive work. Eager to read it 
[2018-04-05T19:40:39.946Z] <5ab421aad73408ce4f92b961> @amueller Besides of books, I would recommend anyone visiting the materials you have posted regarding your University course on machine learning. I specially liked  the fact of introducing unitary tests, continuos integration engines and git as essentials. Keep up the good work!
[2018-04-06T21:56:11.697Z] <551c051b15522ed4b3de2fea> hi all
[2018-04-06T21:56:22.268Z] <551c051b15522ed4b3de2fea> I am doing some testing with gradient descent and labeled data. For X, I have selected two features: one sort of nonsense, and one the EXACT (binary) label. I train on a 66% subset of this data my precision/recall for `y = 1` is 0.00. how is this possible?
[2018-04-06T21:56:40.738Z] <551c051b15522ed4b3de2fea> ```              precision    recall  f1-score   support            0       0.94      1.00      0.97      4194           1       0.00      0.00      0.00       247  avg / total       0.89      0.94      0.92      4441 ```
[2018-04-09T23:46:37.597Z] <589208e2d73408ce4f4770c4> Hi,all I am using scikit 0.19.1 I generated a training model using random forest and saved the model. These were done on ubuntu 16.01 x86_64. I copied the model to a windows 10 64 bit machine and wanted to reuse the saved model. But unfortunately i get the following Traceback (most recent call last): File "C:\Users\PC\Documents\Vincent\nicholas\feverwizard.py.py", line 19, in rfmodel=joblib.load(modelfile) File "C:\Python27\lib\site-packages\sklearn\externals\joblib\numpy_pickle.py", line 578, in load obj = _unpickle(fobj, filename, mmap_mode) File "C:\Python27\lib\site-packages\sklearn\externals\joblib\numpy_pickle.py", line 508, in _unpickle obj = unpickler.load() File "C:\Python27\lib\pickle.py", line 864, in load dispatchkey File "C:\Python27\lib\pickle.py", line 1139, in load_reduce value = func(*args) File "sklearn\tree_tree.pyx", line 601, in sklearn.tree._tree.Tree.cinit ValueError: Buffer dtype mismatch, expected 'SIZE_t' but got 'long long'  What could be happening? Is it because of a switch from ubuntu to windows? However i am able to reuse the model in my ubuntu.
[2018-04-10T13:48:57.563Z] <5a4f6d1cd73408ce4f864c42> @jotes35 i think the issue isn't fixed.  the only feasible solution is retrain it over there in the new architecture, and yes it seems to be because of different architectures, not because it's windows and ubuntu, it happens even on ubuntu and another version of ubuntu
[2018-04-10T13:49:03.780Z] <5a4f6d1cd73408ce4f864c42> have a look at this https://github.com/scikit-learn/scikit-learn/issues/7891
[2018-04-10T17:37:25.197Z] <551c051b15522ed4b3de2fea> in general, what are good starting points for `min_samples_leaf` in random forest classifiers? I find that `0.005` gives me decent results but Im afraid Im overfitting.
[2018-04-11T02:45:33.829Z] <589208e2d73408ce4f4770c4> Thanks @greed2411 . Retraining on the new architecture works.
[2018-04-11T18:06:06.753Z] <564789be16b6c7089cbab8b7> I have a few thousand points on a line and most of them are in a dense part with a few hundred spread out more widely. What is a good way to find the dense part?
[2018-04-11T18:06:22.752Z] <564789be16b6c7089cbab8b7> This looks like a clustering problem with one cluster plus noise
[2018-04-12T22:43:42.148Z] <5acfdfffd73408ce4f95738d> How to get weight for signs(Perceptron, binary classification)? In what function they are?
[2018-04-13T05:13:24.923Z] <5886855fd73408ce4f4586d8> hello everyone
[2018-04-13T05:13:42.982Z] <56bb7a56e610378809c0cb2c> `D3XT3R` HoL
[2018-04-13T05:13:43.809Z] <56bb7a56e610378809c0cb2c> `D3XT3R` a
[2018-04-13T05:50:36.281Z] <5886855fd73408ce4f4586d8> did everyone really stop talking  as soon as I showed up?
[2018-04-13T17:16:42.268Z] <5a4f6d1cd73408ce4f864c42> @quant12345 you can look into the class's attributes. Say if you are using an instance called `mlp` belonging to ` MLPClassifier` class, you can check them at `mlp.coefs_` and `mlp.intercepts_` after fitting/training the model. More on this here : http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier
[2018-04-13T17:37:01.999Z] <5acfdfffd73408ce4f95738d> @greed2411                                                                                                                                          Thank you, for the answer. That is, the "mlp.coefs_ " weights for sign, "mlp.intercepts_ " predicted class labels. There is an example with three classes. I multiplied the signs by weight. The values of each class were obtained: 1.	0.40-043 2.	0.47-0.51 3.	0.24-0.35 Is it possible to get from the function thresholds, which determine the belonging to each class?  regards                                          
[2018-04-14T00:28:06.433Z] <5a4f6d1cd73408ce4f864c42> I don't think mlp works that way. You can't determine which neuron made it predict that output @quant12345 . But try googling it.im not entirely sure either.
[2018-04-20T08:15:20.947Z] <541a528b163965c9bc2053de> @lesshaste if you dimension is low enough (e.g. max 300, the lower the better), then density based clustering such as DBSCAN or https://github.com/scikit-learn-contrib/hdbscan should work well for that case.
[2018-04-20T09:24:30.722Z] <564789be16b6c7089cbab8b7> @ogrisel  Thanks.. in my case the dimension is 1
[2018-04-20T09:25:23.918Z] <564789be16b6c7089cbab8b7> I will see what dbscan gives you. Is it really happy to find just one cluster and ignore the outliers?
[2018-04-20T09:26:46.179Z] <541a528b163965c9bc2053de> it's worth a try with DBSCAN. You do not choose the number of cluster but the typical distance between two points that are to be considered as "core points" that is point in high density regions.
[2018-04-20T09:27:14.279Z] <564789be16b6c7089cbab8b7> @ogrisel  ok thanks. dbscan in 1d it is :)
[2018-04-20T09:27:27.978Z] <541a528b163965c9bc2053de> There are also a bunch of other hyperparams. Read the scikit-learn docs and the hdbscan docs to learn more about this family of estimators.
[2018-04-20T09:27:35.488Z] <564789be16b6c7089cbab8b7> will do
[2018-04-20T09:28:05.809Z] <541a528b163965c9bc2053de> just shape you data as `(n_samples, 1)` that is `n_features=1`.
[2018-04-20T09:30:04.975Z] <564789be16b6c7089cbab8b7> thanks
[2018-04-24T23:03:11.472Z] <5802c9ebd73408ce4f2e8431> hello guys anybody here ? 
[2018-04-27T17:36:19.534Z] <595a8627d73408ce4f6b61ba> hey
[2018-05-01T02:03:12.498Z] <5962cf1ad73408ce4f6c5b9a> I'm trying to understand when `fit_params` would be used in `_fit()` in a `Pipeline`.  ```python def _fit(self, X, y=None, **fit_params):     ... ```  Are there any example Pipelines that make use of this functionality? Is the point of this to allow passing additional data to a `fit`? If the point is to pass parameters what is the use case over adding these parameters to the estimators init? It seems like passing parameters would kind of go against https://github.com/scikit-learn/scikit-learn/issues/1975 no?
[2018-05-01T02:41:39.210Z] <5962cf1ad73408ce4f6c5b9a> I was also curious why `BaseEstimator` supports recursive `get_params`? Are there times when an estimator will have another estimator as a parameter?
[2018-05-03T04:57:49.227Z] <5796939b40f3a6eec05c6fe0> 
[2018-05-03T21:15:40.768Z] <572ccae9c43b8c60197181b7> Is there any way to get the uncertainty on the fit parameters out of a `RANSACRegressor` or an underlying `base_estimator`?
[2018-05-06T12:58:57.420Z] <5a97c979d73408ce4f8f616e> Is there Any existing function for computing partial correlation coefficients ?
[2018-05-09T12:44:44.508Z] <5717ab2f659847a7aff3b583> hi
[2018-05-10T18:47:28.891Z] <5986271dd73408ce4f703d62> Hi guys
[2018-05-10T18:48:43.363Z] <5986271dd73408ce4f703d62> I'm getting an error when I try to train a MultiOutputRegressor using sparse (csr) numpy matrices for both X and y
[2018-05-10T18:49:49.782Z] <5986271dd73408ce4f703d62> I get: ``` AttributeError: 'MultiOutputRegressor' object has no attribute 'fit_transform' ```
[2018-05-11T19:14:13.625Z] <5af5ab1fd73408ce4f98f85e> HI
[2018-05-11T21:55:45.583Z] <55d21ee30fc9f982beadabb8> @gonesbuyo_twitter it is a regressor. The meaningful method is `predict`
[2018-05-11T22:06:20.494Z] <5acfdfffd73408ce4f95738d> Hi! Read all that I found about RandomForestClassifier. Is it possible in any way from 100 trees to make 1 common? The fact that I want to move the logic of the tree with cut-off thresholds in another program. With one tree it is easy to do. And here is how to be with 100 trees from a random forest? Only  if  operator will get a few hundred. Or maybe to calculate importance of characteristics using random forest and then build 1 the  decision tree with relevant signs? What can you advise on this problem in General?
[2018-05-12T06:34:03.131Z] <5a6cb8cdd73408ce4f8a6a10> @quant12345 numirate your questions, please [Answer](https://stackoverflow.com/questions/7152470/how-i-can-merge-two-binary-trees) on the first question 
[2018-05-12T06:37:38.866Z] <5a6cb8cdd73408ce4f8a6a10> Maybe with one tree it's incomplicated problem, but I think after concationations, your tree will be so big
[2018-05-12T10:57:19.247Z] <5acfdfffd73408ce4f95738d> @istom1n_twitter  Looked graphs of all 100 trees. They have different architectures. Do even, if possible to unite them, the tree will be huge. regards 
[2018-05-12T11:08:57.451Z] <5acfdfffd73408ce4f95738d> 1.  To take advantage of a random forest, for later use in a single decision tree graph(diagram). Getting significant features from random forests. Then I use only these features in one solution tree. What do you think about this? 2.  Is there a need to balance classes in the random forest and decision tree(the number of signs in class 1-two times more than in the 2nd class)? If so, what features should I use?
[2018-05-12T12:46:16.078Z] <5a6cb8cdd73408ce4f8a6a10> @quant12345 2. Balabcing, [first in search](https://www.geeksforgeeks.org/how-to-determine-if-a-binary-tree-is-balanced/)
[2018-05-12T12:53:39.649Z] <5a6cb8cdd73408ce4f8a6a10> 1. I don't understand your questions, if you mean reduce your tree after connections, I think you can get Dijkstras Algorithm, Minimum Spanning Trees
[2018-05-12T12:54:41.531Z] <5a6cb8cdd73408ce4f8a6a10> I found good [explanation](https://web.eecs.umich.edu/~akamil/teaching/sp03/041403.pdf)
[2018-05-12T18:18:38.386Z] <5acfdfffd73408ce4f95738d> @istom1n_twitter  Thank you! On the second issue was meant another. Already found a solution: class_weight =balanced
[2018-05-12T18:25:07.538Z] <5a6cb8cdd73408ce4f8a6a10> depends about what tree we're talking, if binary, them balanced is in the left and in the right, we have equal amount of nodes 
[2018-05-12T18:31:50.112Z] <5a6cb8cdd73408ce4f8a6a10> Im only now get your message, strange
[2018-05-12T18:34:51.973Z] <5a6cb8cdd73408ce4f8a6a10> Alright, thats correct, you are welcome
[2018-05-12T18:36:43.947Z] <5a6cb8cdd73408ce4f8a6a10> Question in that, if we connected 100 tree, for example, we get a graph, not tree obviously, and our problem is to find minimum spanning tree
[2018-05-21T06:40:16.399Z] <57ed4d1c40f3a6eec0680da9> Hello everyone, 
[2018-05-21T10:25:27.760Z] <5b029d9cd73408ce4f9a1afe> hii
[2018-05-21T10:26:33.660Z] <5b029d9cd73408ce4f9a1afe> anyone use Named Entity Recognizer ?? 
[2018-05-25T15:19:30.802Z] <5b018bb2d73408ce4f9a05a7> anyone active here?
[2018-05-25T15:19:57.445Z] <5b018bb2d73408ce4f9a05a7> Hello?
[2018-05-25T15:23:32.713Z] <577ebc96c2f0db084a21f545> Yes
[2018-05-25T15:23:52.853Z] <5b018bb2d73408ce4f9a05a7> Hello Prady.
[2018-05-25T15:24:30.503Z] <577ebc96c2f0db084a21f545> Hello Dark Knight (Bruce Wayne) <unconvertable>
[2018-05-25T15:24:53.499Z] <577ebc96c2f0db084a21f545> By the way I love Dark Knight
[2018-05-25T15:24:58.379Z] <5b018bb2d73408ce4f9a05a7> Thanks
[2018-05-25T15:25:43.333Z] <5b018bb2d73408ce4f9a05a7> So are you working on machine learning?
[2018-05-25T15:28:20.223Z] <577ebc96c2f0db084a21f545> Yes I am
[2018-05-25T15:28:33.786Z] <5b018bb2d73408ce4f9a05a7> What exactly?
[2018-05-29T11:00:29.311Z] <5aa26b7ad73408ce4f90978b> @pradyumnad   you kid me?
[2018-05-30T00:47:08.917Z] <5b05ffccd73408ce4f9a806c> I am here to start journey
[2018-05-31T18:01:52.828Z] <5af8e5f8d73408ce4f99309c> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/VVFY/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/VVFY/image.png)
[2018-06-01T22:39:08.137Z] <5b11caa3d73408ce4f9b96b5> As anybody encountered PicklingError when trying to use pipeline.predict with pool.apply_async ?
[2018-06-01T22:39:27.745Z] <54d4a1d6db8155e6700f853b> what's the error?
[2018-06-01T22:39:48.981Z] <5b11caa3d73408ce4f9b96b5> PicklingError: Can't pickle <function Pipeline.predict at 0x1c655cd08>: it's not the same object as sklearn.pipeline.Pipeline.predict
[2018-06-01T22:40:35.560Z] <5b11caa3d73408ce4f9b96b5> The code that I'm using is -  result_train = pool.apply_async( 		 			estimator.predict, 		 			(train_data['X'], ), 		 	)
[2018-06-01T22:41:25.290Z] <54d4a1d6db8155e6700f853b> yeah you can't pickle instance methods like that
[2018-06-01T22:41:43.209Z] <54d4a1d6db8155e6700f853b> write a new function that is not a method and does the prediction.
[2018-06-01T22:42:00.170Z] <5b11caa3d73408ce4f9b96b5> I tried wrapping it into a function. It still throws the same error.
[2018-06-01T22:42:21.072Z] <5b11caa3d73408ce4f9b96b5> def wrapper(*args): 	func = args[0] 	func(*args[1:])
[2018-06-01T22:42:34.089Z] <5b11caa3d73408ce4f9b96b5> result_train = pool.apply_async( 					wrapper, 					(estimator.predict, train_data['X']), 			)
[2018-06-01T22:42:49.331Z] <54d4a1d6db8155e6700f853b> make estimator the argument, not estimator.predict
[2018-06-01T22:43:22.069Z] <5b11caa3d73408ce4f9b96b5> Okay, let me try that.
[2018-06-01T22:45:44.632Z] <5b11caa3d73408ce4f9b96b5> Yes, it works.
[2018-06-01T22:46:11.188Z] <5b11caa3d73408ce4f9b96b5> Thanss @amueller. Where can I read more about this error ?
[2018-06-01T22:49:10.018Z] <54d4a1d6db8155e6700f853b> I don't know.  google pickling instance methods, and you'll see that's not possible
[2018-06-01T22:49:30.560Z] <54d4a1d6db8155e6700f853b> sklearn.pipeline.Pipeline.predict is a bit of a wild beast and not a normal class method, so you can't pickle it
[2018-06-02T02:28:49.535Z] <5b11caa3d73408ce4f9b96b5> Is there a reason Scikit doesnt parallelize predict ?
[2018-06-02T02:31:35.832Z] <5b11caa3d73408ce4f9b96b5> Since estimator wont mutate as a part of the computation, would it be safe to use it across the threads ?
[2018-06-02T03:32:51.003Z] <54d4a1d6db8155e6700f853b> it's often slower, depending on estimator and dataset size
[2018-06-03T21:32:21.624Z] <5b11caa3d73408ce4f9b96b5> I am working with text data. I'm using TfIdf right off the shelf. I noticed that MaxAbsScaler gives a better performance than StandardScaler(with_mean = False). I found this link: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py. This prompted me to try out different scaling transformers. Is there anybody who has worked with text data before ? I wanted to know if "selecting scaler" is worth time spending on ?
[2018-06-03T21:33:25.869Z] <5b11caa3d73408ce4f9b96b5> If it is, the link uses feature distributions, outliers to select a scaler ? Do the above concepts make sense in the space after TfIDF transforms the text data ?
[2018-06-04T02:04:14.884Z] <54d4a1d6db8155e6700f853b> @AMaini503 I think we should deprecate StandardScaler(mean=False). It seems weird to me
[2018-06-04T02:04:32.072Z] <54d4a1d6db8155e6700f853b> but I would just try a bunch and see what makes sense. There's no general rule
[2018-06-05T05:00:24.102Z] <5b018bb2d73408ce4f9a05a7> Hello
[2018-06-05T12:57:11.298Z] <5841d067d73408ce4f3a4ecf> @kelux19 Hey people! ***   string[] name = {"Malin", "Manar", "Stefan", "Ali", "Alexandra", "Robert","Suzana" }; string[] property = { "kind", "bad", "talentfull", "helpfull", "nice", "melancholy", "egoistic" }; string[] role = { "teacher", "system developer", "student", "musician", "programmer", "actor", "doctor"};  *** how can i pick from these three arrays randomly, for example "Ali is a kind teacher"?
[2018-06-05T12:57:47.227Z] <5841d067d73408ce4f3a4ecf> its c# btw
[2018-06-05T16:37:05.628Z] <5b11caa3d73408ce4f9b96b5> @kelux19  I don't think so there is any api to scikit-learn in c#. But you might want to wait for others' answers as well.
[2018-06-05T17:30:49.532Z] <5b11caa3d73408ce4f9b96b5> I'm using  a custom tokenizer for the TfIDF. I trained the model and saved the pipeline object to a pickle file using joblib. However, when I try to load the pickle file in a different script, it throws an error: module '__main__' has no attribute 'MyTokenizer'. Am I pickling the model correctly ?
[2018-06-06T11:21:49.286Z] <541a528b163965c9bc2053de> You should put the code for the MyTokenizer class in an importable module that his installed somewhere in the python path in the Python where you load the model.
[2018-06-06T11:22:39.853Z] <541a528b163965c9bc2053de> Alternatively, you can use `cloudpickle.dump / load` instead of joblib. It will be slightly less efficient if your model has large numpy arrays as attributes but this is probably not a problem in practice.
[2018-06-06T17:24:00.743Z] <5b11caa3d73408ce4f9b96b5> The first solution that you mention works. I read that joblib pickles by remembering the paths to objects
[2018-06-06T17:24:45.131Z] <5b11caa3d73408ce4f9b96b5> So, if I create a function in an interactive session, there is no path to that function. Putting that into an importable module makes it work
[2018-06-06T20:48:58.317Z] <5b11caa3d73408ce4f9b96b5> @ogrisel Coming back to the pickling issue. The way I was using it in another script was by redefining the function. 
[2018-06-06T20:50:26.505Z] <5b11caa3d73408ce4f9b96b5> Now, I'm trying to use the pipeline object inside a class. In the __init__, I try to load the model, it throws the same error again. I tried defining the function inside the __init__, but still the pickle doesn't see the function. Any workaround for this ?
[2018-06-06T20:52:38.970Z] <5b11caa3d73408ce4f9b96b5> Here is the paste: https://pastebin.com/7rLmaxxJ. 
[2018-06-06T20:54:42.885Z] <5b11caa3d73408ce4f9b96b5> Open to suggestions from others.
[2018-06-07T07:51:22.691Z] <541a528b163965c9bc2053de> @AMaini503  please provide a Minimal Complete Verifiable Example in your paste (http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports)
[2018-06-07T21:58:07.519Z] <5b11caa3d73408ce4f9b96b5> I'm trying to get cluster assignments from the linkage matrix. So far, I know that I can use the fcluster to do that. But, how do I specify the n_clusters ?
[2018-06-09T11:58:54.840Z] <5b018bb2d73408ce4f9a05a7> hello 
[2018-06-09T16:34:12.306Z] <5af3b5e8d73408ce4f98c40d> I'm facing an issue in importing svm
[2018-06-09T16:34:25.387Z] <5af3b5e8d73408ce4f98c40d> --------------------------------------------------------------------------- ImportError                               Traceback (most recent call last) <ipython-input-7-264c9a795a14> in <module>() ----> 1 from sklearn import svm  /root/miniconda2/lib/python2.7/site-packages/sklearn/__init__.py in <module>()      61     # process, as it may not be compiled yet      62 else: ---> 63     from . import __check_build      64     from .base import clone      65     __check_build  # avoid flakes unused variable error  ImportError: cannot import name __check_build
[2018-06-10T01:45:54.038Z] <5a2c58c8d73408ce4f8294ba> Is there a reason sklearn.ensemble.partial_dependence only works on gradient boosting?
[2018-06-11T17:06:39.382Z] <5b11caa3d73408ce4f9b96b5> @ucalyptus https://stackoverflow.com/questions/15274696/importerror-in-importing-from-sklearn-cannot-import-name-check-build
[2018-06-11T17:14:42.911Z] <5b11caa3d73408ce4f9b96b5> Can anyone help me with this: https://stats.stackexchange.com/questions/350520/evaluation-of-machine-learning-model-in-production ? 
[2018-06-11T17:15:45.150Z] <5b11caa3d73408ce4f9b96b5> TL;DR - I'm trying to evaluate a model in production. I need advice on what metrics to use ( excluding explicit evaluation on a data set ).
[2018-06-13T23:06:30.403Z] <5634e8e116b6c7089cb8fa99> Hi all, do the kernel density estimators in scikit-learn allow for diagonal (D class) bandwidths, and do any of them also use a leave-one-out bandwidth estimation?
[2018-06-16T15:54:03.928Z] <54d4a1d6db8155e6700f853b> @tanimislam you can use gridsearchcv for that.
[2018-06-16T15:54:10.335Z] <54d4a1d6db8155e6700f853b> (bandwidth estimation)
[2018-06-16T15:54:22.455Z] <54d4a1d6db8155e6700f853b> there's no efficient implementation if that was the question
[2018-06-17T09:42:33.969Z] <5796939b40f3a6eec05c6fe0> 
[2018-06-17T11:40:05.524Z] <5824aa0dd73408ce4f3501a2> Hi everyone, I am Florian and I am a co-organizer of the Python sprints meetup in London (at least I hope so as this is my first time next week). We are planning on doing a small documentation sprint on a few open source libraries. The main organiser is planning to address some issues and structural changes in the pandas documentation and I wanted to help a separate group work on a different library. I thought that maybe https://github.com/scikit-learn/scikit-learn/issues/10453 would be a good issue to work on with a small group of people for about 2-3 hours since it overlaps nicely with the other group. Is that something that would be helpful and is there someone working on it already (did not see anyone on github picking it up so far)?
[2018-06-17T11:50:05.888Z] <55d21ee30fc9f982beadabb8> I don't see anyone working on the issue for the moment and it seems a good opportunity.
[2018-06-17T11:50:50.890Z] <55d21ee30fc9f982beadabb8> It would be beneficial for the project since we start to have some feature (e.g. ColumnTransformer) which can benefit from the pandas.
[2018-06-17T11:58:55.532Z] <5824aa0dd73408ce4f3501a2> ok great, I see where we can get to on Thursday
[2018-06-18T15:57:25.195Z] <5b27cec1d73408ce4f9dbcaf> What is the difference between logloss and cross entropy? Sorry I am a newbie in this field
[2018-06-18T22:27:29.163Z] <5a36ab82d73408ce4f83bb10> hey guys, I am trying to visualize a high dimensional RNA dataset with TSNE 
[2018-06-18T22:27:33.033Z] <5a36ab82d73408ce4f83bb10> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/6rZd/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/6rZd/image.png)
[2018-06-18T22:27:50.106Z] <5a36ab82d73408ce4f83bb10> However I get the error 
[2018-06-18T22:27:51.109Z] <5a36ab82d73408ce4f83bb10> ValueError: could not convert string to float: 'sample_800'
[2018-06-18T22:27:56.531Z] <5a36ab82d73408ce4f83bb10> Any inputs on this? 
[2018-06-19T01:28:16.301Z] <5b27cec1d73408ce4f9dbcaf> @ziweiwu which line is the error on?
[2018-06-19T08:12:36.609Z] <55d21ee30fc9f982beadabb8> Apparently you have string in your data which you try to convert into numeric
[2018-06-20T19:31:07.307Z] <5a36ab82d73408ce4f83bb10> I see. I have solved this issue, what I did is to convert my df to df.values. 
[2018-06-20T19:31:24.189Z] <5a36ab82d73408ce4f83bb10> so only numerical datas are inputted into the algorithm 
[2018-06-20T21:01:10.322Z] <5a32b032d73408ce4f835880> Hey all, Is there a way to pass a sentence like play some music to an AI model and after that chrome tab will open with a random YouTube song Ive been trying to figure out a way to do this for a while and I appreciate any advices or help
[2018-06-20T21:04:02.284Z] <5a32b032d73408ce4f835880> Just curious if anyone has a way or approach how to wrap this up, advice is highly appreciated
[2018-06-22T13:19:37.324Z] <5b2cf725d73408ce4f9e4022> Hi guys trying to analyze a data set for predicting employee absenteeism
[2018-06-22T13:20:33.653Z] <5b2cf725d73408ce4f9e4022> Can you please suggest that linear regression is good or I need to use a time series model. My dataset is 
[2018-06-22T13:21:08.343Z] <5b2cf725d73408ce4f9e4022> https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work
[2018-06-22T13:34:23.287Z] <541a528b163965c9bc2053de> Based on its description, the dataset you linked does not look like timeseries data: it's a table of feature data and one can probably make the i.i.d assumption. This is not a series of events with a timestamp for each with a progressing time dependency.  For supervised regression of the number of hours of absenteism, I would indeed try linear regress ion (+ some feature engineering) and compare with a more complex model such as RandomForestRegressor
[2018-06-24T09:41:56.476Z] <5a5a272ad73408ce4f880912> Hello! I have taken machine learning class from udacity and now there's a problem while loading a pickle file. The file is just 15MB and I've 4GB RAM. Anyone who can get me through this problem?
[2018-06-26T07:10:14.279Z] <5957e40fd73408ce4f6b27e0> @loginofdeath Hi, I am using this pipeline object pipe = Pipeline( 		[ 			('fresh', 			 FeatureAugmenter(column_id='index', column_sort='tick', default_fc_parameters=MinimalFCParameters())), 			('scaler', StandardScaler())  		]) If I fit_transform it on the train data and get some features, will I get the same features on the test data too so that I can give it  to a classifier?
[2018-06-27T17:07:35.391Z] <530c03e25e986b0712efafb8> I apologize for what I'm sure is a common question, but is there a schedule for a 0.20 release?  "No" or "a long time from now" are both useful answers.  I don't want this to be interpretted as "please do a release", I'm just planning some activities and knowing this would help
[2018-06-28T08:06:59.282Z] <55d21ee30fc9f982beadabb8> As fast as possible :)
[2018-06-28T08:07:55.153Z] <55d21ee30fc9f982beadabb8> We are trying to finish up couple of issues and we would like to have a release candidate for SciPy 
[2018-06-28T08:08:42.372Z] <55d21ee30fc9f982beadabb8> However we might have some delay depending on how it will go :)
[2018-06-28T14:25:45.944Z] <530c03e25e986b0712efafb8> Thanks for the response.   Given the "trying to have a release candidate for scipy" statement I'm interpretting this as "weeks away", not days and not months
[2018-06-28T14:27:40.224Z] <55d21ee30fc9f982beadabb8> Yep
[2018-07-02T16:59:59.478Z] <579618a040f3a6eec05c5e42> Hi folks, excuse my ignorant question. I was wondering if it is possible to pass a tensorflow model into scikit OneVsRestClassifier, if I expose fit and predict methods in the tensorflow model? I couln't find an example when I googled it.
[2018-07-03T16:56:53.453Z] <5b11caa3d73408ce4f9b96b5> @kirk86  I don't know about tensorflow. But keras has wrappers to make models a part of sklearn workflow. I think you can take a look at the source for these wrappers. Here's the link: https://keras.io/scikit-learn-api/
[2018-07-04T07:28:28.253Z] <5957e40fd73408ce4f6b27e0> can knn be used for One Class classification?
[2018-07-04T08:29:50.753Z] <564789be16b6c7089cbab8b7> Would it make sense for http://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html to have a transform method?
[2018-07-04T08:30:04.412Z] <564789be16b6c7089cbab8b7> Currently you can't train it on a training set and then use it on a test set it seems
[2018-07-05T20:19:15.160Z] <564e507e16b6c7089cbb6551> Hey guys, is there a nice book or a course online to understand how the MLP and the SGD classifiers implemented in Scikit-learn work?
[2018-07-05T20:20:04.247Z] <564e507e16b6c7089cbb6551> I'm looking at the code, but I can't understand it, without having a basic understanding of the theory behind
[2018-07-06T08:34:33.855Z] <5b2f34c7d73408ce4f9e6615> https://chat.whatsapp.com/EY44e81jzzCFLXEkY0tjFc
[2018-07-06T20:11:21.370Z] <564789be16b6c7089cbab8b7> I have some 2d data which I think would be well classified by two straight intersecting lines. One straight line is logistric regression I believe but how can you get two straight lines as the decision boundary?
[2018-07-07T19:11:21.778Z] <564789be16b6c7089cbab8b7> oh verbosity = 2 does that
[2018-07-07T19:11:32.433Z] <564789be16b6c7089cbab8b7> is it possible to get tpot to optimize the ROC when doing classification?
[2018-07-07T19:12:35.187Z] <564789be16b6c7089cbab8b7> oh that is there too
[2018-07-07T19:12:35.958Z] <564789be16b6c7089cbab8b7> sorry
[2018-07-07T19:59:14.689Z] <564789be16b6c7089cbab8b7> If you have this code:
[2018-07-07T19:59:15.326Z] <564789be16b6c7089cbab8b7> tpot = TPOTClassifier(generations=20, population_size=50, scoring='roc_auc', verbosity=2, n_jobs=-1) tpot.fit(X_train, y_train) print("TPOT score", tpot.score(X_test, y_test))
[2018-07-07T19:59:25.336Z] <564789be16b6c7089cbab8b7> is the score being printed the roc_auc score?
[2018-07-09T14:15:36.087Z] <564789be16b6c7089cbab8b7> I am going to guess it is
[2018-07-09T14:38:02.327Z] <5b437334d73408ce4fa02901> Hello, I'm just not getting anywhere. I have a regression ANN with four inputs and want to draw a contour plot.  So two variable variables and two fixed. Does anyone have an example or can you give me a hint how I do this?
[2018-07-09T14:39:04.716Z] <55d21ee30fc9f982beadabb8> > is the score being printed the roc_auc score?
[2018-07-09T14:39:13.120Z] <55d21ee30fc9f982beadabb8> accuracy for classifier and r2 for regressor
[2018-07-09T14:40:05.261Z] <564789be16b6c7089cbab8b7> @glemaitre  sorry I was really asking a  a tpot question. I think it prints whatever you used when defining TPOTClassifier
[2018-07-09T14:40:13.051Z] <55d21ee30fc9f982beadabb8> so it depends what TPOTClassifier from which class is it deriving but I assume `ClassifierMixin`
[2018-07-09T14:40:26.355Z] <564789be16b6c7089cbab8b7> as in "TPOTClassifier(generations=20, population_size=50, scoring='roc_auc', verbosity=2, n_jobs=-1)" 
[2018-07-09T14:40:33.402Z] <564789be16b6c7089cbab8b7> where scoring is defined  as roc_auc
[2018-07-09T14:40:59.485Z] <564789be16b6c7089cbab8b7> but I could be wrong of course
[2018-07-09T14:41:19.763Z] <55d21ee30fc9f982beadabb8> TPOTClassifier is not something in scikit-learn so I am not aware of how it works or implemented actually
[2018-07-09T14:46:41.962Z] <564789be16b6c7089cbab8b7> of course.. sorry for asking a slightly off topic question here
[2018-07-09T14:47:39.725Z] <55d21ee30fc9f982beadabb8> no problem but looking quickly at their base class, score is calling the associated string score from sklearn
[2018-07-09T14:47:47.824Z] <55d21ee30fc9f982beadabb8> so I think that your guess was good
[2018-07-09T14:47:55.749Z] <564789be16b6c7089cbab8b7> great, thanks!
[2018-07-09T14:48:23.913Z] <564789be16b6c7089cbab8b7> on another topic, I have lots (1000s) of pairs of vectors. For each pair on the left there is exactly one pair on the right that it should be associated with
[2018-07-09T14:49:05.359Z] <564789be16b6c7089cbab8b7> I could make a classification problem out of it by concatenating the vectors and labelling them with 0 or 1 but 1/1000s of the labels would be 1.  That is the fraction of 1 labels would be tiny
[2018-07-09T14:49:12.353Z] <564789be16b6c7089cbab8b7> is there a standard way to approach this sort of problem?
[2018-07-09T14:50:01.890Z] <55d21ee30fc9f982beadabb8> I am not really familiar
[2018-07-09T14:50:09.742Z] <55d21ee30fc9f982beadabb8> but it could something linked to metric learning
[2018-07-09T14:50:20.936Z] <564789be16b6c7089cbab8b7> oh that sounds interesting
[2018-07-09T14:50:22.740Z] <55d21ee30fc9f982beadabb8> in which you want to know the relative distance between pairs
[2018-07-09T14:50:34.151Z] <55d21ee30fc9f982beadabb8> and know which pairs have the minimal distance
[2018-07-09T14:50:55.255Z] <55d21ee30fc9f982beadabb8> https://github.com/metric-learn/metric-learn
[2018-07-09T14:51:49.132Z] <564789be16b6c7089cbab8b7> thanks.. I will see if that is appropriate  The main restriction is that I need to do out of sample prediction
[2018-07-09T14:51:58.441Z] <564789be16b6c7089cbab8b7> I did also look at scikit learn's kernel pca
[2018-07-09T14:52:02.577Z] <564789be16b6c7089cbab8b7> might that work?
[2018-07-09T14:52:54.681Z] <564789be16b6c7089cbab8b7> you would need to feed in a full set of distances which would only ever be 0 or 1
[2018-07-09T14:53:11.010Z] <564789be16b6c7089cbab8b7> I don't know if that is generally a bad idea for kernel pca
[2018-07-09T14:53:22.254Z] <564789be16b6c7089cbab8b7> http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html
[2018-07-09T14:54:41.396Z] <55d21ee30fc9f982beadabb8> I don't have enough background there :)
[2018-07-09T14:54:51.656Z] <564789be16b6c7089cbab8b7> me neither! 
[2018-07-09T14:55:07.204Z] <55d21ee30fc9f982beadabb8> I would presume that having a continuous distance is what you would need
[2018-07-09T14:55:08.082Z] <564789be16b6c7089cbab8b7> I need to find a nice expert online as I don't know anyone in real life who could help
[2018-07-09T14:55:16.043Z] <564789be16b6c7089cbab8b7> That's my intuition too
[2018-07-11T08:50:57.828Z] <5b437ec8d73408ce4fa02a9a> ```  def get_age(df):     return df[['age']]  preprocess_pipeline = Pipeline([             ('get_cols', FunctionTransformer(get_age, validate=False)),             ('median_impute', Imputer(strategy='median')),             ('min_max_scale', MinMaxScaler())         ])  with open('./preprocess_pipeline.pkl', 'rb') as handle:     preprocess_pipeline = pickle.dump(handle) ``` I want to dump and load this pipeline but it requires me to define `get_age` function again when I want to load. I don't want to duplicate my `get_age` function in 2 different files, how can I include only 1 column (`age` in this case) in the pipeline dump/load friendly way?
[2018-07-11T08:51:42.482Z] <5b437ec8d73408ce4fa02a9a> I've tried using lambda function and joblib function of sklearn, didn't work
[2018-07-12T11:07:44.826Z] <564e507e16b6c7089cbb6551> Anyone knows on which paper are based the formulas in: http://scikit-learn.org/stable/modules/sgd.html#id1 for the `weights` and the `learning rate` of the `SGDClassifier`? I couldn't find the exact same formulas in the papers linked at the bottom of those sections.
[2018-07-12T18:15:15.741Z] <54d4a1d6db8155e6700f853b> @h4k1m0u probably bottou's sgd code
[2018-07-13T00:13:15.030Z] <579618a040f3a6eec05c5e42> @AMaini503  thanks for the pointers I was trying to achieve the same outcome but with pure tf. Not luck so far :(
[2018-07-13T18:21:53.022Z] <59e7b052d73408ce4f7aa075> I am fitting several SVRS to images and get ~3MB pickled model file size for ~20MB image data. Does the pickle contain any redundant data (training or otherwise) or is that a reasonable size?
[2018-07-14T14:02:08.176Z] <54d4a1d6db8155e6700f853b> Sprints!!!
[2018-07-14T14:08:15.080Z] <56f8122085d51f252abb1414> Hi all, I would like to know whether there is interest in adding a least absolute deviation regression with L1 penalty to sklearn. The optimization problem is very similar to the Lasso one, but it uses a L1 likelihood rather than L2.
[2018-07-14T14:10:49.223Z] <54d4a1d6db8155e6700f853b> @mirca that's probably a better question for the mailing list. what's the application? robust regression? How does it behave differently from huber in practice?
[2018-07-14T14:36:21.652Z] <56f8122085d51f252abb1414> @amueller yes, thats mostly for robust regression. I dont have the answer on how it compares to huber right now, but I would guess least absolute deviation would work better on sparse settings. I will investigate that and follow up on the mailing list. Thanks!
[2018-07-14T14:36:38.100Z] <54d4a1d6db8155e6700f853b> :)
[2018-07-14T14:56:26.541Z] <54d4a1d6db8155e6700f853b> we're in 105 for now
[2018-07-14T15:02:44.866Z] <55d21ee30fc9f982beadabb8> A list of issues/stalled PRs are tagged "sprint" which could be good selection for the sprint.
[2018-07-14T15:02:45.536Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc+label%3ASprint
[2018-07-14T15:03:40.490Z] <54d4a1d6db8155e6700f853b> also if you're new the ones tagged "good first issue" https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22+sort%3Aupdated-desc
[2018-07-14T15:12:38.289Z] <59b1b233d73408ce4f74ce2d> thanks @amueller and @glemaitre !
[2018-07-14T16:40:40.402Z] <59b1b233d73408ce4f74ce2d> I have a question about the issue here: https://github.com/scikit-learn/scikit-learn/issues/9352 Where should docker be run? https://github.com/scikit-learn/scikit-learn/blob/master/.travis.yml#L62 I assume that we should copy over install and testing scripts and run in a docker container, is that the right path?
[2018-07-14T16:48:35.415Z] <59b1b233d73408ce4f74ce2d> ran tests in the CentOS32 bit docker image. 13 failed, investigating why first
[2018-07-14T16:52:59.967Z] <54d4a1d6db8155e6700f853b> @jrmlhermitte yeah I think travis
[2018-07-14T16:53:11.625Z] <54d4a1d6db8155e6700f853b> @jrmlhermitte olivier is at the back of the room ;)
[2018-07-14T16:54:32.521Z] <589b9e0fd73408ce4f490ba4> @jrmlhermitte you can report the errors you get in that issue about 32bit bits in any case-- it might be helpful for future reference..
[2018-07-14T17:01:20.056Z] <59b1b233d73408ce4f74ce2d> thanks i posted them here : https://github.com/scikit-learn/scikit-learn/pull/11515 waiting for travis to build but i thikn i can start trying to debug locally
[2018-07-14T17:16:26.393Z] <54d4a1d6db8155e6700f853b> I'm hungry
[2018-07-14T17:16:36.206Z] <54d4a1d6db8155e6700f853b> food?
[2018-07-14T17:16:38.614Z] <55d21ee30fc9f982beadabb8> I agree this is time
[2018-07-14T17:16:39.889Z] <55d21ee30fc9f982beadabb8> :)
[2018-07-14T17:16:58.992Z] <54d4a1d6db8155e6700f853b> where should we go?
[2018-07-14T17:17:53.904Z] <55d21ee30fc9f982beadabb8> Whatever works where there is a vegetarian option
[2018-07-14T17:23:34.369Z] <54d4a1d6db8155e6700f853b> the vietnamese place or the indian place? or the food carts if they are there?
[2018-07-14T19:09:09.222Z] <54d4a1d6db8155e6700f853b> can someone merge this please? https://github.com/scikit-learn/scikit-learn/pull/11289#pullrequestreview-137246243
[2018-07-14T19:19:46.496Z] <55d21ee30fc9f982beadabb8> done
[2018-07-14T19:21:04.536Z] <54d4a1d6db8155e6700f853b> https://sci-hub.tw/https://doi.org/10.1002/sim.1822
[2018-07-14T19:25:47.475Z] <55d21ee30fc9f982beadabb8> Can someone merge this one https://github.com/scikit-learn/scikit-learn/pull/11391
[2018-07-14T19:25:51.549Z] <55d21ee30fc9f982beadabb8> :)
[2018-07-14T19:54:08.344Z] <589b9e0fd73408ce4f490ba4> @amueller if you are OK with https://github.com/scikit-learn/scikit-learn/pull/11431 should we merge it?
[2018-07-14T19:55:28.707Z] <5b4a54fdd73408ce4fa0e3c7> Hi all, quick question: how do I run a single test locally? For example the docttests? Thanks!
[2018-07-14T19:57:46.395Z] <54d4a1d6db8155e6700f853b> make test-doc
[2018-07-14T19:57:58.512Z] <54d4a1d6db8155e6700f853b> or pytest file
[2018-07-14T19:58:21.575Z] <5b4a54fdd73408ce4fa0e3c7> Great, thanks!
[2018-07-14T20:02:55.347Z] <589b9e0fd73408ce4f490ba4> To run a single test you can also run, ``` pytest sklearn/file_path..  -k part_of_test-name ``` providing both the path to the file and a part of the test name will make test collection faster.
[2018-07-14T20:07:25.220Z] <589b9e0fd73408ce4f490ba4> See http://scikit-learn.org/dev/developers/tips.html#useful-pytest-aliases-and-flags
[2018-07-14T20:10:33.292Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/11469
[2018-07-14T20:10:50.707Z] <55d21ee30fc9f982beadabb8> I push some changes @amueller @rth 
[2018-07-14T20:16:03.458Z] <5571fe1015522ed4b3e17d90> James Bourbeau (@jrbourbeau) would like to chat with us about how to make GridSearchCV play nicer with dask-ml. If you have a preferred time today, let me know! Otherwise we'll probably just drop by at a random time :-).  To sum up, in GridSearchCV something check that the score returned by the metric is a number, so they dask-ml needs to call `.compute` explicitly which has a bit of friction with the rest of their API (everything is lazy).
[2018-07-14T20:19:42.450Z] <5b4a54fdd73408ce4fa0e3c7> Hi all, I'm afraid I am still a bit test-confused (newbie here). When running `make test`, I can see errors (like `scikit-learn/sklearn/impute.py:547: DocTestFailure`) related to the docstring in the Imputation, but `make test-doc` does not surface these. 
[2018-07-14T20:28:27.267Z] <541a528b163965c9bc2053de> @lesteve we you want
[2018-07-14T20:33:08.709Z] <5b4a54fdd73408ce4fa0e3c7> Ok, `pytest sklearn/impute.py::sklearn.impute.ChainedImputer`  does the trick! I guess that was in the docs, thanks again!
[2018-07-14T20:43:03.586Z] <5571fe1015522ed4b3e17d90> FYI we'll drop by in 5 -10 minutes
[2018-07-14T21:52:33.283Z] <541a528b163965c9bc2053de> Sorry I missed you @lesteve . 
[2018-07-14T21:53:27.474Z] <541a528b163965c9bc2053de> I merged the Python 3.7 ABC warning  fix in 0.19.X and triggered a new build on the MacPython/scikit-learn-wheels repo
[2018-07-14T21:53:49.348Z] <541a528b163965c9bc2053de> if it goes well I can push those wheels to pypi.org
[2018-07-14T22:51:41.330Z] <569fe132e610378809bd5552> I'm getting a doctest failure when building from source on master
[2018-07-14T22:51:50.478Z] <569fe132e610378809bd5552> It's getting raised from modules/compose.rst
[2018-07-14T22:51:59.463Z] <569fe132e610378809bd5552> Has anyone else here run into this?
[2018-07-14T22:52:25.284Z] <54d4a1d6db8155e6700f853b> sprint will end in 10 minutes
[2018-07-14T22:52:39.930Z] <54d4a1d6db8155e6700f853b> also: if you want to ask me something, you have 10 minutes because then I'll f off
[2018-07-15T15:04:55.408Z] <54d4a1d6db8155e6700f853b> does anyone understand what's happening with lgtm? seems like pypi timeouts? @jnothman ?
[2018-07-15T15:37:25.743Z] <54d4a1d6db8155e6700f853b> @ogrisel do you have an opinion on https://github.com/scikit-learn/scikit-learn/pull/11469#discussion_r202540743 ?
[2018-07-15T16:52:44.426Z] <54d4a1d6db8155e6700f853b> @lesteve is there an issue tracking the joblib pickle thing?
[2018-07-15T16:53:19.661Z] <5571fe1015522ed4b3e17d90> Yep, let me find it.
[2018-07-15T16:53:57.121Z] <5571fe1015522ed4b3e17d90> https://github.com/scikit-learn/scikit-learn/issues/11408
[2018-07-15T19:36:16.495Z] <55d21ee30fc9f982beadabb8> There is to pending PR waiting for an extra review to be merged
[2018-07-15T19:36:16.949Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/11469
[2018-07-15T19:36:36.074Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/11391
[2018-07-15T20:31:19.679Z] <589b9e0fd73408ce4f490ba4> Anyone interested in a reviewing a PR on PyPy support ?  https://github.com/scikit-learn/scikit-learn/pull/11010 it's mostly a CI setup + very light changes to make tests pass .. Maybe @lesteve ? :)
[2018-07-15T20:37:27.668Z] <54d4a1d6db8155e6700f853b> I gave my +1
[2018-07-15T21:01:11.389Z] <54d4a1d6db8155e6700f853b> FYI I disabled the lgtm webhook (or tried to?) because it's confusing for the sprinters
[2018-07-15T21:14:55.163Z] <55d21ee30fc9f982beadabb8> Any additional review on the MissingIndicator is welcomed
[2018-07-15T21:14:55.570Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/8075
[2018-07-15T21:31:34.267Z] <55d21ee30fc9f982beadabb8> Anybody can review this one 
[2018-07-15T21:31:34.662Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/9616
[2018-07-15T21:33:46.306Z] <54d4a1d6db8155e6700f853b> does anyone know what happened here? https://github.com/scikit-learn/scikit-learn/pull/11504
[2018-07-15T21:33:56.279Z] <54d4a1d6db8155e6700f853b> there's something funky going on with the pooling_func deprecation
[2018-07-15T21:39:03.447Z] <5b4a4873d73408ce4fa0e326> @amueller 
[2018-07-15T21:39:44.530Z] <5b4a4873d73408ce4fa0e326> @amueller  When I post a future warning, am I to assume we are  currently on version 0.20 of sci-kit learn?
[2018-07-15T21:40:01.414Z] <55d21ee30fc9f982beadabb8> @annaayzenshtat right
[2018-07-15T21:40:07.264Z] <5b4a4873d73408ce4fa0e326> ok, thanks!
[2018-07-15T21:41:15.172Z] <55d21ee30fc9f982beadabb8> @amueller It seems it was done on purpose
[2018-07-15T21:41:16.042Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/commit/b4561f09e6e0ff8a2e16f09be21b3202012bbdd7
[2018-07-15T21:41:36.975Z] <54d4a1d6db8155e6700f853b> fixed in #11537
[2018-07-15T21:41:57.081Z] <54d4a1d6db8155e6700f853b> it's unused in agglomerative clustering but not feature agglomeration which inherits the fit...
[2018-07-15T21:42:16.494Z] <55d21ee30fc9f982beadabb8> oh right
[2018-07-15T21:44:18.162Z] <54d4a1d6db8155e6700f853b> (and that's why I don't want deprecation warnings in the examples and tests ;)
[2018-07-15T21:57:41.102Z] <5b4a4873d73408ce4fa0e326> @amueller  When I do a pull request, should it be against the master branch?
[2018-07-15T21:58:01.003Z] <55d21ee30fc9f982beadabb8> It should be against master
[2018-07-15T21:58:39.684Z] <5b4a4873d73408ce4fa0e326> thanks!
[2018-07-16T10:02:51.561Z] <54e07d0815522ed4b3dc0850> An update from Paris: we have a dozen of people working on a variety of small issues or reviewing (they have marked the issues that they are working on).
[2018-07-16T10:03:09.798Z] <54e07d0815522ed4b3dc0850> I think that some of us are going to prioritize issues needed for the release.
[2018-07-16T13:01:50.939Z] <55d21ee30fc9f982beadabb8> great
[2018-07-16T13:02:05.446Z] <55d21ee30fc9f982beadabb8> we will in the office in 30 minutes or so ready to light up
[2018-07-16T13:03:49.801Z] <54e07d0815522ed4b3dc0850> Awesome. I am busy finishing details on small PRs that are important for the release.
[2018-07-16T13:05:18.177Z] <54e07d0815522ed4b3dc0850> I would like to move a bunch of issues to the next milestone. I think that we should not delay the release. If needed, we can discuss this quickly.
[2018-07-16T13:15:54.228Z] <53232ac75e986b0712efe3af> it will not be in 30 min, Guillaume was a bit optimistic :)
[2018-07-16T13:26:21.850Z] <54e07d0815522ed4b3dc0850> It's good to be optimistic!
[2018-07-16T13:38:03.020Z] <54e07d1515522ed4b3dc0852> anyone looking for a simple issue that is pure doc: https://github.com/scikit-learn/scikit-learn/issues/9196
[2018-07-16T14:24:44.686Z] <560313510fc9f982beb1a331> Anyone able to review a small PR using BLAS? ( https://github.com/scikit-learn/scikit-learn/pull/11420 )
[2018-07-16T14:41:30.290Z] <55d21ee30fc9f982beadabb8> but we eventually got in the office now
[2018-07-16T14:49:16.543Z] <54e07d0815522ed4b3dc0850> OK. Looking at the list of issues for the next release: https://github.com/scikit-learn/scikit-learn/milestone/24, I would like to postpone a few. Things like #11520 , #8642, #9098. My goal is to move us forward to the release.
[2018-07-16T14:49:24.926Z] <54e07d0815522ed4b3dc0850> Any objections?
[2018-07-16T14:49:58.192Z] <54d4a1d6db8155e6700f853b> I don't want to postpone the Yeo-Johnson because it will be the default for PowerTransform
[2018-07-16T14:50:10.701Z] <54e07d0815522ed4b3dc0850> Also, #11408 needs a review. It fixes one of the problems of the build
[2018-07-16T14:50:56.571Z] <54d4a1d6db8155e6700f853b> basically if we don't do #11520 then we'll release with power transform only working on non-negative data and we need a deprecation cycle to change the default to yeo-johnson
[2018-07-16T14:51:23.364Z] <54e07d0815522ed4b3dc0850> @amueller : OK, but this list is too long. We are going to have to make choices. The delay in the release is not good for our users. I am happy focusing on things to get them done (including #11520), but we will not be able to address all this.
[2018-07-16T14:51:29.868Z] <54d4a1d6db8155e6700f853b> I'm also untagging some things right now, and tagging other things as blockers
[2018-07-16T14:51:41.964Z] <54d4a1d6db8155e6700f853b> yes I know it is
[2018-07-16T14:51:55.835Z] <54d4a1d6db8155e6700f853b> I think joris is creating a github project board right now
[2018-07-16T14:53:09.517Z] <54e07d0815522ed4b3dc0850> Great. I'll have a look at #11520 right now
[2018-07-16T14:54:31.923Z] <5b3cc3c9d73408ce4f9f9bf8> Hi . please help me about visualization of SVM, cross validation and its performance measures
[2018-07-16T14:57:55.038Z] <54d4a1d6db8155e6700f853b> what' about #9723 ?
[2018-07-16T15:00:13.299Z] <55d21ee30fc9f982beadabb8> If we consider it as a bug fix then this is ready to be merged.
[2018-07-16T15:00:21.656Z] <55d21ee30fc9f982beadabb8> I really think that it was actually a bug
[2018-07-16T15:00:47.959Z] <54d4a1d6db8155e6700f853b> yeah looks like it from a glance
[2018-07-16T15:01:09.146Z] <54d4a1d6db8155e6700f853b> @GaelVaroquaux I kinda wanted estimator tags in, but I guess we might not be able to do that :-/
[2018-07-16T15:01:53.654Z] <54d4a1d6db8155e6700f853b> KMedoids? #11099  I'd say delay
[2018-07-16T15:02:14.585Z] <54d4a1d6db8155e6700f853b> #10058 NCA I'd say delay as well
[2018-07-16T15:05:34.585Z] <54e07d0815522ed4b3dc0850> I do think that NCA is delayed :(
[2018-07-16T15:06:02.531Z] <55d21ee30fc9f982beadabb8> we need a second review on https://github.com/scikit-learn/scikit-learn/pull/11464
[2018-07-16T15:07:21.074Z] <54d4a1d6db8155e6700f853b> ok most PRs that are tagged either are small and have +1 or are bug fixes or blockers
[2018-07-16T15:09:52.297Z] <54d4a1d6db8155e6700f853b> ok apart from KMedoids I think tagged PRs are relatively reasonable right now
[2018-07-16T15:10:00.840Z] <54d4a1d6db8155e6700f853b> anyone have oppinions on KMedoids?
[2018-07-16T15:11:22.212Z] <54e07d0815522ed4b3dc0850> I think that we should delay KMedoids
[2018-07-16T15:11:36.330Z] <54e07d0815522ed4b3dc0850> It would be good to have it, but this release is already a big one
[2018-07-16T15:16:27.124Z] <55d21ee30fc9f982beadabb8> We also need to fix the MICE/ChainedImputer/IterativeImputer
[2018-07-16T15:16:27.804Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/11350
[2018-07-16T15:17:01.151Z] <55d21ee30fc9f982beadabb8> basically the remaining question would be link to the default imputer to use (RidgeCV or RandomForest)
[2018-07-16T15:28:13.463Z] <54e07d0815522ed4b3dc0850> I commented on this choice directly in the PR, to keep the discussion on github.
[2018-07-16T16:07:56.160Z] <54d4a1d6db8155e6700f853b> @GaelVaroquaux do you have opinions on https://github.com/scikit-learn/scikit-learn/issues/11536 ?
[2018-07-16T16:08:07.486Z] <54d4a1d6db8155e6700f853b> there is tons of convergence warnings everywhere currently
[2018-07-16T16:08:57.870Z] <54d4a1d6db8155e6700f853b> also, the examples and tests have tons of warnings about iid. Should we do something about that? not sure if it's worth in the examples, in the test we should probably catch
[2018-07-16T16:09:44.207Z] <54d4a1d6db8155e6700f853b> @ogrisel also would love to hear your thoughts on https://github.com/scikit-learn/scikit-learn/issues/11536
[2018-07-16T16:26:17.982Z] <54e07d0815522ed4b3dc0850> @amueller is adding issues to the milestone faster than we can close them :)
[2018-07-16T16:26:48.898Z] <54d4a1d6db8155e6700f853b> @GaelVaroquaux sorry :-/ only thing that I'm noticing now that we broke
[2018-07-16T16:55:04.300Z] <54e07d0815522ed4b3dc0850> Yes, but it's quite depressing to see the percentage going down as we work. I really worry about feature creep. I was expecting this release to be out a couple months ago.
[2018-07-16T16:55:43.489Z] <54d4a1d6db8155e6700f853b> what feature creep? you mean scope of sklearn or scope of this release?
[2018-07-16T16:56:05.666Z] <54d4a1d6db8155e6700f853b> I'm just going through examples and dogfooding all the changes we did and make sure the user experience is sane
[2018-07-16T16:57:26.414Z] <54d4a1d6db8155e6700f853b> like the iid change can easily lead to a wall of deprecations. I guess the user can always catch them...
[2018-07-16T16:57:37.399Z] <589b9e0fd73408ce4f490ba4> Opinions of what should be done about the blocking  euclidean_distance in 32 bit issue would be welcome https://github.com/scikit-learn/scikit-learn/issues/9354#issuecomment-405314164 
[2018-07-16T17:26:36.759Z] <54d4a1d6db8155e6700f853b> this is ready for reviews: https://github.com/scikit-learn/scikit-learn/pull/11561
[2018-07-16T17:30:17.825Z] <55d21ee30fc9f982beadabb8> This could be merged (MRG+2): https://github.com/scikit-learn/scikit-learn/pull/9616
[2018-07-16T17:34:23.366Z] <54d4a1d6db8155e6700f853b> I was trying to press the green button on #9616 but got many unicorns
[2018-07-16T17:34:59.383Z] <55d21ee30fc9f982beadabb8> what is #9616
[2018-07-16T17:35:10.366Z] <55d21ee30fc9f982beadabb8> because gitter says that it is not found
[2018-07-16T18:03:49.652Z] <54e07d0815522ed4b3dc0850> OK, we are wrapping up here in Paris. I am signing off, as I have "real work" to do for tonight. Sorry
[2018-07-16T19:14:37.136Z] <54d4a1d6db8155e6700f853b> thanks!
[2018-07-16T19:15:00.066Z] <54d4a1d6db8155e6700f853b> @glemaitre the one you just posted lol
[2018-07-16T19:18:38.496Z] <547d8325db8155e6700da60b> @amueller https://hub.github.com/
[2018-07-16T19:18:58.806Z] <5571fe1015522ed4b3e17d90> or this without dependencies: git push https://github.com/lmcinnes/scikit-learn pr/8554:sparse-LLE-Isomap -f
[2018-07-16T19:20:05.522Z] <55d21ee30fc9f982beadabb8> @amueller You seem to be interested in merging this one since the test are passing
[2018-07-16T19:20:05.783Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/8075
[2018-07-16T19:23:17.991Z] <54d4a1d6db8155e6700f853b> what about https://github.com/scikit-learn/scikit-learn/pull/8760 ?
[2018-07-16T19:23:20.788Z] <54d4a1d6db8155e6700f853b> anyone working on that?
[2018-07-16T19:23:23.689Z] <54d4a1d6db8155e6700f853b> is that a regression?
[2018-07-16T19:41:35.283Z] <5a83f33dd73408ce4f8d133f> I'm working on it (PR related to issue #8720 which I commented)
[2018-07-16T19:44:26.776Z] <54d4a1d6db8155e6700f853b> @rth do you wanna review the openml loader? #11419 ?
[2018-07-16T19:47:35.629Z] <54d4a1d6db8155e6700f853b> anyone else have a quick review for #11561 ?
[2018-07-16T19:47:58.126Z] <55d21ee30fc9f982beadabb8> I'll do that while waiting for some benchmark
[2018-07-16T19:48:05.879Z] <54d4a1d6db8155e6700f853b> thanks :)
[2018-07-16T19:49:43.489Z] <54d4a1d6db8155e6700f853b> this is related but not the consistency: #6425
[2018-07-16T19:50:13.470Z] <54d4a1d6db8155e6700f853b> this is the actual issue #7242
[2018-07-16T19:54:09.681Z] <54e07d0815522ed4b3dc0850> @amueller : feature creep = scope of release. Not scope of scikit-learn. I think that we are doing good on this.
[2018-07-16T19:54:30.382Z] <54d4a1d6db8155e6700f853b> ok
[2018-07-16T19:54:44.567Z] <53232ac75e986b0712efe3af> @amueller https://github.com/scikit-learn/scikit-learn/pull/10198 (OneHotEncoder.get_feature_names, was not tagged apparently)
[2018-07-16T19:56:50.826Z] <54d4a1d6db8155e6700f853b> someone look at #11567 ? ;)
[2018-07-16T19:57:08.941Z] <54d4a1d6db8155e6700f853b> (still opening issues and PRs quicker than people can close them)
[2018-07-16T20:23:52.345Z] <54e07d0815522ed4b3dc0850> Hey Austin, while both y'all and we all are awake, how about we schedule a hangout for tomorrow
[2018-07-16T20:23:57.293Z] <54e07d0815522ed4b3dc0850> I miss you all!
[2018-07-16T20:24:23.182Z] <541a528b163965c9bc2053de> Alright, which time would be fine with you?
[2018-07-16T20:57:26.699Z] <54d4a1d6db8155e6700f853b> jan: https://github.com/scikit-learn/scikit-learn/pull/11570
[2018-07-16T21:10:45.195Z] <55d21ee30fc9f982beadabb8> @rth https://github.com/scikit-learn/scikit-learn/pull/11561 merge this since your comments have been addressd
[2018-07-16T21:21:55.449Z] <54d4a1d6db8155e6700f853b> @rth do you know about this? 11572
[2018-07-16T21:21:57.222Z] <54d4a1d6db8155e6700f853b> #11572
[2018-07-16T21:22:07.097Z] <54d4a1d6db8155e6700f853b> it's about AUC reorder
[2018-07-16T21:47:42.504Z] <547d8325db8155e6700da60b> @amueller https://github.com/scikit-learn/scikit-learn/pull/10495/files
[2018-07-16T21:52:27.980Z] <54d4a1d6db8155e6700f853b> can someone change the working in https://github.com/scikit-learn/scikit-learn/pull/10495 from interpret to convert?
[2018-07-16T22:04:21.858Z] <547d8325db8155e6700da60b> I'll do a PR, rewording it
[2018-07-16T22:11:30.430Z] <55d21ee30fc9f982beadabb8> Second review needed on the SimpleImputer which was buggy for sparse matrix
[2018-07-16T22:11:30.955Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/11496
[2018-07-17T05:27:48.796Z] <54e07d0815522ed4b3dc0850> Sorry, I missed the reply about the hangout. Let's do it when you guys are up, and maybe an hour or so after you have started. That gives you time to get organized.
[2018-07-17T12:57:22.454Z] <54e07d0815522ed4b3dc0850> https://github.com/scikit-learn/scikit-learn/issues/11536 is blocker and needs a discussion
[2018-07-17T13:43:33.601Z] <5a280cdcd73408ce4f820b9c> scikit-learn/scikit-learn#11557 ready for review
[2018-07-17T14:16:16.663Z] <547d8325db8155e6700da60b> @amueller #11577
[2018-07-17T14:40:41.991Z] <589b9e0fd73408ce4f490ba4> @ogrisel  could you have a look at a small BLAS related change in https://github.com/scikit-learn/scikit-learn/pull/11420 by @jakirkham Thanks.
[2018-07-17T14:54:04.399Z] <54d4a1d6db8155e6700f853b> quick reviews on #11593 please?
[2018-07-17T14:54:35.029Z] <53232ac75e986b0712efe3af> @amueller https://github.com/scikit-learn/scikit-learn/pull/11592
[2018-07-17T15:09:14.507Z] <547d8325db8155e6700da60b> @amueller  maybe you can merge #11124
[2018-07-17T15:12:30.384Z] <547d8325db8155e6700da60b> (or anyone who can click the green button !0
[2018-07-17T15:12:31.544Z] <547d8325db8155e6700da60b> )
[2018-07-17T15:13:32.534Z] <54e07d1515522ed4b3dc0852> review https://github.com/scikit-learn/scikit-learn/pull/11535 ?
[2018-07-17T15:13:57.849Z] <54e07d0815522ed4b3dc0850> @massich : done for #11124
[2018-07-17T15:15:50.334Z] <54e07d0815522ed4b3dc0850> @agramfort : done
[2018-07-17T15:15:58.698Z] <5b4c47d0d73408ce4fa101b0> @GaelVaroquaux can you have a look at #11589 ?
[2018-07-17T15:17:30.175Z] <54e07d0815522ed4b3dc0850> The travis backlog is starting to be a major problem. Does someone have a contact at travis to ask them if they could bump our plan for the day?
[2018-07-17T15:17:35.655Z] <54e07d0815522ed4b3dc0850> @jbschiratti : on it
[2018-07-17T15:17:59.109Z] <547d8325db8155e6700da60b> Can I get comments in #11563 maybe it can be merged without CI
[2018-07-17T15:18:07.396Z] <54d4a1d6db8155e6700f853b> I don't have a contact. I had talked to them in the past, sometimes it works. You're in the same time zone as them @GaelVaroquaux ;)
[2018-07-17T15:23:22.013Z] <54d4a1d6db8155e6700f853b> btw I think https://github.com/scikit-learn/scikit-learn/pull/11570 should basically be good t ogo
[2018-07-17T15:25:40.562Z] <54d4a1d6db8155e6700f853b> @GaelVaroquaux are you contacting travis?
[2018-07-17T15:35:24.498Z] <54e07d0815522ed4b3dc0850> What contact should I use?
[2018-07-17T15:35:28.656Z] <54e07d0815522ed4b3dc0850> For travis?
[2018-07-17T15:39:07.252Z] <55d21ee30fc9f982beadabb8> By the way I'll like to have discussion regarding Stacking and the issue of fit.transform != fit_transform such that we can unlock the PR
[2018-07-17T15:39:17.987Z] <55d21ee30fc9f982beadabb8> I know this is not for the coming release thought
[2018-07-17T15:39:35.315Z] <54d4a1d6db8155e6700f853b> they have an email thing on the website @GaelVaroquaux 
[2018-07-17T15:39:55.694Z] <54d4a1d6db8155e6700f853b> support@travis-ci.com
[2018-07-17T15:40:01.410Z] <54e07d0815522ed4b3dc0850> If we want to do a hangout, it's in the next hour or so.
[2018-07-17T15:40:32.868Z] <54e07d0815522ed4b3dc0850> @amueller : on it
[2018-07-17T15:40:42.882Z] <54d4a1d6db8155e6700f853b> are there particular topics for the hangout? the stacking fit_transform? pandas column names? the governance doc?
[2018-07-17T15:41:34.880Z] <54e07d0815522ed4b3dc0850> All these seem important
[2018-07-17T15:44:00.868Z] <54e07d0815522ed4b3dc0850> Done for travis. We'll see what they reply
[2018-07-17T15:53:37.822Z] <54d4a1d6db8155e6700f853b> whether we should backport estimator-tags to the RC branch if I can finish it within a week lol ;)
[2018-07-17T15:53:41.426Z] <54d4a1d6db8155e6700f853b> (semi-kidding)
[2018-07-17T15:53:46.654Z] <54d4a1d6db8155e6700f853b> should we do the call?
[2018-07-17T16:03:05.834Z] <54e07d0815522ed4b3dc0850> Good with the call.
[2018-07-17T16:03:15.573Z] <54e07d0815522ed4b3dc0850> Do you want to call me
[2018-07-17T16:04:05.630Z] <54e07d0815522ed4b3dc0850> When you do, I'll run in the room next door, and whoever wants will join me
[2018-07-17T16:05:35.901Z] <541a528b163965c9bc2053de> I'll try to call you.
[2018-07-17T16:37:48.261Z] <541a528b163965c9bc2053de> we can call you by phone on a free mobile
[2018-07-17T16:39:17.865Z] <54d4a1d6db8155e6700f853b> well but this sounds like we need a slep
[2018-07-17T16:39:30.996Z] <54d4a1d6db8155e6700f853b> so the outcome of this discussion is: we disagree so far
[2018-07-17T16:39:40.048Z] <54d4a1d6db8155e6700f853b> I'll write a slep, we can discuss it and we can vote
[2018-07-17T16:52:33.273Z] <560313510fc9f982beb1a331> > The travis backlog is starting to be a major problem.  There is an auto-cancellation feature for PRs with outdated commits  ref: https://blog.travis-ci.com/2017-03-22-introducing-auto-cancellation
[2018-07-17T16:53:18.814Z] <560313510fc9f982beb1a331> There's a similar feature for PRs on AppVeyor
[2018-07-17T16:53:22.915Z] <560313510fc9f982beb1a331> HTH
[2018-07-17T16:53:23.147Z] <55d21ee30fc9f982beadabb8> I think that we have that 
[2018-07-17T16:53:30.036Z] <55d21ee30fc9f982beadabb8> activated 
[2018-07-17T16:55:43.105Z] <589b9e0fd73408ce4f490ba4> yes, both in Travis and AppVeyor, but not circle ci..
[2018-07-17T16:56:02.266Z] <55d21ee30fc9f982beadabb8> @amueller The PR regarding the n_estimators=100 in Forest is ready for review
[2018-07-17T16:56:02.901Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/11542
[2018-07-17T16:59:34.056Z] <53232ac75e986b0712efe3af> @GaelVaroquaux and other people there: are you OK with switching the default in `ColumnTransformer` from `remainder='passthrough'` to `remainder='drop'` ?
[2018-07-17T17:01:12.461Z] <541a528b163965c9bc2053de> The motivation is that silently passing through uniquely identifying columns (e.g. a user id) will lead to catastrophic  overfitting that beginner users will have a hard time to debug.
[2018-07-17T17:01:30.787Z] <54d4a1d6db8155e6700f853b> also changing the mode of one-hot-encoder to sparse=False in the "new mode"
[2018-07-17T17:02:03.436Z] <541a528b163965c9bc2053de> Furthermore, it would also make most of our examples a bit more concise. 
[2018-07-17T17:03:05.219Z] <5b4e20f7d73408ce4fa13b54> appveyor is failing very quickly (less than 1min) for a lot of PRs 
[2018-07-17T17:07:05.200Z] <560313510fc9f982beb1a331> We have a script for fast cancelling old builds in c-f. Here's a [usage example]( https://github.com/conda-forge/numpy-feedstock/blob/0d8089f7d346fabaa8bf1ea948d89a9c42e9f9c8/.circleci/fast_finish_ci_pr_build.sh#L3-L4 ). This works on Travis CI, AppVeyor, and CircleCI as long as the proper environment variables are supplied  ref: https://github.com/conda-forge/conda-forge-ci-setup-feedstock/blob/master/recipe/ff_ci_pr_build.py
[2018-07-17T17:14:45.505Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/11583
[2018-07-17T17:17:51.176Z] <5a280cdcd73408ce4f820b9c> scikit-learn/scikit-learn#11585 on sparse PCA needs review
[2018-07-17T17:18:14.821Z] <55d21ee30fc9f982beadabb8> I will look at it now
[2018-07-17T17:20:03.513Z] <547d8325db8155e6700da60b> https://github.com/scikit-learn/scikit-learn/pull/11599
[2018-07-17T17:22:14.807Z] <589b9e0fd73408ce4f490ba4> Thanks @jakirkham , that's very useful. I'll look into it.
[2018-07-17T17:24:50.047Z] <547d8325db8155e6700da60b> here's how appveyor kills all but last commit https://github.com/conda-forge/staged-recipes/blob/master/.appveyor.yml#L19-L23
[2018-07-17T17:26:08.635Z] <547d8325db8155e6700da60b> https://github.com/conda-forge/staged-recipes/blob/master/.circleci/fast_finish_ci_pr_build.sh
[2018-07-17T17:26:15.887Z] <547d8325db8155e6700da60b> here's for CircleCI
[2018-07-17T17:33:27.393Z] <5a83f33dd73408ce4f8d133f> https://github.com/scikit-learn/scikit-learn/pull/11526 is also ready for a last review/merge
[2018-07-17T17:40:15.316Z] <54e07d0815522ed4b3dc0850> Travis bumped our resources!!
[2018-07-17T17:40:17.557Z] <54e07d0815522ed4b3dc0850> They rock
[2018-07-17T17:40:25.586Z] <54e07d0815522ed4b3dc0850> We'll need to thank them
[2018-07-17T18:15:23.081Z] <5a280cdcd73408ce4f820b9c> I'm off until tomorrow guys.  You can have a look at scikit-learn/scikit-learn#11596 and continue if you wanna merge quickly.
[2018-07-17T18:26:40.645Z] <54e07d0815522ed4b3dc0850> Hey, does anybody understand what the problem is on appveyor: https://ci.appveyor.com/project/sklearn-ci/scikit-learn/build/1.0.23610/job/fab9oqavus2wy8sa ?
[2018-07-17T18:26:59.389Z] <54e07d0815522ed4b3dc0850> It's happening on several PR. I don't love the smell of it.
[2018-07-17T18:48:46.548Z] <5a83f33dd73408ce4f8d133f> https://github.com/scikit-learn/scikit-learn/pull/11578 is almost green on tests, ready for a second review
[2018-07-17T19:00:12.064Z] <54d4a1d6db8155e6700f853b> looks like travis bumped up to 10 according to @jorisvandenbossche 
[2018-07-17T19:02:28.762Z] <54d4a1d6db8155e6700f853b> @GaelVaroquaux did you tweet about it?
[2018-07-17T19:02:39.209Z] <54d4a1d6db8155e6700f853b> we should also tweet to enthought maybe?
[2018-07-17T19:03:11.802Z] <54e07d0815522ed4b3dc0850> Yes, travis did bump up to 10.
[2018-07-17T19:03:17.896Z] <54e07d0815522ed4b3dc0850> It makes a big different
[2018-07-17T19:04:10.607Z] <54e07d0815522ed4b3dc0850> I didn't tweet, but I'll thank them in the blog post
[2018-07-17T19:05:50.930Z] <54d4a1d6db8155e6700f853b> can someone riddle me this? https://github.com/scikit-learn/scikit-learn/pull/11542
[2018-07-17T19:06:17.481Z] <54d4a1d6db8155e6700f853b> SAG test failure on python2.7 in the n_estimators=100 branch?!
[2018-07-17T19:06:44.006Z] <5571fe1015522ed4b3e17d90> No idea about the AppVeyor problem but it does seem to happen quite often.
[2018-07-17T19:06:56.366Z] <541a528b163965c9bc2053de> @GaelVaroquaux the appveyor issue is recent. One possibility might be that have changed something in their API and that breaks and that broke our trick to automatically cancel / skip builds on PRs that have received new push events in the mean time. 
[2018-07-17T19:08:12.698Z] <54e07d0815522ed4b3dc0850> OK, but it's a random failure?
[2018-07-17T19:08:31.420Z] <54e07d0815522ed4b3dc0850> I'll merge the PRs despite of it.
[2018-07-17T19:08:58.340Z] <54d4a1d6db8155e6700f853b> @GaelVaroquaux you mean the appveyor, not the tranvis I mentioned, right?
[2018-07-17T19:09:07.139Z] <541a528b163965c9bc2053de> I don't know if it's random with a very high likelihood or if it's a deterministic failure. It might be a temporary outage.
[2018-07-17T19:09:29.817Z] <54e07d0815522ed4b3dc0850> Yes, I mean appveor
[2018-07-17T19:11:56.049Z] <54d4a1d6db8155e6700f853b> ok cool
[2018-07-17T19:12:10.264Z] <55d21ee30fc9f982beadabb8> Somebody to open the door of Enthought ;)
[2018-07-17T19:12:48.585Z] <5571fe1015522ed4b3e17d90> I have AppVeyor enabled in my fork and I have some green builds recently: https://ci.appveyor.com/project/lesteve/scikit-learn/history 
[2018-07-17T19:13:36.265Z] <5571fe1015522ed4b3e17d90> This could well be the HTTP request we use which is problematic.
[2018-07-17T19:18:35.559Z] <5571fe1015522ed4b3e17d90> I'll look at the AppVeyor problem more in details.
[2018-07-17T19:22:41.995Z] <54e07d0815522ed4b3dc0850> Thanks Loic!
[2018-07-17T19:30:05.439Z] <54d4a1d6db8155e6700f853b> my current reading is that we shouldn't have done the error_score deprecation in ``_fit_and_score`` but in BaseSearchCV. But it depends on what we want to do in learning_curve, cross_validate and cross_val_score (and other places I haven't thought of)
[2018-07-17T19:30:15.937Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/issues/11576
[2018-07-17T19:51:41.633Z] <53232ac75e986b0712efe3af> @amueller column transformer remainder change: https://github.com/scikit-learn/scikit-learn/pull/11603
[2018-07-17T19:52:52.588Z] <547d8325db8155e6700da60b> https://github.com/scikit-learn/scikit-learn/pull/11604
[2018-07-17T19:52:58.636Z] <547d8325db8155e6700da60b> try to fix appveyor !
[2018-07-17T20:13:21.932Z] <547d8325db8155e6700da60b> @amueller https://github.com/scikit-learn/scikit-learn/pull/11570/files#r203161922
[2018-07-17T20:34:49.254Z] <54d4a1d6db8155e6700f853b> so @rth made the good point that the deprecation warning thing should be removed in the release
[2018-07-17T20:40:09.177Z] <5a83f33dd73408ce4f8d133f> my PR is green now if someones wants to be the 2nd reviewer: https://github.com/scikit-learn/scikit-learn/pull/11578
[2018-07-17T20:44:09.561Z] <5571fe1015522ed4b3e17d90> We looked at AppVeyor with Sik. There is a work-around in master and all the current running AppVeyor builds have been killed. Just push a new commit in your branch if you want AppVeyor to run again or ask me while I have a sklearn-ci tab opened.
[2018-07-17T20:53:50.179Z] <541a528b163965c9bc2053de> I will also cancel all the circle ci builds as the queue is far too long. We can restart new builds on new PR (preferably recently opened ones, or those with a recent master merge commit).
[2018-07-17T22:01:54.737Z] <547d8325db8155e6700da60b> any comments here https://github.com/scikit-learn/scikit-learn/pull/11213
[2018-07-17T22:01:55.876Z] <547d8325db8155e6700da60b> ??
[2018-07-17T22:06:59.232Z] <547d8325db8155e6700da60b> @lesteve https://github.com/scikit-learn/scikit-learn/pull/11213
[2018-07-17T22:08:50.603Z] <547d8325db8155e6700da60b> sorry https://github.com/scikit-learn/scikit-learn/pull/11552
[2018-07-17T22:42:24.503Z] <547d8325db8155e6700da60b> @lesteve https://github.com/scikit-learn/scikit-learn/pull/11563
[2018-07-18T05:15:22.069Z] <54e07d0815522ed4b3dc0850> Hum, CI is a bit in a mess. There is going to be some work there
[2018-07-18T05:23:45.008Z] <589b9e0fd73408ce4f490ba4> In the lastest commit on master there is just 1 test failing in one build.  Attempting to fix that in https://github.com/scikit-learn/scikit-learn/pull/11617 Appveyor and Circle CI should be hopefully OK, the issue is mostly a very long queue.. 
[2018-07-18T05:32:18.184Z] <54e07d0815522ed4b3dc0850> Great! I was about to look at this face issue! Thanks!
[2018-07-18T05:35:19.436Z] <54e07d0815522ed4b3dc0850> OK, @rth: I reviewed it. Travis will be done with it in 20mn. It needs a second review
[2018-07-18T05:54:56.491Z] <54e07d0815522ed4b3dc0850>  scikit-learn/scikit-learn#11617  is green and needs a second review
[2018-07-18T06:09:11.567Z] <5571fe1015522ed4b3e17d90> Travis is green in master :fireworks: !
[2018-07-18T06:09:37.096Z] <5571fe1015522ed4b3e17d90> https://travis-ci.org/scikit-learn/scikit-learn/builds/405208107
[2018-07-18T17:45:13.517Z] <54e07d0815522ed4b3dc0850> It seems that travis is failing again on one of the configuration. I have made a PR that should fix that: https://github.com/scikit-learn/scikit-learn/pull/11625
[2018-07-18T17:54:57.660Z] <54e07d0815522ed4b3dc0850> It fixes travis indeed. It would be good to have reviews +merge, as many PRs are red because of this small issue
[2018-07-18T18:42:51.032Z] <54e07d0815522ed4b3dc0850> OK, I now realize that it was fixed in the mean time by downgrading the joblib requirement on travis :). Still good to have!
[2018-07-19T06:24:40.818Z] <56a5a8fce610378809be08d1> Hi, is it possible to use different distance metrics for `kmeans`? I noticed that `cosine` and `manhattan` are already implemented in `metrics/pairwise.py`.  Is there any quick dirty way to somehow specify these metrics instead of euclidean distance for `kmeans`?  
[2018-07-19T20:08:30.972Z] <560313510fc9f982beb1a331> Is there a way to check what BLAS scikit-learn is built with? Maybe like an info function or something?
[2018-07-19T20:08:55.587Z] <54d4a1d6db8155e6700f853b> @jakirkham there's a pr for that ;)
[2018-07-19T20:09:07.197Z] <54d4a1d6db8155e6700f853b> but it's whatever numpy is build with, I think
[2018-07-19T20:09:10.474Z] <560313510fc9f982beb1a331> Really, where's that :)
[2018-07-19T20:09:47.057Z] <54d4a1d6db8155e6700f853b> #11596
[2018-07-19T20:09:49.376Z] <54d4a1d6db8155e6700f853b> merged actually!
[2018-07-19T20:09:55.304Z] <54d4a1d6db8155e6700f853b> so you have it in master
[2018-07-19T20:10:02.480Z] <560313510fc9f982beb1a331> :tada: 
[2018-07-19T20:10:09.911Z] <560313510fc9f982beb1a331> Thank you
[2018-07-19T20:13:09.584Z] <560313510fc9f982beb1a331> If it says `cblas`, does that mean scikit-learn's internal BLAS?
[2018-07-19T20:25:17.952Z] <54d4a1d6db8155e6700f853b> I think we stopped shipping blas, didn't we?
[2018-07-19T20:33:08.716Z] <5b4c9e4bd73408ce4fa10b88> @amueller  not merged yet :)
[2018-07-19T21:25:08.015Z] <5a280cdcd73408ce4f820b9c> @jakirkham the method you are looking for is `sklearn._build_utils.get_blas_info()`
[2018-07-19T21:59:34.052Z] <560313510fc9f982beb1a331> Great thanks!
[2018-07-22T06:59:26.474Z] <58d1e48dd73408ce4f52af1b> Hello - for BallTree can I use a user defined metric as great circle distance calculated from PyProj ? I believe the answer is YES but just confirming it here on gitter
[2018-07-22T07:02:51.240Z] <58d1e48dd73408ce4f52af1b> as shown in this SO answer - https://stackoverflow.com/questions/21052509/sklearn-knn-usage-with-a-user-defined-metric
[2018-07-23T06:42:54.419Z] <541a528b163965c9bc2053de> We still ship a bunch of cblas and actually use it in the windows and linux wheels. The easiest way to get rid of that would be to use scipy cython BLAS functions API but this won't be possible before we bump up the dependencies.
[2018-07-23T17:10:19.032Z] <560313510fc9f982beb1a331> Sounds like issue ( https://github.com/scikit-learn/scikit-learn/issues/11638 ) :wink:
[2018-07-23T19:16:08.941Z] <59cbaaecd73408ce4f779597> Hello peoplw
[2018-07-23T19:17:55.936Z] <59cbaaecd73408ce4f779597> I want to begin with scikit, how should I begin ?
[2018-07-23T19:17:59.053Z] <59cbaaecd73408ce4f779597> Please suggest
[2018-07-23T19:18:22.269Z] <54d4a1d6db8155e6700f853b> @geekyharshal https://jakevdp.github.io/PythonDataScienceHandbook/
[2018-07-23T22:19:59.130Z] <5a2c58c8d73408ce4f8294ba> Hey guys, are there any prebuild Docker images to work with sagemaker for sklearn? They support Apache MXNet or TensorFlow directly but not sklearn. https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb
[2018-07-23T22:25:25.582Z] <5a2c58c8d73408ce4f8294ba> This is an option if not https://github.com/jupyter/repo2docker
[2018-07-24T11:58:45.179Z] <54d4a1d6db8155e6700f853b> that example shows you what to do, doesn't it?
[2018-07-24T11:58:52.776Z] <54d4a1d6db8155e6700f853b> Don't think anyone here has used sagemaker
[2018-07-24T17:55:15.890Z] <5a2c58c8d73408ce4f8294ba> I can build it myself but its more a question of if there are standard images. Maybe this is more or a conda question since it is about making a consistent collection of packages. 
[2018-07-24T17:57:32.696Z] <5a2c58c8d73408ce4f8294ba> I would suggest you guys take a look at sagemaker. There are not any good exampke for scikit learn for the whole train test deploy. Would be good for adoption of sklearn. Althoughj, i am sure you have no shortage of projects
[2018-07-24T17:58:23.291Z] <54d4a1d6db8155e6700f853b> I was visiting the sagemaker team like a month ago
[2018-07-24T18:37:22.071Z] <5a2c58c8d73408ce4f8294ba> Cool. My team uses sklearn a lot and we are just getting started with sagemaker for deployment. We do everything locally now but will move to AWS for train and predict. We will try to come up with a good example for the deployment and maybe add it to their existing examples.
[2018-07-26T13:36:10.106Z] <5a5a272ad73408ce4f880912> Hello! My name is Tushar.  I recently finished a course on machine learning and now I'm making some projects. One of them is object classification, I have googled all I could.  The problem is, I am confused on how to preprocess the images to work. I have worked on text. Now I am having troubles with images. All the things  I saw were using deep learning and tensorFlow. Articles with sklearn were using the dataset already provided in datasets. And that wasn't helping. If anyone can guide me, I'd appreciate it. Thanks
[2018-07-27T03:34:49.799Z] <5a2c58c8d73408ce4f8294ba> Typically each pixel is encoded as rgb so 3 features per pixel. Sklearn can try to classify this with a number of algorithms but I suspect you will not get far. The pooling and covolutional layers in a NN are what gives the power for image classification. Sklearn does not have any NN beyond an MLP so you lose that ability. 
[2018-07-28T18:22:52.622Z] <5b52e812d73408ce4fa1c2c2> hey i am here to contibute pls assign me some task
[2018-07-28T19:41:25.047Z] <5a5a272ad73408ce4f880912> Thank you very much Keith!
[2018-07-28T19:42:14.401Z] <5a5a272ad73408ce4f880912> I actually finished a machine learning course and I'd like to make a few projects before I move on to deep learning and neural networks. 
[2018-07-29T05:35:45.245Z] <5a2c58c8d73408ce4f8294ba> Then don't do image recognition
[2018-07-29T18:21:29.367Z] <5a2c58c8d73408ce4f8294ba> @Ishaan28malik Tasks are more claimed than assigned. Go to the open issues on github and find one you can do. Ask if anybody is activly working on it. If not then you can give it a try
[2018-08-01T09:18:24.017Z] <58d1e48dd73408ce4f52af1b> Hello - are we allowed to put links to SO questions here ? 
[2018-08-01T09:19:03.668Z] <54d4a1d6db8155e6700f853b> @winash12 you can but I wouldn't encourage it, I guess?
[2018-08-01T09:19:15.590Z] <54d4a1d6db8155e6700f853b> Generally it's better to ask on stackoverflow
[2018-08-01T09:19:23.504Z] <58d1e48dd73408ce4f52af1b> @amueller  yes understood
[2018-08-01T09:19:30.133Z] <58d1e48dd73408ce4f52af1b> i had an issue with BallTree
[2018-08-01T09:19:45.917Z] <58d1e48dd73408ce4f52af1b> Can I ask here ?
[2018-08-01T09:19:48.689Z] <54d4a1d6db8155e6700f853b> I mean if you're about to ask the same question again then post the SO link ;)
[2018-08-01T09:20:10.787Z] <58d1e48dd73408ce4f52af1b> @amueller Ok then here you go - https://stackoverflow.com/questions/51627721/typeerror-with-scikit-learns-balltree
[2018-08-01T09:23:59.084Z] <54d4a1d6db8155e6700f853b> what's the type of bt.data ?
[2018-08-01T09:24:27.382Z] <54d4a1d6db8155e6700f853b> and what's the type of ``matches``?
[2018-08-01T09:25:31.536Z] <58d1e48dd73408ce4f52af1b> So like in scipy it must be the coordinates of point
[2018-08-01T09:25:40.205Z] <58d1e48dd73408ce4f52af1b> in this case x and y
[2018-08-01T09:26:07.455Z] <54d4a1d6db8155e6700f853b> no the type
[2018-08-01T09:26:13.649Z] <54d4a1d6db8155e6700f853b> type(bt.data), type(matches)
[2018-08-01T09:26:34.639Z] <58d1e48dd73408ce4f52af1b> hang on let me run my toy example
[2018-08-01T09:27:48.875Z] <54d4a1d6db8155e6700f853b> ok that's what I thought. bt.data is a memory view, the docs are wrong :-/
[2018-08-01T09:28:13.187Z] <58d1e48dd73408ce4f52af1b> type(matches) is a list
[2018-08-01T09:28:22.948Z] <54d4a1d6db8155e6700f853b> you can use "points" instead of "bt.data"
[2018-08-01T09:29:39.668Z] <58d1e48dd73408ce4f52af1b> So in kdtree the bt.data equivalent is numpy ndarray
[2018-08-01T09:31:40.975Z] <54d4a1d6db8155e6700f853b> yeah here it's not. I opened https://github.com/scikit-learn/scikit-learn/issues/11728
[2018-08-01T09:31:56.043Z] <54d4a1d6db8155e6700f853b> but you already have the numpy array, it's just points
[2018-08-01T09:31:59.533Z] <54d4a1d6db8155e6700f853b> ``points`` that is
[2018-08-01T09:33:06.315Z] <58d1e48dd73408ce4f52af1b> @amueller  An honor to converse with the author of scikit-learn !
[2018-08-01T09:33:13.438Z] <58d1e48dd73408ce4f52af1b> Thank you for opening the issue on github !!
[2018-08-01T09:33:35.725Z] <54d4a1d6db8155e6700f853b> I'm not "the author" by any means
[2018-08-01T09:33:47.647Z] <58d1e48dd73408ce4f52af1b> co-author ?
[2018-08-01T09:33:51.932Z] <54d4a1d6db8155e6700f853b> I guess
[2018-08-01T09:34:04.454Z] <54d4a1d6db8155e6700f853b> together with like 500 other people or something ;)
[2018-08-01T09:34:19.245Z] <54d4a1d6db8155e6700f853b> I'm the person that opened the most issues, I think. Dubious honor.
[2018-08-01T09:36:22.528Z] <58d1e48dd73408ce4f52af1b> Thank you for opening mine :)
[2018-08-01T09:37:52.369Z] <54d4a1d6db8155e6700f853b> you can just do np.array on bt.data to get a numpy array for now, but you already have the array as ``points`` so there's really no need...
[2018-08-01T09:40:08.860Z] <58d1e48dd73408ce4f52af1b> yes thanks. I have accepted your answer on SO as well :) Hopefully I will be notified that the problem has been fixed so I can reinstall scikit-learn
[2018-08-01T09:42:30.221Z] <58d1e48dd73408ce4f52af1b> I had another question. I had a offline conversation with another core developer of  scikit-learn
[2018-08-01T09:43:17.070Z] <58d1e48dd73408ce4f52af1b> I want to use BallTree with https://en.wikipedia.org/wiki/Great-circle_distance and that core developer warned me against it and asked me to use Haversine instead.
[2018-08-01T09:43:20.336Z] <58d1e48dd73408ce4f52af1b> Any reason why ?
[2018-08-01T09:44:17.483Z] <58d1e48dd73408ce4f52af1b> PyProj provides great circle distances and I can define a custom metric. What is the objection in doing this ?
[2018-08-01T09:44:23.145Z] <54d4a1d6db8155e6700f853b> that wiki pages says the harvesine formula is more stable?
[2018-08-01T09:44:31.587Z] <54d4a1d6db8155e6700f853b> not my area of expertise but look at the wiki page
[2018-08-01T09:44:47.046Z] <54d4a1d6db8155e6700f853b> that's probably what pyproj is using or should be using?
[2018-08-01T09:45:33.911Z] <58d1e48dd73408ce4f52af1b> Not sure what pyproj is doing - https://jswhit.github.io/pyproj/pyproj.Geod-class.html#fwd
[2018-08-01T09:45:52.106Z] <58d1e48dd73408ce4f52af1b> but the author told me it is the  most accurate
[2018-08-01T09:48:24.659Z] <58d1e48dd73408ce4f52af1b> Can I raise this as a issue on github as people on my project want to use pyproj ?
[2018-08-01T09:54:10.119Z] <54d4a1d6db8155e6700f853b> you can ask on pyproj? who did you talk to as sklearn? Jake?
[2018-08-01T09:54:52.919Z] <58d1e48dd73408ce4f52af1b> yes you are right. I did ask  Jake
[2018-08-01T09:55:51.375Z] <58d1e48dd73408ce4f52af1b> No I mean I do not understand how asking pyproj would help. The question is why I cannot use pyproj's great circle distance with scikit-learn
[2018-08-01T09:58:54.889Z] <54d4a1d6db8155e6700f853b> I think you can
[2018-08-01T09:59:04.990Z] <54d4a1d6db8155e6700f853b> ask jake what he meant lol
[2018-08-01T09:59:15.648Z] <54d4a1d6db8155e6700f853b> jake is unlikely to reply to an issue on github
[2018-08-01T10:00:00.334Z] <58d1e48dd73408ce4f52af1b> By the way I used points in that code example and I get another error -` File "testballtree.py", line 23, in main     x1,y1 = bt.points[matches].T AttributeError: 'sklearn.neighbors.ball_tree.BallTree' object has no attribute 'points'` 
[2018-08-01T10:01:15.018Z] <58d1e48dd73408ce4f52af1b> np.array gives the same exception as the one I showed on SO
[2018-08-01T10:01:36.545Z] <54d4a1d6db8155e6700f853b> not bt.points. your array points
[2018-08-01T10:01:43.552Z] <58d1e48dd73408ce4f52af1b> aah OK
[2018-08-01T10:58:34.902Z] <58d1e48dd73408ce4f52af1b> I think PyProj uses the Vincenty formula 
[2018-08-01T13:42:19.636Z] <572d9bc3c43b8c601971985f> hello
[2018-08-02T07:00:26.081Z] <58d1e48dd73408ce4f52af1b> @amueller I got BallTree to work with PyProj's inv()
[2018-08-02T07:14:19.241Z] <58d1e48dd73408ce4f52af1b> @amueller As mentioned by you in this issue - https://github.com/scikit-learn/scikit-learn/issues/6256 you are suggesting that the custom myfunc can be written in Cython which I am willing to do. But we are shipping a product. What happens when there is a new version of scikit-learn and what will happen to my Cython extension ?
[2018-08-03T02:18:55.310Z] <58d1e48dd73408ce4f52af1b> The second question I had is the following - in my field the requirement is that the Nearest Neighbors search for a particular grid point of say 2D data must be include contributions from above and below the surface in question. Supposing i have three 2-D surfaces. top and below the current surface. Then I do a radius of influence query for the three surfaces separately. The interpolated value for the grid point in the current surface must include contributions from all three surfaces from above and below the current surface as well as the current surface
[2018-08-07T22:26:35.521Z] <5a2c58c8d73408ce4f8294ba> Hey, I notices something strange in the documentation. For the GradientBoostingClassifier is says the criterion=friedman_mse for the default. I would have expected criterion=gini like in RandomForestClassifier since mse is typically used for regression not classificaiton. The text is the same as in GradientBoostingRegressor. Is it possible that it was copied by accident?
[2018-08-10T17:27:51.490Z] <560313510fc9f982beb1a331> Has anyone played with memory pools or custom allocators in the context of scikit-learn?
[2018-08-13T23:06:10.671Z] <57957e3e40f3a6eec05c4d2a> Hey guys. I'm dealing with an older version of sklearn (0.13.1) (not able to upgrade at the time) where the class attribute `_label` for `svm.SVC` object is used instead of `classes_`. So where I'd have `'classes_': array(['compatible', 'incompatible'], dtype=object)` in my fitted svm object, how would I replace that with `_label`? Simply exchanging the key names doesn't do the trick. I get the error message: `dtype mismatch, expected 'int32_t' but got Python object`.  If you guys could help me figure this out, you're be even more awesome than you already are.
[2018-08-20T10:06:56.222Z] <589b9e0fd73408ce4f490ba4> @jakirkham not to my knowledge. What approaches were you considering and why do you think it might be beneficial? 
[2018-08-20T15:17:32.322Z] <530c03e25e986b0712efafb8> Is there an estimate on a release date of 0.20 ?  No pressure or expectations, I'm just doing some planning.  "No estimate" is also a fine response.
[2018-08-20T15:53:33.250Z] <589b9e0fd73408ce4f490ba4> @mrocklin See https://github.com/scikit-learn/scikit-learn/pull/11838 for the 0.20.rc1 , probably several weeks later for the 0.20 final .
[2018-08-20T15:54:21.096Z] <530c03e25e986b0712efafb8> Thank you for the pointer @rth .  I should have been able to find that :)
[2018-08-20T16:06:27.178Z] <54d4a1d6db8155e6700f853b> hope to do the RC today or tomorrow but I'm an optimist ;)
[2018-08-20T16:07:14.899Z] <54d4a1d6db8155e6700f853b> I need to convince some more people that I'm right and they are wrong before we can do that, though
[2018-08-20T18:51:16.844Z] <530c03e25e986b0712efafb8> That shouldn't take long :)
[2018-08-21T18:25:52.450Z] <560313510fc9f982beb1a331> > not to my knowledge. What approaches were you considering and why do you think it might be beneficial?   There are cases where we seem to be allocating very similar sized blocks for arrays repeatedly (e.g. enforcing Fortran order on inputs, applying LASSO repeatedly on similar sized arrays). The time for the allocations here is larger than I would naively expect, which makes me think that whatever default memory allocation scheme is running into issues.  Am debating the value of allocating a larger array that includes N such blocks and distributes sliced chunks of it for these allocation operations. This may be too naive, but this is my first thought. WDYT?
[2018-08-21T18:52:41.076Z] <54d4a1d6db8155e6700f853b> does anyone get what I'm doing wrong with appveyor?
[2018-08-21T18:52:41.483Z] <54d4a1d6db8155e6700f853b> https://ci.appveyor.com/project/sklearn-wheels/scikit-learn-wheels/build/job/8ij4qa5mcayg8xr8
[2018-08-22T01:51:18.329Z] <54d4a1d6db8155e6700f853b> the appveyor thing is mostly what's preventing me from doing the RC right now :-/
[2018-08-22T07:01:50.345Z] <5582e83c15522ed4b3e21bef> @amueller there seem to be a few different issues. Very strange.
[2018-08-22T07:02:04.970Z] <5582e83c15522ed4b3e21bef> There are unicode differences. 'foo' vs. u'foo'
[2018-08-22T07:02:40.719Z] <5582e83c15522ed4b3e21bef> and there are also a lot of `, dtype=int32)`vs  `, dtype=int64)`
[2018-08-22T15:21:39.943Z] <54d4a1d6db8155e6700f853b> @bgruening that's actually not the problem I was having, @jnothman has fixed my problem :)
[2018-08-22T15:22:26.855Z] <54d4a1d6db8155e6700f853b> We're supposed to be skipping doctests on 32bit and possibly on py27. or maybe there was a fix in the doctests for py27 changes? Anyone remember lol?
[2018-08-23T14:13:45.976Z] <560313510fc9f982beb1a331> If anyone has time to look at PR ( https://github.com/scikit-learn/scikit-learn/pull/11896 ) and/or PR ( https://github.com/scikit-learn/scikit-learn/pull/11898 ), that would be greatly appreciated. The former is just a slimmed down version of PR ( https://github.com/scikit-learn/scikit-learn/pull/11507 )
[2018-08-24T08:45:05.050Z] <5b52e812d73408ce4fa1c2c2> Ok thanks @DrEhrfurchtgebietend  any link for the issues .pls 
[2018-08-24T16:58:15.820Z] <5b52e812d73408ce4fa1c2c2> @DrEhrfurchtgebietend  any link for joining the org at github like any invitation or anything ..
[2018-08-31T19:11:55.855Z] <564789be16b6c7089cbab8b7> Is there a reason why LinearSVC doesn't have predict_proba? 
[2018-08-31T19:12:14.755Z] <54d4a1d6db8155e6700f853b> @lesshaste yeah it's not a probabilistic model
[2018-08-31T19:12:33.663Z] <564789be16b6c7089cbab8b7> oh!  Hmm...
[2018-08-31T19:13:42.855Z] <564789be16b6c7089cbab8b7> http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html has predict_proba
[2018-08-31T19:13:53.618Z] <564789be16b6c7089cbab8b7> @amueller  I am confused why one is a probabilistic model but the other isn't
[2018-08-31T19:14:55.750Z] <564789be16b6c7089cbab8b7> I mean there is no randomness in the decision tree classifier
[2018-08-31T19:51:24.435Z] <54d4a1d6db8155e6700f853b> randomness has nothing to do with whether it's a probabilistic model. there's no randomness in logistic regression
[2018-08-31T20:59:45.492Z] <564789be16b6c7089cbab8b7> @amueller  Yes sorry my mistake. Could you give a short reason why one is a probabilistic model and the other isn't?
[2018-08-31T21:00:03.191Z] <564789be16b6c7089cbab8b7> Please
[2018-08-31T21:08:55.550Z] <54d4a1d6db8155e6700f853b> not really? There is a way to interpret a tree model in a probabilistic way but there is no way to interpret an SVM in a probabilistic way
[2018-09-01T10:16:20.006Z] <564789be16b6c7089cbab8b7> @amueller  Thanks, that's interesting. I noticed that you can always use  http://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html to make probabilities
[2018-09-01T16:02:38.092Z] <54d4a1d6db8155e6700f853b> yes you can
[2018-09-01T18:56:42.162Z] <5b6fe633d73408ce4fa45408> I tagged my pull request with WIP. However,  right now, Id like if someone would have a look over it. Im not sure if my approach is the desired one. I could do some stuff on documentation of course, but it might be that my approach is declined entirely. So should I change the name of the request? For completeness: this is the pull request (https://github.com/scikit-learn/scikit-learn/pull/11891). Of course I know that time is precious for all of us. 
[2018-09-03T14:55:49.566Z] <5b85ed51d73408ce4fa6261d> I know this is out of topic here but trying to get as much as data we can. Can you please help me understand your use of agile methods by completing this one minute survey https://www.surveymonkey.com/r/98JMTJ2
[2018-09-04T10:46:41.427Z] <5582e83c15522ed4b3e21bef> Hi all! What is the current recommended was to save models and redistribute them. We tried https://github.com/uchicago-cs/deepdish and similar concepts, but all do pickle the object at some point. This is not relocatable and breaks with different python versions etc ... is there any emerging standard. Any hint how the ML community is tackling this at the moment or in the future?
[2018-09-04T16:48:54.760Z] <5a2c58c8d73408ce4f8294ba> @bgruening Use pickle from joblib and build in a docker container. It seems to be the standatd method but is not without flaws. In a standard local server deployment i rarely use the docker containers and just keep track of package versions.
[2018-09-04T17:13:25.380Z] <5582e83c15522ed4b3e21bef> @DrEhrfurchtgebietend I consider this a very bad hack :)
[2018-09-04T17:13:34.686Z] <5582e83c15522ed4b3e21bef> Is there no emerging standard :(
[2018-09-04T19:29:42.243Z] <55d21ee30fc9f982beadabb8> I would refer to the talk of Alejandro Saucedo at EuroSciPy couple of days ago https://axsauze.github.io/scalable-data-science/#/
[2018-09-04T19:30:17.349Z] <55d21ee30fc9f982beadabb8> and more precisely
[2018-09-04T19:30:17.975Z] <55d21ee30fc9f982beadabb8> https://github.com/axsauze/awesome-machine-learning-operations
[2018-09-04T19:33:26.790Z] <55d21ee30fc9f982beadabb8> However, I did not check all the solution and I cannot ensure you that you will not get the pickling issue that you mentioned.
[2018-09-04T19:43:19.305Z] <5b6fe633d73408ce4fa45408> thx for sharing Guillaume
[2018-09-07T20:40:10.265Z] <5a2c58c8d73408ce4f8294ba> Much of that has to do with code versioning not really the deployment method. PKL + docker is a common method mentioned in the Guillaume's links
[2018-09-14T08:44:53.546Z] <5b9b749bd73408ce4fa82693> Hi. I'm a student and am new to sklearn. One of my peers told me that once I get a job, I can't and shouldn't use sklearn for professional projects. Is this true? Is not sklearn completely open source and free to use?
[2018-09-14T08:46:12.507Z] <5b9b749bd73408ce4fa82693> which license does it come under?
[2018-09-14T08:48:59.289Z] <5b9b749bd73408ce4fa82693> If the response is too detailed to be mentioned in a chat, please respond on my email : ujjawalpanchal32@gmail.com Thanks for your help. Looking forward to replies.
[2018-09-14T10:00:06.804Z] <5582e83c15522ed4b3e21bef> @Ujjawal-K-Panchal just look at github: https://github.com/scikit-learn/scikit-learn/blob/master/COPYING
[2018-09-15T03:34:11.640Z] <5b9b749bd73408ce4fa82693> Thanks!
[2018-09-15T11:20:15.065Z] <561a58f7d33f749381a8ff2f> interesting question: https://stats.stackexchange.com/questions/367051/how-to-learn-new-clusters-on-residuals-of-kmeans
[2018-09-15T11:20:36.259Z] <561a58f7d33f749381a8ff2f> given you have 40k frozen centroids, how to learn 40k more?
[2018-09-15T14:40:54.245Z] <561a58f7d33f749381a8ff2f> `partial_fit` and `_mini_batch_step` don't feel very modular
[2018-09-15T14:54:51.776Z] <5b953136d73408ce4fa76b1f> hello
[2018-09-18T12:15:14.634Z] <567f5d7716b6c7089cc043a8> question: does it make sense to go through the docstrings and make sure the default values are mentioned for each optional parameter, preferably with a consistent format? Or should we just try to enforce it for new PRs and leave the rest alone? There are some funny cases though (http://scikit-learn.org/dev/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor)
[2018-09-18T12:16:21.031Z] <54d4a1d6db8155e6700f853b> @adrinjalali making sure defaults are there would be great. consistent formatting has the issue that there's gonna be a lot of changes creating lots of conflicts with existing PRs.
[2018-09-18T12:16:38.619Z] <54d4a1d6db8155e6700f853b> but it'll be hard to search for missing defaults without a consistent format :-/
[2018-09-18T12:19:59.407Z] <567f5d7716b6c7089cc043a8> @amueller why would it create a conflict with existing PRs, if those PRs haven't change the line corresponding to the parameter? And if they have, it does make sense for them to follow whatever convention we choose anyway, doesn't it?
[2018-09-18T12:21:20.652Z] <54d4a1d6db8155e6700f853b> I think it's enough if there's changes around the line for it to create a conflict
[2018-09-18T12:24:09.727Z] <567f5d7716b6c7089cc043a8> hmm, fair enough.  So no easy way to fix. Although I'm not sure how much it would bug PR submitters to fix those conflicts. Well, I guess then we'll leave it as is. Unless you have a better solution.
[2018-09-22T05:52:04.182Z] <58bef343d73408ce4f4f062f> Hello everybody! I just wrote an article about Machine Learning. Let me know what you think about it :wink: https://medium.freecodecamp.org/how-to-predict-likes-and-shares-based-on-your-articles-title-using-machine-learning-47f98f0612ea
[2018-09-24T08:03:31.651Z] <5657989e16b6c7089cbc5309> @flaviohenriquecbc nice report! Two suggestions. One, it would be nice to explain what the red and blue colors mean. I didn't get a strong sense of what those were when reading the Medium post or your final report PDF. And two, if you were to improve this accuracy of your models, maybe consider feature selection to narrow which words you use in your model, instead of using all of them. From your final report, it appears you used all of them, but if I missed that part of your analysis, forgive me. Thanks for sharing your work and results!
[2018-09-24T08:04:56.836Z] <5657989e16b6c7089cbc5309> @flaviohenriquecbc And feel free to share in the [freeCodeCamp DataScience](https://gitter.im/FreeCodeCamp/DataScience) room as well :wink: 
[2018-09-24T08:25:27.514Z] <58bef343d73408ce4f4f062f> thank you for your feedback, @erictleung .. i will try to implement what you said :)
[2018-09-24T08:43:48.541Z] <58bef343d73408ce4f4f062f> actually the colors didn't mean anything.. it was a style that i used for the graphs
[2018-09-24T17:43:09.495Z] <564e507e16b6c7089cbb6551> @amueller checked Bottou's sgd code in C++ (https://leon.bottou.org/projects/sgd), I'm not sure where that same formula used for the learning rate can be found there.
[2018-09-24T20:21:20.560Z] <54d4a1d6db8155e6700f853b> @h4k1m0u which one?
[2018-09-25T13:13:11.159Z] <564e507e16b6c7089cbb6551> @amueller I cannot find this one $\eta = \frac{1}{\alpha (t_0 + t)}$ (http://scikit-learn.org/stable/modules/sgd.html#id1) in Bottou's source code
[2018-09-25T14:45:05.623Z] <54d4a1d6db8155e6700f853b> Isn't that the same as svmsgd?
[2018-09-25T15:03:11.937Z] <564e507e16b6c7089cbb6551> @amueller I've opened `svm/svmsgd.cpp`, I can't locate that same formula. I found this one which is different: `double eta = eta0 / (1 + lambda * eta0 * t);`
[2018-09-25T15:04:58.332Z] <54d4a1d6db8155e6700f853b> @h4k1m0u open an issue or ask the mailing list maybe?
[2018-09-25T15:05:31.312Z] <564e507e16b6c7089cbb6551> @amueller Thanks I'll open an issue on Github
[2018-09-25T15:35:13.903Z] <54d4a1d6db8155e6700f853b> :+1:
[2018-09-25T18:23:06.185Z] <54de281a15522ed4b3dbfc22> For demonstration purposes, I would like to track the kmeans centers during each iteration of the fit. Is that possible with sklearn kmeans, e.g. with a callback?
[2018-09-25T18:50:51.735Z] <54de281a15522ed4b3dbfc22> I will try to run kmeans for one iteration at a team, initializing the centers with the centers from the previous kmeans. That should do the trick.
[2018-09-25T19:44:37.611Z] <54d4a1d6db8155e6700f853b> yeah that should work. at that point it's easy enough to implement it yourself as well though ;)
[2018-09-25T21:04:29.610Z] <54de281a15522ed4b3dbfc22> :plus1: 
[2018-09-27T12:15:26.841Z] <5b7904d9d73408ce4fa50f7a> Hello guys, I wish to start contributing to sci-kit learn. As I am a beginner, so can anybody suggest me how to start contributing. 
[2018-09-27T16:09:08.374Z] <5a2c58c8d73408ce4f8294ba> There are issues on GitHub marked with "easy"/"good first issue" https://github.com/scikit-learn/scikit-learn/issues
[2018-09-28T07:38:38.783Z] <58a84478d73408ce4f4b3982> Number of features of the model must match the input. Model n_features is 13 and input n_features is 2 
[2018-09-28T07:38:48.795Z] <58a84478d73408ce4f4b3982> What does it mean?
[2018-09-28T15:57:11.316Z] <54d4a1d6db8155e6700f853b> @Praful-cs can you please say what's unclear about that so we can improve the error message?
[2018-09-28T15:57:23.125Z] <54d4a1d6db8155e6700f853b> The model was trained with 13 features and you give it data with 2 features
[2018-10-03T15:58:05.219Z] <54d4a1d6db8155e6700f853b> @nicolashug you here?
[2018-10-03T15:58:30.681Z] <5baf7d9ad73408ce4fa9c9b2> yup
[2018-10-03T15:58:57.607Z] <54d4a1d6db8155e6700f853b> so in lbfgs alpha = 1/C
[2018-10-03T15:59:16.143Z] <54d4a1d6db8155e6700f853b> I'm trying to figure out the loss computation for lbfgs first because we can most easily access the function
[2018-10-03T16:18:20.475Z] <54d4a1d6db8155e6700f853b> @NicolasHug https://pastebin.com/5Vv72rLc
[2018-10-03T16:18:28.519Z] <54d4a1d6db8155e6700f853b> these two are identical and identical to what's internally used
[2018-10-03T16:21:14.773Z] <54d4a1d6db8155e6700f853b> and if you want SGD to be equivalent to LogisticRegression, you have indeed to set alpha = 1/(C  * n_samples)
[2018-10-11T17:20:07.984Z] <5bbc5d22d73408ce4faacee2> Hi. Can you anyone tell me if there is any tutorial for ML ?
[2018-10-11T18:58:17.295Z] <54d4a1d6db8155e6700f853b> @KoulickS https://jakevdp.github.io/PythonDataScienceHandbook/
[2018-10-11T18:58:30.740Z] <54d4a1d6db8155e6700f853b> https://www.kaggle.com/kanncaa1/machine-learning-tutorial-for-beginners
[2018-10-12T19:41:22.041Z] <5b15820ad73408ce4f9bec06> Greetings everyone, anyone knows about bitcoin price prediction algorithms ?
[2018-10-13T09:36:28.734Z] <5b3f6eedd73408ce4f9fd9e7> Hi, i will try to predict customer lifetime period. My dataset has information about customer lifetime period. Should i set this column as target and do regression for predict it?
[2018-10-13T15:16:58.779Z] <567f5d7716b6c7089cc043a8> @MahmoudElsayad you probably would need algorithms which deal well with time series challenges, such as HMM or RNN (mostly LSTM related) models, which are not included in scikit-learn. You may find more information in the following places: - https://hmmlearn.readthedocs.io/en/latest/ - https://machinelearningmastery.com/make-predictions-time-series-forecasting-python/ - https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/
[2018-10-13T15:29:01.014Z] <567f5d7716b6c7089cc043a8> @talatccan that would be a start. But please note that issues such as preprocessing and scaling your inputs and/or outputs, and hyperparameters of your models, may substantially affect your results. You can refer to the resources posted above your message for more information.
[2018-10-13T16:48:36.856Z] <5bbc5d22d73408ce4faacee2> What all do you think is the future scope of ML and AI in the field of data science
[2018-10-17T00:58:59.601Z] <5bc6614fd73408ce4fabae05> https://docs.google.com/viewerng/viewer?url=https://s3.amazonaws.com/acadgildsite/course/masteringdatascience/session23/ACD_MDS_V2_Session_23_Project_1_Main.pdf
[2018-10-17T00:59:14.577Z] <5bc6614fd73408ce4fabae05> Someone help with this assigment 
[2018-10-17T00:59:26.051Z] <5bc6614fd73408ce4fabae05> Ir could be pais
[2018-10-17T03:19:02.334Z] <5a2c58c8d73408ce4f8294ba> Not cool
[2018-10-18T07:46:15.782Z] <5bbdfc48d73408ce4faaf97c>   Write a function to return the intercept as a float (rounded to the nearest 3 integers) of a linear regression model  def lin_reg_intercept(X_train, y_train): 
[2018-10-20T18:45:55.718Z] <5abc16fed73408ce4f938d6d> @GONZALORUIZR_twitter what help do u need?
[2018-10-21T01:16:08.061Z] <5bc6614fd73408ce4fabae05> I need somebody do the assigment and send me via open repository
[2018-10-24T15:14:52.038Z] <5a2c58c8d73408ce4f8294ba> Is it for course credit? Are you going to pay?
[2018-10-28T04:54:12.083Z] <5bd4b048d73408ce4facfb79> Hi guys.  I just have a doubt.  Is it better to scale down the target values before using it as ground truth for training a model or can we use the target values as such?
[2018-10-28T04:55:00.025Z] <5bd4b048d73408ce4facfb79> My target values are in the range of 100's currently.
[2018-10-28T10:23:03.656Z] <5668c71116b6c7089cbe1ea3> @MVenkat_28_gitlab if you have one target that you are predicting, scaling should have no real effect. What models/approaches are you using ... maybe there is something I am not thinking about? 
[2018-10-28T10:23:49.750Z] <5668c71116b6c7089cbe1ea3> so rounding error would be a concern if you had massive range in your targets
[2018-10-28T10:24:23.370Z] <5668c71116b6c7089cbe1ea3> And it is generally easier to start with a classifier rather than regressor ...
[2018-10-28T14:38:23.583Z] <5bd4b048d73408ce4facfb79> I have only one target.  I'm currently using a regression neural network.
[2018-10-28T14:39:41.707Z] <5bd4b048d73408ce4facfb79> @cottrell how do you say that for one target scaling will make no effect?
[2018-10-28T17:17:13.668Z] <5b7c5fe0d73408ce4fa555ef> hi, everyone i'm new here so anything i need to know?
[2018-10-29T06:59:13.097Z] <5668c71116b6c7089cbe1ea3> @MVenkat_28_gitlab well, I guess I mean for unregularized regression. Linear scaling mathematically should not have a direct impact for most models and methods. I think the linear scaling will just factor out of everything. Of course, it might help with numerical stability if the target has extreme values.  Basically, intuition is that for regression methods, min F(X) - y is same problem as min F(X) - \alpha * y but with a modified X. For example, you could just scale the weights of the last layer to get the different Y.   With SGD or whatever method you are using to solve, you could of course get different results with scaled y.   This is not a proof of course ... just found this: https://roamanalytics.com/2016/11/17/translation-and-scaling-invariance-in-regression-models/#Scaling-does-not-affect-unregularized-regression  which is potentially a good illustration of the details.
[2018-10-29T07:16:14.702Z] <5668c71116b6c7089cbe1ea3> @nisnt2411 Hi, I dunno I jumped in recently without even asking anything :). Seems like a mix of questions from people starting and a few technical discussions. (human) Latency is pretty high. Just try to help people who are stuck if you know some answers to questions I guess. 
[2018-10-29T08:31:53.958Z] <5b7c5fe0d73408ce4fa555ef> @cottrell thanks! I thought there might be some prerequisites . 
[2018-10-29T20:56:32.473Z] <54d4a1d6db8155e6700f853b> @nisnt2411 wanting to contribute. Python and ML knowledge is helpful ;)
[2018-10-29T20:56:52.499Z] <54d4a1d6db8155e6700f853b> start with the contributors guide and "good first issue" tag if you want to start helping
[2018-10-29T20:57:06.755Z] <54d4a1d6db8155e6700f853b> and yes, review latency is terribly high unfortunately
[2018-11-05T07:48:46.008Z] <54fdd51a15522ed4b3dd04b7> Hi all, i see a bunch of `unused variables` alert  in lgtm. https://lgtm.com/projects/g/scikit-learn/scikit-learn/alerts/?mode=tree&ruleFocus=6780086 Would this be a useful PR?
[2018-11-05T15:20:30.928Z] <54d4a1d6db8155e6700f853b> @whiletruelearn not if they are in externals or backports. otherwise yes.
[2018-11-05T16:40:29.002Z] <5bc6614fd73408ce4fabae05> How wants to code in a kaggle team! 
[2018-11-06T03:40:55.545Z] <5be10c63d73408ce4fadfb10> Hi all! How can I see a error in this build?   https://circleci.com/gh/gilbertoolimpio/scikit-learn/11?utm_campaign=workflow-failed&utm_medium=email&utm_source=notification  Can you help me?
[2018-11-06T08:58:06.022Z] <5b9b523bd73408ce4fa82230> Hi all I am a newbie here only have coding experience but I would like to contribute in this project so where should I start with
[2018-11-06T09:01:55.575Z] <567f5d7716b6c7089cc043a8> @dwibedis the contributing guides (http://scikit-learn.org/dev/developers/contributing.html) and the "good first issue" ones on github (https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) are not a bad place to start, if you haven't checked them already.
[2018-11-06T09:05:01.735Z] <567f5d7716b6c7089cc043a8> @OlimpioGilberto_twitter you can download the build log there, and look for errors (if there's any). But I'm not sure why you're looking in that build log. those are mostly for the docs, and that particular one is for python2, which is deprecated in master (it's still there cause future 0.20.xxx releases still support python2). If you're trying to see some build logs and to check the tests, you probably need to check the travis-ci logs, not circle-ci.
[2018-11-06T09:36:28.504Z] <5be10c63d73408ce4fadfb10> @adrinjalali Thank you! I am looking in the circle-ci because my PR was labeled with an error, because of this problem and I did not find which was the error that was triggered. But now, I suppose this problem is not so serious! Tks!
[2018-11-06T09:37:36.297Z] <567f5d7716b6c7089cc043a8> @OlimpioGilberto_twitter if you want, and the problem still exists, I can try and have a look if you paste here the PR number.
[2018-11-06T09:46:04.122Z] <5be10c63d73408ce4fadfb10> @adrinjalali here is my PR number #12524 Tks!
[2018-11-06T10:41:08.414Z] <5be10c63d73408ce4fadfb10> @adrinjalali Very tks! I'll fix my code! Your help was very important!
[2018-11-07T09:39:37.410Z] <541a528b163965c9bc2053de> Hi all, I am trying to update the DNS of scikit-learn.org to enable https, and it broke. Working on fixing it.
[2018-11-07T09:40:04.389Z] <541a528b163965c9bc2053de> For reference I was trying to follow the instructions from https://github.com/scikit-learn/scikit-learn/issues/12278
[2018-11-07T09:41:45.976Z] <541a528b163965c9bc2053de> It works again \o/
[2018-11-07T09:42:00.492Z] <541a528b163965c9bc2053de> I did nothing more, it just took a bit of time apparently.
[2018-11-07T09:42:11.496Z] <567f5d7716b6c7089cc043a8> woohooo 
[2018-11-07T09:42:41.967Z] <567f5d7716b6c7089cc043a8> now computer says yes :P
[2018-11-07T09:49:20.501Z] <589b9e0fd73408ce4f490ba4> Now I won't be able  to use scikit-learn.org with Airports wifi one of the remaining websites that doesn't use https to get redirected to the network sign-in. So this can break some use cases :) Great that it happened, can confirm it works!
[2018-11-07T09:49:39.645Z] <541a528b163965c9bc2053de> http://8.8.8.8
[2018-11-07T09:50:03.610Z] <541a528b163965c9bc2053de> It should trigger sign-in pages on open wifi networks.
[2018-11-07T09:52:58.886Z] <589b9e0fd73408ce4f490ba4> Yeah, but scikit-learn.org was smoother to type on a French keyboard  :)
[2018-11-07T09:53:44.234Z] <589b9e0fd73408ce4f490ba4> Just kidding, thanks for making it happen!
[2018-11-07T15:13:16.440Z] <54d4a1d6db8155e6700f853b> sweet!
[2018-11-07T15:13:37.101Z] <54d4a1d6db8155e6700f853b> example.com walso works @rth 
[2018-11-07T20:31:13.655Z] <579618a040f3a6eec05c5e42> hi folks, sorry to bother. I've came across an old scikit example on GPs for which I can't seem to find any documentation or example on how to translate it to the current version: ``` from sklearn.gaussian_process import GaussianProcess gp = GaussianProcess(corr='cubic', theta0=1e-2, thetaL=1e-4, thetaU=1E-1,                      random_start=100) xfit = np.linspace(0, 10, 1000) yfit, MSE = gp.predict(xfit[:, np.newaxis], eval_MSE=True) ``` I understand that's GPR but the parameters have changed, so `corr=cubic` and `thetas` don't really exist. Anyone has any idea how to translate this to version 0.20?
[2018-11-08T11:01:14.810Z] <567f5d7716b6c7089cc043a8> @kirk86 you need to find the appropriate kernels from `sklearn.gaussian_process.kernels` and construct the equivalent kernel to construct your covariance matrix for the GP. I haven't looked into them to know if there's a one to one mapping between the old ones and the new implementations. Alternatively, you can try and construct the solution to your usecase from scratch using tutorials such as: https://scikit-learn.org/dev/modules/gaussian_process.html#gaussian-process
[2018-11-08T11:54:49.112Z] <567f5d7716b6c7089cc043a8> @amueller in less than two weeks we're going to have a meetup for people who are new and interested in open source development. I'll be introducing them to scikit-learn's development process, for which it'll be nice to have the issue/pr labels updated. The main issue which also troubles myself whenever I'm looking for something to work on, is that the "help wanted" labels are very rarely removed from the issues once they're put there. Going through the first 25 issues tagged with "help wanted", only 7 actually really need help, and for most of them there's already an open PR to fix the issue. I'm not sure how it can be improved in a sustainable way, but it'd be nice if somebody could update the labels at least for now :)
[2018-11-08T11:56:16.306Z] <5b6f95c3d73408ce4fa450d4> @adrinjalali I second that. 
[2018-11-08T11:57:22.237Z] <5b6f95c3d73408ce4fa450d4> Is there any proposed date for this? @adrinjalali ?
[2018-11-08T11:57:59.462Z] <567f5d7716b6c7089cc043a8> this is our meetup: https://www.meetup.com/opensourcediversity/events/255369540/
[2018-11-08T15:38:46.695Z] <579618a040f3a6eec05c5e42> @adrinjalali thank you for taking time to respond. I was thinking the same think that you're suggesting but I can't find any `cubic` kernel in the list of available kernels: ``` >>> sklearn.gaussian_process.kernels. sklearn.gaussian_process.kernels.ABCMeta(                sklearn.gaussian_process.kernels.PairwiseKernel(         sklearn.gaussian_process.kernels.kv( sklearn.gaussian_process.kernels.CompoundKernel(         sklearn.gaussian_process.kernels.Product(                sklearn.gaussian_process.kernels.math sklearn.gaussian_process.kernels.ConstantKernel(         sklearn.gaussian_process.kernels.RBF(                    sklearn.gaussian_process.kernels.namedtuple( sklearn.gaussian_process.kernels.DotProduct(             sklearn.gaussian_process.kernels.RationalQuadratic(      sklearn.gaussian_process.kernels.np sklearn.gaussian_process.kernels.ExpSineSquared(         sklearn.gaussian_process.kernels.StationaryKernelMixin(  sklearn.gaussian_process.kernels.pairwise_kernels( sklearn.gaussian_process.kernels.Exponentiation(         sklearn.gaussian_process.kernels.Sum(                    sklearn.gaussian_process.kernels.pdist( sklearn.gaussian_process.kernels.Hyperparameter(         sklearn.gaussian_process.kernels.WhiteKernel(            sklearn.gaussian_process.kernels.signature( sklearn.gaussian_process.kernels.Kernel(                 sklearn.gaussian_process.kernels.abstractmethod(         sklearn.gaussian_process.kernels.six sklearn.gaussian_process.kernels.KernelOperator(         sklearn.gaussian_process.kernels.cdist(                  sklearn.gaussian_process.kernels.squareform( sklearn.gaussian_process.kernels.Matern(                 sklearn.gaussian_process.kernels.clone(                   sklearn.gaussian_process.kernels.NormalizedKernelMixin(  sklearn.gaussian_process.kernels.gamma( ```
[2018-11-08T17:31:40.632Z] <579618a040f3a6eec05c5e42> A question for the developers, how can someone add a custom kernel to gaussian process, I have custom method but keep getting error when adding it directly do we need to wrap it with some base estimator because it complains about the `get_params` method
[2018-11-08T17:34:56.004Z] <579618a040f3a6eec05c5e42> ``` (Pdb) gp.fit(np.random.randn(10, 3), np.random.randn(10)) *** TypeError: Cannot clone object 'array([0.99946371, 0.99859908, 0.99818002, 0.9994673 , 0.99954341,        0.99969851, 0.99905772, 0.99932515, 0.99906479, 0.99983097])' (type <class 'numpy.ndarray'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods. ```
[2018-11-08T17:47:34.327Z] <579618a040f3a6eec05c5e42> I guess this is still an issue https://stackoverflow.com/questions/49188159/how-to-create-a-custom-kernel-for-a-gaussian-process-regressor-in-scikit-learn
[2018-11-09T16:54:00.600Z] <54d4a1d6db8155e6700f853b> @kirk86 can you please open an issue? I don't think there's an issue open on that
[2018-11-10T17:39:23.919Z] <579618a040f3a6eec05c5e42> @amueller just did #12558
[2018-11-10T17:39:31.776Z] <579618a040f3a6eec05c5e42> thanks
[2018-11-10T18:15:20.297Z] <579618a040f3a6eec05c5e42> Another question for the developers. It seems that `sklearn.feature_extraction.text.CountVectorizer` is lacking an option to pass a 2d numpy array of strings or objects. It seems that it's impossible at the moment. It would be nice because at some point someone might need to do text wrangling and cleaning on another tool such as pandas or spark and be able to dump that as 2d numpy array in order to further analyze.
[2018-11-10T19:17:44.822Z] <54d4a1d6db8155e6700f853b> @kirk86 I'm not sure I understand the usecase. You want several separate text-fields and have each vectorized separately? Or together?
[2018-11-10T21:57:52.575Z] <579618a040f3a6eec05c5e42> Apologies for not clearly explaining the usecase. Let's say that our dataset is like this: ``` X = np.array([['this is a text'], ['the brown fox jumped over the fence'], ['This is a longer string for just showcasing an example'], ['Dummy text here'], ...]) X.shape = (1000, 10) ``` Each sample or row from `X` creates a vector representing the bag of words. Each vector is of variable size because it depends on the length of the sting a.k.a how many times a word is present in the string. One could pad with zeros all of those vectors in order to have the same dimensions. Ideally it would be nice to give `X` to `sklearn.feature_extraction.text.CountVectorizer ` and get back a matrix `X_new .shape = (1000, m)`  where `m` represents that each row vector in `X_new` has the same length. Is that a bit more clear?  
[2018-11-10T22:03:09.522Z] <54d4a1d6db8155e6700f853b> sorry, what's the 10 in your example? Is each example a single string or multiple strings?
[2018-11-10T22:35:38.878Z] <579618a040f3a6eec05c5e42> the 10 is the number of columns and each of them may or may not contain multiple stings
[2018-11-11T17:00:05.693Z] <54d4a1d6db8155e6700f853b> Can you give an example of such an X? Sorry I'm being slow. The X example you gave above has shape (n_samples, 1)
[2018-11-11T18:44:59.415Z] <5a1fcc56d73408ce4f810256> What are the typical approaches used for time series based classification decisions. Appreciate any pointers. I am planning to start with decision trees to somehow learn features based on class transitions. ( I only expect a couple of class transitions amongst  
[2018-11-11T18:46:26.650Z] <5a1fcc56d73408ce4f810256> Classes which got renamed over time but Essentially carry similar features - say classes a1, a2,a3) besides the vanilla classification problem against classes b1,b2 and c1. 
[2018-11-12T13:42:09.350Z] <579618a040f3a6eec05c5e42> @amueller here's an example: ``` array(['dsny', 'bcc - brooklyn south', 'sanitation condition',        '15 street cond/dump-out/drop-off', 'street', '218 31 street',        '31 street', 'brooklyn', 'closed', '07 brooklyn', 'brooklyn'],       dtype=object) ``` 
[2018-11-12T13:46:45.927Z] <579618a040f3a6eec05c5e42> [![example.png](https://files.gitter.im/scikit-learn/scikit-learn/LYOA/thumb/example.png)](https://files.gitter.im/scikit-learn/scikit-learn/LYOA/example.png)
[2018-11-12T13:47:51.501Z] <579618a040f3a6eec05c5e42> here `X` is (n_samples, 11)
[2018-11-12T16:29:33.520Z] <54d4a1d6db8155e6700f853b> these two are different examples, though?! Ok so do you want one vectorizer for each column?
[2018-11-12T16:30:25.431Z] <54d4a1d6db8155e6700f853b> ``make_column_transformer(*[(c, CountVectorizer()) for c in X.columns])`` should do that.
[2018-11-12T16:30:58.681Z] <54d4a1d6db8155e6700f853b> but really status here is probably a categorical variable - thought I guess CountVectorizer also works for those
[2018-11-12T16:31:27.893Z] <54d4a1d6db8155e6700f853b> Well unless there's a space in one of the category names - so explictly saying these are categorical might be better
[2018-11-12T17:26:53.444Z] <579618a040f3a6eec05c5e42> > these two are different examples, though?  They are the same in the sense that the picture is `X` and the array above corresponds just to the first row of `X`.   > but really status here is probably a categorical variable  True, its a categorical value.
[2018-11-12T17:27:03.285Z] <579618a040f3a6eec05c5e42> Thanks!
[2018-11-12T17:27:45.042Z] <54d4a1d6db8155e6700f853b> yeah well treating a single column is different from treating the table, and the single column example is exactly what CountVectorizer does
[2018-11-13T10:13:38.784Z] <5bbdfc48d73408ce4faaf97c> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/2epS/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/2epS/image.png)
[2018-11-13T10:14:08.906Z] <5bbdfc48d73408ce4faaf97c> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/l8Ri/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/l8Ri/image.png)
[2018-11-13T10:14:39.537Z] <5bbdfc48d73408ce4faaf97c> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/HwWK/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/HwWK/image.png)
[2018-11-14T01:09:19.310Z] <54d4a1d6db8155e6700f853b> @Ngamlana this seems entirely unrelated. Please don't spam the channel
[2018-11-17T13:18:58.420Z] <599feaf2d73408ce4f72e9d5> Hello. I am new to this community. I would love to contribute. Can someone help me start
[2018-11-17T14:28:15.120Z] <567f5d7716b6c7089cc043a8> @Naman9639 the contributing guide (https://scikit-learn.org/dev/developers/contributing.html) is a very good place to start, and then you can try some of the "good first issue" (https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) ones.
[2018-11-17T15:36:48.880Z] <599feaf2d73408ce4f72e9d5> Thanks I will start
[2018-11-22T12:39:06.330Z] <5bbc5d22d73408ce4faacee2> How to access groups under NetCDF4 files?
[2018-12-05T13:26:31.878Z] <5b3f6eedd73408ce4f9fd9e7> Hi, i get following error when im trying to apply one hot to categoric columns. I didnt understand what is problem exactly. Error is: TypeError: Wrong type for parameter `n_values`. Expected 'auto', int or array of ints, got <class 'numpy.ndarray'>
[2018-12-05T13:33:43.534Z] <5b3f6eedd73408ce4f9fd9e7> and here is the my one hot code: col_index = ([train.columns.get_loc(c) for c in train.columns if c in temp_cat_cols]) print('OneHot Uygulanacak Columns: ', col_index) ohe = OneHotEncoder(categorical_features=col_index, handle_unknown='ignore') X_train = ohe.fit_transform(X_train).toarray() X_test = ohe.transform(X_test).toarray()
[2018-12-13T00:31:43.032Z] <54d4a1d6db8155e6700f853b> @talatccan can you give a minimum example to reproduce?
[2018-12-13T00:32:25.893Z] <54d4a1d6db8155e6700f853b> and what version of sklearn are you using?
[2018-12-14T11:05:59.151Z] <567f5d7716b6c7089cc043a8> master's circle-ci badge says failing, but I fail to find the build which fails, is the badge wrong? Or am I looking at the wrong place?
[2018-12-14T16:58:55.545Z] <541a528b163965c9bc2053de> There is an issue with the ssh key in the deploy step in the master branch: https://circleci.com/gh/scikit-learn/scikit-learn/tree/master
[2018-12-14T17:00:21.069Z] <541a528b163965c9bc2053de> Here is the end of the log of the last failure:  ``` ...  rewrite dev/searchindex.js (73%) + git push ERROR: The key you are authenticating with has been marked as read only. fatal: Could not read from remote repository.  Please make sure you have the correct access rights and the repository exists. Exited with code 128 ```
[2018-12-14T17:12:27.801Z] <541a528b163965c9bc2053de> The sklearn-ci github user has a user ssh key named "sklearn-docbuilder" that should be able to push to the scikit-learn.github.io repo. However I don't understand how the cicleci job is supposed to have access to this ssh private key.
[2018-12-14T17:13:43.769Z] <541a528b163965c9bc2053de> The recent changes in the `scikit-learn/scikit-learn/.circleci/config.yml` do not seem to be related in any way to the ssh key configuration.
[2018-12-14T19:16:34.505Z] <567f5d7716b6c7089cc043a8> shouldn't that be inside a section in circle-ci holding "secrets"? And then giving access to those values to jobs via environment variables or something? I have no idea how circle-ci works though.
[2018-12-14T23:54:30.800Z] <541a528b163965c9bc2053de> yes I believe so but I did not see anything related to this in the circle CI settings menus and I am not the one who configured it in the first place so I am not sure what has changed and what should be done to restore the push.
[2018-12-15T09:10:37.234Z] <567f5d7716b6c7089cc043a8> On circle-ci, when I look at our jobs, it says "Projects currently running on CircleCI 1.0 are no longer supported. Please migrate to CircleCI 2.0." up there, and the migrate thingy is a hyperlink. We already use circle-ci 2 in our pipeline scripts, but it'd be nice if we upgraded there as well I suppose.
[2018-12-15T12:03:12.941Z] <5c03c22dd73408ce4fb0b61d> Just posted in pydata/pandas but someone suggested I ask here too:   Does anyone where the joblib folks hang out? I am trying some custom store backend stuff with pyarrow serializers and want to see if anyone else is messing around in this space. Feels like am between dask, joblib and pyarrow communities and want to make sure I'm not missing something someone else is already doing.
[2018-12-15T16:08:54.150Z] <54d4a1d6db8155e6700f853b> @david-cottrell_gitlab joblib folks are here ;) I think it's primarily @lesteve and @ogrisel ?
[2018-12-15T16:09:14.098Z] <54d4a1d6db8155e6700f853b> pretty sure they haven't thought about pyarrow though
[2018-12-15T16:09:33.603Z] <54d4a1d6db8155e6700f853b> (but @ogrisel is probably the best person to know these three communities)
[2018-12-15T16:34:08.817Z] <5c03c22dd73408ce4fb0b61d> @lesteve @ogrisel @amueller basically just wondering if there is some hidden trove of custom store backend hackers out there, there are some interesting use cases with using something like hyperdb (decentralized) as a store_backend for sharing the cache globally but it means swapping out all the pkl for something safer.  I am just playing around but I would suprised if someone hadn't gone down this route before.
[2018-12-17T06:34:56.113Z] <5c171a90d73408ce4fb225f1> guys need some help
[2018-12-17T07:36:13.272Z] <5a2c58c8d73408ce4f8294ba> You would be better of posting on SO and putting a link here
[2018-12-18T08:35:16.485Z] <541a528b163965c9bc2053de> @david-cottrell_gitlab I am not aware of any arrow-serializer aware store for joblib. As far as I know there is only pkl based things.
[2018-12-18T10:00:44.416Z] <5c03c22dd73408ce4fb0b61d> @ogrisel Thanks. 
[2018-12-20T02:13:18.585Z] <5c0f2d1bd73408ce4fb18b9f> Hi, sorry if this is a silly question, very new to SVM in general. Was wondering if it's possible to create a model for one-class classification (ie. training on normal data, testing on normal and novel data), where there are more than 2 features for each example. All the code I've seen online seem to only consider 2 features
[2018-12-20T10:13:16.744Z] <567f5d7716b6c7089cc043a8> Those are hand-made minimal examples mostly for presentation purposes. I've applied SVMs to 22k+ features and have gotten good results. I guess that answers the question :) You may find the "Learning with Kernels" book useful if you decide to get deeper into the topic.
[2018-12-20T10:15:34.325Z] <541a528b163965c9bc2053de> Also if you interest is novelty detection, don't restrict yourself to OneClassSVM. You should also give IsolationForest and LOF a try: https://scikit-learn.org/stable/modules/outlier_detection.html
[2018-12-21T18:52:42.392Z] <5b97b76ed73408ce4fa7b2da> Hello everyone , I am a noobie with scikit , interested in datascience , can anyone give me trusted quick reference and reading material link , Thanks 
[2018-12-21T18:53:32.570Z] <54d4a1d6db8155e6700f853b> https://jakevdp.github.io/PythonDataScienceHandbook/ @Ritzing (free online)
[2018-12-21T18:55:49.188Z] <5b97b76ed73408ce4fa7b2da> Thanks @amueller 
[2018-12-24T05:01:59.956Z] <5634e8e116b6c7089cb8fa99> In scikit-learn, where `gpr` is a GaussianProcessRegressor object. The dimension of the $$Y$$ variable is $$N$$. $$X$$ consists of $$M$$ points.  In this code below ```python y_pre, y_cov = gpr.predict( X,  return_cov=True ) ``` Why isn't `y_cov` an array of $M$ covariance matrices of size $$N \times N$$, where $N$ is the dimensionality of the $$Y$$ variable? Why is `y_cov` an array of $$M$$ scalar values?
[2018-12-24T16:57:51.288Z] <5810cd4cd73408ce4f3101ce> Hey... why is `DecisionTreeClassifier/Regressor` using a `random_state` from my understanding  greedy tree building algorithms dont need random? 
[2018-12-25T17:59:18.402Z] <567f5d7716b6c7089cc043a8> @yupbank there can be some randomness in choosing the splits in the trees as you can see [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
[2018-12-25T18:02:06.467Z] <567f5d7716b6c7089cc043a8> @g_abhishek10_twitter probably doing some research on named entity recognition would give you some good hints.
[2019-01-02T16:14:33.716Z] <5810cd4cd73408ce4f3101ce> why would there be any randomness in choosing splits? since decision_tree is  a greedy algorithm, find the best feature to split 
[2019-01-02T16:14:43.702Z] <5810cd4cd73408ce4f3101ce> @adrinjalali ^
[2019-01-02T16:19:20.995Z] <567f5d7716b6c7089cc043a8> @yupbank  I suggest you look for `random_state` in [here](https://github.com/scikit-learn/scikit-learn/blob/7389dbac82d362f296dc2746f10e43ffa1615660/sklearn/tree/_splitter.pyx) to better understand how it's working.
[2019-01-02T16:19:57.062Z] <5810cd4cd73408ce4f3101ce> Thanks man, i understand how the code works...  but i dont understand why are we doing this
[2019-01-03T20:35:01.660Z] <5810cd4cd73408ce4f3101ce> https://gist.github.com/yupbank/1e0c2f50d5ed571e10559a681e7bb76f should be fun for some people 
[2019-01-06T19:19:43.182Z] <5799a0a940f3a6eec05cd618> Any pull requests or changes/additions/stars to this repository would be very much beneficial, please help https://github.com/gautam1858/python-awesome
[2019-01-08T15:35:22.005Z] <54fdd51a15522ed4b3dd04b7> Hi, I have been seeing some conversation in the mailing list regarding an upcoming Dev sprint. I have made a couple of contributions at the tail end of last year and it's one of my goals this year to see if I can contribute more. 
[2019-01-08T15:35:57.315Z] <54fdd51a15522ed4b3dd04b7> Will this be an event which I will be able to participate remotely as well or do I need to be France to participate?
[2019-01-08T17:26:04.470Z] <5bd837dbd73408ce4fad4032> I have a minor question on making open-source contributions.. Traditionally, before I decide to change a file, I ALWAYS FIRST do a `git pull` to get the updated version. I then switch to the branch I created initially, and then make the changes, and do the `git add .`,  commit and push, and then submit a pull request. Correct?
[2019-01-08T20:42:08.758Z] <5bd837dbd73408ce4fad4032> Is the SAME procedure followed for making contribution to this library? I do 'git pull' everytime? 
[2019-01-08T21:32:36.125Z] <5a2c58c8d73408ce4f8294ba> Is this a bug? https://stackoverflow.com/questions/54098749/how-can-i-make-gradientboostingregressor-work-with-a-baseestimator-in-scikit-lea
[2019-01-09T04:21:29.228Z] <5a1fcc56d73408ce4f810256> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/gww6/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/gww6/image.png)
[2019-01-09T04:22:16.658Z] <5a1fcc56d73408ce4f810256> Can someone help me on why words of 1 characters are not available as features here?  
[2019-01-09T08:49:24.228Z] <5c34f182d73408ce4fb408a6> Hello World,I am new.Can someone link me up on how I can start contributing.
[2019-01-09T09:55:26.104Z] <567f5d7716b6c7089cc043a8> @sameshl https://scikit-learn.org/dev/developers/index.html
[2019-01-11T06:26:01.770Z] <589b9e0fd73408ce4f490ba4> @whiletruelearn Yes, of course it's is possible to participate in the sprint remotely.  I guess list of participants on the wiki is mostly there for organization reasons (booking the room of the right size etc). If you want to participate just comment on gitter (here or on the dev channel) during the sprint and someone will help get you started. 
[2019-01-11T06:28:15.118Z] <589b9e0fd73408ce4f490ba4> @rbhambriiit Word of one character are ignored because typically they are stop words (i.e. have no predictive power). If you want to keep them you can change the regexp in the `token_pattern`.
[2019-01-11T06:30:27.461Z] <589b9e0fd73408ce4f490ba4> @DrEhrfurchtgebietend Thanks for the heads up. Yes, it should be fixed by https://github.com/scikit-learn/scikit-learn/pull/12436 I think
[2019-01-12T05:28:21.618Z] <54fdd51a15522ed4b3dd04b7> Thanks @rth . Looking forward to it
[2019-01-14T04:29:52.790Z] <5c3b550cd73408ce4fb482cc> Hello Everyone! I am New here, My name is Vedang and currently studying at IET-DAVV,Indore. Can someone please tell how can I start contributing. Thanks
[2019-01-14T12:56:59.193Z] <567f5d7716b6c7089cc043a8> @vedangj044 https://scikit-learn.org/dev/developers/index.html
[2019-01-14T13:05:51.474Z] <5c3b550cd73408ce4fb482cc> @adrinjalali thanks, i would look into it.
[2019-01-23T15:07:04.336Z] <564e507e16b6c7089cbb6551> Hi everyone, I'm currently doing a pixel-based supervised classification of an image with the SGDClassifier. I want to include the spatial context between pixels in the classification besides the pixel intensity. So, I just found out about `sklearn.feature_extraction.image.grid_to_graph()`, and was wondering if there was a way to include this information (or the graph adjacency matrix) in the classification?
[2019-01-24T05:04:16.010Z] <5c459020d73408ce4fb56d8d> A good source for data set for malware detection using ML?
[2019-01-25T14:39:07.781Z] <5b4da81ed73408ce4fa12924> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/CO5c/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/CO5c/image.png)
[2019-01-25T14:39:49.580Z] <5b4da81ed73408ce4fa12924> why in the lst  line this throws an error "value eror"
[2019-01-25T14:39:59.785Z] <5b4da81ed73408ce4fa12924> string to float?
[2019-01-25T14:41:04.686Z] <5b4da81ed73408ce4fa12924> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/Jl8c/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/Jl8c/image.png)
[2019-01-25T14:41:08.135Z] <5b4da81ed73408ce4fa12924> ??
[2019-01-28T15:42:38.594Z] <59afadccd73408ce4f748432> @farman32 the OneHotEncoder should be used on numerical features. So, for instance, use it on your r LabekEncoder, but reshaped : OneHotEncoder.fit_transform(r.reshape(-1,1).toarray(=
[2019-01-28T15:43:28.308Z] <59afadccd73408ce4f748432> Oups... toarray()!
[2019-01-28T16:43:33.185Z] <59afadccd73408ce4f748432> @ronitneve_twitter interesting http://arxiv.org/abs/1802.10135
[2019-01-30T09:21:44.123Z] <5c516662d73408ce4fb6565a> Salaam everyone! I am currently working on my final year project which includes 3 modules out of which one is 'Topic Generation'. Right now i am stucked in the results. I am using LDA mallet model but the results are not accurate. Help needed!
[2019-02-01T20:29:18.751Z] <597cbd65d73408ce4f6f49d7> Can anyone recommend a pretrained model for text summarization with for instance Apache license for commercial use?
[2019-02-09T19:38:22.621Z] <5c5f2b37d73408ce4fb75701> hi all
[2019-02-12T21:01:31.854Z] <5ba621efd73408ce4fa90312> Good sources to learn scikit for beginners?
[2019-02-13T18:19:51.479Z] <559c8ad915522ed4b3e39cec> @Akash-Sharma-1 try intro to machine learning course on udacity. Its free and uses skikit library.
[2019-02-13T19:24:00.557Z] <5ba621efd73408ce4fa90312> @anandvimal thanks for help
[2019-02-13T19:24:20.742Z] <5ba621efd73408ce4fa90312> I am gonna jump straight into it
[2019-02-13T19:37:57.963Z] <559c8ad915522ed4b3e39cec> It also has a full project in the end to practice the complete ml flow. 
[2019-02-14T02:02:33.129Z] <54d4a1d6db8155e6700f853b> There's also Jake Vanderplas' data science handbook
[2019-02-15T01:16:26.745Z] <5c660e14d73408ce4fb7d8fc> just fun
[2019-02-22T19:24:19.538Z] <57922eec40f3a6eec05c04ef> Hi together, I like to write custom transformers which should not rely on sklearn as a dependency but should be usable in sklearn pipelines anyway (if necessary). Is that possible by simply providing `fit` and `fit_transform` methods? I assume not looking at [BaseEstimator](https://github.com/scikit-learn/scikit-learn/blob/7389dbac82d362f296dc2746f10e43ffa1615660/sklearn/base.py#L129). Thanks for any help.
[2019-02-22T21:16:40.998Z] <5bec622ed73408ce4faeed82> @Akash-Sharma-1 also look into hands on machine learning with scikitl-learn and tensorflow
[2019-02-25T12:39:17.014Z] <54e07d6515522ed4b3dc0858> @mansenfranzen you need to provide `transform` as well, since there are cases where `transform` is called on different data than `fit`; and otherwise make sure you follow the custom estimator guidelines, if you have any parameters to set: https://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator
[2019-02-25T13:08:03.214Z] <5c73c654d73408ce4fb8d721> sprint Paris: I am continuing #5862
[2019-02-25T13:44:24.239Z] <57922eec40f3a6eec05c04ef> @vene Thanks alot for the link to the documentation - it's exactly what I was looking for :-)
[2019-02-25T19:06:31.679Z] <580fa6b0d73408ce4f30ca61> oecd_bli = oecd_bli[oecd_bli["INEQUALITY"]=="TOT"] can anyone explain the last line of code? I can't understand this line properly.
[2019-02-25T19:06:48.726Z] <580fa6b0d73408ce4f30ca61> '''
[2019-02-25T19:07:08.959Z] <580fa6b0d73408ce4f30ca61> ''' def prepare_country_stats(oecd_bli, gdp_per_capita):     oecd_bli = oecd_bli[oecd_bli["INEQUALITY"]=="TOT"] ''' can anyone explain the last line of code? I can't understand this line properly.
[2019-02-26T09:39:05.579Z] <541a528b163965c9bc2053de> @Pritom-Mazhi `oecd_bli[oecd_bli["INEQUALITY"]=="TOT"]` selects the all the lines of a pandas dataframe named `oecd_bli` where the `INEQUALITY` column has value `"TOT"` All the other lines are dropped.
[2019-02-27T09:04:34.508Z] <54d4a1d6db8155e6700f853b> I'm having no luck with this building. Can someone tell me which contineny were in? Second floor, tight?
[2019-02-27T09:06:16.251Z] <567f5d7716b6c7089cc043a8> 7th floor
[2019-02-27T09:06:33.420Z] <567f5d7716b6c7089cc043a8> should I come down to get you?
[2019-02-27T09:07:20.634Z] <567f5d7716b6c7089cc043a8> african continent
[2019-02-27T13:01:53.981Z] <5988340fd73408ce4f706113> Doing a presentation on ONNX right now 
[2019-02-27T13:02:04.199Z] <5988340fd73408ce4f706113> for people at the sprint
[2019-02-27T15:40:06.591Z] <5c73c654d73408ce4fb8d721> @adrinjalali, what is the difference between `min_samples` and `min_cluster_size` in optics ?
[2019-02-27T18:06:35.269Z] <567f5d7716b6c7089cc043a8> @assiaben by convention (I think dbscan uses the same thing) `min_samples` is the parameter used to do the nearest neighbor part, and `min_cluster_size` is used when _extracting_ the clusters from the reachability distances.
[2019-02-27T18:06:46.223Z] <567f5d7716b6c7089cc043a8> we probably need to find a way to better explain these
[2019-02-27T21:51:43.713Z] <5c6af6cad73408ce4fb82b1c> hello guys! Im working on a movie dataset for item-item collaborative filtering. Im able to get my cosine_similarity function working with for loop on a trunkated part of the dataset. I hear that utilizing apply(lambda x: <func>) is much faster. Anyone familar with converting?
[2019-02-28T21:16:43.674Z] <5c70487dd73408ce4fb8a95a> @troykirin a minimal example copypasta would be helpful to get us started; usually its as simple as you described `apply(lambda x: func(x))` assuming all records in the loop are independent
[2019-02-28T22:15:42.540Z] <5c6af6cad73408ce4fb82b1c> @tylerkontra-system1 this is the loop im trying to work with ```  for pair in combinations(np_array_movieandratings[:,],2):     x1 = pair[0]     x2 = pair[1]     np.append.(cos_sim(x1,x2) ``` 
[2019-02-28T23:57:16.034Z] <5c70487dd73408ce4fb8a95a> it might make more sense to do something like this ``` import numpy as np from itertools import combinations  def my_func(p):     return np.sum(p) my_array = np.array(range(100)) my_combin = np.array(tuple(combinations(my_array, 2))) my_result = [my_func(pair) for pair in my_combin] ``` since the biggest performance boost is likely to be from simply using numpys data structures (re: https://stackoverflow.com/questions/38709313/numpy-vectorize-multidimensional-function)
[2019-03-01T20:15:46.838Z] <541a528b163965c9bc2053de> scikit-learn 0.20.3 is online! https://scikit-learn.org/stable/whats_new.html#version-0-20-3
[2019-03-03T09:05:49.749Z] <5860d0cbd73408ce4f3f55a5> why do we use random numbers in machine learning ?
[2019-03-03T09:06:26.721Z] <5860d0cbd73408ce4f3f55a5> I don't quite get it 
[2019-03-03T10:30:55.177Z] <5c667cfad73408ce4fb7e11a> @Devosource there can be many uses of random numbers. For example if you are working on a dataset of a hundred thousand images and you need to check the result randomly, then you might use a randInt() function i guess.   Also, that was just an example. I didnt quite understood the context of your question. Hope you got your answer but if not then you could be more specific and someone would give you the answer you are looking for.
[2019-03-03T15:26:55.958Z] <5860d0cbd73408ce4f3f55a5> i was going through keras beginner's tutorial and abit of CNN model tutorial. I found that the first thing to do after importing modules is to fix random seed for reproducibility , for random numbers. That's what I don't understand 
[2019-03-03T15:27:25.175Z] <5860d0cbd73408ce4f3f55a5> ``` from keras.layers import Dense import numpy # fix random seed for reproducibility numpy.random.seed(7) ```
[2019-03-03T17:44:22.462Z] <5c667cfad73408ce4fb7e11a> @Devosource  So basically when you are watching a tutorial and coding along with it, you can use fix seed for the same result as in the tutorial you are watching. Just for the sake of same random number generation throughout the code whenever a random number is generated. 
[2019-03-04T08:41:38.265Z] <5860d0cbd73408ce4f3f55a5> @algo-circle thanks
[2019-03-04T08:49:41.948Z] <5c667cfad73408ce4fb7e11a> @Devosource You are welcome sir! <unconvertable>
[2019-03-10T19:41:17.667Z] <5c03c22dd73408ce4fb0b61d> Anyone know anything about why the keras.io room is blocked? Says github users only. I think there is a glitch?
[2019-03-10T19:42:50.493Z] <5668c71116b6c7089cbe1ea3> Yes, it is a glitch with gitter. They link accounts but sign-in still matters.
[2019-03-15T17:47:55.786Z] <5824457cd73408ce4f34ebbd> Hello everyone, I have a quick question regarding normalization (min-max-scaling) of output values. Usually you are supposed to use normalization only on the training data set and then apply those stats to the validation and test set. But for instance, my prediction variable is a single percentage value ranging [0, 100%]. And I know for sure that in the "real world" regarding my problem statement, that I will get samples ranging form 60 - 100%. But my training set is to small and does not contain enough data points including all possible output values. So here comes my question: Should I stay with my initial statement (normalization only on training data) or should I apply the maximum possible value of 100% for my output value to max()-value of the normalization step?  
[2019-03-15T17:51:29.737Z] <57007657187bb6f0eadd96e8> Are you doing regression? Typically minn max scaling is used on the feature vector values that are inputs into the classifier. Not necessarily on the outputs of the classifier
[2019-03-15T17:51:44.783Z] <5824457cd73408ce4f34ebbd> yes, regression
[2019-03-15T17:54:26.890Z] <5824457cd73408ce4f34ebbd> Another silly idea was to squash my output value into the range [0,1] by applying target/100. Does that make sense? 
[2019-03-15T17:54:59.697Z] <57007657187bb6f0eadd96e8> thats just chaning how you look at it, not really changing the properties of it
[2019-03-15T17:55:54.560Z] <57007657187bb6f0eadd96e8> just checking I understand your problem though. You are saying in your training set, you have min max output of  something like  .2 - .6 and so you are scaling that to 0-1. 
[2019-03-15T17:56:54.639Z] <57007657187bb6f0eadd96e8> It depends on the problem you are trying to solve. You'll have to decide if it is appropriate for your problem or not. 
[2019-03-15T17:58:37.626Z] <57007657187bb6f0eadd96e8> what min max scaling does in that case is stretch the predictions between .2 and .6 to a higher resolution, and then make evertying outside .2 or .6 equal to each other
[2019-03-15T17:59:26.988Z] <57007657187bb6f0eadd96e8> if that makes sense to do will be application specific
[2019-03-15T18:00:07.880Z] <5824457cd73408ce4f34ebbd> Maybe I'm just dump. So, my target value ranges from something like 60% - 100% and I'm trying to predict it by using MLP/CNN. My understanding is that I have to scale my output value that it matches my output activation function (ReLU). But I got cought up with normalization in general and the correct usage on training,validation and test data.
[2019-03-15T18:00:59.093Z] <5824457cd73408ce4f34ebbd> That's how I got confused
[2019-03-15T18:01:59.839Z] <57007657187bb6f0eadd96e8> ok, yeah so any scaling that you do on your training data. You will want to apply those same normalization to the validation and test data 
[2019-03-15T18:04:34.592Z] <57007657187bb6f0eadd96e8> you can also set the normalization of the training to be what you expect from your real data 
[2019-03-15T18:09:11.565Z] <5824457cd73408ce4f34ebbd> Exactly, but what if my training set doesn't include all possible outcomes for my output value due to the small sample size. Usually that would just mean, I would have to include more samples. But that is not possible at this point. So furthermore this leads to the situation that my test sample will have output values which are not present in the training set.  One solution would be to give the model the information in advance that the max possible range of the output value will be 100%. 
[2019-03-15T18:09:49.269Z] <5824457cd73408ce4f34ebbd> But this idea contradicts the Literature
[2019-03-17T13:11:01.909Z] <5860d0cbd73408ce4f3f55a5> jupyter notebook crashes when running opneAI's gym env
[2019-03-17T13:11:10.522Z] <5860d0cbd73408ce4f3f55a5> any fix for this ?
[2019-03-17T13:51:53.941Z] <5c8e506dd73408ce4fbaeb3b> Hello Guys and Girls DO you Wanna Meme Based Group Only Of Data Science and Machine Learning I have Created One Dumbily For You People To Join https://www.facebook.com/groups/2084179105032029/ Join in With your Facebook Account 
[2019-03-27T18:46:44.551Z] <5c9bc1dad73408ce4fbc0304> Hi anyone can please assist me to 
[2019-03-27T18:46:54.598Z] <5c9bc1dad73408ce4fbc0304> Install anaconda on Ubuntu
[2019-03-27T20:42:06.436Z] <567f5d7716b6c7089cc043a8> have you tried an online tutorial and failed @SadiaAman ?
[2019-03-28T06:51:46.860Z] <5c9b282cd73408ce4fbbf1ed> Can i join in with my github account?
[2019-03-28T09:05:14.685Z] <5c99f27ad73408ce4fbbd772> @wwf6688 just login with github account
[2019-03-28T09:06:02.356Z] <5c9b282cd73408ce4fbbf1ed> I can't open the website in China
[2019-03-28T09:06:15.977Z] <5c9b282cd73408ce4fbbf1ed> https://www.facebook.com/groups/2084179105032029/
[2019-03-28T09:30:52.953Z] <5c99f27ad73408ce4fbbd772> Try using vpn
[2019-03-28T09:31:16.385Z] <5c99f27ad73408ce4fbbd772> Shadowsocks or any other way
[2019-03-29T03:49:44.825Z] <5c9b282cd73408ce4fbbf1ed> ok
[2019-04-08T22:02:24.183Z] <542e902b163965c9bc208763> I'm looking to take a set of attributes about an object in the real world, and then determine a set of products that would best fit it based on these attributes. Would this be a good fit for using a decision tree?
[2019-04-08T22:05:41.886Z] <542e902b163965c9bc208763> these set of products would be values calculated from the attributes themselves
[2019-04-08T22:08:42.726Z] <542e902b163965c9bc208763> I am not looking for any type of prediction though, just a method of representing logic branches nicely in some pretty complex business rules
[2019-04-14T10:54:58.332Z] <5b58594ed73408ce4fa23ee3> Hi, what's the reason why none of the CV iterators support single splits (i.e. `n_splits=1`)?
[2019-04-15T09:44:58.479Z] <558c0fd615522ed4b3e2b943> n_splits is the number of chunks produced. So n_splits=1 means not to split the data at all, leave it in one chunk
[2019-04-15T13:06:57.072Z] <5b58594ed73408ce4fa23ee3> That's not right if I understand you correctly, running  ``` cv = KFold(n_splits=2) len(list(cv.split(np.arange(10)))) ``` returns 2, i.e. 2 tuples of two arrays, not  a single tuple. 
[2019-04-16T18:44:56.614Z] <558c0fd615522ed4b3e2b943> Take a look at the list itself and it'll become clear. You have 2 chunks. First you use the first chunk as train and second chunk as test set. Then, you use the second chunk as train and first chunk as test set.
[2019-04-16T18:47:16.296Z] <558c0fd615522ed4b3e2b943> I should not call them chunks. They're folds. Two folds :) 
[2019-04-16T19:03:23.016Z] <5b58594ed73408ce4fa23ee3> Yes, I understand that, but why can it not give me a single train and a single test set (`n_splits=1`) as `split_train_test` does? Because it's then not really folds anymore? 
[2019-04-16T19:14:02.855Z] <558c0fd615522ed4b3e2b943> I guess `n_splits` is a bit of a misnomer. `n_folds` would've been clearer maybe.
[2019-04-17T16:10:36.875Z] <5b58594ed73408ce4fa23ee3> Yes, okay, but still why not return a single split? Any underlying design choice/complication?
[2019-04-18T18:32:57.782Z] <564789be16b6c7089cbab8b7> I know this is going to sound like I am complaining, but I am not. In 2015 I suggested adding Gower similarity/dissimilarity to our metrics. https://github.com/scikit-learn/scikit-learn/issues/5884 . It is now April 2019 and the PR is still in the works https://github.com/scikit-learn/scikit-learn/pull/9555
[2019-04-18T18:36:31.396Z] <564789be16b6c7089cbab8b7> It feels like someone  could have coded up the dissimilarity score in a day and written tests in a week. Is this sort of 4 year period normal or something worth exploring?
[2019-04-18T18:38:21.592Z] <564789be16b6c7089cbab8b7> In fact it was implemented in 2017 I see in the issue as a jupyter notebook 
[2019-04-19T08:48:36.299Z] <558c0fd615522ed4b3e2b943> It's easy for PRs to get buried.
[2019-04-20T22:42:24.956Z] <5aecc12bd73408ce4f982900> Hi, I have a question about what `GridSearchCV` (or, in my case, `RidgeCV`) passes to the scorer for evaluation. I created a custom scorer that takes in `y_true` and `y_pred` and returns the correlation (see below). However, I stuck a `print` statement in there to verify the shape of what's being passed to the scorer. I'm using `KFold` cross-validation with e.g. _k_ = 10, which for 200 samples will return splits with shapes `y_train` = 180 and `y_test` = 20. It seems that both arrays of shape 180 and 20 are being passed to the scorer for evaluation. As if the scorer is being run on both the test set (expected) and the train set (unexpected, for me). Is this actually what's going on? If so, is this the desired behavior? Maybe my implementation of the scorer is screwed up, but couldn't figure this out from the documentation. Thanks, and sorry for any confusion! ```python def correlation_metric(y_true, y_pred):         y_true_demean = y_true - np.mean(y_true, axis=0)     y_pred_demean = y_pred - np.mean(y_pred, axis=0)     numerator = np.sum(y_true_demean * y_pred_demean, axis=0)     denominator = np.sqrt(np.sum(y_true_demean ** 2, axis=0) *                           np.sum(y_pred_demean ** 2, axis=0))     print(f"True shape: {y_true.shape}; Predicted shape: {y_pred.shape} "           f"Correlation: {numerator/denominator}")     return numerator / denominator correlation_scorer = make_scorer(correlation_metric) ``` 
[2019-04-20T22:43:22.442Z] <5aecc12bd73408ce4f982900> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/vOzF/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/vOzF/image.png)
[2019-04-22T14:38:37.218Z] <5b4b30e3d73408ce4fa0eefc> Hello, is there a simple way how to make a polynomial regression of given degree?
[2019-04-24T19:55:27.664Z] <5baf7d9ad73408ce4fa9c9b2> @Borda take a look at  https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html
[2019-04-24T19:58:16.792Z] <5baf7d9ad73408ce4fa9c9b2> @snastase yes GridSearchCV has a `return_train_score` attribute (the default will change in the next version)
[2019-04-25T17:05:59.216Z] <5aecc12bd73408ce4f982900> Ah got itthanks! @NicolasHug 
[2019-04-25T18:45:23.185Z] <5ba59281d73408ce4fa8fbb5> hi anyone here?
[2019-04-25T18:45:56.790Z] <5ba59281d73408ce4fa8fbb5> while using librosa I 'm getting this error ImportError: cannot import name '_inplace_contiguous_isotonic_regression'
[2019-04-25T18:46:15.521Z] <5ba59281d73408ce4fa8fbb5> I tried googling it but I got nothing 
[2019-04-25T18:46:22.505Z] <5ba59281d73408ce4fa8fbb5> please help
[2019-04-25T18:48:01.309Z] <541a528b163965c9bc2053de> This is private API that is not guaranteed to stay stable across scikit-learn releases, maybe librosa was meant to be used with a specific version of scikit-learn. Please check with its documentation or asking its developers and make sure that you have the correct version of scikit-learn.
[2019-04-25T18:48:29.206Z] <55d21ee30fc9f982beadabb8> https://github.com/librosa/librosa/blob/master/setup.py#L50
[2019-04-25T18:48:46.893Z] <55d21ee30fc9f982beadabb8> could be that > 0.19 could be problematic
[2019-04-25T18:48:50.900Z] <5ba59281d73408ce4fa8fbb5> hmmm ok thanks let me try it on librosa
[2019-04-25T18:49:32.504Z] <5ba59281d73408ce4fa8fbb5> can u plz give a one liner pip code to downgrade it
[2019-04-25T18:49:36.154Z] <5ba59281d73408ce4fa8fbb5> ?
[2019-04-25T18:49:55.215Z] <55d21ee30fc9f982beadabb8> pip install scikit-learn==0.18
[2019-04-25T18:50:08.050Z] <5ba59281d73408ce4fa8fbb5> thanks a lot
[2019-04-25T18:57:32.865Z] <5ba59281d73408ce4fa8fbb5> now I m getting another error ImportError: cannot import name 'astype'
[2019-04-25T18:59:38.889Z] <5ba59281d73408ce4fa8fbb5> plz help
[2019-04-25T19:01:49.303Z] <5ba59281d73408ce4fa8fbb5> I have python 3.8.Does it matter by that too ?
[2019-04-30T06:55:10.557Z] <5cc7f07cd73408ce4fbf0399> hi all
[2019-04-30T07:41:43.002Z] <5cb72452d73408ce4fbdf818> *Hi all*
[2019-04-30T08:04:52.537Z] <5b3ed273d73408ce4f9fcb4e> Hi, I have a doubt on `TfidfVectorizer` in the `sklearn.feature_extraction.text` package.
[2019-04-30T08:05:30.832Z] <5b3ed273d73408ce4f9fcb4e> I see that stopwords like the which occur frequently in all documents I am trying, have an IDF value of 1
[2019-04-30T08:05:51.591Z] <5b3ed273d73408ce4f9fcb4e> Shouldnt the IDF value be 0 (because log of 1 is 0)?
[2019-04-30T08:06:03.104Z] <5b3ed273d73408ce4f9fcb4e> The example documents I am using are:
[2019-04-30T08:06:22.919Z] <5b3ed273d73408ce4f9fcb4e> > ["The quick brown fox jumped over the lazy dog.", 		"The dog.", 		"The fox"]
[2019-04-30T08:07:04.692Z] <5b3ed273d73408ce4f9fcb4e> I suspect the log is not being taken, how do I configure the vectorizer to take the log and get an IDF of 0?
[2019-04-30T09:58:41.594Z] <5b3ed273d73408ce4f9fcb4e> I think I figured out he IDF calculation. It seems to be `ln(N/df) + 1`. Where `N` is the total number of documents and `df` is the number of documents a particular term appears in
[2019-04-30T09:59:47.354Z] <5b3ed273d73408ce4f9fcb4e> So for the word the it is `ln(3/3) + 1` = `0+1`, which is why the value is 1. How do I configure the vectorizer not to add the 1?
[2019-05-05T19:43:08.008Z] <5a720f91d73408ce4f8b1403> can you tell me what is the api name for congressional voting records datasets?
[2019-05-05T19:43:19.719Z] <5a720f91d73408ce4f8b1403> as i have to import the dataset what i should write?
[2019-05-05T19:43:31.048Z] <5a720f91d73408ce4f8b1403> data = datasets.load_?????
[2019-05-05T20:01:27.409Z] <5a720f91d73408ce4f8b1403> please tell me how to find the right dataset name api
[2019-05-06T07:21:20.878Z] <589b9e0fd73408ce4f490ba4> @aarck you could try to see if that dataset is uploaded on OpenML in which case it would be `datasets.load_openml`. If not, it's up to you to write a loader for this dataset (or upload it to OpenML).
[2019-05-07T12:01:14.279Z] <5ccfd89fd73408ce4fbf7a43> hello everyone is there someone who knows about scikit-multiflow library ???
[2019-05-16T17:07:13.551Z] <5cdd97bed73408ce4fc07acf> @Praful-cs  , Hiii, let me help you with this.
[2019-05-20T08:57:32.127Z] <58de4778d73408ce4f551e04> Hello all, I have a question regarding joblib's "vendor" distribution present in scikit-learn `0.20.X` : is it up to date with the latest release of joblib? I know that the latest version of scikit-learn (`0.21.X` and above) are now using joblib as a dependency directly but I need to use scikit-learn `0.20.X` for python 2.7 support. Thank you! :)
[2019-05-20T08:59:26.193Z] <541a528b163965c9bc2053de> @jjerphan scikit-learn 0.20.3 is embedding joblib 0.13.0: https://github.com/scikit-learn/scikit-learn/blob/0.20.X/sklearn/externals/joblib/__init__.py#L109
[2019-05-20T09:00:06.613Z] <58de4778d73408ce4f551e04> Thank you @ogrisel for this quick answer!
[2019-05-20T09:01:15.344Z] <541a528b163965c9bc2053de> if we release 0.20.4 we should think of upgrading the joblib version as well. You can also set the `SKLEARN_JOBLIB_SITE=1` environment variable to use an independently installed version of joblib instead of the vendored version.
[2019-05-20T09:01:54.381Z] <541a528b163965c9bc2053de> Note however that future versions of joblib might stop supporting python 2 as well, so better start thinking of upgrading to Python 3 in any case :)
[2019-05-20T09:02:52.686Z] <58de4778d73408ce4f551e04> Thanks for the tips ; I would like to upgrade but I sadly can't in my setup <unconvertable> sigh. :)
[2019-05-20T09:03:55.824Z] <58de4778d73408ce4f551e04> Are there any significant changes between joblib 0.13.0 and 0.13.2 ?
[2019-05-20T09:04:59.788Z] <541a528b163965c9bc2053de> Potentially important bugfixes: https://github.com/joblib/joblib/blob/master/CHANGES.rst
[2019-05-20T09:05:17.407Z] <58de4778d73408ce4f551e04> Yes, I just came across this.
[2019-05-24T00:20:06.690Z] <5bb35f10d73408ce4faa17f3> @zzj0402_gitlab What is cross correlation? What is the relationship between it and convolution? I am not sure if it's cross product between data and convolution is just flipping the signal from both data sets to negative?
[2019-05-28T04:10:54.347Z] <58663b41d73408ce4f402d24> Hey guys!!! Can someone suggest me any dataset available on kaggle which contains both numerical and textual data? I have to apply machine learning as well as nlp concepts on it.
[2019-05-31T07:50:52.289Z] <5bc98094d73408ce4fabf741> Quick question, when using TfIdf vectorizer, would you consider it beneficial to lemmatize the body of the document before fitting?
[2019-05-31T07:52:57.817Z] <5b3ed273d73408ce4f9fcb4e> Lemmatization is always a good idea. Maybe you can run the vectorizer first and see in how many cases you got a wrong prediction because of no lemmatization and then take a call
[2019-05-31T07:55:15.817Z] <5bc98094d73408ce4fabf741> I will check that in practice then I guess as suggested. Thanks @srniranjan 
[2019-06-01T12:05:44.416Z] <5c7f95bad73408ce4fb9ca5e> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/DQTb/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/DQTb/image.png)
[2019-06-01T12:06:03.174Z] <5c7f95bad73408ce4fb9ca5e> how to handle with this error?
[2019-06-01T12:12:17.658Z] <5c7f95bad73408ce4fb9ca5e> Hey guys!!! Can someone suggest me any dataset available on kaggle which contains both numerical and textual data? I have to apply machine learning as well as nlp concepts on it.  refer this----->>>>https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling
[2019-06-01T12:12:36.781Z] <5c7f95bad73408ce4fb9ca5e> @mukul09 
[2019-06-04T14:11:46.130Z] <5cf106a0d73408ce4fc1d8b2> Can anybody please explain me batch decent gradient and the procedure to calculate it
[2019-06-04T14:12:13.036Z] <5cf106a0d73408ce4fc1d8b2> I have just started machine learning 
[2019-06-04T14:12:23.627Z] <5cf106a0d73408ce4fc1d8b2> In python
[2019-06-04T14:18:27.866Z] <5c13ca6dd73408ce4fb1f2d5> Batch gradient descent uses the whole dataset to calculate the gradient vector unlike mini-batch or stochastic gradient descent, thats the key point. The procedure in common words is: calculate partial derivatives for a cost function with respect to each coefficient using the whole dataset, make a gradient step, update coefficients
[2019-06-04T14:28:04.068Z] <5c651687d73408ce4fb7c2c8> Hi there. Try this link for batch gradient descent in python 
[2019-06-04T14:28:06.661Z] <5c651687d73408ce4fb7c2c8> https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f
[2019-06-04T15:29:14.773Z] <5cf106a0d73408ce4fc1d8b2> Thanks @isaacaugustus  and @gyrdym 
[2019-06-05T04:39:23.269Z] <5b3ed273d73408ce4f9fcb4e> @harshchaplot this is a great resource too: https://www.youtube.com/watch?v=bxe2T-V8XRs&list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU
[2019-06-05T05:48:00.347Z] <5cf106a0d73408ce4fc1d8b2> Thanks @srniranjan 
[2019-06-05T09:35:09.067Z] <5bc98094d73408ce4fabf741> Say you have over 9000 features which you would like to significantly reduce, what outside of PCA you can use to put down that number?
[2019-06-05T09:36:19.536Z] <5c13ca6dd73408ce4fb1f2d5> You may use lasso regression, for instance
[2019-06-05T09:36:50.864Z] <5cf106a0d73408ce4fc1d8b2> What is PCA?
[2019-06-05T09:37:14.770Z] <541a528b163965c9bc2053de> https://en.wikipedia.org/wiki/Principal_component_analysis
[2019-06-05T09:37:26.409Z] <5b3ed273d73408ce4f9fcb4e> PCA is a linear way of reducing your dimensions to a few Principal components. You can use Neural Networks for a non-linear approach for the same
[2019-06-05T09:38:25.566Z] <5b3ed273d73408ce4f9fcb4e> Basically the last hidden layer of your neural network is a representation of your input in much the same way projecting to principal components is
[2019-06-05T09:38:59.086Z] <5b3ed273d73408ce4f9fcb4e> The number of dimensions of this representation will be the number of neurons in the last hidden layer
[2019-06-05T09:41:14.539Z] <5cf106a0d73408ce4fc1d8b2> Ohk thanks @srniranjan 
[2019-06-05T09:43:34.427Z] <5bc98094d73408ce4fabf741> @gyrdym does it work with sparse matrices so I can use it with tfIds vectorized text?
[2019-06-05T09:43:50.690Z] <5bc98094d73408ce4fabf741> tfidf*
[2019-06-05T09:45:08.190Z] <5c13ca6dd73408ce4fb1f2d5> As far as I know, it works with sparse matrices, but I myself havent use it for such situations
[2019-06-05T09:45:15.356Z] <5bc98094d73408ce4fabf741> I see TruncatedSVD which uses LSA underneath for the decomposition of sparse matrices suggested by sklearn team
[2019-06-05T09:45:31.581Z] <5bc98094d73408ce4fabf741> but this method lets me go down only by about 200 features which is just not enough.
[2019-06-05T09:46:07.820Z] <5bc98094d73408ce4fabf741> and I need to cut it down say to 2000 features so I don't spend days training one model
[2019-06-05T09:46:23.213Z] <541a528b163965c9bc2053de> SVD is not using LSA underneath: LSA is the application of (truncated) SVD to text data represented as bag of words (e.g. TF-IDF vectors).
[2019-06-05T09:46:49.578Z] <541a528b163965c9bc2053de> SVD is a generic mathematical tool, LSA is one specific application of SVD to text mining.
[2019-06-05T09:47:04.156Z] <5b3ed273d73408ce4f9fcb4e> @piotr-mamenas 9k features is huge! Are you having such a big feature set because youre considering each word in the vocabulary as a feature?
[2019-06-05T09:47:30.073Z] <541a528b163965c9bc2053de> PCA is SVD on centered data.
[2019-06-05T09:47:45.405Z] <5bc98094d73408ce4fabf741> yes it is, not entire vocabulary, I have stop words filtered out and lemmas extracted
[2019-06-05T09:48:04.758Z] <5b3ed273d73408ce4f9fcb4e> Thats not the recommended approach when doing NLP
[2019-06-05T09:48:16.556Z] <541a528b163965c9bc2053de>  9k features features is pretty low number of features for bag of words vectors. Bag of Words is very very sparse.
[2019-06-05T09:48:32.515Z] <5b3ed273d73408ce4f9fcb4e> Look at word2vec to get dense vectors
[2019-06-05T09:48:59.930Z] <5bc98094d73408ce4fabf741> What would be the recommended way?
[2019-06-05T09:49:03.831Z] <5b3ed273d73408ce4f9fcb4e> Glove is also recommended to get dense vectors 
[2019-06-05T09:49:29.552Z] <5b3ed273d73408ce4f9fcb4e> Depends on your use case.. what are you trying to solve?
[2019-06-05T09:49:32.215Z] <541a528b163965c9bc2053de> SVD on TF-IDF / bag of words is a good fast preprocessing used as baseline for text classification / clustering and information retrieval / text mining.
[2019-06-05T09:54:17.498Z] <5bc98094d73408ce4fabf741> I have a set of classes with labelled data which I want to build several binary output models from, each model would just output 0, 1 to highlight whenever the article belongs to a class or not (1 class per model)
[2019-06-05T09:56:50.592Z] <541a528b163965c9bc2053de> LogisticRegression on TF-IDF vectors should be a good and fast baseline. You can also try: TF-IDF => TruncatedSVD => LogisticRegression or RandomForestClassifier and TF-IDF => NMF => LogisticRegression / RandomForestClassifier as alternatives.
[2019-06-05T09:58:00.454Z] <5bc98094d73408ce4fabf741> but this stays with the TfIdf approach, how would it handle the 9600 or so features?
[2019-06-05T09:58:02.414Z] <541a528b163965c9bc2053de> You can also try to include features derived from pretrained word vectors (e.g. word2vec or glove) and some fancy neural networks with keras or pytorch but I would try the above baselines first.
[2019-06-05T09:58:53.669Z] <541a528b163965c9bc2053de> > but this stays with the TfIdf approach, how would it handle the 9600 or so features?  How is this a problem? LogisticRegression works fine on high dimensional sparse data
[2019-06-05T10:00:11.198Z] <541a528b163965c9bc2053de> About the first question: lemmatization is not always a good idea depending on what you are try to predict.
[2019-06-05T10:01:26.191Z] <5bc98094d73408ce4fabf741> I asked that question the other day and wrote about it, lemmas might lose the context of whole sentences so in theory they will lower the accuracy but that's also a way to lower the amount of data to process
[2019-06-05T10:01:32.910Z] <5bc98094d73408ce4fabf741> Lets see the logistic regression approach then
[2019-06-05T10:01:35.734Z] <5bc98094d73408ce4fabf741> THanks
[2019-06-05T10:12:35.903Z] <5bc98094d73408ce4fabf741> @ogrisel this looks suprisingly good, it was training just for a few seconds on a set of only 3500 articles and the confusion matrix looks like this:
[2019-06-05T10:12:36.935Z] <5bc98094d73408ce4fabf741> array([[1262,   19],        [   0,    0]], dtype=int64)
[2019-06-05T10:15:31.335Z] <5bc98094d73408ce4fabf741> Accuracy:  0.985167837626854
[2019-06-05T10:15:43.563Z] <5bc98094d73408ce4fabf741> if it looks to good, there must be something wrong
[2019-06-05T10:30:02.809Z] <5c13ca6dd73408ce4fb1f2d5> Is your data well balanced? Maybe you need to shuffle the original dataset before do logistic regression. 
[2019-06-05T10:32:00.334Z] <5c13ca6dd73408ce4fb1f2d5> It would be good also to use cross validation to get the answer if your model is really so good
[2019-06-05T10:51:01.053Z] <5bc98094d73408ce4fabf741> Yeah, I am checking it.
[2019-06-05T11:20:30.779Z] <541a528b163965c9bc2053de> array([[1262,   19],        [   0,    0]], dtype=int64) means that the mode always predict the class 0. It's the constant predictor (probably caused too much bias / regularization)
[2019-06-05T11:22:36.360Z] <541a528b163965c9bc2053de> Your test data is actually imbalanced with  19 to 1262 ratio. 1262 / (12 + 1262) == 0.99 accuracy which is weird because this does not match your reported accuracy.
[2019-06-05T11:23:18.875Z] <541a528b163965c9bc2053de> @piotr-mamenas I hope you did a proper train test split :)
[2019-06-05T11:24:14.106Z] <541a528b163965c9bc2053de> You should use a balanced accuracy or ROC AUC or precision / recall / f-beta score to evaluate your model instead of the raw accuracy.
[2019-06-05T14:05:59.888Z] <5bc98094d73408ce4fabf741> ``` UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.   'recall', 'true', average, warn_for) ```
[2019-06-05T14:06:11.863Z] <5bc98094d73408ce4fabf741> the train test split was 0.75:0.25 ratio
[2019-06-05T14:08:38.764Z] <5bc98094d73408ce4fabf741> It can't predict 0.98 with constant class because you got 1200/5000 samples class 1, and the TP is 1262
[2019-06-05T14:10:37.214Z] <5bc98094d73408ce4fabf741> and train test split takes into account balance of classes from what I know
[2019-06-05T14:10:55.093Z] <5bc98094d73408ce4fabf741> @gyrdym 
[2019-06-05T14:12:57.030Z] <5bc98094d73408ce4fabf741> the overall class balance of the entire dataset is a difficult topic, the type of class I am trying to detect may appear in every 1/100 articles but as said I have 1200 samples of "1" and 3800 samples of "0" so I am guessing increasing the "0" sample would prove beneficial generally
[2019-06-05T14:16:02.776Z] <541a528b163965c9bc2053de> check the content of your `y_test`: the recall warning seems to indicate that you only have negative samples (samples from the majority class) in your test set.
[2019-06-05T14:23:44.045Z] <5bc98094d73408ce4fabf741> ok got it @ogrisel 
[2019-06-05T14:23:55.090Z] <5bc98094d73408ce4fabf741> ``` Accuracy:  0.8227946916471507 Precision:  0.9347826086956522 Recall:  0.28013029315960913 ```
[2019-06-05T14:24:10.675Z] <5bc98094d73408ce4fabf741> ``` array([[968,   6],        [221,  86]], dtype=int64) ``` 
[2019-06-05T14:24:25.919Z] <5bc98094d73408ce4fabf741> looks different now
[2019-06-05T14:25:07.316Z] <5bc98094d73408ce4fabf741> I shuffled the dataset on the train test split and it changed completely as you can see
[2019-06-05T14:26:00.540Z] <5bc98094d73408ce4fabf741> but the score is anyway pretty impressive considering the sample and no hyperparameter tuning
[2019-06-05T14:26:23.527Z] <5bc98094d73408ce4fabf741> thanks
[2019-06-05T14:27:21.982Z] <5c13ca6dd73408ce4fb1f2d5> You may also try stratified shuffled split instead of the regular one - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html
[2019-06-05T14:28:03.953Z] <5bc98094d73408ce4fabf741> I will check it out, thanks @gyrdym 
[2019-06-05T14:28:22.729Z] <5c13ca6dd73408ce4fb1f2d5> You're welcome
[2019-06-05T14:34:23.297Z] <5bc98094d73408ce4fabf741> Anyone has 2$ million dollars by the way? : p
[2019-06-05T15:15:21.353Z] <5bc98094d73408ce4fabf741> oh and that's what I like, I added 6000 articles to the 0 class and I already have 0.92
[2019-06-05T15:15:24.068Z] <5bc98094d73408ce4fabf741> ``` array([[2492,    7],        [ 235,   47]], dtype=int64) ```
[2019-06-05T16:45:58.667Z] <541a528b163965c9bc2053de> Accuracy is rather meaningless for unbalanced problems. Look at precision and recall and plot the precision recall curve. Here a recall of 0.2 might be too bad for your classifier to be useful. It depends on the application of your classifier
[2019-06-05T16:47:25.636Z] <541a528b163965c9bc2053de> If you do parameter tuning of your text classification pipeline, use scoring="balanced_accuracy" or "f1_score".
[2019-06-05T16:48:28.626Z] <541a528b163965c9bc2053de> See the end of this tutorial on how to build a pipeline and do parameter tuning: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#evaluation-of-the-performance-on-the-test-set
[2019-06-05T18:38:57.856Z] <5bc98094d73408ce4fabf741> That will be useful, thanks @ogrisel 
[2019-06-05T21:52:17.221Z] <5553244215522ed4b3e05112> hi guys does scikit sdk or articles available for go language
[2019-06-06T01:13:14.956Z] <5cf106a0d73408ce4fc1d8b2> https://www.quora.com/Go-vs-Python-which-is-better-for-AI
[2019-06-06T17:36:09.547Z] <5bc98094d73408ce4fabf741> anyone on windows?
[2019-06-06T17:36:43.584Z] <5bc98094d73408ce4fabf741> I am trying to run a script with just "python script.py" but I am getting missing module errors and I am sure I should have this installed
[2019-06-06T17:36:55.198Z] <5bc98094d73408ce4fabf741> these*
[2019-06-06T18:24:06.841Z] <5cf106a0d73408ce4fc1d8b2> Check the spellings of the modules you have imported
[2019-06-06T18:24:36.692Z] <5cf106a0d73408ce4fc1d8b2> And also check whether the modules you imported contain that specific module
[2019-06-06T18:25:11.415Z] <5cf106a0d73408ce4fc1d8b2> And just as shortcut run pip install on all the modules to ensure everything has been properly installed
[2019-06-06T18:27:10.726Z] <5cf106a0d73408ce4fc1d8b2> It also depends on the version of python you are using
[2019-06-07T00:55:07.738Z] <5cf106a0d73408ce4fc1d8b2> Python 2.7 does not support many modules that are supported by python 3.6 and other newer versions 
[2019-06-07T11:34:29.050Z] <541a528b163965c9bc2053de> @piotr-mamenas on windows I would recommend you to use conda environments: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html (or alternatively Python 3 builtin venv module) to get a fine control on the list of packages installed in the currently active environment
[2019-06-08T08:37:36.240Z] <5c70f4fad73408ce4fb8b1b8> *IIT BHU* conducting Coding fest (online as well as offline also) which is *free of cost* + lots of goodies  <unconvertable>  Some information regarding codefest 2019  Just registered yourself .   https://codefest.tech/login?referral=qbK0w2UF   1.Annual coding fest of CSE Department ,IIT BHU 2. 8 events covering almost every domain of Computer Science and Engineering 3. Global participation from more than 100 countries 4. *Cash prize* of nearly *500k* ,goodies an other merchandise as well 5. No registeration cost, *certificate to all participants* 6. *Onsite events,HaXplore,accomodation,goodies and food <unconvertable> will be provided to everyone ,travel <unconvertable> reimbursement as well*  *Share with your buddies also*
[2019-06-09T11:16:07.480Z] <5bc98094d73408ce4fabf741> @ogrisel that's what I am doing locally, I work with a jupyter notebook with a separate tensorflow + scikit environment installed and used with "activate" and conda
[2019-06-09T11:16:54.957Z] <5bc98094d73408ce4fabf741> I was asking because I've got a separate lightweight service running inside of container and I wanted to keep it limited to just pip and relevant libs on production
[2019-06-09T11:17:33.099Z] <5bc98094d73408ce4fabf741> In the container I don't want to use conda
[2019-06-09T16:06:52.887Z] <5824aa0dd73408ce4f3501a2> @piotr-mamenas have you considered Miniconda as a lightweight alternative? https://docs.conda.io/en/latest/miniconda.html
[2019-06-09T16:07:23.140Z] <5824aa0dd73408ce4f3501a2> I think there is also the odd dockerhub image to build of
[2019-06-09T20:46:50.671Z] <541a528b163965c9bc2053de> @piotr-mamenas use a venv and pip install everything you need in it. You can also prepare a lightweight conda environment with some tricks: https://twitter.com/jiminy_crist/status/1135637901457395712
[2019-06-11T09:59:14.190Z] <5b3ed273d73408ce4f9fcb4e> I have an input sparse matrix in the csr format. Any suggestions on how to generate mini batches for training from this input?
[2019-06-11T17:30:52.123Z] <5cf106a0d73408ce4fc1d8b2> U can use the sklearn.model_selection.train_test_split
[2019-06-11T17:31:24.937Z] <5cf106a0d73408ce4fc1d8b2> https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
[2019-06-12T04:02:34.224Z] <5b3ed273d73408ce4f9fcb4e> does it work with sparse matrices?
[2019-06-12T04:52:26.219Z] <5cf106a0d73408ce4fc1d8b2> I think it will
[2019-06-12T11:12:38.902Z] <55d21ee30fc9f982beadabb8> you can use `sklearn.utils.safe_indexing` that will return a matrix given a set of indices
[2019-06-12T11:12:51.240Z] <55d21ee30fc9f982beadabb8> and will work with dataframe, array, sparse matrix
[2019-06-12T11:13:09.704Z] <5b3ed273d73408ce4f9fcb4e> Great, thanks
[2019-06-12T11:15:08.395Z] <55d21ee30fc9f982beadabb8> depending what you are doing with mini-batch, we have some generator of mini-batch in imbalanced-learn
[2019-06-12T11:15:08.658Z] <55d21ee30fc9f982beadabb8> http://imbalanced-learn.org/en/stable/api.html#module-imblearn.keras
[2019-06-12T11:15:27.250Z] <55d21ee30fc9f982beadabb8> you can check the implementation if you want to bypass the resampling stage
[2019-06-12T14:13:11.231Z] <5cec1aa6d73408ce4fc17534> hi everyone 
[2019-06-12T14:13:35.919Z] <5cec1aa6d73408ce4fc17534> can i ask you something
[2019-06-12T14:14:08.130Z] <5cec1aa6d73408ce4fc17534> is there autocomplete C# codes in komodo
[2019-06-13T09:03:14.405Z] <541a528b163965c9bc2053de> @akil101 please ask on a channel related to komodo or C# development.
[2019-06-15T16:51:37.093Z] <5bc98094d73408ce4fabf741> I wonder what you guys think.
[2019-06-15T16:52:09.398Z] <5bc98094d73408ce4fabf741> Say you have a terrible unbalanced text data set that you vectorize, 1:50 ratio
[2019-06-15T16:52:35.898Z] <5bc98094d73408ce4fabf741> binary classification
[2019-06-15T16:53:02.805Z] <5bc98094d73408ce4fabf741> would you consider it a bad practice to lower the imbalance by duplicating proportionally the first class?
[2019-06-15T16:54:40.389Z] <5bc98094d73408ce4fabf741> so practically speaking, if I have 1000 articles with class 0 and 50000 with class 1, just copy each one of the class 0 to get another set of 1000 articles and push it into the training set so I have a 1:25 ratio instead?
[2019-06-15T16:55:06.846Z] <5bc98094d73408ce4fabf741> Similar to how its done with image classification
[2019-06-15T18:29:57.422Z] <5bc98094d73408ce4fabf741> Another thing, how would you measure quality of scrapped data provided from 3rd party data science firm? Text.
[2019-06-15T18:31:38.649Z] <5bc98094d73408ce4fabf741> I would assume if i do cluster analysis on the data and get word frequency per cluster I should be able to see more or less but that doesn't give me a full picture
[2019-06-19T22:58:45.862Z] <54d4a1d6db8155e6700f853b> @piotr-mamenas https://www.youtube.com/watch?v=EUiIydNBIbE&list=PL_pVmAaAnxIQGzQS2oI3OWEPT-dpmwTfA&index=10 and https://www.youtube.com/watch?v=Eix70D-H5ag&list=PL_pVmAaAnxIQGzQS2oI3OWEPT-dpmwTfA&index=11 are relevant to the first question
[2019-06-19T22:59:18.971Z] <54d4a1d6db8155e6700f853b> For imbalanced data I would worry about evaluation first
[2019-06-20T00:53:50.415Z] <55f1d9790fc9f982beb04bb2> @piotr-mamenas yeah as long as you are randomly sampling, you can either upsample from the smaller class or down sample..  or use an algorithm that can tolerate unbalanced data.. you could even turn the problem into an anomaly detection one.. if the smaller class has only very few data points.. There are other techniques like SMOTE .. that you could look into.. as well.
[2019-06-20T10:06:39.546Z] <5bc98094d73408ce4fabf741> Thanks for the answers @amueller and @rahulunair , I wasn't aware you have models for working with imbalanced data sets specifically, how do they fare against large sparse matrices, I am talking word vectors?
[2019-06-20T16:49:55.590Z] <55f1d9790fc9f982beb04bb2> @piotr-mamenas I would consider the word vectors as the input embeddings? and if you are looking to classify something, you can look into SVMs that deal with unbalanced classes, essentially it weights the unbalanced class differently.. scikit-learn has a section for that: https://scikit-learn.org/stable/modules/svm.html
[2019-06-20T16:54:40.547Z] <55f1d9790fc9f982beb04bb2> or try a tree based algorithms to see how your accuracy numbers and ROC curve is
[2019-06-20T16:54:50.672Z] <55f1d9790fc9f982beb04bb2> for accuracy , check out: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html
[2019-06-20T18:52:07.291Z] <5bc98094d73408ce4fabf741> Thanks @rahulunair your response is much appreciated, I will take a look at it.
[2019-06-21T17:24:27.994Z] <564789be16b6c7089cbab8b7> if you are doing image classification using scikit learn, do you have to convert the images into 1d arrays first?
[2019-06-21T17:24:45.625Z] <55d21ee30fc9f982beadabb8> yes
[2019-06-21T17:25:03.732Z] <564789be16b6c7089cbab8b7> @glemaitre  hmm... that seems to lose some vital information
[2019-06-21T17:25:16.712Z] <564789be16b6c7089cbab8b7> i..e that pixels next to each other are related
[2019-06-21T17:25:16.760Z] <55d21ee30fc9f982beadabb8> you can look at an example of `load_digits` to see that the 8x8 images are transformed to 1d 64 arrays
[2019-06-21T17:25:17.411Z] <541a528b163965c9bc2053de> you can use a pre-trained convolutional neural network to extract interesting features
[2019-06-21T17:25:46.508Z] <541a528b163965c9bc2053de> or you can use scikit-image HoG features for instance. Depending on the kinds of images, it might be enough.
[2019-06-21T17:25:47.180Z] <55d21ee30fc9f982beadabb8> > you can use a pre-trained convolutional neural network to extract interesting features  which a much better approach
[2019-06-21T17:26:08.424Z] <564789be16b6c7089cbab8b7> HoG features?
[2019-06-21T17:26:35.868Z] <564789be16b6c7089cbab8b7> Histogram of Oriented Gradients ?
[2019-06-21T17:26:43.586Z] <541a528b163965c9bc2053de> Histogram of Oriented Gradients
[2019-06-21T17:26:45.778Z] <541a528b163965c9bc2053de> yes
[2019-06-21T17:27:05.922Z] <55d21ee30fc9f982beadabb8> https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html
[2019-06-21T17:27:31.341Z] <564789be16b6c7089cbab8b7> all very interesting thanks. It seems a weakness somehow in the general non-NN classification model that it can't take advantage of 2d data
[2019-06-21T17:28:36.653Z] <55d21ee30fc9f982beadabb8> I think that I have 2 quick examples showing a bit how things can be connected:
[2019-06-21T17:28:38.553Z] <55d21ee30fc9f982beadabb8> https://scikit-image.org/docs/dev/auto_examples/applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-applications-plot-haar-extraction-selection-classification-py
[2019-06-21T17:28:46.802Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/6509/files
[2019-06-21T17:28:49.423Z] <564789be16b6c7089cbab8b7> I suppose even in 1d random forests etc are invariant to permutations of the input array
[2019-06-21T17:29:16.584Z] <564789be16b6c7089cbab8b7> @glemaitre  thanks
[2019-06-21T17:29:34.457Z] <541a528b163965c9bc2053de> yes, you have to do feature engineering first. You can consider the 2D conv layers before the final flatten / global average pooling as a feature extractor and the last fully connected layers as a standard classifier. It's just that both the feature extraction and the classifier are trained end-to-end together
[2019-06-21T17:29:44.780Z] <564789be16b6c7089cbab8b7> it's only really the convolutions that  take advantage of the neighborhood of pixels I suppose
[2019-06-21T17:30:18.035Z] <564789be16b6c7089cbab8b7> @ogrisel  right.  
[2019-06-21T17:30:29.839Z] <541a528b163965c9bc2053de> but nowawdays, (convolutional) neural networks are almost always the good solution for image classification, unless you have very specific prior knowledge on the image you want to classify.
[2019-06-21T17:31:02.314Z] <564789be16b6c7089cbab8b7> I wonder if random forests could be changed to take arrays of pairs, say, as inputs
[2019-06-21T17:31:21.809Z] <564789be16b6c7089cbab8b7> @ogrisel  that's true but I am also thinking of time series data
[2019-06-21T17:31:40.924Z] <564789be16b6c7089cbab8b7> where it makes a big difference if two values are from successive times or not
[2019-06-21T17:31:44.260Z] <541a528b163965c9bc2053de> > it's only really the convolutions that  take advantage of the neighborhood of pixels I suppose  No: if you have deep conv layers with downsampling (strides or max pooling for instance) the conv layers can capture large high level complex patterns that span a large receptive field.
[2019-06-21T17:32:10.158Z] <564789be16b6c7089cbab8b7> @ogrisel  you said No but I read your answer as yes :)
[2019-06-21T17:32:34.564Z] <541a528b163965c9bc2053de> we need an example of some standard feature engineering you can do on time windows for time series forecasting / classification.
[2019-06-21T17:32:59.794Z] <564789be16b6c7089cbab8b7> @ogrisel  that would be good to see
[2019-06-21T17:33:01.396Z] <541a528b163965c9bc2053de> I misread the original quote, then yes.
[2019-06-21T17:33:19.564Z] <541a528b163965c9bc2053de> But what I meant is that deep conv net can model non-local patterns
[2019-06-21T17:33:48.227Z] <564789be16b6c7089cbab8b7> @ogrisel yes . What I meant is that without any convolutions you don't get to see local patterns
[2019-06-21T17:34:42.306Z] <564789be16b6c7089cbab8b7> on an NN topic, is there software to give you a good guess at a reasonable architecture for a classification task? I saw autokeras but it's pretty heavy.
[2019-06-21T17:34:46.538Z] <541a528b163965c9bc2053de> if you really want to use decision trees for image classification you might be interested in https://arxiv.org/abs/1905.10073 but this is not (and will not) be implemented in scikit-learn ;)
[2019-06-21T17:35:19.378Z] <564789be16b6c7089cbab8b7> @ogrisel thanks! Why won't it be implemented? Because it doesn't work or coding resources?
[2019-06-21T17:35:37.445Z] <541a528b163965c9bc2053de> I don't know what is the practical state of the art for architecture search for image classification
[2019-06-21T17:35:58.562Z] <564789be16b6c7089cbab8b7> really I am secretly interested in time series 
[2019-06-21T17:35:59.039Z] <541a528b163965c9bc2053de> because it is not a standard, established method.
[2019-06-21T17:36:03.869Z] <564789be16b6c7089cbab8b7> @ogrisel  got you
[2019-06-21T17:36:23.267Z] <564789be16b6c7089cbab8b7> image classification was just interesting because the data is in 2d
[2019-06-21T17:36:33.288Z] <541a528b163965c9bc2053de> https://scikit-learn.org/stable/faq.html#what-are-the-inclusion-criteria-for-new-algorithms
[2019-06-21T17:36:35.260Z] <564789be16b6c7089cbab8b7> but even in 1d it seems unclear to me what the right thing to do is
[2019-06-21T17:36:52.436Z] <564789be16b6c7089cbab8b7> @ogrisel  I have read those guidelines! They seem very sensible to me
[2019-06-21T17:37:03.956Z] <541a528b163965c9bc2053de> https://scikit-learn.org/stable/faq.html#why-is-there-no-support-for-deep-or-reinforcement-learning-will-there-be-support-for-deep-or-reinforcement-learning-in-scikit-learn
[2019-06-21T17:37:07.221Z] <564789be16b6c7089cbab8b7> I greatly admire how scikit learn is run in general
[2019-06-21T17:37:27.215Z] <564789be16b6c7089cbab8b7> @ogrisel  I read that second link too :)
[2019-06-22T06:26:11.022Z] <5cb5be0ed73408ce4fbddb96> hi
[2019-06-22T21:03:30.577Z] <5872a729d73408ce4f421fb8> What version of OpenMP does scikit-learn require? Is 2.5 sufficient?
[2019-06-23T13:42:36.081Z] <541a528b163965c9bc2053de> Probably, we use OpenMP via the `prange` construct of Cython.
[2019-07-03T19:25:54.993Z] <5bd32ac1d73408ce4facdf3c> Hey guys, so I'm new to scikit, so please bear with me. I have a pandas dataframe that looks like this: [email, businessId, manager, app1, app2, app3, ... , app170] So essentially one row defines one user that has either a 1 or NaN on each of the appX columns specifying if they have that app or not. 
[2019-07-03T19:26:39.713Z] <5bd32ac1d73408ce4facdf3c> What I want is a classifier that given email, businessId, and manager ....would return a list of apps should have
[2019-07-03T19:27:26.216Z] <5bd32ac1d73408ce4facdf3c> I've got the data in that format as i specified, what are the models do you guys think would b good for creating this type of classifier? And how would i go about this in general?
[2019-07-04T20:26:48.097Z] <5bc98094d73408ce4fabf741> How I get the individual components from classification_report?
[2019-07-04T20:26:51.887Z] <5bc98094d73408ce4fabf741> I found this: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format
[2019-07-04T20:27:19.754Z] <5bc98094d73408ce4fabf741> sorry, this: https://stackoverflow.com/questions/48417867/access-to-numbers-in-classification-report-sklearn
[2019-07-04T20:28:57.832Z] <5bc98094d73408ce4fabf741> but the output_dict=True doesn't seem to work, I am receiving an error stating this parameter does not exist on the classification_report function, I also don't trust precision_recall_fscore_support, plus it misses accuracy
[2019-07-05T23:24:10.018Z] <5c77a43ed73408ce4fb93081> @piotr-mamenas Please check the version of sklearn you are using. I believe `output_dict` was added in 0.20.
[2019-07-06T13:02:56.023Z] <5bc98094d73408ce4fabf741> @thomasjpfan yup, I figured it out yesterday and after some fight with tensorflow dependencies I got it running
[2019-07-10T16:29:35.805Z] <5c49f26dd73408ce4fb5d342> hi everyone
[2019-07-13T14:56:21.950Z] <569fe132e610378809bd5552> Hello from the SciPy sprints!
[2019-07-13T15:31:03.695Z] <5b4a4878d73408ce4fa0e331> Hi All, also from the SciPy sprints :)
[2019-07-13T16:08:00.588Z] <54d4a1d6db8155e6700f853b> Welcome everybody :)
[2019-07-13T16:29:43.651Z] <54d4a1d6db8155e6700f853b> @thomasjpfan wanna look at https://github.com/scikit-learn/scikit-learn/pull/14326 ?
[2019-07-13T22:30:31.117Z] <54d4a1d6db8155e6700f853b> anyone wanna look at https://github.com/scikit-learn/scikit-learn/pull/14320 ?
[2019-07-17T17:11:15.989Z] <5ba59281d73408ce4fa8fbb5> how can i use yolo to detect numbers in sudoku puzzle?
[2019-07-17T17:11:57.887Z] <5ba59281d73408ce4fa8fbb5> I want to read those numbers but Canny, Hough, contour aren't working any good
[2019-07-18T06:26:23.908Z] <5d300aebd73408ce4fc65994> Please let me know your opinion on this https://github.com/scikit-learn/scikit-learn/issues/4450#issuecomment-512681856
[2019-07-24T05:18:38.330Z] <5bf776ebd73408ce4fafd6e3> Hello People,
[2019-07-24T05:19:19.288Z] <5bf776ebd73408ce4fafd6e3> Do we have any package like NLTK to support your languages other than English
[2019-07-24T06:50:14.104Z] <54fdd51a15522ed4b3dd04b7> @venkyyuvy this looks 
[2019-07-24T06:53:27.582Z] <54fdd51a15522ed4b3dd04b7> Like a good feature to have in LabelEncoder. Would this make sense as a feature @amueller 
[2019-07-26T12:22:47.501Z] <58f1ce53d73408ce4f588a29> Hi
[2019-07-26T12:27:35.326Z] <5baf7d9ad73408ce4fa9c9b2> @adityap31 we choose to only officially support English in our documentation, to avoid having to maintain different versions
[2019-07-30T12:34:44.737Z] <5bf776ebd73408ce4fafd6e3> Thanks @NicolasHug 
[2019-07-30T14:02:49.514Z] <5d36d216d73408ce4fc6ba51> Please the best c# tutorial online
[2019-07-30T14:03:19.192Z] <5d36d216d73408ce4fc6ba51> Give me ideas
[2019-07-30T18:37:28.520Z] <54d4a1d6db8155e6700f853b> @Emoruwa since you're not the first one asking this here: what gave you the idea of asking about C# in a channel about a Python library for machine learning?
[2019-07-31T14:30:51.081Z] <5944c1e5d73408ce4f67f652> Hi, everyone. My name is Manish and It's nice to meet you all. I used SK learn for one of my projects this summer and  I really love this library. I want to start contributing to it. I'm new to open source stuff and I don't know how to get started. I checked issues under good first issue label but I'm not able to understand anything. Can anyone plz guide me with this??
[2019-07-31T16:49:55.639Z] <54d4a1d6db8155e6700f853b> @ManishAradwad welcome! the easiest way is probably to ask directly on the issue. Have you checked out the contributors guide?
[2019-08-01T03:15:20.875Z] <5944c1e5d73408ce4f67f652> Yes, I'm now going through the repo first. I'll then go for the issues. Thanks for the reply!
[2019-08-01T15:57:44.340Z] <54d4a1d6db8155e6700f853b> I wouldn't try going to the repo, it's a lot. I would start with the contributor docs
[2019-08-01T15:58:23.097Z] <54d4a1d6db8155e6700f853b> even understanding how we set up and run tests would probably take me a week to understand
[2019-08-01T21:21:42.809Z] <564789be16b6c7089cbab8b7> is there something in scikit learn for 4000 dimension regression where I know I only one or two of the coefficients to be non-zero?
[2019-08-01T21:26:49.629Z] <564789be16b6c7089cbab8b7> something like forward stepwise regression?
[2019-08-02T21:03:50.397Z] <54d4a1d6db8155e6700f853b> not yet. mlxtend has it and there's a PR
[2019-08-02T21:06:05.899Z] <54d4a1d6db8155e6700f853b> #8684
[2019-08-04T09:09:22.772Z] <564789be16b6c7089cbab8b7> @amueller  Thanks! I will take a look at mixtend which I didn't know about
[2019-08-04T09:10:48.139Z] <5bcb2df0d73408ce4fac1a51> Can anyone please provide a good source of how to deal with categorical data? It's very helpful and thanku
[2019-08-04T13:21:25.143Z] <5944c1e5d73408ce4f67f652> @amueller  Hi!! As you said I've gone through the contributing guides and set up the development environment. Can you plz tell me what should I do next. Thanks for the help!!
[2019-08-05T14:19:09.428Z] <54d4a1d6db8155e6700f853b> @ManishAradwad look at things tagged as "good first issue" and "help wanted" as outlined in the contributing guide
[2019-08-05T14:45:09.285Z] <5a7aea3dd73408ce4f8c133a> Hello guys, maybe anyone can help me out here. I am running following validation code: ``` train_scores, valid_scores = validation_curve(estimator=pipeline,  # estimator (pipeline)                                               X=features,  # features matrix                                               y=target,  # target vector                                              param_name='pca__n_components',                                              param_range=range(1,50),  # test these k-values                                              cv=5,  # 5-fold cross-validation                                              scoring='neg_mean_absolute_error')  # use negative validation ```  in the same `.py` file on different machines, which I would name `#1 localhost`, `#2 staging`, `#3 live`, `#4 live`  localhost and staging have both i7 cpus, localhost needs around 40s for the validation, staging needs around 13-14 seconds  live (#3) and live (#4) need almost 10 minutes for executing the validation - both of these servers have intel cpus with 48 threads.   In order to get more "trustworthy" numbers I dockerized the images and run them on the servers. Anyone has an idea why the speed is so different? 
[2019-08-05T14:47:30.369Z] <54d4a1d6db8155e6700f853b> how many cores do you have in localhost and staging?
[2019-08-05T14:48:00.539Z] <54d4a1d6db8155e6700f853b> could be that you're overallocating processes in the estimator and parallelization actually hurts you
[2019-08-05T14:50:01.649Z] <5a7aea3dd73408ce4f8c133a> @amueller localhost and staging are both with i7 (4 cores and 8 threads)
[2019-08-05T14:50:31.044Z] <54d4a1d6db8155e6700f853b> what's pipeline?
[2019-08-05T14:50:39.556Z] <54d4a1d6db8155e6700f853b> so the number of cores is the likely difference, right?
[2019-08-05T14:51:24.045Z] <5a7aea3dd73408ce4f8c133a> yeah, live 3 and live 4 have 48 threads, 24 cores. Pipeline: ``` from sklearn.linear_model import LinearRegression model = LinearRegression() from sklearn.preprocessing import PolynomialFeatures poly_transformer = PolynomialFeatures(degree=2, include_bias=False) from sklearn.pipeline import Pipeline pipeline = Pipeline([('poly', poly_transformer), ('reg', model)]) ```
[2019-08-05T15:29:26.539Z] <5a7aea3dd73408ce4f8c133a> After profiling, I saw this (slowest time on bottom, sorted by 3rd column): ```      4150  208.706    0.050  208.706    0.050 {built-in method numpy.dot}       245   13.112    0.054   13.360    0.055 decomp_svd.py:16(svd)      2170  142.567    0.066  143.360    0.066 decomp_lu.py:153(lu) ```  Just executed `python -m cProfiler validation.py`
[2019-08-05T15:48:42.216Z] <54d4a1d6db8155e6700f853b> can you try to benchmark just calling svd directly without any sklearn around it?
[2019-08-05T15:49:17.721Z] <54d4a1d6db8155e6700f853b> if that's a pure scipy issues that would be good to isolate
[2019-08-05T15:53:40.771Z] <5a7aea3dd73408ce4f8c133a> how can I isolate it, make a separate `.py` and run `cProfiler` on it?
[2019-08-05T16:32:21.309Z] <54d4a1d6db8155e6700f853b> make a py file that calls scipy.linalg.svd without using sklearn
[2019-08-05T17:31:06.166Z] <54d4a1d6db8155e6700f853b> lol I am killing the sorting in the pull requests in the issue tracker with adding tags. sorry lol
[2019-08-05T18:52:46.807Z] <5a7aea3dd73408ce4f8c133a> I will try this and report here. Any ideas what could be the reason? Localhost and staging are intel i7, live3 and live4 are xeon cpus, do you think mkl would improve speed or setting up the environment in another way? (Tensorflow recommends custom compile for speed for example)
[2019-08-05T18:54:07.461Z] <54d4a1d6db8155e6700f853b> how did you install numpy and scipy? if you did custom compilation that might be a reason. if you install binaries they will use mkl or openblas, either of which should be quite fast
[2019-08-05T18:59:10.539Z] <5a7aea3dd73408ce4f8c133a> Using pipenv, numpy 1.16.x i think
[2019-08-05T18:59:25.324Z] <5a7aea3dd73408ce4f8c133a> They are using openblas
[2019-08-05T19:11:49.400Z] <54d4a1d6db8155e6700f853b> well that should work
[2019-08-06T06:38:13.458Z] <5a7aea3dd73408ce4f8c133a> @amueller I don't know if this helps: I ran ``` from scipy import linalg import numpy as np m, n = 9, 6 a = np.random.randn(m, n) + 1.j*np.random.randn(m, n) U, s, Vh = linalg.svd(a) print(U.shape,  s.shape, Vh.shape) ```  `cProfile` says: ```       394    0.004    0.000    0.017    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)       900    0.004    0.000    0.004    0.000 {built-in method posix.stat}         1    0.006    0.006    0.006    0.006 lil.py:23(lil_matrix)     81/24    0.007    0.000    0.011    0.000 sre_compile.py:64(_compile)   402/399    0.011    0.000    0.022    0.000 {built-in method builtins.__build_class__}     212/1    0.023    0.000    0.222    0.222 {built-in method builtins.exec}       190    0.024    0.000    0.024    0.000 {built-in method marshal.loads}     39/37    0.038    0.001    0.043    0.001 {built-in method _imp.create_dynamic} ``` (sorted by second column)   ```         9    0.000    0.000    0.000    0.000 __future__.py:79(__init__)         9    0.000    0.000    0.000    0.000 _globals.py:77(__repr__)         9    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}         9    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}         9    0.000    0.000    0.000    0.000 os.py:742(encode)         9    0.000    0.000    0.001    0.000 abc.py:151(register)         9    0.000    0.000    0.001    0.000 datetime.py:356(__new__)       900    0.001    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)       900    0.004    0.000    0.004    0.000 {built-in method posix.stat}       936    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:321(<genexpr>)        96    0.000    0.000    0.000    0.000 enum.py:630(<lambda>)     39/37    0.038    0.001    0.043    0.001 {built-in method _imp.create_dynamic}         1    0.002    0.002    0.002    0.002 __init__.py:259(_reset_cache)         1    0.006    0.006    0.006    0.006 lil.py:23(lil_matrix) ``` (sorted by third column)
[2019-08-06T06:38:32.434Z] <5a7aea3dd73408ce4f8c133a> this is on the 24 core machine
[2019-08-06T06:43:27.458Z] <5a7aea3dd73408ce4f8c133a> @amueller when I run this code: ``` train_scores, valid_scores = validation_curve(estimator=pipeline,  # estimator (pipeline)                                               X=features,  # features matrix                                               y=target,  # target vector                                              param_name='pca__n_components',                                              param_range=range(1,50),  # test these k-values                                              cv=5,  # 5-fold cross-validation                                              scoring='neg_mean_absolute_error')  # use negative validation ```  directly on the host (with 24 cores) I get ~30 seconds. When I run it directly on localhost (4 cores, 8 threads) I get around 30-40 seconds as well. When I run inside docker with cpu limit of 6 cores and 6GB RAM, it needs almost 10 minutes. Inside a VirtualBox with 2 cores.. around 30 seconds, seems scikit does not play well with docker limitations which uses the CFS Scheduler: [link](https://docs.docker.com/config/containers/resource_constraints/#configure-the-default-cfs-scheduler)
[2019-08-06T06:47:18.169Z] <5a7aea3dd73408ce4f8c133a> Also found out that if I adjust `param_range` to `range(1,5)`the code runs much faster (I am no data scientist)
[2019-08-06T07:02:57.877Z] <5a7aea3dd73408ce4f8c133a> It seems `validation_curve` does not really profit from multithreading/multiprocessing. I get almost same results on intel i7 (4 cores) and intel xeon (24 cores). The problem is that if the validation curve runs on the xeon machines.. it uses all cores and the machine is overloaded, which makes no sense, really :) 
[2019-08-06T07:09:10.313Z] <5a7aea3dd73408ce4f8c133a> `cv=3` makes it faster as well
[2019-08-06T13:11:31.945Z] <5c34f182d73408ce4fb408a6> How should I install the dependencies for local development of scikit-learn?
[2019-08-06T14:26:07.139Z] <54d4a1d6db8155e6700f853b> @sameshl https://scikit-learn.org/stable/developers/advanced_installation.html#install-bleeding-edge
[2019-08-06T14:27:09.367Z] <54d4a1d6db8155e6700f853b> I'd recommend using conda and doing ``conda install numpy scipy cython matplotlib pytest flake8 sphinx sphinx-gallery`` or something like that
[2019-08-06T14:27:43.924Z] <5a7aea3dd73408ce4f8c133a> @amueller by the way, numpy and scipy from conda perform somehow faster than from pip
[2019-08-06T14:27:52.586Z] <5a7aea3dd73408ce4f8c133a> but I still haven't found out why
[2019-08-06T14:28:00.445Z] <54d4a1d6db8155e6700f853b> @katsar0v thats mkl vs openblas possibly
[2019-08-06T14:28:06.401Z] <54d4a1d6db8155e6700f853b> but could also be how they are configured by default
[2019-08-06T14:28:15.995Z] <54d4a1d6db8155e6700f853b> i.e. how many threads they use etc
[2019-08-06T14:28:35.360Z] <5a7aea3dd73408ce4f8c133a> @amueller how can I reconfigure numpy and scipy to use max threads e.g. 6?
[2019-08-06T14:28:56.657Z] <5a7aea3dd73408ce4f8c133a> I have no `mkl` (from conda or pip)
[2019-08-06T14:29:15.045Z] <54d4a1d6db8155e6700f853b> pip has no mkl ;)
[2019-08-06T14:29:21.048Z] <54d4a1d6db8155e6700f853b> (so far)
[2019-08-06T14:29:38.652Z] <54d4a1d6db8155e6700f853b> https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy
[2019-08-06T14:29:45.353Z] <5a7aea3dd73408ce4f8c133a> https://pypi.org/project/mkl/ 
[2019-08-06T14:31:44.324Z] <54d4a1d6db8155e6700f853b> @katsar0v I don't think that helps given that numpy and scipy will not be linked against it
[2019-08-06T14:34:15.844Z] <5a7aea3dd73408ce4f8c133a> this saved my life @amueller 
[2019-08-06T14:34:20.170Z] <54d4a1d6db8155e6700f853b> well in your script n and m are way too small to show anything useful
[2019-08-06T14:36:11.305Z] <5a7aea3dd73408ce4f8c133a> it reduced my validation curve
[2019-08-06T14:36:14.316Z] <5a7aea3dd73408ce4f8c133a> from 500s to 15 seconds
[2019-08-06T14:36:29.299Z] <5a7aea3dd73408ce4f8c133a> @amueller this is a life saver
[2019-08-06T14:36:30.844Z] <54d4a1d6db8155e6700f853b> what did?
[2019-08-06T14:36:37.194Z] <5a7aea3dd73408ce4f8c133a> https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy
[2019-08-06T14:36:39.161Z] <5a7aea3dd73408ce4f8c133a> these envs
[2019-08-06T14:36:46.244Z] <54d4a1d6db8155e6700f853b> ah
[2019-08-06T14:36:54.612Z] <54d4a1d6db8155e6700f853b> well stackoverflow saved your live
[2019-08-06T14:36:56.617Z] <54d4a1d6db8155e6700f853b> *life
[2019-08-06T14:37:07.295Z] <5a7aea3dd73408ce4f8c133a> It's good for performance tweaks
[2019-08-07T05:02:53.313Z] <5c34f182d73408ce4fb408a6> How should I build the docs for harversine_distances in my local repo? I ran `python setup.py install` but still I can't find it under `doc/modules/`
[2019-08-07T08:20:41.481Z] <55d21ee30fc9f982beadabb8> The documentation is another command line
[2019-08-07T08:21:08.208Z] <55d21ee30fc9f982beadabb8> ``` cd doc make html ``` should work all OS I think
[2019-08-07T08:22:27.829Z] <55d21ee30fc9f982beadabb8> then it will create a `_build/html` folder and you can search for the `index.html` 
[2019-08-07T08:39:50.448Z] <5571fe1015522ed4b3e17d90> @sameshl note this part of the contributing scikit-learn doc: https://scikit-learn.org/stable/developers/contributing.html#documentation
[2019-08-07T08:40:48.673Z] <5571fe1015522ed4b3e17d90> If you see ways the contributing doc can be improved while you face this "setup" issues, let us know or/and open PRs to improve the contributing docs!
[2019-08-07T10:07:36.528Z] <5c34f182d73408ce4fb408a6> @lesteve Sure. Thanks for the help. 
[2019-08-07T10:09:32.116Z] <5c34f182d73408ce4fb408a6> As a beginner contributor to this organisation, the arrangements of the docs did feel a bit tough to navigate. I will put my thoughts about it more concisely and then open a issue and PR for the same
[2019-08-07T10:10:52.379Z] <567f5d7716b6c7089cc043a8> We're working on improving our contributing docs @sameshl, there's some discussion under #14582 
[2019-08-07T10:15:50.061Z] <5c34f182d73408ce4fb408a6> Thats great. Would love to contribute on https://github.com/scikit-learn/scikit-learn/issues/14582
[2019-08-07T10:19:09.986Z] <5c34f182d73408ce4fb408a6> I am working on https://github.com/scikit-learn/scikit-learn/issues/14575. So I found the corresponding example under `sklearn/metrics/pairwise.py`.  My question is, are the examples run in the doc building process and output is generated or I am supposed to manually write the output of the example in the docstring of a function?
[2019-08-07T11:22:58.760Z] <567f5d7716b6c7089cc043a8> you should write the output in the example. The doc build will run the code and check if the generated output is the same as the one you put there. See https://docs.python.org/3.5/library/doctest.html for more info
[2019-08-07T11:32:45.884Z] <5c34f182d73408ce4fb408a6> Thanks @adrinjalali !
[2019-08-07T19:57:24.511Z] <5ba59281d73408ce4fa8fbb5> Does anyone here knows a good source to learn rnn structure ?
[2019-08-07T19:59:32.789Z] <5ba59281d73408ce4fa8fbb5> Is it like replacing every hidden node with a rnn cell?
[2019-08-09T19:13:39.055Z] <5c34f182d73408ce4fb408a6> I am working on https://github.com/scikit-learn/scikit-learn/issues/14131 . So, I thought that I could append a note in the docstring of `KDTree` regarding the issue. But  I looked into `sklearn/neighbors/kd_tree.pyx ` and it looks like `KDTree` is inheriting its docstring from `BinaryTree`. So can someone tell me an elegant way to append my note docstring to the inherited docstring of `KDTree` or if I could do something else to solve this issue.
[2019-08-11T14:32:18.513Z] <5944c1e5d73408ce4f67f652> Currently working on #14081.  I am supposed to create a pitfalls section which includes practices not to be followed by users. Quite confused about how should I approach it, should I create a whole new section in documentation.html or is there another way to do this?? Thanks for the help!!!
[2019-08-15T11:12:30.220Z] <5810cd4cd73408ce4f3101ce> Hey channel, ive being working on vectorizing regression tree with Numpy, and i have achieved some speed up against the cython version of sklearn.  in case anyone is interested, here is the link https://github.com/yupbank/np_decision_tree#regression-with-mae 
[2019-08-15T11:19:41.472Z] <5810cd4cd73408ce4f3101ce> on median data(10000*100), with MAE criteria, achieved 20 times speed up :) 
[2019-08-15T12:52:52.109Z] <567f5d7716b6c7089cc043a8> still haven't checked the code in depth. But it's definitely interesting @yupbank . What do you think @NicolasHug ? 
[2019-08-15T12:55:23.440Z] <5810cd4cd73408ce4f3101ce> i havent clean the code yet, and also working on a blog post explainning what i did, and add some CI to it.  But i would love to have some extra inputs before i proceed, e.g. reviews. 
[2019-08-15T12:58:48.784Z] <567f5d7716b6c7089cc043a8> I don't think it'd be easy, but I'd love to see if it actually passes our tree tests, and if it doesn't why not and which tests. Feel free to ping me when you write the blog post.
[2019-08-15T12:59:51.485Z] <5810cd4cd73408ce4f3101ce> sure.. that would be nice,
[2019-08-15T13:50:42.863Z] <5baf7d9ad73408ce4fa9c9b2> @yupbank pretty cool stuff! I took a quick glance at the tree grower and the `greedy_split` function and it looks good as far as I can tell. I wouldn't advertise benchmarks with only `max_depth=1` though ;) Please definitely ping us when you write the blog post!!
[2019-08-15T13:51:46.511Z] <5810cd4cd73408ce4f3101ce> lol, you are right, actually with max_depth=10, i only get 5 times faster. 
[2019-08-17T14:47:27.030Z] <5810cd4cd73408ce4f3101ce> @NicolasHug  @adrinjalali  hey.. i have a draft version here.. comments are very welcome :) https://yupbank.github.io/learning/2019/08/08/faster-regression-tree.html 
[2019-08-19T14:52:09.863Z] <5810cd4cd73408ce4f3101ce> omg omg omg, For L2 loss, if i replace `import numpy as np` with `import cupy as np`, i get another 10x Speed up for 1 split, but i would lost the edge when i have too many depth.. i need to refactor my code... 
[2019-08-19T14:54:05.818Z] <567f5d7716b6c7089cc043a8> +1
[2019-08-19T14:54:52.977Z] <5810cd4cd73408ce4f3101ce> but i really like the fact that, switching to GPU is so trivial ... 
[2019-08-19T20:37:21.135Z] <5924c519d73408ce4f61c9c7> Have a question maybe someone can answer. Trying to use a simple model on a set of data. About a couple thousand rows and only a dozen features, most are binary. I'm training on Logistic Regression, and found my model overfits. So when I try to tune my hyperparameters, my accuracy remains entirely unchanged. Has anyone seen this before or know why this is happening?
[2019-08-20T08:17:31.691Z] <55d21ee30fc9f982beadabb8> Do you have imbalanced classes?
[2019-08-22T05:02:04.850Z] <5c34f182d73408ce4fb408a6> I want to rebuild the 'scikit-learn' project. I tried running `pip install --editable .` as stated in the docs https://scikit-learn.org/stable/developers/advanced_installation.html#building-from-source but I am getting this error. Can someone help me out. ``` ERROR: Cannot uninstall 'scikit-learn'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. ```
[2019-08-22T08:03:48.147Z] <589b9e0fd73408ce4f490ba4> @sameshl See https://github.com/pypa/pip/issues/5247#issuecomment-381550610 probably best to reinstall in a new virtual environment.
[2019-08-22T14:18:30.239Z] <54d4a1d6db8155e6700f853b> @thomasjpfan you like puzzles, right? https://github.com/scikit-learn/scikit-learn/pull/14704
[2019-08-24T14:07:20.895Z] <5d10a5b9d73408ce4fc459a6> I can't seem to get to make the virtual environment with sphinxgallery  conda create -n sklearndev numpy scipy matplotlib pytest sphinx cython ipykernel sphinxgallery  or   conda create -n sklearndev numpy scipy matplotlib pytest sphinx cython ipykernel sphinx-gallery
[2019-08-24T14:11:25.061Z] <5d10a5b9d73408ce4fc459a6> never mind! the solution is in the other gitter chat!
[2019-08-28T17:07:05.539Z] <5a32fea2d73408ce4f836261> Hi team, I am new to Cpython but really wants to play with the internals of sklearn. I want to test out some of the cdef classes in the pyx file but looks like the methods are inaccessible within Python. Any thought?   For example:  ```python from sklearn.tree import _utils ph = _utils.PriorityHeap(100) dir(ph) ```   And I cannot find call methods like pop, push.  Usually how does the workflow look like if I want to play with the internals of sklearn within Jupyter notebook. 
[2019-08-29T06:41:51.297Z] <5d677234d73408ce4fc98654> hello everyone. I'm really new to Machine learning in general and i have been working with some sklearn Regressors. I need some help :). My question is how do i know if the RMSE i have is minimum enough for good predictions. To what do i compare this RMSE to?
[2019-08-29T17:27:39.233Z] <5d68027ed73408ce4fc99289> I was able to create a model by curve fitting a set of data that has 5 variables using GaussianProcessRegressor.    The problem is I am unable to export/load this model into an older version of python (version 2.5.2).  Is there a way to dump the equation/formula into mathematical terms in relations to these 5 variables so that I can use this prediction on the older python?  Thanks
[2019-08-30T10:15:13.047Z] <567f5d7716b6c7089cc043a8> @enoch-sun We don't really support those Python versions anymore. You can try and figure it out with some other persisting models such as ONNX or PMML, but you'll be mostly on your own
[2019-09-02T03:09:17.236Z] <5c77a43ed73408ce4fb93081> @biwa7636 The PriorityHeap functions `pop` and `push` are cdef, which means they are not available in python.
[2019-09-03T20:31:00.314Z] <5d5565e0d73408ce4fc880d5> Is there a scikit-learn preferred way to store a vector using Cython?  I've seen libcpp.vector, array.array and numpy used in the code base.  @NicolasHug @amueller 
[2019-09-03T20:33:47.807Z] <5baf7d9ad73408ce4fa9c9b2> The way we do it now is to allocate numpy arrays (in python or in cython), and then use a memory view for pure cython parts. You can take a look at how we do it in e.g. `ensemble/_hist_gradient_boosting`
[2019-09-04T10:16:43.336Z] <57fc82e4d73408ce4f2d5a7b> Hi, does apply in df.apply(fun) iterate over each columns in 'df' data-frame and pass them to 'fun' function as a series?
[2019-09-04T17:05:42.303Z] <5a32fea2d73408ce4f836261> @thomasjpfan, you are right, however, I also tried to execute the above code too using `%%cython` magic also from `sklearn.tree cimport _utils` but still did not work. Was it supposed to be like that? 
[2019-09-04T17:07:15.419Z] <5a32fea2d73408ce4f836261> ```python %%cython # requires numpy headers from sklearn.tree._utils cimport Stack s = Stack(10) print(s.top) >>> AttributeError: 'sklearn.tree._utils.Stack' object has no attribute 'top' ```
[2019-09-04T17:09:24.435Z] <5a32fea2d73408ce4f836261> I found the source code so well written, fascinating and really want to be able to get the development environment up and running. 
[2019-09-04T17:56:05.618Z] <5a32fea2d73408ce4f836261> Weird, the above code will work if I replace `s = Stack(10)` with `cdef  Stack s = Stack(10)`, I believe this must have something to do with static type declaration.
[2019-09-05T19:26:54.683Z] <5d5565e0d73408ce4fc880d5> Does anyone know why the base estimator for `ExtraTreesClassifier` is `ExtraTreeClassifier`, instead of `DecisionTreeClassifier` with splitter='random'?   I am working on adding a new type of tree. @NicolasHug @amueller 
[2019-09-05T19:37:47.980Z] <5baf7d9ad73408ce4fa9c9b2> No idea. It doesn't make much sense for `ExtraTreeClassifier` to allow for a splitter that isn't 'random' IMO. Would you want to submit a PR to deprecate the parameter?
[2019-09-06T10:06:59.130Z] <5d722e7fd73408ce4fca2f1f> Hi All, I`m getting the following error while executing the python setup.py install  error: Command "cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MT -IC:\Users\Moti\Anaconda3\envs\motidevs\lib\site-packages\numpy\core\include /EHsc /Tpsklearn\svm\src\libsvm\libsvm_template.cpp /Fobuild\temp.win-amd64-3.7\sklearn\svm\src\libsvm\libsvm_template.obj" failed with exit status 127  Do you have any idea? Thanks!
[2019-09-06T21:15:05.363Z] <579618a040f3a6eec05c5e42> Any scikit devs who can shed some light on why `calibration_curve` is only for binary estimators?
[2019-09-10T08:02:58.176Z] <5d77583cd73408ce4fca7b58> how can i start committing to the open source
[2019-09-10T08:08:58.269Z] <567f5d7716b6c7089cc043a8> @Anj-ali you can start by going through our contributing guides: https://scikit-learn.org/dev/developers/contributing.html#contributing
[2019-09-10T08:09:55.040Z] <5d77583cd73408ce4fca7b58> thank you Sir, surely i will do that
[2019-09-19T13:50:45.899Z] <541a528b163965c9bc2053de> Heads up: if you use conda and upgrade your env, you might get a crash when using `n_jobs>=2`. This is caused by an updated version of intel-openmp in the default channel of conda. I reported the issue upstream as https://github.com/ContinuumIO/anaconda-issues/issues/11294 and the problem is tracked in this PR on the scikit-learn side: https://github.com/scikit-learn/scikit-learn/pull/15020
[2019-09-19T13:53:08.248Z] <541a528b163965c9bc2053de> The error message is `OMP: Error #13: Assertion failure at z_Linux_util.cpp(2361)` reported by the dying worker process.
[2019-09-19T13:53:31.569Z] <541a528b163965c9bc2053de> Which in turns causes loky to raise: `TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGABRT(-6)}`.
[2019-09-20T16:46:51.356Z] <5c34f182d73408ce4fb408a6> If someone is free to review, please take a look at https://github.com/scikit-learn/scikit-learn/pull/14993 and https://github.com/scikit-learn/scikit-learn/pull/15045.
[2019-09-27T16:28:51.046Z] <54d4a1d6db8155e6700f853b> hm is there a pandas gitter? Or is @jorisvandenbossche around lol? For a pandas dtype, how do I get the closest numpy dtype to cast to?
[2019-09-27T16:29:09.844Z] <53232ac75e986b0712efe3af> yep
[2019-09-27T16:29:37.943Z] <53232ac75e986b0712efe3af> there is pandas gitter actually (pydata/pandas)
[2019-09-27T16:29:59.623Z] <53232ac75e986b0712efe3af> I don't think there is a typical way to do it
[2019-09-27T16:30:10.643Z] <53232ac75e986b0712efe3af> If I remember correctly, there is an issue about it
[2019-09-27T16:30:41.945Z] <53232ac75e986b0712efe3af> Basically, you would like to know the dtype of `np.asarray(obj).dtype` right? (but without needing to do the actual conversion?)
[2019-09-27T16:30:57.132Z] <54d4a1d6db8155e6700f853b> indeed
[2019-09-27T16:31:48.159Z] <54d4a1d6db8155e6700f853b> it's for https://github.com/scikit-learn/scikit-learn/pull/15094 which is currently failing because np.result_type(pd.CategoricalDType) raises an error
[2019-09-27T16:33:20.701Z] <53232ac75e986b0712efe3af> the issue that I rememered is https://github.com/pandas-dev/pandas/issues/22791
[2019-09-27T16:35:34.075Z] <54d4a1d6db8155e6700f853b> ok. so no solution :-/ is there a work-around?
[2019-09-27T16:35:51.931Z] <54d4a1d6db8155e6700f853b> like what does actually happen when you do the conversion?
[2019-09-27T16:36:08.543Z] <54d4a1d6db8155e6700f853b> is it from the ``pd.DataFrame.__array__`` method or something?
[2019-09-27T16:45:23.756Z] <54d4a1d6db8155e6700f853b> yeah it is, no way to figure that one out :-/
[2019-10-04T21:28:27.883Z] <5d5565e0d73408ce4fc880d5>  Hello all (I am new to Cython),  I am currently working on adding an augmented version of Brieman's forest-RC (similar to RandomForest) algorithm into my fork of scikit-learn: In short, the algorithm takes linear combinations of features and projects them with weights randomly selected in {-1,1} to form a new feature to split on. The number of features combined at each split is a random variable.    The current `SplitRecord` only holds one feature, I need something to store a vector of features and a vector to hold weights.   1. I tried initializing an np.ndarray and using memoryviews, but ran into GIL issues. 1. I tried to make an `ObliqueSplitRecord` class, but that can't be passed as a pointer into functions because it is a Python object. 1. I tried to augment the `SplitRecord` struct in [_splitter.pxd](https://github.com/scikit-learn/scikit-learn/blob/a47e914163c2dbecb4a80ec40d2d8fe313a83010/sklearn/tree/_splitter.pxd#L23-L32) but that didn't seem to work because vectors would then be of fixed length. 1. I tried to use something similar to the [`tree/_utils:Stack`](https://github.com/scikit-learn/scikit-learn/blob/3046990e76c7c90a1150c26770572c8d76ee00de/sklearn/tree/_utils.pyx#L81-L157) but fell into the same problem as it was a class and couldn't be passed as a pointer into a function.  I am looking into using cppclass, but am not sure if that will fix solve my problem.   Does anyone have suggestions on how to best implement this in a Cythonic way?  i.e. storing a vector of things while avoiding the GIL and not using python objects? 
[2019-10-06T09:24:11.048Z] <567f5d7716b6c7089cc043a8> @MrAE you can use a cpp vector in cython. But since you're changing the splitrecord struct, you'll need to change the code in quite a lot of places.
[2019-10-06T20:01:35.876Z] <5c2cf216d73408ce4fb369e2> Hi, I have some basic question about local docs build for scikit. I've been trying to modify docs inside API for some file in `sklearn/linear_model` and followed instructions in Contributors Guide. But after few attempts the `make` command inside `/docs` does not seem to modify local docs build inside `_build`. In the browser,  API docs didn't change although I modified the sources. Am I missing something? 
[2019-10-07T14:08:04.131Z] <5baf7d9ad73408ce4fa9c9b2> @mtsokol it seems that you're doing it right... maybe double check that 1. you're actually changing the sources, i.e. not anything in the _build folder, 2. the doc that you're changing is about a public estimators/tools (private tools aren't rendered in the doc anyway) and 3. that you're looking at the generated html in `doc/_build/html/stable/`
[2019-10-07T14:14:54.302Z] <5baf7d9ad73408ce4fa9c9b2> @MrAE   re 1. you can't use (let alone allocate) numpy arrays when the GIL is released because these are Python objects. Is there a way for you to allocate the arrays somewhere where the GIL is held, and use memory views when the GIL is released? Memory views are safe to use without the GIL  re 2. is it still considered a Python object if you use a `cdef`ed class and all the attributes are `cdef`ed as well?  re 3. what vectors? can't you use a view as a field of the struct?
[2019-10-07T18:16:59.473Z] <5baf7d9ad73408ce4fa9c9b2> Also @MrAE  I happen to have been writing about Cython over the weekend... maybe that could help http://nicolas-hug.com/blog/cython_notes
[2019-10-12T08:30:03.897Z] <5a58e8b8d73408ce4f87dd73> could somebody share a good example for class docstrings in scikit-learn that we could use as a sort of template? thanks!
[2019-10-12T08:30:50.468Z] <5a7aea3dd73408ce4f8c133a> @janjagusch https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/compose/_column_transformer.py#L37 ?
[2019-10-12T08:39:08.775Z] <5da1908ed73408ce4fcda13f> Here is the issue search string "is:issue is:open examples class docs involves:adrinjalali"
[2019-10-12T08:39:40.577Z] <5da1908ed73408ce4fcda13f> https://github.com/scikit-learn/scikit-learn/issues/3846
[2019-10-12T11:07:56.023Z] <5da1908ed73408ce4fcda13f> Hey guys who is veerlosar on Githib? just want to talk about OneVsRestClassifier example
[2019-10-12T11:08:12.530Z] <5da1908ed73408ce4fcda13f> https://github.com/scikit-learn/scikit-learn/pull/15200/
[2019-10-13T09:54:39.575Z] <5da18989d73408ce4fcda083> @zioalex I can talk to veerlosar, we're at the same sprint
[2019-10-13T10:37:11.274Z] <5da2fdd6d73408ce4fcdafbd> > Hey guys who is veerlosar on Githib? just want to talk about OneVsRestClassifier example  @zioalex  what did you want to talk about?
[2019-10-16T13:33:30.190Z] <5da71b2fd73408ce4fce084d> how to learn complete sk learn ? please give the resources?
[2019-10-16T13:35:47.545Z] <5b4c9e4bd73408ce4fa10b88> Andreas Muller's book, Introduction to Machine Learning with Python: A Guide for Data Scientists, is quite complete. You can also look at the user guides: https://scikit-learn.org/stable/user_guide.html
[2019-10-17T07:10:56.369Z] <54d4a1d6db8155e6700f853b> there's also my lecture series: https://youtube.com/AndreasMueller   The only complete resource is the user guide though
[2019-10-19T09:22:32.761Z] <5a09ec4ed73408ce4f7e6c27> Hello there!
[2019-10-20T22:05:53.671Z] <5d5565e0d73408ce4fc880d5> Hey guys, me again: Regarding me previous message :point_up: [October 4, 2019 5:28 PM](https://gitter.im/scikit-learn/scikit-learn?at=5d97b97b0e67130aae15b693) I've gone through some more attempts that don't quite work.    @NicolasHug The blog post helped a bit with my understanding of memory-views, however I still have a few questions:  Can a memory-view be initialized `with nogil`? And no, a struct member cannot be a memory view.  I tried to make my own class but then got yelled at because it's not of type `Splitter`, so that was a bust.   I augmented the `SplitRecord` with 2 cpp vectors, but that caused things to go wonky requiring cpp in files that I'm not willing to touch.   I ended up augmenting `SplitRecord` with 2 Cython vectors with hard-coded length, but then can't seem to initialize a memory-view into them inside of the `node_split`.  I'm pretty much stuck (in my current view of things), because I'm trying to do as little modification as possible, but it seems that in order to accomplish my task I'll have to re-write a big chunk of ensemble methods. I'd have to add an input argument to the `node_split` method? That doesn't sound like a good idea.  Any ideas?  Much appreciated.
[2019-10-24T18:12:07.311Z] <5571fe5f15522ed4b3e17d94> Hi all, I'm trying to help my team reduce creating new code when leveraging existing libraries might get the job done. Does anyone have thoughts on how the following can be accomplished? https://stackoverflow.com/q/58533004/1566074  Basically finding the optimal subgroups for a dataset to then feed into an estimator to reduce noise.
[2019-10-26T21:12:43.479Z] <59605bcbd73408ce4f6c2b60> Hello the scikit-learn community! I'd like to have your thoughts on what I coded. It's a way to do automatic machine learning on scikit-learn pipelines. It allows for handling hyperparameter spaces as well as hyperparameters. Example: https://www.neuraxio.com/en/neuraxle/stable/examples/hyperparams.html#sphx-glr-examples-hyperparams-py
[2019-10-30T15:10:00.341Z] <567f5d7716b6c7089cc043a8> any takers on https://github.com/scikit-learn-contrib/imbalanced-learn/issues/616? it's a good first issue.
[2019-10-30T15:10:47.793Z] <55d21ee30fc9f982beadabb8> a first good issue?
[2019-10-30T15:11:10.146Z] <55d21ee30fc9f982beadabb8> a find it a bit harsh :)
[2019-10-30T15:14:13.517Z] <567f5d7716b6c7089cc043a8> lol, I'm just a messenger, Joel tagged it as such :D
[2019-10-30T15:14:39.819Z] <55d21ee30fc9f982beadabb8> Basically, I was starting to solve the issue yesterday
[2019-10-30T15:16:16.339Z] <55d21ee30fc9f982beadabb8> While making `master` work with `master` is easy (just change the import path), the challenging part is to make work out-of-date version with a newer scikit-learn.
[2019-10-30T15:16:50.274Z] <55d21ee30fc9f982beadabb8> In the latest case, we need to make some `try except ImportError` as you suggested I think
[2019-10-30T15:18:49.782Z] <567f5d7716b6c7089cc043a8> Yep. If you're already at it, please leave a comment so that others don't start working on it ;)
[2019-10-30T15:19:47.899Z] <55d21ee30fc9f982beadabb8> Yep I just cross-reference my PR 
[2019-11-02T09:14:57.544Z] <55d21ee30fc9f982beadabb8> For the people joining the MAN-AHL sprint, you can find the instructions to install scikit-learn from source at the following documentation page: https://scikit-learn.org/dev/developers/advanced_installation.html#building-from-source
[2019-11-02T09:48:14.515Z] <55d21ee30fc9f982beadabb8> In addition, you can find the contributing guide as the following address: https://scikit-learn.org/dev/developers/contributing.html
[2019-11-02T09:51:27.530Z] <55d21ee30fc9f982beadabb8> Finally, if you are searching for an issue to work on, several issues have been tagged specifically for sprints: https://github.com/scikit-learn/scikit-learn/issues?utf8=%E2%9C%93&q=is%3Aopen+is%3Aissue+label%3ASprint You can set some other tags if you want ("good first issues", etc.). You also free to search any issue that you are interested in on the issue tracker.
[2019-11-02T10:05:31.197Z] <589b9e0fd73408ce4f490ba4> One example of a "good first issue", particularly if you have never contributed to large open-source projects before is  https://github.com/scikit-learn/scikit-learn/issues/15440 aiming to improve docstrings. That would allow you to see how the contribution workflow works before tackling more complex issues.
[2019-11-02T10:35:05.664Z] <589b9e0fd73408ce4f490ba4> Also it's useful to read the contribution guide at https://scikit-learn.org/dev/developers/contributing.html
[2019-11-02T11:14:52.990Z] <5dbd6437d73408ce4fcfbf0f> Hi @rth I just tried to run `test_docstrings` and looks like just 13 out of 1619 tests pass. I suppose I can pick any estimator to start to improve docstrings, am I right? is there any scale of priorities?
[2019-11-02T11:17:29.222Z] <589b9e0fd73408ce4f490ba4> @gbroccolo Yes, you can pick any estimator that fails :)
[2019-11-02T11:17:53.684Z] <5dbd6437d73408ce4fcfbf0f> thanks
[2019-11-02T11:25:28.057Z] <5dbd6769d73408ce4fcfbf2c> Hi @rth I'd like to pick RadiusNeighborsClassifier
[2019-11-02T11:32:51.586Z] <589b9e0fd73408ce4f490ba4> Sure, please comment about it in the issue
[2019-11-02T16:13:02.186Z] <5dbd6437d73408ce4fcfbf0f> Would like to take care of one of the PR that has been labeled as `stalled` and `help wanted`. I suppose a new one can pick this and conclude the PR also taking into account the comments of the reviewers. What's the best here? Create a new PR that refers to the already existing one?
[2019-11-02T16:20:52.239Z] <5dbd5484d73408ce4fcfbe0b> Trying to take a look at https://github.com/scikit-learn/scikit-learn/issues/13045 -- Does this seem like a decent issue to tackle?
[2019-11-02T16:21:30.422Z] <54d4a1d6db8155e6700f853b> @norvan sure please comment there. Are you part of the wimlds sprint?
[2019-11-02T16:22:06.612Z] <5dbd5484d73408ce4fcfbe0b> I'm at the man hackathon
[2019-11-02T16:22:17.263Z] <54d4a1d6db8155e6700f853b> ah :)
[2019-11-02T16:22:30.596Z] <54d4a1d6db8155e6700f853b> I didn't realize there were two today lol
[2019-11-02T17:03:07.996Z] <55d21ee30fc9f982beadabb8> :)
[2019-11-12T19:18:54.085Z] <5dcb056cd73408ce4fd0cb72> hi there any clue for identify text from one document to another?
[2019-11-12T19:19:16.327Z] <5dcb056cd73408ce4fd0cb72> we are working on a prototype for fake news
[2019-11-17T08:13:18.044Z] <5dd100ecd73408ce4fd140ae> hi
[2019-11-17T08:14:45.081Z] <5dd100ecd73408ce4fd140ae> anyone there to help
[2019-11-17T18:22:44.152Z] <5dbd6437d73408ce4fcfbf0f> Hi @qazi1002 @eliseo looks like you need some NLP for this project...can you provide more info about which kind of help do you need? Are you meant to use specifically scikit-learn for this? Also, not sure that this is the proper place where to talk about this - topics should be strictly focused on scikit-learn development/bug fixing/etc.
[2019-11-17T19:41:10.246Z] <567f5d7716b6c7089cc043a8> I don't think we have a strict policy for this channel being related to the dev only. But in the interest of the rest of the community being able to use the answers we give to your questions related to the usage, posting them on stackoverflow or other related forums may be more appropriate.
[2019-11-18T12:45:32.401Z] <5dd100ecd73408ce4fd140ae> @gbroccolo  I need help regarding software development...as i am beginner so I want to get some tips for developing softwares... I want to develop software that reads the smart ID cards using card reader.
[2019-11-22T22:27:10.394Z] <564e507e16b6c7089cbb6551> Hi there, is k-means clustering stochastic even when the initial centers are given? I'm noticing different results when I run my code multiple times
[2019-11-22T22:27:59.370Z] <54d4a1d6db8155e6700f853b> @h4k1m0u I don't think it should be
[2019-11-22T22:32:25.495Z] <564e507e16b6c7089cbb6551> @amueller That's weird, I can't find out why in this short piece of code (https://bpaste.net/show/ORPVW) the centroids found by kmeans are sometimes located at the center of the 3 samples and sometimes not
[2019-11-22T22:33:02.268Z] <54d4a1d6db8155e6700f853b> you don't fix the random seed so the data changes
[2019-11-22T22:34:26.029Z] <564e507e16b6c7089cbb6551> Oh sorry, I've completely forgotten the np.random above. Thanks a lot for reminding about that.
[2019-11-25T19:58:15.489Z] <5acfdfffd73408ce4f95738d>  When using "random forest" and "gradient boosting". I add to the main signs, a sign that in the picture. [title](https://ibb.co/997YpMK) The data is clearly not stationary. To make the series stationary, I apply a one-time difference to the data(increments) After all, I normalize the data. [title](https://ibb.co/6tbdVzJ) Why, if I don't use increments(one-time difference), then classes are separated better? [title](https://ibb.co/dBJrnDf) Although in all textbooks they write that non-stationary data should be decomposed into increments. For training, I use the first 5000 characters. If you pay attention to the data, extreme values start after 5000. That is, the model does not even see that such large values were in the training sample.
[2019-11-28T13:53:08.868Z] <5671093916b6c7089cbede6a> I have two files that contain Event Name, Event City, Event Venue, Event State but in both files it's written in different ways or you can assume both the files are from different source.  I want to create a Machine learning-based algorithm that can do the matching.  I have tried with fuzzy-wuzzy to get string similarity. Can anyone please tell me if I want to solve this with Deep Learning what would be the approach. Thanks @amueller 
[2019-12-02T20:32:45.831Z] <564e507e16b6c7089cbb6551> Hi, what does it mean when `linear_model.Ridge`returns `n_iter_` = None? does it mean it didn't even perform one single iteration?
[2019-12-02T21:29:25.867Z] <5baf7d9ad73408ce4fa9c9b2> @h4k1m0u the doc says     n_iter_ : None or array of shape (n_targets,)         Actual number of iterations for each target. Available only for         sag and lsqr solvers. Other solvers will return None.  you're probably not using sag or lsqr?
[2019-12-03T12:33:15.813Z] <564e507e16b6c7089cbb6551> Thanks @NicolasHug , you  were right I was actually not even setting that parameter (`solver='auto'`). With solver=sag, it returns the # of iterations
[2019-12-04T01:24:46.144Z] <56e08c0d85d51f252ab801e4> Hi, semi random question but I can't find it in the docs - do y'all implement a consensus clustering evaluator that's not the bicluster one?
[2019-12-05T12:57:32.432Z] <5684304216b6c7089cc0a229> Hi, I am the "maintainer" (more like caretaker) of hmmlearn (which was split out of sklearn a couple of years ago); I tried moving the CI to azure and realized that the macOS tests were failing (previously testing was only done on linux (travis) and windows (appveyor)) but can't test locally on macOS, would anyone be willing to have a look? https://dev.azure.com/anntzer/hmmlearn/_build/results?buildId=170  Thanks!
[2019-12-06T12:59:02.195Z] <5baf7d9ad73408ce4fa9c9b2> @anntzer , running the test locally on my linux I get a bunch of  zero division warnings on the failing test, so you might be able to debug locally still
[2019-12-06T13:31:03.703Z] <5684304216b6c7089cc0a229> I get a single warning running tests locally but they still pass...
[2019-12-06T15:07:51.426Z] <5baf7d9ad73408ce4fa9c9b2> yeah they pass but they probably should not. Unless you do expect to get a zero division in the test, in which case you need to protect the call. the macOS CIs probably use different versions of numpy or scipy so that's why they fail while the others don't
[2019-12-06T15:54:21.115Z] <5684304216b6c7089cc0a229> I'll look into it but it would be strange that different versions of numpy are being used
[2019-12-08T12:28:32.164Z] <5684304216b6c7089cc0a229> wait, are you really getting zero division warnings from TestGMMHMMWithTiedCovars::test_fit_zero_variance (which is the failing test on osx)?  I get only get warnings on TestGMMHMMWithDiagCovars::test_fit_zero_variance (another test)
[2019-12-08T13:25:12.786Z] <5decf929d73408ce4fd36f72> Dear, I i tried to tune hyperparameters of scikit GradientBoostingRegressor model using the Hyperopt optimizer. I set search space for learning_rate parameter in the range [0.01, 1] by many ways (for example : ""'learning_rate': hp.quniform('learning_rate', 0.01, 1, 0.05)"" or as simple array ""[0.01, 0.02, 0.03, 0.1]"") but when I run the code hyperopt start to calculation and I get the error " ValueError: learning_rate must be greater than 0 but was 0".  I do not know what is problem in the code because zero value is not in the parameter's scope. How zero value come to function?  Please help me to solve this problem.
[2019-12-09T09:13:51.696Z] <541a528b163965c9bc2053de> This looks like a bug in hyperopt, no? Can you add print statements (or debugger breakpoint) in the hyperopt and scikit-learn code to check where this zero comes from?
[2019-12-09T09:17:26.472Z] <541a528b163965c9bc2053de> Actually hp.quniform is for rounding to integer values. You probably want `hp.loguniform(-3, 0)` or someting similar.
[2019-12-09T12:22:25.093Z] <5baf7d9ad73408ce4fa9c9b2> @anntzer I get an underflow for `TestGMMHMMWithTiedCovars::test_fit_sparse_data` and indeed most of the zero div warnings come from `TestGMMHMMWithDiagCovars`, not the tied version  Maybe addressing the existing warnings would fix the one that's failing?
[2019-12-09T13:01:32.772Z] <5684304216b6c7089cc0a229> that's interesting, I don't get any warning with Tied::test_fit_sparse_data and you don't see it on Azure either; what's your numpy/scipy/anythingelse relevant version?
[2019-12-09T14:47:17.272Z] <5baf7d9ad73408ce4fa9c9b2> ``` System:     python: 3.7.4 (default, Oct  4 2019, 06:57:26)  [GCC 9.2.0] executable: /home/nico/.virtualenvs/sklearn/bin/python    machine: Linux-5.3.1-arch1-1-ARCH-x86_64-with-arch  Python dependencies:        pip: 19.0.3 setuptools: 40.8.0    sklearn: 0.23.dev0      numpy: 1.17.1      scipy: 1.3.0     Cython: 0.29.10     pandas: 0.24.2 matplotlib: 3.0.0     joblib: 0.13.2  Built with OpenMP: True  ```
[2019-12-09T14:49:58.069Z] <5baf7d9ad73408ce4fa9c9b2> Here's my pytest output. I locally installed the master branch of hmmlearn  ``` lib/hmmlearn/tests/test_gmm_hmm_new.py::TestGMMHMMWithSphericalCovars::test_fit_zero_variance lib/hmmlearn/tests/test_gmm_hmm_new.py::TestGMMHMMWithTiedCovars::test_fit_sparse_data   /home/nico/dev/hmmlearn/lib/hmmlearn/hmm.py:849: RuntimeWarning: underflow encountered in multiply     post_comp_mix = post_comp[:, :, np.newaxis] * post_mix  lib/hmmlearn/tests/test_gmm_hmm_new.py::TestGMMHMMWithDiagCovars::test_fit_zero_variance   /home/nico/dev/hmmlearn/lib/hmmlearn/stats.py:47: RuntimeWarning: divide by zero encountered in log     + np.dot(X ** 2, (1.0 / covars).T))  lib/hmmlearn/tests/test_gmm_hmm_new.py::TestGMMHMMWithDiagCovars::test_fit_zero_variance   /home/nico/dev/hmmlearn/lib/hmmlearn/stats.py:47: RuntimeWarning: divide by zero encountered in true_divide     + np.dot(X ** 2, (1.0 / covars).T))  lib/hmmlearn/tests/test_gmm_hmm_new.py::TestGMMHMMWithDiagCovars::test_fit_zero_variance   /home/nico/dev/hmmlearn/lib/hmmlearn/stats.py:47: RuntimeWarning: invalid value encountered in add     + np.dot(X ** 2, (1.0 / covars).T))  -- Docs: https://docs.pytest.org/en/latest/warnings.html  Results (20.38s):       93 passed        3 xpassed       15 xfailed ```
[2019-12-10T17:16:57.866Z] <5684304216b6c7089cc0a229> that's... curiouser and curiouser.  I don't get the warnings with the exact same versions of everything (AFAICT, except that cpython is from conda), whether with pip-installed numpy and scipy or conda-forge ones.
[2019-12-30T00:50:50.341Z] <5e094955d73408ce4fd54a90> Hi, does anyone know about any plans that might exist involving the release cycle or timeline in moving  IterativeImpute package out of it's experimental version? Thanks, I'm hoping to use it and it looks great for my use case!
[2019-12-30T02:53:09.782Z] <5e0961a4d73408ce4fd54be5> [![Screenshot 2019-12-28 14.29.36.png](https://files.gitter.im/scikit-learn/scikit-learn/Xmzs/thumb/Screenshot-2019-12-28-14.29.36.png)](https://files.gitter.im/scikit-learn/scikit-learn/Xmzs/Screenshot-2019-12-28-14.29.36.png)
[2019-12-30T02:53:47.971Z] <5e0961a4d73408ce4fd54be5> Hi, I want to apply Multinomial Logistic Regression to compute winning probabilities for each contestant in my races. The Data I want to feed in my model look like the image above. I'm tring to understand how should I feed the target class to my model because every race can have a different number of runners, the target class for race A has 5 contestants, instead target class for race B has just 4 contestants.  Is there a way to model this using scikit-learn? 
[2019-12-30T16:43:55.589Z] <567f5d7716b6c7089cc043a8> @guptane6 we hope to fix some issues by the next release. But no guarantees 
[2020-01-04T16:38:22.953Z] <59605bcbd73408ce4f6c2b60> Worth reading: https://www.neuraxio.com/en/blog/scikit-learn/2020/01/03/what-is-wrong-with-scikit-learn.html
[2020-01-05T22:14:57.758Z] <55d21ee30fc9f982beadabb8> I would probably found cool to have an entitled the blog post with something "Limitations and Caveats ..." instead of "What's wrong ...". This said I think that there are some criticisms that should be discussed by opening issues to come up with adequate solutions.
[2020-01-06T16:12:09.973Z] <54d4a1d6db8155e6700f853b> ugh they credit me as the creator of sklearn
[2020-01-06T16:16:19.222Z] <567f5d7716b6c7089cc043a8> haha, yeah I saw :D THE creator :P to be fair, you're the sole maintainer contact on pypi (IIRC)
[2020-01-06T16:16:36.143Z] <54d4a1d6db8155e6700f853b> that means nothing lol
[2020-01-06T17:40:06.375Z] <59605bcbd73408ce4f6c2b60> @amueller Thanks for the feedback haha! I'll edit the post soon to correct what you just pointed out. I sincerely thought you were the main creator of sklearn, as you are the top contributor, and also that you are very very involved. I'd love to know if there is anything I could do to help, or if you have any idea of things you'd like to see in Neuraxle to help with making sklearn more integrated in Deep Learning projects.   For instance, I think the following code snippet is really talkative as a way to do Deep Learning pipelines using the pipe and filter design pattern: https://www.neuraxle.org/stable/Neuraxle/README.html#deep-learning-pipelines  Would you have any ideas to share, or things you'd like to point out for me to work on next with Neuraxle? 
[2020-01-06T17:44:17.742Z] <59605bcbd73408ce4f6c2b60> @glemaitre "Limitations and Caveats ..." sounds cool! I could rename the article. I wanted it to catch the eye, seems like it worked hehe. I love sklearn tho :)   On my side, I've already fixed 95% of the issues I listed, in Neuraxle (as per the links to the Neuraxle website documentation for each problem listed). 
[2020-01-06T17:51:35.774Z] <55d21ee30fc9f982beadabb8> Regarding deep learning pipeline, I think that we want to be conservative: https://scikit-learn.org/stable/faq.html#why-is-there-no-support-for-deep-or-reinforcement-learning-will-there-be-support-for-deep-or-reinforcement-learning-in-scikit-learn
[2020-01-06T17:53:03.832Z] <55d21ee30fc9f982beadabb8> Issues regarding serialization and hyperparameter search could be discussed, however.
[2020-01-06T17:53:52.977Z] <55d21ee30fc9f982beadabb8> I think that onnx-sklearn provide a nice way to deployed scikit-learn model in production
[2020-01-06T17:55:18.565Z] <567f5d7716b6c7089cc043a8> yeah, that's the goal (onnx-sklearn), but it still needs a bit of work. I'm all in favor of focusing a bit on partial_fit (mini batches) though.
[2020-01-06T17:55:25.662Z] <55d21ee30fc9f982beadabb8> but this is rather challenging to retrain models and update models across versions. This might not be in the scope of scikit-learn but having a third-library to manage those could be nice
[2020-01-06T17:57:29.025Z] <55d21ee30fc9f982beadabb8> @adrinjalali Incremental learning, early stopping, and callbacks are things which would be nice
[2020-01-06T17:57:46.659Z] <55d21ee30fc9f982beadabb8> they are in the roadmap I think
[2020-01-06T17:58:29.002Z] <567f5d7716b6c7089cc043a8> yeah they are, they're just hard :P
[2020-01-06T17:58:50.333Z] <55d21ee30fc9f982beadabb8> :) yes indeed
[2020-01-06T17:59:30.451Z] <59605bcbd73408ce4f6c2b60> Nice to confirm that you scope scikit-learn like that. I feared I'd play a bit too much in your backyard but it seems fine, I'm glad you have this opinion. I'm totally down to make Neuraxle a way to handle all those callbacks and things required for doing deep learning, + serialization. I don't know about Onyx, but there could be a way that I adapt to that to save every neural net usign that instead of building custom savers. For now I'm doing 2 other libraries already: Neuraxle-TensorFlow and Neuraxle-PyTorch to provide default neural net savers to allow serialization and checkpointing and have those models have their special callbacks. Might also do Neuraxle-Keras and so forth. 
[2020-01-06T18:00:49.018Z] <55d21ee30fc9f982beadabb8> you also have keras-onnx
[2020-01-06T18:00:53.964Z] <55d21ee30fc9f982beadabb8> and pytorch-onnx
[2020-01-06T18:01:16.175Z] <55d21ee30fc9f982beadabb8> which manage the same way than sklearn-onnx
[2020-01-06T18:01:22.125Z] <55d21ee30fc9f982beadabb8> but this is for prediction only
[2020-01-06T18:01:33.411Z] <54d4a1d6db8155e6700f853b> They are for serialization and deployment, though. I think @gulliaume-chevalier wants training as well
[2020-01-06T18:01:44.597Z] <54d4a1d6db8155e6700f853b> lol ok you beat me to it ;)
[2020-01-06T18:01:57.395Z] <59605bcbd73408ce4f6c2b60> I'll need to look into that. For now, with Neuraxle, someone could do this using 3 tf functions that builds tf graphs:  ``` model = TensorflowV2ModelStep(     create_model, create_loss, create_optimizer,     has_expected_outputs=False ).set_hyperparams(hp).set_hyperparams_space(hps) ``` And I have savers that allows for saving and reloading and continue a fit (already!) 
[2020-01-06T18:04:04.666Z] <59605bcbd73408ce4f6c2b60> Same API would work for TF v1 using a TensorflowV1ModelStep instead, also PyTorch (using some `nn.Module`s), and eventually Keras in some ways
[2020-01-06T18:05:57.885Z] <59605bcbd73408ce4f6c2b60> I also have a `ParallelTransform` class which uses the savers for parallelizing instead of using joblib. So all the pytorch, tf, and keras code is parallelizeable. I also am building right now a `ClusteringWrapper` which acts like the ParallelTransform using savers, but sends the saved wrapped pipeline over a worker that has a REST API. So the Clustering Wrapper can split a batch of data to N workers, by first sending the model, and then sending the data it splitted in parallel. 
[2020-01-06T18:09:13.611Z] <59605bcbd73408ce4f6c2b60> The same concept applies to a new `StreamingPipeline` class I'm creating right now :D it has the ability to have some steps (e.g.: sub-pipelines) run in different threads, and to have queues between each thread like a consumer-producer design pattern. I also already have a [MiniBatchSequentialPipeline](https://www.neuraxle.org/stable/api/neuraxle.pipeline.html#neuraxle.pipeline.MiniBatchSequentialPipeline) that just like a single-threaded [Pipeline](https://www.neuraxle.org/stable/api/neuraxle.pipeline.html#neuraxle.pipeline.Pipeline), but that already uses mini-batches, meaning that it splits the batches into mini batches, and it's just like having a normal Pipeline but calling `.fit` many times in a row (sorry, I didn't name it `partial_fit`, my `fit` is already thought of as potentially always a partial one. 
[2020-01-06T18:15:06.415Z] <59605bcbd73408ce4f6c2b60> @glemaitre You said:  > @adrinjalali Incremental learning, early stopping, and callbacks are things which would be nice  If you look closely [here](https://www.neuraxle.org/stable/Neuraxle/README.html#deep-learning-pipelines), I already have incremental learning (e.g.: if you CTRL+F for the `MiniBatchSequentialPipeline `). I'd love to add early stopping and other callbacks soon, good idea. I opened an issue [here](https://github.com/Neuraxio/Neuraxle/issues/228) for such things, I'd add callbacks to it! 
[2020-01-06T18:16:30.417Z] <59605bcbd73408ce4f6c2b60> So in the issue [#228](https://github.com/Neuraxio/Neuraxle/issues/228) I just linked to, there is some example API code, but it might not be enough. I'd like to really discover the good design patterns for that, although I at least found something that seems like it would work properly. 
[2020-01-07T22:28:14.275Z] <5a2c58c8d73408ce4f8294ba> Does HistGradientBoostingRegressor have an equivalent of subsample and max_features in GradientBoostingRegressor? I have a GradientBoostingRegressor model with tuned hyperparameters and I want to see if HistGradientBoostingRegressor is better
[2020-01-07T22:30:37.719Z] <54d4a1d6db8155e6700f853b> @DrEhrfurchtgebietend not right now. Do you want to open an issue as a feature request? I would recommend first comparing with the default parameters of HistGradientBoosting
[2020-01-07T22:32:02.560Z] <5a2c58c8d73408ce4f8294ba> OK, I can try with the defaults. I will open a request if I remember
[2020-01-07T22:33:46.294Z] <5a2c58c8d73408ce4f8294ba> There also is no min_samples_split
[2020-01-07T22:34:26.880Z] <54d4a1d6db8155e6700f853b> no, but there is min_samples_leaf (which is not the same but similar)
[2020-01-07T22:36:41.303Z] <5a2c58c8d73408ce4f8294ba> @amueller Yea, that is likely good enough. While I have you. I did send you and Gael an email about entity embedding as we discussed at NeurIPS
[2020-01-07T22:37:21.459Z] <54d4a1d6db8155e6700f853b> oh that was you! sorry I didn't connect your handle to you in-person. I've been in grant-writing mode and just procrastinating ;)
[2020-01-07T22:38:53.318Z] <54d4a1d6db8155e6700f853b> I'm not sure when I'll have time to look at it tbh, in particular because it's unlikely we can directly integrate with sklearn. I didn't forget about it but my list of todos is pretty long...
[2020-01-07T22:39:08.662Z] <54d4a1d6db8155e6700f853b> maybe I should add it to my class hand have my students do it ;)
[2020-01-07T22:40:51.158Z] <5a2c58c8d73408ce4f8294ba> Yup, I tend to not use real name on the internet. Anyway, as I say in the email. It might be better as a scikit learn add on. A separate but dependant package. There are a number of them.
[2020-01-07T23:03:14.599Z] <5c77a43ed73408ce4fb93081> @DrEhrfurchtgebietend Are you thinking of using entity embedding for transfer learning?
[2020-01-07T23:04:23.807Z] <5a2c58c8d73408ce4f8294ba> No, categorical encoding. If you have many level it is great. I saw like a 5% RMSE improvement
[2020-01-08T00:02:20.124Z] <5c77a43ed73408ce4fb93081> For your use case, how did you learn the entity embeddings?
[2020-01-08T00:02:45.828Z] <5a2c58c8d73408ce4f8294ba> yea, this is a must otherwise they are not tied to your target
[2020-01-08T00:09:18.090Z] <5a2c58c8d73408ce4f8294ba> here is the proof it works https://github.com/entron/entity-embedding-rossmann
[2020-01-08T00:09:41.596Z] <5a2c58c8d73408ce4f8294ba> and the paper https://arxiv.org/abs/1604.06737
[2020-01-08T00:35:59.677Z] <5a2c58c8d73408ce4f8294ba> @amueller so I am unable to run HistGradientBoostingRegressor because you use np.isnan '''  File "C:\Anaconda3\lib\site-packages\sklearn\ensemble\_hist_gradient_boosting\gradient_boosting.py", line 151, in fit     has_missing_values = np.isnan(X_train).any(axis=0).astype(np.uint8)'''
[2020-01-08T00:36:47.023Z] <5a2c58c8d73408ce4f8294ba> There is a "bug" if you have mixed types. Which is pretty common.   https://stackoverflow.com/questions/59637976/potential-bug-in-np-isnan-for-mixed-types-on-pandas-dataframe
[2020-01-08T01:58:10.140Z] <5a2c58c8d73408ce4f8294ba> Maybe switch to pd.isnull or do u npt want pandas dependance?
[2020-01-08T12:39:49.383Z] <55d21ee30fc9f982beadabb8> @DrEhrfurchtgebietend we don't want dependence on pandas. However, I would have expected to have `X_train` to be a NumPy array at that stage.
[2020-01-08T12:43:50.724Z] <55d21ee30fc9f982beadabb8> Uhm we used a `check_X_y` earlier in `fit`. Could you open a bug report with a minimal example.
[2020-01-08T16:52:57.520Z] <5a2c58c8d73408ce4f8294ba> Normally Pandas passes through with numpy functions fine so you do not have a dependence technically. It is pretty common in practice to use pandas in this way as it makes it more simple to keep your features organized
[2020-01-08T16:55:44.756Z] <55d21ee30fc9f982beadabb8> but `pd.isnull` will require an import of pandas?
[2020-01-08T16:56:17.440Z] <5a2c58c8d73408ce4f8294ba> That is only one possible solution. 
[2020-01-08T16:56:53.419Z] <55d21ee30fc9f982beadabb8> Do you have a minimal code example because I am unsure of what is your input
[2020-01-08T16:57:19.727Z] <55d21ee30fc9f982beadabb8> because the HistGradientBoostingClassifier will not support mixed type
[2020-01-08T16:58:10.659Z] <5a2c58c8d73408ce4f8294ba> OK, that is the crux of the issue. If the algorithm does not support mixed types then I will just cast it beforehand. Is there a preferred type?
[2020-01-08T16:58:51.768Z] <5a2c58c8d73408ce4f8294ba> GradientBoostingRegressor supports mixed types
[2020-01-08T16:59:06.519Z] <55d21ee30fc9f982beadabb8> nop
[2020-01-08T17:00:03.688Z] <55d21ee30fc9f982beadabb8> This is where I am confused because the array should be converted into float 64 when passing in `check_X_y`. So I would really like a minimal code example
[2020-01-08T17:00:22.987Z] <55d21ee30fc9f982beadabb8> it should failed before the line that you pointed out which is interesting
[2020-01-08T17:00:56.232Z] <5a2c58c8d73408ce4f8294ba> Well GradientBoostingRegressor it runs with a mix of float64, int64, bool in a dataframe
[2020-01-08T17:01:21.801Z] <5a2c58c8d73408ce4f8294ba> I am trying to upgrade to HistGradientBoostingRegressor and hit this error
[2020-01-08T17:01:22.001Z] <55d21ee30fc9f982beadabb8> internally they will all be converted to float64
[2020-01-08T17:02:11.828Z] <55d21ee30fc9f982beadabb8> all of them
[2020-01-08T17:02:14.429Z] <5a2c58c8d73408ce4f8294ba> OK perhaps that conversion needs to be done in HistGradientBoostingRegressor before  np.isnan is called
[2020-01-08T17:02:32.191Z] <55d21ee30fc9f982beadabb8> it is done in `check_X_y` which is called before
[2020-01-08T17:02:42.246Z] <55d21ee30fc9f982beadabb8> but apparently it is not working as expected
[2020-01-08T17:03:01.477Z] <55d21ee30fc9f982beadabb8> But a minimal example will help :P
[2020-01-08T17:03:03.399Z] <5a2c58c8d73408ce4f8294ba> yea, it would seem that way
[2020-01-08T17:03:51.198Z] <5a2c58c8d73408ce4f8294ba> I do not have one since I am just swapping out GradientBoostingRegressor for HistGradientBoostingRegressor in a huge package. 
[2020-01-08T17:04:01.707Z] <5a2c58c8d73408ce4f8294ba> Ill play around a bit and get back to you
[2020-01-08T17:04:57.696Z] <55d21ee30fc9f982beadabb8> Basically this line should do the conversion: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py#L104
[2020-01-08T17:05:39.963Z] <5a2c58c8d73408ce4f8294ba> clf.fit(X_train.values , y_train.values) works but clf.fit(X_train, y_train) does not. The issue seems to be that I am passing a dataframe
[2020-01-08T17:06:16.778Z] <5a2c58c8d73408ce4f8294ba> I can just do clf.fit(X_train.values , y_train.values)
[2020-01-08T17:06:19.986Z] <55d21ee30fc9f982beadabb8> X_train.values will not give a numpy array necessarly
[2020-01-08T17:07:51.147Z] <55d21ee30fc9f982beadabb8> oh sorry this is the way it works. so it should give you a numpy array
[2020-01-08T17:08:35.119Z] <55d21ee30fc9f982beadabb8> you can always check by hand
[2020-01-08T17:09:08.495Z] <55d21ee30fc9f982beadabb8> ```python X, y = check_X_y(X_train, y_train, dtype=[np.float64], force_all_finite=False) ```  
[2020-01-08T17:09:19.617Z] <55d21ee30fc9f982beadabb8> to check what X is looking like
[2020-01-08T17:09:33.121Z] <55d21ee30fc9f982beadabb8> and the same by passing `X_train.values` 
[2020-01-08T17:09:37.336Z] <55d21ee30fc9f982beadabb8> to spot difference
[2020-01-08T17:14:01.144Z] <5a2c58c8d73408ce4f8294ba> yes there is a difference. For example with a date originally 2011.  ```sklearn.utils.check_X_y(X_train, y_train, dtype=[np.float64], force_all_finite=False)``` gives the original 2011
[2020-01-08T17:14:50.559Z] <5a2c58c8d73408ce4f8294ba> but  ```sklearn.utils.check_X_y(X_train.values, y_train.values, dtype=[np.float64], force_all_finite=False)``` gives 2.011e+03 which I presume is how it would show it as a float
[2020-01-08T17:15:46.390Z] <55d21ee30fc9f982beadabb8> `X.dtype` is `object` in the first case?
[2020-01-08T17:16:00.081Z] <5a2c58c8d73408ce4f8294ba> dtype('O') yes
[2020-01-08T17:16:12.477Z] <5a2c58c8d73408ce4f8294ba> in the second dtype('float64')
[2020-01-08T17:17:28.016Z] <55d21ee30fc9f982beadabb8> Uhm this is really weird
[2020-01-08T17:17:32.514Z] <5a2c58c8d73408ce4f8294ba> I have a fix with X_train.values so I am good but I would think this issue will come up a lot as HistGradientBoostingRegressor becomes popular
[2020-01-08T17:17:40.561Z] <55d21ee30fc9f982beadabb8> dtype=[np.float64] should force the conversion
[2020-01-08T17:18:27.280Z] <5a2c58c8d73408ce4f8294ba> Is this then a bug in sklearn.utils.check_X_y. Was it designed to handle being passed dataframes?
[2020-01-08T17:18:47.377Z] <55d21ee30fc9f982beadabb8> normally yest
[2020-01-08T17:19:08.319Z] <55d21ee30fc9f982beadabb8> this would be in `check_array` in `sklearn.utils.validation.py`
[2020-01-08T17:20:26.892Z] <55d21ee30fc9f982beadabb8> might be a side effect of this https://github.com/scikit-learn/scikit-learn/pull/15797/files
[2020-01-08T17:23:27.627Z] <55d21ee30fc9f982beadabb8> ups
[2020-01-08T17:23:41.179Z] <55d21ee30fc9f982beadabb8> we might have forgot to backport the fix in 0.22.1
[2020-01-08T17:25:29.175Z] <55d21ee30fc9f982beadabb8> uhm no it is fine
[2020-01-08T17:25:36.119Z] <55d21ee30fc9f982beadabb8> can you check the version of scikit-learn
[2020-01-08T17:25:53.207Z] <55d21ee30fc9f982beadabb8> are you using `0.22.0` because we corrected the bug in `0.22.1`
[2020-01-08T17:26:03.218Z] <5a2c58c8d73408ce4f8294ba> yup hold on
[2020-01-08T17:26:33.652Z] <5a2c58c8d73408ce4f8294ba> 0.22
[2020-01-08T17:26:45.625Z] <5a2c58c8d73408ce4f8294ba> 0.22.1 not ready in conda yet
[2020-01-08T17:28:28.619Z] <5a2c58c8d73408ce4f8294ba> This issue only happens if X_train has a float in it already
[2020-01-08T17:28:47.067Z] <5a2c58c8d73408ce4f8294ba> I have a minimum example. 
[2020-01-08T17:29:03.478Z] <5a2c58c8d73408ce4f8294ba> ```  import pandas as pd import sklearn import numpy as np  raw_data = {'Binary 1': [True, True, False, False, True],      'Binary 2': [False, False, True, True, False],      'age': [42, 52, 36, 24, 73],      'preTestScore': [4.4, 24.1, 31.3, 2.2, 3.1],     'postTestScore': [25.7, 94.5, 57.0, 62.2, 70.9]} df = pd.DataFrame(raw_data, columns = ['Binary 1', 'Binary 2', 'age', 'preTestScore', 'postTestScore'])    X_train = df[['Binary 1', 'Binary 2', 'age', 'preTestScore']]   y_train = df['postTestScore']  print(X_train.dtypes)  X, y = sklearn.utils.check_X_y(X_train, y_train, dtype=[np.float64], force_all_finite=False)  print(X.dtype)  X, y = sklearn.utils.check_X_y(X_train.values, y_train.values, dtype=[np.float64], force_all_finite=False)  print(X.dtype)   X_train = df[['Binary 1', 'Binary 2', 'age']]   y_train = df['postTestScore']  X, y = sklearn.utils.check_X_y(X_train, y_train, dtype=[np.float64], force_all_finite=False)  print(X.dtype)  X, y = sklearn.utils.check_X_y(X_train.values, y_train.values, dtype=[np.float64], force_all_finite=False)  print(X.dtype) ```
[2020-01-08T17:30:58.747Z] <5a2c58c8d73408ce4f8294ba> Sorry the markdown is not working as I would expect. Does this work for you?
[2020-01-08T17:31:47.725Z] <55d21ee30fc9f982beadabb8> Jump a line after the 3 quotes
[2020-01-08T17:32:19.782Z] <55d21ee30fc9f982beadabb8> you can install from conda-forge
[2020-01-08T17:32:29.284Z] <55d21ee30fc9f982beadabb8> we upload the packages yesterday
[2020-01-08T17:32:42.888Z] <55d21ee30fc9f982beadabb8> or via PyPI
[2020-01-08T17:32:50.759Z] <55d21ee30fc9f982beadabb8> yes it was the bug
[2020-01-08T17:34:23.953Z] <5a2c58c8d73408ce4f8294ba> so in 0.22.1 the last 4 print statements all give float64?
[2020-01-08T17:34:44.202Z] <55d21ee30fc9f982beadabb8> let me try but it should
[2020-01-08T17:35:12.704Z] <5a2c58c8d73408ce4f8294ba> OK sure. Thanks so much for the real time tech support. This is some high quality service
[2020-01-08T17:35:15.040Z] <55d21ee30fc9f982beadabb8> ``` Binary 1           bool Binary 2           bool age               int64 preTestScore    float64 dtype: object float64 float64 float64 float64 ```
[2020-01-08T17:35:56.461Z] <5a2c58c8d73408ce4f8294ba> Awesome. I will update.
[2020-01-08T18:44:53.816Z] <5a2c58c8d73408ce4f8294ba> I cannot update ``` conda install scikit-learn=0.22.1 ```  does not work
[2020-01-08T20:13:21.062Z] <55d21ee30fc9f982beadabb8> `conda install scikit-learn -c conda-forge`
[2020-01-08T20:13:31.839Z] <55d21ee30fc9f982beadabb8> the package are only upload to conda-forge
[2020-01-08T20:13:48.597Z] <55d21ee30fc9f982beadabb8> conda is managing directly the default channel and it can take a bit more time
[2020-01-09T08:09:20.582Z] <5e16d36cd73408ce4fd62604> **Curious To Learn & Contribute To Scikit-learn At The 'Paris Scikit-learn Sprint Of The Decade' | Jan 28 - 31, 2020**  It was quite insightful listening to Reshama Shaikh's recent podcast: https://www.listennotes.com/podcasts/the-banana-data/bdn-15-finding-community-in-uK-yL2tf_S4/  It was quite helpful to broaden my horizon and perspective on open-source when I learned the challenges the organization faces in finding the sponsors and fundraisers for scikit-learn sprint events.  As an avid user of scikit-learn for my research projects in the recent past, Im excited about the potential of contributing and working alongside other attendees at the Paris scikit-learn sprint. Reshama's comments about funding & accessibility have made me even more eager to join the team.  Would you all mind letting me know if I could connect with the other participants remotely from Bengaluru, India?  Best, Sandeep Aswathnarayana
[2020-01-09T09:25:32.966Z] <5c8bb176d73408ce4fbac89c> @SandeepAswathnarayana, sprints are meant to allow people to meet in person, remote participation is not planned. There will be other sprints I'm sure you will be able to attend. In the meanwhile, thanks for your enthusiasm... if you check the contributors guidelines (https://scikit-learn.org/stable/developers/contributing.html) you could probably start helping already.
[2020-01-09T13:53:02.220Z] <5e16d36cd73408ce4fd62604> @cmarmo, Thanks for reverting to my query. I was aware of the already existing ways to contribute. I was only curious to see if I could be a part of the scikit-learn sprint which allows me to do 'Pair Programming' with individuals from diverse backgrounds attending the event.
[2020-01-09T14:00:14.804Z] <5e16d36cd73408ce4fd62604> @cmarmo, Any leads or inputs on future possibilities for remote participation are greatly appreciated. Thank you!
[2020-01-09T14:42:24.314Z] <5c8bb176d73408ce4fbac89c> @SandeepAswathnarayana  > Any leads or inputs on future possibilities for remote participation are greatly appreciated. Thank you!  noted: indeed, there is always room for improvemnts.
[2020-01-09T17:44:18.376Z] <5e1765c2d73408ce4fd6356c> hey folks. I have started my Data Science journey. In the process of completing the DataQuest online Data Science bootcamp . Is SciKit Learn & specifically Auto Sklearn a good set of tools to learn to help accelerate my journey and on the way to becoming an expert?
[2020-01-10T20:03:15.297Z] <5e1765c2d73408ce4fd6356c> @ScottHameed_twitter I know it's not a dev/Git related question, but appreciate the help
[2020-01-12T19:17:56.363Z] <5e1b6aa3d73408ce4fd674ca> @ScottHameed_twitter It's a necessary library used in machine learning. Learn it
[2020-01-13T00:12:22.260Z] <59605bcbd73408ce4f6c2b60> Hey, I opened the PR to add Neuraxle to the Related Projects page:  https://github.com/scikit-learn/scikit-learn/pull/16100  I've put it under the category for `Auto-ML` as it seems better suited here. I'm still developing the serialization plugin/extra libraries for TensorFlow and PyTorch as of right now, so those plugins could go into the `Model export for production` category later on (to allow saving / reloading / then continue training / partial_fit whenever after). 
[2020-01-13T00:18:45.611Z] <59605bcbd73408ce4f6c2b60> I also corrected the thing about "the creator of scikit-learn" in my article :) srry again for the mistake haha
[2020-01-13T10:29:52.261Z] <55a361b55e0d51bd787b3315> I tried building scikit from source, its giving me import error for conftest.py
[2020-01-13T10:31:13.328Z] <55a361b55e0d51bd787b3315> ``` pytest sklearn/metrics/_classification.py  ImportError while loading conftest '/media/sid21g/Dev/github-dev/scikit-learn/conftest.py'. conftest.py:15: in <module>     from sklearn import set_config sklearn/__init__.py:81: in <module>     from . import __check_build  # noqa: F401 sklearn/__check_build/__init__.py:46: in <module>     raise_build_error(e) sklearn/__check_build/__init__.py:41: in raise_build_error     %s""" % (e, local_dir, ''.join(dir_content).strip(), msg)) E   ImportError: No module named 'sklearn.__check_build._check_build' E   ___________________________________________________________________________ E   Contents of /media/sid21g/Dev/github-dev/scikit-learn/sklearn/__check_build: E   setup.py                  _check_build.c            _check_build.pyx E   __init__.py               __pycache__ E   ___________________________________________________________________________ E   It seems that scikit-learn has not been built correctly. E E   If you have installed scikit-learn from source, please do not forget E   to build the package before using it: run `python setup.py install` or E   `make` in the source directory. E E   If you have used an installer, please check that it is suited for your E   Python version, your operating system and your platform. ```
[2020-01-14T15:27:51.341Z] <5baf7d9ad73408ce4fa9c9b2> @sid21g  try maybe `make clean` and start over following the build guidelines
[2020-01-16T16:33:46.033Z] <5acfdfffd73408ce4f95738d> In order not to be verbose, I place a link to the question [stackexchange](https://ai.stackexchange.com/questions/17334/interpretation-of-feature-selection-based-on-the-model) no one answered me There, but there is a desire to understand. I apologize in advance for my poor English).  
[2020-01-16T17:54:07.344Z] <5dbd6437d73408ce4fcfbf0f> @quant12345 as already replied to your post, have a read to this: https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py  In RF, feature importance is affected by features able to overfit the model.
[2020-01-16T22:06:50.963Z] <5acfdfffd73408ce4f95738d> @gbroccolo Thanks!
[2020-01-17T00:12:15.107Z] <5a7dae0ad73408ce4f8c6d2e> Why does `GradientBoostingClassifier` use `DecisionTreeRegressor` instead of `DecisionTreeClassifier`?
[2020-01-17T06:34:12.976Z] <55a361b55e0d51bd787b3315> @NicolasHug Worked!
[2020-01-17T12:19:02.102Z] <5baf7d9ad73408ce4fa9c9b2> @jacobcvt12 because gradient boosting tries to predict gradients which are always continuous targets, even in the case of classification. With a log loss (as used in sklearn) these gradients are homogeneous to a log-odds ratio, and are then passed through a sigmoid function to become a probability between [0, 1]
[2020-01-17T12:20:06.075Z] <5baf7d9ad73408ce4fa9c9b2> self plug: http://nicolas-hug.com/blog/around_gradient_boosting
[2020-01-19T13:38:13.283Z] <56f3953b85d51f252aba800a> Hello, I would be very grateful for help or hint. What I would like to do is to somehow find pattern in text. Lets say you have forum and people or posting on it. I would like to find pattern which would indicate me what are they talking about the most. Thank you for hint.
[2020-01-20T07:04:15.333Z] <5a2c58c8d73408ce4f8294ba> Try TF-IDF
[2020-01-20T13:15:25.574Z] <5dce8ae9d73408ce4fd11e31> Hello. How can I make the program better predict? When you enter the numbers 771, 322, 344, 632, 10, the program predicts 234168, but I need it to be 200000-210000. In linear regression, more than 1000 examples are already embedded.
[2020-01-20T15:18:33.013Z] <5a7dae0ad73408ce4f8c6d2e> Thanks @NicolasHug . I'm trying to figure out why sklearn's GradientBoostingClassifier gives different estimates from R's GBM. I had thought it might be the criterion for splitting, but maybe not. Any suggestions?
[2020-01-20T19:25:03.227Z] <5baf7d9ad73408ce4fa9c9b2> @jacobcvt12 I'm not familiar with R's gbm. The splitting criterion will definitely be a major factor. I'd suggest checking the parameters of each implementation and try to find equivalent settings. In a vanilla implementation of gradient boosting (ignoring the sub-estimator which is a tree in our case), the only parameters are the learning rate / shrinkage, the loss, and the number of iterations.
[2020-01-22T19:22:16.433Z] <5e289bb3d73408ce4fd77f83> Hi
[2020-01-23T16:28:25.865Z] <54d4a1d6db8155e6700f853b> @jacobcvt12 gbm supports categorical variables, I think
[2020-01-26T13:45:43.611Z] <5e2d9704d73408ce4fd7ced4> [![image.png](https://files.gitter.im/scikit-learn/scikit-learn/6t1w/thumb/image.png)](https://files.gitter.im/scikit-learn/scikit-learn/6t1w/image.png)
[2020-01-26T13:47:35.637Z] <5e2d9704d73408ce4fd7ced4> Hello, I'm new to using Pipelines and getting the above error 'Last step of Pipeline should implement fit or be the string 'passthrough'. I can't figure out how to overcome this step. Please assist if you can. 
[2020-01-26T13:53:31.755Z] <5baf7d9ad73408ce4fa9c9b2> @wbadiah_gitlab you're passing a list, instead just pass the estimators directly as in the example: `make_pipeline(StandardScaler(), GaussianNB(priors=None), ...)` `
[2020-01-26T13:53:59.287Z] <5baf7d9ad73408ce4fa9c9b2> i.e. remove the brackets. you can also remove the redundant parenthesis around the estimators
[2020-01-26T14:01:29.713Z] <5e2d9704d73408ce4fd7ced4> Thanks @NicolasHug It worked! 
[2020-01-29T09:09:40.548Z] <54f621ca15522ed4b3dcc151> This PR by me is also with the Paris Sprint https://github.com/scikit-learn/scikit-learn/pull/16256
[2020-01-29T09:12:18.108Z] <54e07d1515522ed4b3dc0852> I'll start by completing https://github.com/scikit-learn/scikit-learn/pull/11296/files at Paris Sprint
[2020-01-29T09:23:27.816Z] <593bb72fd73408ce4f663d44> I am working on this Issue https://github.com/scikit-learn/scikit-learn/issues/12542 as part of the Paris Sprint
[2020-01-29T09:36:06.994Z] <5d43be47d73408ce4fc78bde> I'm working on the issue scikit-learn/scikit-learn#12730 at the Paris Sprint
[2020-01-29T09:59:32.005Z] <54f621ca15522ed4b3dcc151> I'm working on GenericUnivariateSelect of https://github.com/scikit-learn/scikit-learn/issues/11000
[2020-01-29T10:03:20.747Z] <5e314a9cd73408ce4fd81532> I'm working on random_state descriptions for _weight_boosting of  scikit-learn/scikit-learn#16264 
[2020-01-29T10:51:00.373Z] <589b9e0fd73408ce4f490ba4> Please also comment in the issues to indicate the topic you are working on  @DatenBiene @ksslng @martinagvilas @maskani-moh so that other people don't work on the same things.
[2020-01-29T15:29:04.371Z] <5e314ae8d73408ce4fd81550> I'm working on a documentation for _coordinate_descent scikit-learn/scikit-learn#16285 related to the issue scikit-learn/scikit-learn#15761 at the Paris Sprint
[2020-02-07T00:44:22.445Z] <5911fe0fd73408ce4f5e38ec> Is there like a standard file format for storing the output of roc_curve? Maybe something that is easy to read, analyze, visualize, etc?
[2020-02-08T20:09:40.545Z] <5d8b71ded73408ce4fcc0322> Can you help me please !!
[2020-02-08T20:10:12.127Z] <5d8b71ded73408ce4fcc0322> How can i reach to each tree in random forest algorithm 
[2020-02-08T20:10:36.035Z] <54d4a1d6db8155e6700f853b> the estimators_ attribute, check the docs
[2020-02-08T20:11:27.322Z] <5d8b71ded73408ce4fcc0322> I want to extract the rules for every tree i get the following code put there is an error in it 
[2020-02-08T20:13:44.488Z] <5d8b71ded73408ce4fcc0322> model=RandomForestClassifier(n_estamator=10)
[2020-02-08T20:15:00.244Z] <5d8b71ded73408ce4fcc0322> model.fit(iris.data,iris.target)
[2020-02-08T20:15:59.352Z] <5d8b71ded73408ce4fcc0322> estamator =model.n_estamator_[5]
[2020-02-08T20:18:10.808Z] <5d8b71ded73408ce4fcc0322> The error is ''RandomForestClassifier object has no attribute 'n_estimators_'
[2020-02-08T20:18:36.499Z] <5d8b71ded73408ce4fcc0322> how can i write this line please 
[2020-02-08T20:19:28.297Z] <5d8b71ded73408ce4fcc0322> estimator=model.n_estimators_[5]
[2020-02-09T06:59:49.592Z] <5d7aee71d73408ce4fcacd7e> Hello. I'm new to this community and I have got no prerequisites to get started, could someone please help me getting started. Thank you! :)
[2020-02-12T09:48:20.716Z] <5d837603d73408ce4fcb7845> Hey guys! New here. Got a question: why oob_score computing isn't done in parallel like the predict method from RandomForestRegressor?
[2020-02-12T10:55:12.863Z] <5e352127d73408ce4fd863d1> Hi there,  I'm new here... quick question, I'm recently using MLFLOW to manage model lifecycle... I've used it with some scikit-learn models and TensorFlow. Any opinion about mlflow framework? just wanted to know other experiences
[2020-02-20T00:47:59.691Z] <5634e8e116b6c7089cb8fa99> can GaussianProcessRegressor fail in subtle and obvious ways? I might have uncovered a bug.
[2020-02-20T00:53:37.720Z] <5634e8e116b6c7089cb8fa99> demonstration here: https://github.com/tanimislam/sharing-github/blob/master/DEMO%20GPR%20MISUNDERSTANDING.ipynb
[2020-02-20T18:31:08.513Z] <5634e8e116b6c7089cb8fa99> never mind, found the subtlety in scikit-learns GPR and possibly other regressors <unconvertable> scaling the variables made the problem disappear.
[2020-02-20T20:07:18.664Z] <5dbe0c1fd73408ce4fcfc84a> @tanimislam hi any body Please, I am beginner ,how can i update 3.6 to 3.8 python version on window 10 , 64 bit ? _
[2020-02-21T15:55:47.288Z] <5dbe0c1fd73408ce4fcfc84a> Hi any body , I am beginner , can body can give me some basic assignments for python , just for beginners to learn Please? I am using PyCharm . _
[2020-02-22T06:37:04.961Z] <57e9f34a40f3a6eec06789ad> @anjumuaf123_twitter  sir you can join cs50 or EDX Mit course on INTRODUCTION TO PROGRAMMING USING PYTHON
[2020-02-22T14:28:23.720Z] <5dbe0c1fd73408ce4fcfc84a> @jhamlal Dear Sir, how to join this , is it free?  Please send me link  @jhamlal  @jhamlal  @jhamlal 
[2020-02-22T14:36:48.244Z] <5dbe0c1fd73408ce4fcfc84a> @jhamlal Sir, when will you online  acc. to your indian time ?? I need to discuss few things 
[2020-02-22T14:36:50.814Z] <5dbe0c1fd73408ce4fcfc84a> please 
[2020-02-22T14:37:19.430Z] <5dbe0c1fd73408ce4fcfc84a> @jhamlal I can explain  or tell you in details 
[2020-02-22T14:46:58.118Z] <5dbe0c1fd73408ce4fcfc84a> @anshu_bansal280_twitter  I am also new like for learning python 
[2020-02-25T03:30:10.999Z] <57e9f34a40f3a6eec06789ad> > [![perceptron.png](https://files.gitter.im/scikit-learn/scikit-learn/Tyle/thumb/perceptron.png)](https://files.gitter.im/scikit-learn/scikit-learn/Tyle/perceptron.png)  can anyone explain line 6-7 update work , if example that would be great
[2020-02-25T03:51:50.343Z] <5dbe0c1fd73408ce4fcfc84a> @jhamlal  hi sir
[2020-02-25T03:51:56.116Z] <5dbe0c1fd73408ce4fcfc84a> google colab mutb??
[2020-02-25T14:37:03.838Z] <5a32d2b0d73408ce4f835d1a> Hello, why does `cross_val_predict` "eats" prints from `Pipeline`? When i set verbose on Pipeline i dont see any verbosity and when i have debug step in the pipeline that prints shape of the data it also doesnt print anything but when i execute the pipeline manualy it prints all the thing above
[2020-02-25T14:56:04.780Z] <5e2072c5d73408ce4fd6daef> Hello! new, hopefully soon to be contributor here, I am working with a team of fellow data science majors who have recently submitted a pull request for documentation. Would love some guidance or suggestions as we haven't heard anything back yet and are working on more as we speak! Thanks in advance! 
[2020-02-25T14:57:22.054Z] <567f5d7716b6c7089cc043a8> nice to have you on board @hansenallison . Review time is our main bottleneck, and therefore it may take some time before a reviewer can get to check your PR. What's your PR number?
[2020-02-25T14:59:20.243Z] <5e2072c5d73408ce4fd6daef> thank you so much, understandably so! we are PR #16417 and really just added a couple lines of documentation
[2020-02-25T15:03:42.022Z] <5e2072c5d73408ce4fd6daef> @adrinjalali thanks again for responding, even if someone has a minute to let us know if we are on the right track that would be super helpful! 
[2020-02-25T15:15:13.726Z] <5a32d2b0d73408ce4f835d1a> I am running the same version of sklearn but once the pipeline outputs the verbose when in cross_val_predict and the other time it doesnt, could it be something conserning jupyter?
[2020-02-25T15:47:11.035Z] <567f5d7716b6c7089cc043a8> @EnyMan probably it'd be easier to track the problem if you open an issue with a reproducible bit of code 
[2020-03-02T08:38:45.509Z] <5e540a2fd73408ce4fda9945> Hey everyone I recently discovered the partial_fit method for certain regressors such as SGDRegressor, I wondered if I can partial_fit the model with a decreasing learning rate, save it, then reload it and further train with partial_fit but with a different learning rate schedule as before? Thank you in advance
[2020-03-03T11:05:23.108Z] <5d1b262ed73408ce4fc50b53> Can we use an unsupervised algorithm to perform sentiment analysis? If no , how to extract dataset on the customer support conversation transcripts ? as I dont' have any dataset I looking for unsupervised model Please let me know how to proceed ?
[2020-03-03T12:55:40.436Z] <5dbd6437d73408ce4fcfbf0f> Hi @vishu_rj_twitter it depends from what you need...which kind of sentiment analysis would you like to perform? Through unsupervised models you could in theory clusterise the conversations, and for this I'd suggest to have a look to bag of words techniques, word2vec, doc2vec, etc.  But I think you need to classify the conversation following some criteria that exploits the sentiment, right? In this case I don't see any alternative to a supervised classification. And like any supervised problem, find a godd training dataset it's not trivial at all.  But anyway, I'd be open to any further suggestion that could come from this chat. Hope it helped anyway.
[2020-03-03T13:02:19.569Z] <5d1b262ed73408ce4fc50b53> @gbroccolo  I am looking for happy / unhappy ( or positive /negative) criteria sentiments. I have searched for the  customer support conversation transcripts , but I did not got any datasets . I have searched in kaggle and google . let me know if any other repository for such datasets 
[2020-03-03T14:25:14.415Z] <5dbd6437d73408ce4fcfbf0f> @vishu_rj_twitter have a look on NLTK package: there should be some basic implementation based on word's semantics (i.e. it extracts single words and check the presence of generally negative terms like "isn't", "aren't", etc.).
[2020-03-03T14:29:11.373Z] <5dbd6437d73408ce4fcfbf0f> but, again, it strongly depends from what you define "positive" or "negative" in your sentiment analysis. In most cases, you need supervised approaches, and generally you need your own labeled datasets. Machine learning stops to be nice at the moment you realise  you need to label your datasets by your own :)
[2020-03-05T19:01:36.097Z] <5e614c10d73408ce4fdbbb92> Hello, i'm ML student and i'm loving scikit-learn. Altough, i'm struggling using AdaboostClassifier. I'd like to set MLPClassifier as base_estimator but it says "MLPClassifier does not implement sample_weight function". Is there anyway i can customize this to accept this learner and others?
[2020-03-05T19:02:56.422Z] <5e614c10d73408ce4fdbbb92> I also tried to create a VotingClassifier of MLPClassifiers, and then using AdaboostClassifier with VotingClassifier as base_estimator, but no success
[2020-03-05T22:17:59.575Z] <5baf7d9ad73408ce4fa9c9b2> @vendrafilm you can't use AdaBoost with MLP because MLP does not support sample weights and AdaBoost requires the the `base_estimator` parameter to support sample weights (it's in the docstring). AdaBoost works by re-weighting some of the samples, so support for SW is mandatory. There's no way around it unfortunately.
[2020-03-05T22:22:33.769Z] <5e614c10d73408ce4fdbbb92> oh
[2020-03-05T22:23:15.205Z] <5e614c10d73408ce4fdbbb92> @NicolasHug do you recommend another option to achieve this? I really need an Adaboost of MLP classifiers, even if it's not scikit-learn
[2020-03-06T19:25:14.225Z] <5e3f3d7cd73408ce4fd915a4> Hi all, I am working on revamping the [Keras](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/keras) [Scikit-Learn wrappers](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/wrappers/scikit_learn.py). This essentially requires implementing the entire Scikit-Learn API supporting multi-outputs, etc. I think I got everything working just by reading the API reference, but I would like to see if any of the Scikit-Learn developers are willing to take a look at the implementation and give me any pointers on things that might be issues. For example, it is not clear to me if ensembles of multi-output estimators are supported, and other edge cases of that nature. The PR is [here](https://github.com/tensorflow/tensorflow/pull/37201) if anyone wants to take a look. Thank you!
[2020-03-07T01:39:48.651Z] <5e3f3d7cd73408ce4fd915a4> @vendrafilm you should actually check out that PR I just linked! It should be easy to make an MLP in Keras that supports sample_weight and then wrap it to be Scikit-Learn compatible
[2020-03-07T06:41:30.754Z] <5e633ca9d73408ce4fdbe6d6> Hi, I've recently cloned the scikit-learn repository. But I'm having difficulty debugging the code in my Pycharm editor. I keep running into the infamous relative import error. Can someone pass me a reference that guides me on how to do it?  Also, please take a look at my debug configurations and let me know if something's wrong: Working directory: S:\Scikit-learn\scikit-learn\sklearn (I already marked sklearn as the source root) Python interpreter is the virtual environment I created for this. Running "pip show scikit-learn" in this env correctly shows 'Version: 0.23.dev0'. Script path: S:\Scikit-learn\scikit-learn\sklearn\ensemble\_iforest.py I even tried using Module instead of Script for debugging: "sklearn.ensemble._forest".  This just throws another runtime warning and fails. Pycharm is using "pydev debugger (build 193.6494.30)".  Am I wrong to try and debug this file? How can I debug the module as a whole? Some stack overflow discussions answer this but I couldn't figure it out for sklearn. Any help here would be greatly appreciated. Thanks in advance!
[2020-03-07T21:58:43.074Z] <5e614c10d73408ce4fdbbb92> @adriangb thank you, i will take a look. In fact, i need not only Adaboost to support MLP but also support different base estimators in one AdaboostClassifier.. not quite sure if it's possible
[2020-03-13T14:31:16.428Z] <5e6b96b3d73408ce4fdca2f0> Hello, I wanted to write a usage-question on github, but the issue tracker brought me here. I have a multilabel problem which i want to solve with a RandomForestClassifier. But I have so much data that I use a dataloader and a random forest with warmstart: https://stats.stackexchange.com/questions/327335/batch-learning-w-random-forest-sklearn . But I get an error after I fitted the model multiple times and try to predict testdata with multilabels. I broke it down to a minimal example (which fails too), but when I fit data, which i created with make_multilabel_classification, in one go the prediction of the random forest works. Any ideas?
[2020-03-15T15:25:09.672Z] <5b58594ed73408ce4fa23ee3> Hi, I want to write a new scikit-learn compatible estimator where the behaviour of fit/predict depends on a "strategy" hyper-parameter (similar to DummyClassifier but the behaviour is more complicated). Is there any other way/design pattern to implement this apart from making case distinctions within fit/predict? 
[2020-03-15T19:41:34.467Z] <5baf7d9ad73408ce4fa9c9b2> @mloning if the different "strategies" share common code, the conveniently named strategy design pattern might be worth using
[2020-03-16T08:52:25.434Z] <59f3eda9d73408ce4f7c14ba> Hi,In the Scikit learn Website: https://scikit-learn.org/stable/testimonials/testimonials.html#who-is-using-scikit-learn. I know many other companies use scikit-learn package but do not see in the list, what is the process to list the testimonials in the website. 
[2020-03-16T13:00:49.551Z] <5b58594ed73408ce4fa23ee3> @NicolasHug well I guess scikit-learn's Estimator class itself follows the strategy design pattern, but no, the fit/predict behaviour does not share code. I could encapsulate them into their respective classes (`StrategyARegressor`, `StrategyBRegressor`, etc) but then I could tune over the strategy parameter ... any other idea or example in scikit-learn that comes to mind? Thanks for the help! 
[2020-03-16T13:17:25.201Z] <5baf7d9ad73408ce4fa9c9b2> @mloning you can run parameter search over multiple estimators by wrapping them in a Pipeline object (slightly hacky, but it works: https://stackoverflow.com/questions/38555650/try-multiple-estimator-in-one-grid-search). Otherwise,  you can have both StrategyARegressor and StrategyBRegressor, and use these as instances in a MyRegressorClass.
[2020-03-16T14:35:02.588Z] <5b58594ed73408ce4fa23ee3> @NicolasHug "Otherwise, you can have both StrategyARegressor and StrategyBRegressor, and use these as instances in a MyRegressorClass." so how does this last suggestion work? Like a composition? So I'd have something like `if strategey="a": self.estimator = StrategyARegressor()` and then call `fit` by calling `self.estimator.fit()`
[2020-03-16T15:37:03.455Z] <5baf7d9ad73408ce4fa9c9b2> yup
[2020-03-16T17:45:37.264Z] <57b364d540f3a6eec05fce2b> Hello all, i'd be grateful if anyone could take some time to see my question:  https://datascience.stackexchange.com/questions/69788/valueerror-the-estimator-should-be-a-classifier
[2020-03-16T17:49:52.766Z] <57b364d540f3a6eec05fce2b> Briefly, i need ELMClassifier from sklearn-extensions running with VotingClassifier and AdaboostClassifier. After some customizations, i am able to pass the ELM directly to the Adaboost, but i also need to pass a VotingClassifier (of ELMs) to the Adaboost as well. And that's where i'm struggling 
[2020-03-23T04:27:02.017Z] <5df656e9d73408ce4fd42524> Hi everyone , Im a begginer and i want to contribute to scikit learn. I have worked on few Deep Learning projects in pytorch . I cant find a good issue to work as someone is already assigned to it or somebody has already fixed it . Can someone guide me to contributing in this repo
[2020-03-23T08:43:04.625Z] <56bb7a56e610378809c0cb2c> `jonpsy` I can see the chat's packed already,anyway here's my two cents  I was going through the implementation of RandomFourierFeatures implemented in sklearn, under kernel_approximation.py. I noticed a part where you put  ``` class RBFSampler(..):     . . .. def transform(..): .. ..  np.cos(projection,projection) ..  return projection ``` Now np.cos doesn't take two arguments, so what's happening? I tried replicating this in my console and I got error, also why is no variable storing that information ?. I've created the corresponding [issue](https://github.com/scikit-learn/scikit-learn/issues/16746).   Thanks for the help :) 
[2020-03-23T12:41:51.780Z] <56bb7a56e610378809c0cb2c> `jonpsy` Nvm Issue solved thanks !! 
[2020-03-23T12:41:58.019Z] <56bb7a56e610378809c0cb2c> `jonpsy`  * Nvm Issue solved thanks Nicolas Hug (Gitter) . 
[2020-03-24T04:16:09.006Z] <5e7988c7d73408ce4fddc8ec> greetings!
[2020-03-24T04:21:33.728Z] <5e7988c7d73408ce4fddc8ec> I have an assignment in which I am supposed to implement a neural network from scratch. My NN outputs a number between 0 and 1 to classify the input to either +1 or -1. so if the output if less than 0.5 then it belongs to -1, else +1. Unfortunately, my code only returns either +1 or -1, depending on how I initialize the weight matrix. I THINK I'm facing vanishing gradient problem. But I need an expert's opinion to make sure. anyone can please help me??
[2020-03-24T04:22:14.891Z] <5e7988c7d73408ce4fddc8ec> link to my code: https://www.kaggle.com/mowhamadrexa/kernel2ee3f07315
[2020-03-28T12:27:05.573Z] <5decf929d73408ce4fd36f72> I made some machine learning models using Python scikitlearn library and I found some strange situation for me regarding real importance of some variables (features) to ML model. I found that variable which has smaller Pearson coefficient has higher importance on ML model (when exclude variable from model using backward elimination principle) than variables which has higher Pearson.  Below I send the real results of three models where first model includes all three variables and another two models excludes some variables (- means variable is excludes). Iuse Random Forest method.  Model Name     MAE  ModelV1V2V3 0.92 ModelV1V2- 3.86 ModelV1-V3 2.96  PearsonV1=0.99, PearsonV1=0.82, PearsonV3=0.02  When I exclude variables which has no importance based on Pearson (0.02) I got model with better performance comparing to model which includes another variable (V2) whic has far higher Pearson (0.82). Please, help me to explain this situation.  Please, answer me as soon as possible.  Thank You in advance.  Dusko Tovilovic
[2020-03-30T14:59:11.145Z] <5e8208c9d73408ce4fde8bc4> Is it possible to create an adjacency matrix  with LDA?
[2020-04-03T11:32:10.284Z] <5799a0a940f3a6eec05cd618> Hosting TFUG Mysore first meetup : TensorFlow JS - Show and Tell by Jason Mayes  - Senior Developer Advocate at Google. 8 presenters showing what they have #MadeWithTFJS with epic demos lined up + more. RSVP now  http://meetu.ps/e/HTwBV/jYwqF/a
[2020-04-08T01:12:26.738Z] <54db2b1015522ed4b3dbe1bc> greetings
[2020-04-11T23:52:55.760Z] <5e925802d73408ce4fe01b38> Hello, I was using sklearn.svm.SVC and it took five hours.  I did get good results, but I am wondering if scikit-learn has an ETA (Estimated time to Arrival) setting, which shows the estimated time for the program to run.
[2020-04-12T08:20:25.641Z] <5668c71116b6c7089cbe1ea3> @luishrd  There is a verbose setting and a max_iter. 
[2020-04-12T22:18:51.526Z] <5e860fd3d73408ce4fdefde9> @JohnPaulMSU15_twitter There are 2 interesting things I found after a bit of research . There is a parameter you can set for your SVM called `verbose` .  As such you can write: ``` cf = svc.SVM(verbose=2) cf.fit(X,Y) ``` Now , according to [this](https://stackoverflow.com/questions/22443041/predicting-how-long-an-scikit-learn-classification-will-take-to-run) stackoverflow answer, setting this parameter will only output the number of iterations required for optimization as they finish, so they may only give you a hint.  The second and more interesting thing I found is this library : [scitime](https://github.com/scitime/scitime)  It does exactly what you need, trying to provide an estimate for your system. More info at the docs they provide :)
[2020-04-18T18:28:59.789Z] <5e9b457bd73408ce4fe0e90c> I need to write a custom random_selection(for random selection of feature i.e "max_feature" and subset of train data i.e. "subsample") module in scikit-learn to be used with sklearn.ensemble.RandomForestClassifier and GradientBoostingClassifier. Can someone point to some example/documentation/discussion etc.?
[2020-04-22T01:01:46.865Z] <5dc8e3cfd73408ce4fd09e96> What is the best score for the Iris Dataset?
[2020-04-22T07:48:56.660Z] <567f5d7716b6c7089cc043a8> @Dgomzi you probably need to look at the source code for that.
[2020-04-22T15:42:33.948Z] <537bc9bd048862e761fa2239> Hey! Is there a way of computing the dimensionality of a given dataset in scikit-learn? I have some high-dimensional data, which I believe reside on a lower-dimension manifold, the dimension of which is unknown. What I am looking for is some way of measuring the number of dimension of the manifold.
[2020-04-22T16:21:27.589Z] <5e540a2fd73408ce4fda9945> Hey everyone! I wanted to know why sci-kit learn provides the quantile loss for GBRT but not for the SGDRegressor? I am aware that the quantile loss is non-smooth, however GBRT seems to calculate the subgradient at zero for that reason. Wouldn't this be applicable for SGD?
[2020-04-22T18:23:52.229Z] <5dbe0c1fd73408ce4fcfc84a> @arturgvieira_twitter  hi sir
[2020-04-23T12:16:30.931Z] <5baf7d9ad73408ce4fa9c9b2> @cphyc the PCA estimator has a `mle` option to automatically choose the number of components to project on. That's not exactly what you want but I think it's related
[2020-04-24T10:07:06.050Z] <581f1608d73408ce4f33fcaf> hello, would adding the `return_std` argument to the `predict` method of the lightgbm regressor class be enough to plug it into scikit optimize? Also what kind of stdev is it referencing to by `std(Y | X)` ? I tried to look how it is added to the estimators provided by the skopt but it appears it is done in different ways for all of them so it is not clear to me..
[2020-04-25T13:30:05.513Z] <5ad33bbad73408ce4f95b5df> Hi Everyone. I would like to contribute to this open-source project. May I know the process, please. 
[2020-04-25T13:30:42.376Z] <5dbe0c1fd73408ce4fcfc84a> @Akram1234 hi sir
[2020-04-25T13:32:13.570Z] <5ad33bbad73408ce4f95b5df> Hello @anjumuaf123_twitter  sir
[2020-04-25T13:33:01.114Z] <5dbe0c1fd73408ce4fcfc84a> I  am  beginner   for python
[2020-04-25T13:33:22.855Z] <5dbe0c1fd73408ce4fcfc84a> I want to  go for time series analysis
[2020-04-25T13:33:53.846Z] <5dbe0c1fd73408ce4fcfc84a>   @Akram1234  I have my own data 
[2020-04-25T13:33:57.940Z] <5dbe0c1fd73408ce4fcfc84a> @Akram1234 Would you like to help me?
[2020-04-25T13:34:00.388Z] <5dbe0c1fd73408ce4fcfc84a> Please
[2020-04-25T17:12:55.733Z] <5ad33bbad73408ce4f95b5df> sure  @anjumuaf123_twitter 
[2020-04-27T08:34:14.387Z] <5b58594ed73408ce4fa23ee3> Hi all, what's the reason why one shouldn't set other attributes during construction in sklearn estimators apart from those in the `__init__` signature (see estimator check: https://github.com/scikit-learn/scikit-learn/blob/95d4f0841d57e8b5f6b2a570312e9d832e69debc/sklearn/utils/estimator_checks.py#L2390)? If I understand it correctly, `clone` calls the constructor and so all other attributes will also be re-set.
[2020-04-27T08:37:59.230Z] <567f5d7716b6c7089cc043a8> `clone` doesn't call the constructor with the expected parameters. The parameters are set in `set_params`. That means if setting some other attributes depends on some given attribute to `__init__`, and that logic is not duplicated in `set_params`, the constructor would be in an invalid state. Putting those in `fit` makes them all consistent.
[2020-04-27T08:38:52.731Z] <567f5d7716b6c7089cc043a8> But there are ways where you can handle it with setting other parameters in `__init__`, and the estimator not going into an invalid state, if you know what you're doing, then you can ignore that test.
[2020-04-28T09:54:13.142Z] <5b58594ed73408ce4fa23ee3> Thanks for the quick reply, yes, so, as long as there is no logic or interaction of attributes in `__init__`, I can initialise other attributes in `__init__`. We are developing a toolbox that extends sklearn to time series and currently have an `is_fitted` attribute in our base estimator which is initialised to `False`, any reason why this may be a bad idea? 
[2020-04-28T10:04:19.753Z] <567f5d7716b6c7089cc043a8> That's just a bad idea cause we have a `check_is_fitted` utility function which should be used ;)
[2020-04-28T11:10:59.038Z] <5b58594ed73408ce4fa23ee3> I know, I find having an `is_fitted` state cleaner than following the trailing-underscore convention :)  thanks for the help 
[2020-04-29T22:27:03.887Z] <567363d316b6c7089cbf1f13> Hey all, currently doing some dev loop on the pyx in the neighbors package
[2020-04-29T22:27:24.945Z] <567363d316b6c7089cbf1f13> any way to get a faster dev loop than `pip install --editable .`
[2020-04-29T22:27:46.634Z] <567363d316b6c7089cbf1f13> on ubuntu 16.04
[2020-04-30T07:05:36.844Z] <567f5d7716b6c7089cc043a8> You probably wanna pass `-no-build-isolation` as well @mhamilton723 
[2020-04-30T11:56:37.894Z] <5baf7d9ad73408ce4fa9c9b2> @mhamilton723  `make inplace` will only recompile the files that you changed Also if you do lots of back and forth, https://ccache.dev/ might help
[2020-05-01T13:33:48.937Z] <5af2b904d73408ce4f98a88d> Hi everyone!
[2020-05-01T13:34:51.203Z] <5af2b904d73408ce4f98a88d> I've got a few questions considering lin regression. These are mostly focussed on using scikit learn, but I guess the questions are also applicable to all kinds of ML tools :)
[2020-05-01T13:36:40.335Z] <5af2b904d73408ce4f98a88d> [More general formulation of the questions: standardization, onehotencoding/dummy coding with mixed var. types for poly. reg](https://stats.stackexchange.com/questions/463894/feature-standardization-for-polynomial-regression-with-categorical-data)
[2020-05-01T13:37:42.691Z] <5af2b904d73408ce4f98a88d> [and here the python/sklearn specific formulation of the problem with a focus on onehotencoding](https://stats.stackexchange.com/questions/463690/multiple-regression-with-mixed-continuous-categorical-variables-dummy-coding-s)
[2020-05-01T13:38:02.091Z] <5af2b904d73408ce4f98a88d> any help is welcome and appreciated. :)
[2020-05-01T13:39:24.460Z] <5af2b904d73408ce4f98a88d> Since I didn't find any information on this topic anywhere in the user guide, I could also help with improving the user guide once I have more information :)
[2020-05-01T17:26:42.532Z] <567363d316b6c7089cbf1f13> Thank you @adrinjalali  and @NicolasHug :)
[2020-05-02T06:29:11.554Z] <5dbe0c1fd73408ce4fcfc84a> hi guys, I wrote some codes  to get Latitude  and longitude of some districts  but error , Please help me 
[2020-05-03T07:05:18.752Z] <5d1b67bcd73408ce4fc51274> Hi everyone I have a quick question about the math behind the last step of Linear Discriminant Analysis (LDA) for dimensionality reduction. So I understand for the algorithm to calculate for k projection vector(s) you need to determine the eigenvector(s) that corresponds to the top k eigenvalue(s). But does anyone know what you do with those eigenvectors after you have calculated them? My guess is to multiply all of the eigenvectors (projection vectors) together and then multiply that with each point, x, in the original dataset to produce a new point y. Does this seem right? Thank you in advance
[2020-05-03T07:05:54.282Z] <5dbe0c1fd73408ce4fcfc84a> @nadimk1 hi sir
[2020-05-03T07:06:48.237Z] <5dbe0c1fd73408ce4fcfc84a> @nadimk1 I am new  in python . I want to ask that Lubuntu and window 10  can be run in  one machine
[2020-05-03T07:06:50.921Z] <5dbe0c1fd73408ce4fcfc84a> ?
[2020-05-03T17:32:53.457Z] <5d1b67bcd73408ce4fc51274> @anjumuaf123_twitter don't quote me on this, but I think you could probably run it in a virtual machine on your computer using virtualbox
[2020-05-04T17:50:35.834Z] <5d1b67bcd73408ce4fc51274> okay super basic question, but does anyone know how to determine if a KNN model (Sklearn-KNN) is overfitting the data
[2020-05-04T17:51:01.842Z] <5d1b67bcd73408ce4fc51274> I am trying to run it on the MNIST digits dataset, but the accuracy seems way too high
[2020-05-06T19:40:28.433Z] <5446d339db8155e6700cd529> Hi, anyone with Cython knowledge who would have an idea what is going on in here: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_tree.pyx#L817  To me, it seems like a node is being subtracted by an array of nodes, which is given as a pointer index. Also, it looks like the index arithmetic is done on the smaller value, causing supposedly a negative index.
[2020-05-06T19:40:46.855Z] <5446d339db8155e6700cd529> Is it just the index being subtracted here, or is there something else happening here?
[2020-05-07T13:36:41.972Z] <5baf7d9ad73408ce4fa9c9b2> @toldjuuso from what I understand `self.nodes` is both the array of nodes *and* the address of the root node (In C and thus in Cython, an array is just a constant pointer on the first value of that array) so `node - self.nodes` will be positive and it correspond to the offset between the final node `node` and the root i.e. it corresponds to its index in the `self.nodes` array
[2020-05-07T17:47:32.166Z] <5446d339db8155e6700cd529> @NicolasHug Ooh now I see, makes much more sense. I don't program in C, so this has been quite cryptic. I appreciate the help, really!
[2020-05-08T11:31:34.413Z] <5eb542add73408ce4fe31aad> Hi, I'm trying to use Pipeline for combining feature extraction and clustering. I see that there are ways in sklearn for transforming a single column into one or more columns. What I would like to do is specify a new feature as a function of a number of features, inside a pipeline.  I looked at ColumnTransformer, FeatureUnion, and Pipeline, but neither of these enable what I am looking for. Do I have to create these new *features* before I put them in the pipeline? Or am I missing something int he documentation?
[2020-05-08T16:02:59.311Z] <5baf7d9ad73408ce4fa9c9b2> @Bri9k_gitlab maybe the FunctionTransformer is what you're looking for?
[2020-05-09T11:10:15.333Z] <5eb542add73408ce4fe31aad> @NicolasHug Thanks! I think that will work.
[2020-05-19T19:08:22.052Z] <54d4a1d6db8155e6700f853b> does someone remember what the "s" in pandas stands for?
[2020-05-19T19:33:15.328Z] <5baf7d9ad73408ce4fa9c9b2> @amueller  I would have guessed it comes from "Shit, `panda` is already taken" but according to PyPI `pandas` predates `panda` so IDK
[2020-05-19T19:33:37.978Z] <54d4a1d6db8155e6700f853b> lol
[2020-05-20T03:06:05.577Z] <5ec49d18d73408ce4fe44c2c> Hi, I am trying to create anisotropic exponential and anisotropic gaussian kernel function for Sklearns' Gaussian Process Regressor. Any idea how I can do this with sklearns' inbuilt kernels? See attached image. ![alt](https://i.stack.imgur.com/DRKAE.png)
[2020-05-20T03:07:30.473Z] <5ec49d18d73408ce4fe44c2c> I am new to this and I have been looking for help since a long time. Any help will very appreciated. Thanks.
[2020-05-22T13:22:18.823Z] <5e7de2b6d73408ce4fde36e6> At the bottom of the scikit-learn website it says " <unconvertable> 2007 - 2019, scikit-learn developers (BSD License)". I assume it should be 2020 instead of 2019, right? If yes, I'm happy to make an issue and fix it.
[2020-05-22T14:12:25.379Z] <5baf7d9ad73408ce4fa9c9b2> Thanks for noticing @marenwestermann , this is already fixed in the dev version https://scikit-learn.org/dev/user_guide.html
[2020-05-22T14:45:56.817Z] <5e7de2b6d73408ce4fde36e6> Thanks for pointing it out! I'll have a look there first next time.
[2020-05-22T16:53:20.700Z] <5b58594ed73408ce4fa23ee3> Hi, do you have any useful resources for thinking about legal issues in open source (e.g. governance, sponsoring, contributor license agreements)? Would be much appreciated, thanks! :)   
[2020-05-22T17:44:28.928Z] <5baf7d9ad73408ce4fa9c9b2> @mloning I think this book https://producingoss.com/ covers some of these topics
[2020-05-23T08:40:40.578Z] <5ec8df4dd73408ce4fe4a46b> want a project partner for kaggleing
[2020-05-24T13:04:15.306Z] <5b58594ed73408ce4fa23ee3> Thanks @NicolasHug 
[2020-05-26T14:19:38.252Z] <54d4a1d6db8155e6700f853b> FYI in case anyone is interested here's a quick intro video to contributing to sklearn: https://www.youtube.com/watch?v=5OL8XoMMOfA&feature=youtu.be I probably forgot a couple of things, this one is made with the upcoming data umbrella sprint in mind
[2020-05-28T08:45:05.408Z] <5ecf797dd73408ce4fe523d7> Hey guys, I'm trying to use Agglomerative Clustering. When applying the distance threshold, does it have a specific range? E.g. 0-1? or 0-10? or 0-1000? When I tried 1000, it gave me all the same cluster. When trying 500 it gave me clusters 0 1 2 3. I wanted to do something like: "All vectors above 70% similarity should merge" but I'm not sure how to implement that with distance threshold.
[2020-05-28T08:53:30.376Z] <567f5d7716b6c7089cc043a8> what does 70% similarity mean?
[2020-05-28T08:53:41.251Z] <567f5d7716b6c7089cc043a8> the range is applied on the output of your distance metric
[2020-05-28T08:54:10.938Z] <567f5d7716b6c7089cc043a8> if you want .7 to mean 70% similarity, then you should give a metric which results in 0.7 when they're 70% similar, with whatever definition you have
[2020-05-28T08:54:55.125Z] <567f5d7716b6c7089cc043a8> but the distances are not bounded, and therefore usually you need to sample from your distances, look at the distribution, and decide on what the threshold should be
[2020-05-28T08:56:12.283Z] <5ecf797dd73408ce4fe523d7> Yes I do mean something like: if I tried to do cosine distance with 2 vectors and then subtract that by 1 and get the absolute value, I get the similarity. 
[2020-05-28T08:56:20.396Z] <5ecf797dd73408ce4fe523d7> Sorry I'm not familiar with what distance metric refers to
[2020-05-28T08:58:02.756Z] <5ecf797dd73408ce4fe523d7> When you say the distances are not bounded, do you mean that, for every dataset I apply this to, the clustering behavior would change? Basically my situation is I have a bunch of sentence embeddings and I want to cluster the sentences. I found that with my sentence embedding model, sentences with a similarity above 0.7 tend to be actually similar. 
[2020-05-28T08:59:05.223Z] <567f5d7716b6c7089cc043a8> "sentences with a similarity above 0.7 tend to be actually similar. " is not welldefined unless you define you metric, if it's cosine, then your statement may be correct, in which case you should set the `affinity` parameter to cosine
[2020-05-28T08:59:11.605Z] <567f5d7716b6c7089cc043a8> the default is euclidean 
[2020-05-28T08:59:23.163Z] <567f5d7716b6c7089cc043a8> https://scikit-learn.org/dev/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering
[2020-05-28T09:00:14.217Z] <5ecf797dd73408ce4fe523d7> Ah okay I'm currently trying to test with cosine, will report back. Thank you!
[2020-05-28T09:01:39.914Z] <5ecf797dd73408ce4fe523d7> The confusing part for me is the linkage choice. I'm not sure which would give the desired effect. I'll try to search for tutorials online for that though.
[2020-05-28T09:05:06.949Z] <5ecf797dd73408ce4fe523d7> Okay doing this: AgglomerativeClustering(distance_threshold=1,n_clusters=None, affinity='cosine', linkage='complete').fit(sentence_embeddings)
[2020-05-28T09:05:12.925Z] <5ecf797dd73408ce4fe523d7> Gives me 147 clusters 
[2020-05-28T09:05:39.197Z] <5dbe0c1fd73408ce4fcfc84a> @youssefabdelm_twitter Hi Sir, 
[2020-05-28T09:06:17.524Z] <5ecf797dd73408ce4fe523d7> Hey @anjumuaf123_twitter 
[2020-05-28T09:07:29.091Z] <5dbe0c1fd73408ce4fcfc84a> sir,  are you familiar with python GIS?
[2020-05-28T09:07:53.154Z] <5ecf797dd73408ce4fe523d7> I'm not @anjumuaf123_twitter 
[2020-05-28T09:08:05.956Z] <5dbe0c1fd73408ce4fcfc84a> @youssefabdelm_twitter RIGHT SIR
[2020-05-28T09:08:21.583Z] <5dbe0c1fd73408ce4fcfc84a> @youssefabdelm_twitter tHANK YOU VERY MUCH 
[2020-05-28T09:09:06.459Z] <5ecf797dd73408ce4fe523d7> I expected something like 1 cluster for that last line: AgglomerativeClustering(distance_threshold=1,n_clusters=None, affinity='cosine', linkage='complete').fit(sentence_embeddings)"
[2020-05-28T09:16:20.382Z] <5ecf797dd73408ce4fe523d7> Just realized where I might've gone wrong in my thinking there. My dataset probably has a bunch of sentences which are in fact that similar.
[2020-05-28T09:17:20.029Z] <567f5d7716b6c7089cc043a8> you not similar, more like orthogonal and dissimilar
[2020-05-28T09:19:13.359Z] <5ecf797dd73408ce4fe523d7> Ah yes. 1 would refer to more dissimilarity per cluster and 0 more similarity per cluster I think.
[2020-05-28T09:19:42.152Z] <567f5d7716b6c7089cc043a8> yes
[2020-06-03T02:07:11.621Z] <5e148b88d73408ce4fd5f28a> Can anyone help with the sprint event? I already filled the form.
[2020-06-03T06:29:22.419Z] <567f5d7716b6c7089cc043a8> @reshama should know better about the participants and RSVPs
[2020-06-04T00:43:40.856Z] <5ecf797dd73408ce4fe523d7> Hey guys, is the agglomerative clustering in scikit learn soft or hard? Or is there a setting somewhere we could use to set that?
[2020-06-04T00:46:38.805Z] <5ecf797dd73408ce4fe523d7> Also, while using agglomerative clustering on 100K data points, my computer crashed. I assume this is because I didn't use the 'memory' parameter for caching? Or did I misunderstand something there?
[2020-06-04T19:02:52.793Z] <54d4a1d6db8155e6700f853b> the memory parameter will not help you here. What do you mean by soft or hard?
[2020-06-04T19:04:10.922Z] <54d4a1d6db8155e6700f853b> it might be useful to precomputed the distance matrix in a chunked way
[2020-06-04T19:06:01.227Z] <54d4a1d6db8155e6700f853b> how much RAM do you have?
[2020-06-04T19:11:18.600Z] <54d4a1d6db8155e6700f853b> and which linkage mode are you using?
[2020-06-05T00:04:42.289Z] <5ecf797dd73408ce4fe523d7> Hey @amueller ! By soft or hard I mean to refer to soft clustering or hard clustering - which if I understand correctly, soft clustering refers to when datapoints can co-exist in different clusters whereas with hard clustering they can only exist in one cluster. 
[2020-06-05T00:04:46.204Z] <5ecf797dd73408ce4fe523d7> I have 16 GB of RAM
[2020-06-05T00:04:53.536Z] <5ecf797dd73408ce4fe523d7> Using complete linkage
[2020-06-05T00:05:09.538Z] <5ecf797dd73408ce4fe523d7> How could I go about precomputing the distance matrix in a chunked way?
[2020-06-05T00:40:22.124Z] <5ecf797dd73408ce4fe523d7> I don't know if I got this right so far: 
[2020-06-05T00:41:45.479Z] <5ecf797dd73408ce4fe523d7> from sklearn.metrics import pairwise_distances_chunked from sklearn.cluster import AgglomerativeClustering  chunked = pairwise_distances_chunked(sentence_embeddings, metric='cosine', n_jobs=-1)  for chunk in chunked:        clustering = AgglomerativeClustering(distance_threshold=0.5,n_clusters=None, affinity='precomputed', linkage='complete').fit(chunk)
[2020-06-05T00:41:54.159Z] <5ecf797dd73408ce4fe523d7> print(clustering.labels_)
[2020-06-05T13:41:52.641Z] <589b9e0fd73408ce4f490ba4> @youssefabdelm_twitter You could try https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-transformer
[2020-06-05T14:14:31.703Z] <54d4a1d6db8155e6700f853b> @youssefabdelm_twitter you should call pairwise_distances directly I think as it does chunking internally. Though I now realized agglomerativeclustering might already be doing. Also agglomerative clustering is hard clustering @rth I was thinking about that, but shouldn't agglomerativeclustering be already chunked using the working_memory parameter? cc @jnothman 
[2020-06-05T16:15:50.588Z] <5ecf797dd73408ce4fe523d7> Interestingly I actually tried the code I shared above on a small example and it worked, but on the 100K embeddings it just exported 1 cluster, and the amount of embeddings in that was around 750 which really confused me. I still have no idea what happened.
[2020-06-05T16:16:25.478Z] <5ecf797dd73408ce4fe523d7> By calling it directly, do you mean something like this:  "for chunk in pairwise_distances_chunked(sentence_embeddings, metric='cosine', n_jobs=-1):"
[2020-06-05T16:16:46.189Z] <5ecf797dd73408ce4fe523d7> Or this: AgglomerativeClustering(distance_threshold=0.5,n_clusters=None, affinity='precomputed', linkage='complete').fit(pairwise_distances_chunked(sentence_embeddings, metric='cosine', n_jobs=-1))
[2020-06-05T16:23:30.813Z] <5ecf797dd73408ce4fe523d7> @rth Do you mean using this in place of agglomerative clustering or for chunking / precomputing the distance matrix? 
[2020-06-05T16:28:53.174Z] <5ecf797dd73408ce4fe523d7> @amueller  I tried both, I assume you mean the first as that one works. The second gives me an error. "ValueError: Expected 2D array, got scalar array instead: array=<generator object pairwise_distances_chunked at 0x11009fc78>. Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
[2020-06-05T16:39:15.497Z] <5ecf797dd73408ce4fe523d7> Oops! Now I see where I was wrong
[2020-06-05T16:39:27.782Z] <5ecf797dd73408ce4fe523d7> And why those 100K data points only exported 1 cluster 
[2020-06-05T16:40:10.300Z] <5ecf797dd73408ce4fe523d7> In the toy example, I did this:  chunked = pairwise_distances_chunked(sentence_embeddings, metric='cosine', n_jobs=-1)  for chunk in chunked: clustering = AgglomerativeClustering(distance_threshold=0.5,n_clusters=None, affinity='precomputed', linkage='complete').fit(chunk)
[2020-06-05T16:40:30.469Z] <5ecf797dd73408ce4fe523d7> I set the parameter metric to 'cosine' in pairwise distances 
[2020-06-05T16:40:42.689Z] <5ecf797dd73408ce4fe523d7> and I set affinity to 'precomputed' in AgglomerativeClustering
[2020-06-05T16:40:56.780Z] <5ecf797dd73408ce4fe523d7> When I then tried to do this with the 100K datapoints
[2020-06-05T16:41:07.721Z] <5ecf797dd73408ce4fe523d7> I forgot to change 'cosine' to 'precomputed' in AgglomerativeClustering
[2020-06-05T17:07:04.307Z] <5ecf797dd73408ce4fe523d7> Now I'm getting this new error: "ValueError: Distance matrix should be square, Got matrix of shape {X.shape}"
[2020-06-05T17:07:13.272Z] <5ecf797dd73408ce4fe523d7> After making that change
[2020-06-05T17:20:08.467Z] <5ecf797dd73408ce4fe523d7> I hope I'm making some other stupid mistake rather than this being a consequence of a large input
[2020-06-05T17:29:22.724Z] <5ecf797dd73408ce4fe523d7> So far I don't see any difference between the toy example and the code I'm using for the 100K embeddings
[2020-06-05T17:39:26.095Z] <5ecf797dd73408ce4fe523d7> This is what I'm using for the 100K embeddings: 
[2020-06-05T17:39:54.161Z] <5ecf797dd73408ce4fe523d7> chunked_distances = pairwise_distances_chunked(sentence_embeddings, metric='cosine', n_jobs=-1, working_memory=3072) for chunk in tqdm(chunked_distances, total=22):    with io.capture_output() as captured:     clustering = AgglomerativeClustering(distance_threshold=0.5,n_clusters=None, affinity='precomputed', linkage='complete').fit(chunk)
[2020-06-05T20:49:00.985Z] <589b9e0fd73408ce4f490ba4> @youssefabdelm_twitter I don't think that using AgglomerativeClustering on chunks of the distance matrix would give you anything meaningful. I meant using `KNeighborsRegressor`to precompute a sparse distance matrix, but then I'm not sure if `AgglomerativeClustering` actually supports sparse distance matrices. You won't be able to compute a dense as for 100k samples that would be ~80GB.  Generally AgglomerativeClustering doesn't scale well with default options (https://hdbscan.readthedocs.io/en/latest/performance_and_scalability.html) so I would suggest starting with a smaller dataset and progressively increase the number of samples to see how it scales. You may run into performance issues before memory ones. @amueller I haven't looked at the code in detail, but internally it never uses `pairwise_distances` on the full dataset.
[2020-06-05T20:49:38.067Z] <54d4a1d6db8155e6700f853b> hm. I was wondering if we need to add an example of doing some chunked clustering
[2020-06-05T21:09:59.911Z] <5ecf797dd73408ce4fe523d7> @rth Does this mean that besides a sparse distance matrix (I'll give it a shot soon), there's really no way to do this all at the same time without a more powerful computer? So far what I've been doing is doing the clustering in chunks, meaning slicing the data (38K data points at a time) and then creating clusters from those. However, to me this is undesirable because of course (in my case) I get sentences which are in separate clusters which should more preferably be in one. I thought one idea to mitigate this is to calculate the centroid of each cluster, and then after all the 38K chunks are done, to compare centroids and then merge if they're below a certain distance threshold. Of course this loses the benefit of having the leaves & children info though.
[2020-06-05T21:11:10.193Z] <5ecf797dd73408ce4fe523d7> I ask because eventually, I want to do this with around 1 million vectors
[2020-06-05T21:12:55.553Z] <5ecf797dd73408ce4fe523d7> Also curious why you say that using AgglomerativeClustering on chunks of the distance matrix wouldn't give any meaningful results. Is it for the same reason I said above on getting different clusters which should really be one cluster?
[2020-06-05T21:14:32.041Z] <589b9e0fd73408ce4f490ba4> @youssefabdelm_twitter Looks like single linkage should scale better for agglomeration clustering https://github.com/scikit-learn/scikit-learn/pull/11514#issuecomment-557349961  Well I mean it's just awkward to work with N separate clustering, but you can if you are comfortable with it. 
[2020-06-05T21:17:38.055Z] <5ecf797dd73408ce4fe523d7> @rth Very useful, thank you!
[2020-06-05T21:17:41.086Z] <589b9e0fd73408ce4f490ba4> Also I think think Birch or DBSCAN might scale better if want a hierarchy of clusters. If you have 1M samples that certainly going to put constraints on the algorithms you can use (cf above linked HDBSCAN docs for a comparison) unless you can accept working on a subsampled dataset.
[2020-06-05T21:20:29.389Z] <5ecf797dd73408ce4fe523d7> Awesome! Helpful charts. Wanted to ask what you meant by "N separate clustering"
[2020-06-05T21:22:00.617Z] <5ecf797dd73408ce4fe523d7> I assume you mean what I described above with splitting the data?
[2020-06-05T21:24:18.707Z] <589b9e0fd73408ce4f490ba4> yes, I mean that if you do `AgglomerativeClustering().fit(X_chunk)` in a loop, as mentionned in your above code, at each iteration you are going to get a new clustering. All previous information is erased when you call fit, it's not a `partial_fit`. So that would be just equivalent to running the this clustering on N subsets of the full dataset I think.
[2020-06-05T21:25:16.554Z] <5ecf797dd73408ce4fe523d7> Ah makes sense, thank you
[2020-06-05T21:30:53.901Z] <5ecf797dd73408ce4fe523d7> I might try the 'meta-clustering' approach I talked about where I just compare centroids (or try to apply complete linkage) of clusters from different chunks and then merge, and sort of testing that against what agglomerative clustering would normally do and see how the results vary. Do you think this would yield expected results (All points above 70% similarity should be grouped) or should I instead go with HDBSCAN? My one need is not specifying the number of clusters, but instead a distance threshold of some kind.
[2020-06-05T21:55:32.740Z] <5ecf797dd73408ce4fe523d7> Sorry never mind, I didn't know about epsilon! I gotta do more research on HDBSCAN as I'm not that familiar with it.
[2020-06-06T09:39:41.571Z] <5bac969fd73408ce4fa98ba2> @adrinjalali https://github.com/scikit-learn/scikit-learn/issues/16951
[2020-06-06T10:14:45.486Z] <567f5d7716b6c7089cc043a8> I think the "go wanted" tag was removed from the issue cause we already have at least a half solution to the issue. Not sure if we want to work on it during the sprint @Mariam-ke 
[2020-06-06T10:16:53.741Z] <567f5d7716b6c7089cc043a8> *"help wanted"
[2020-06-06T10:17:15.647Z] <567f5d7716b6c7089cc043a8> Is it on the issue list for the sprint @Mariam-ke ?
[2020-06-06T20:52:29.023Z] <5a9c7b4dd73408ce4f8fd92e> I have a small concern.  I am wondering if matplotlib should also be installed in setup.py along with NumPy and scipy. Is there is a reason it is not?
[2020-06-06T21:33:52.142Z] <54d4a1d6db8155e6700f853b> @Sahanave there is no reason to. It's a soft dependency and many people run scikit-learn in a server setup where there's not even a screen attached
[2020-06-07T00:19:20.077Z] <5a9c7b4dd73408ce4f8fd92e> That makes sense. Thansk @amueller 
[2020-06-08T11:12:18.984Z] <5a3b81c4d73408ce4f84514c> Hello ! I have a question about the use of GutHub. I have started working on a pull request with Joseph Lucas (https://github.com/JosephTLucas) during the Data Umbrella sprint this week-end (https://github.com/scikit-learn/scikit-learn/pull/17504). I am trying to add a commit to this pull request (while I have not created it, Joseph has). In order to do so, I want to send a pull request to Joseph Lucas on his branch. However, I do not understand why I the github interface does not propose his repo as base when I create the pull request (while he has his own scikit-learn repo https://github.com/JosephTLucas/scikit-learn). What do you recommend I do ? I would prefer not to open a new pull request.
[2020-06-08T11:19:10.774Z] <567f5d7716b6c7089cc043a8> I think when you open a PR there's a checkbox which says "show all forks" or something, and then it'd show you Joseph's fork as well.
[2020-06-08T11:24:22.404Z] <5a3b81c4d73408ce4f84514c> Github displays the following :  Open a pull request Create a new pull request by comparing changes across two branches. If you need to, you can also compare across forks. When I click on "compare across forks", it displays a list of forks (base repository), but Joseph's fork does not appear. (the list seems too short to contain all forks of scikit-learn). Github does not manage to find his fork even when I enter the repo name :  JosephTLucas/scikit-learn.
[2020-06-08T11:25:33.301Z] <5571fe1015522ed4b3e17d90> Yeah this seems be a github interface issue (not 100% sure more of a wild guess).
[2020-06-08T11:25:33.796Z] <567f5d7716b6c7089cc043a8> interesting, I'm not sure then
[2020-06-08T11:26:22.679Z] <5571fe1015522ed4b3e17d90> I think if you go to a URL like this: https://github.com/JosephTLucas/scikit-learn/compare/master...ab-anssi:master
[2020-06-08T11:26:36.210Z] <5571fe1015522ed4b3e17d90> You should be able to create a PR to JosephTLucas repo
[2020-06-08T11:27:00.236Z] <5a3b81c4d73408ce4f84514c> Thanks ! That is exactly what I wanted : )
[2020-06-08T11:28:02.085Z] <5571fe1015522ed4b3e17d90> There is this weird thing that if you use the "natural way" (at least to me) of creating a PR to JosephTLucas fork it insists on creating a PR to the main repo (scikit-learn/scikit-learn)
[2020-06-08T11:29:00.068Z] <5571fe1015522ed4b3e17d90> If you go there: https://github.com/JosephTLucas/scikit-learn/pulls and click "New Pull Request" it creates the PR against scikit-learn/scikit-learn from JosephTLucas fork and as you noticed I was not able to change that to use JosephTLucas fork as the target (**edit** it turns out clicking on the blue arrow between base and head fork is another work-around)... 
[2020-06-08T11:40:00.648Z] <5a3b81c4d73408ce4f84514c> I have sent the pull request to Joseph. Thanks for help. It is the first time I send a pull request to a contributor to update his pull request to the main repo. If he accepts my pull request (to the branch of the pull request), will it automatically update the pull request (to the main repo) with my commit ?
[2020-06-08T11:52:00.295Z] <5571fe1015522ed4b3e17d90> Short answer: yes. Longer answer: his PR is tied to his branch so as soon he merges your PR on his fork, his branch will be updated and your changes will appear on the PR to scikit-learn/scikit-learn.
[2020-06-08T11:53:35.311Z] <5571fe1015522ed4b3e17d90> Side-comment: if you collaborate from time to time with JosephTLucas a reasonable way to make that easier is that JosephTLucas gives you write access to his fork. This way you can push directly to his branch without doing a PR on his fork.
[2020-06-08T12:01:35.787Z] <5a3b81c4d73408ce4f84514c> @lesteve Thanks for the "side-comment". I will ask him if he agrees to do so. It would be much easier : )
[2020-06-08T12:21:16.674Z] <5ec571c9d73408ce4fe461b0> Sounds like a plan!
[2020-06-10T11:05:00.121Z] <5ee0be30d73408ce4fe67f61> Hello, i hope this is the right place for my question
[2020-06-10T11:07:45.954Z] <5ee0be30d73408ce4fe67f61> i have a problem with a 1D-Classification. I simplified my problem to the following: There are 2 classes +1 and -1 and i have a trainvalue for each of the classes 0.0293294646367189  (class -1) and  0.025545042466768184 (class 1) Now that i trained a LinearSVC with those values i throw some random values to the classifier to predict
[2020-06-10T11:08:04.309Z] <5ee0be30d73408ce4fe67f61> i expect the decision limit to be in the center of the two example values
[2020-06-10T11:08:42.658Z] <5ee0be30d73408ce4fe67f61> but even 0.025545042466768184, the train data for class 1 is predicted as -1
[2020-06-10T11:10:19.006Z] <5ee0be30d73408ce4fe67f61> i even tried to move this to a 2D Problem adding a 2nd feature to the values [0.0293294646367189, 0] and [0.025545042466768184, 0] but this didn't worked either
[2020-06-10T15:49:38.954Z] <564789be16b6c7089cbab8b7> I have some data I want to so linear regression on. When I use LinearRegression().fit(X_scaled, y[policy]) I get a score of over 0.96
[2020-06-10T15:49:54.567Z] <564789be16b6c7089cbab8b7> when I use LassoLarsCV(cv=5).fit(X_scaled, y[policy]) I get a score of 0
[2020-06-10T15:50:00.439Z] <564789be16b6c7089cbab8b7> what am I doing wrong?
[2020-06-10T19:43:53.256Z] <54d4a1d6db8155e6700f853b> what's the complete code? Training set score or test set score?
[2020-06-12T09:13:05.460Z] <5c3cec52d73408ce4fb4aea1> Hi, I have a large dataset, 600K rows and 2 columns of target. Multioutput xgboost works well, but Random Forest is so slow. How Can I perform it ?
[2020-06-12T09:13:28.254Z] <5c3cec52d73408ce4fb4aea1> Its a regression problem
[2020-06-13T19:36:48.229Z] <5ee529b7d73408ce4fe6ceb3> i am writing a neural network without any external libraries for MNIST with only 4 labels.In the train _labels.csv  file i have one hot encoded data(1000) for all samples, my doubt is how to call the data directly to the function in the code. iam using softmax as my activation function in output layer
[2020-06-14T18:18:04.569Z] <5dbd6437d73408ce4fcfbf0f> Hi @FranciscoPalomares Random Forest is a collection of models which can be trained independently and can be parallelised: I guess for the classification you are using the RandomForestClassifier, you can scale the training through the n_jobs parameter when you instantiate it, something like  ``` RandomForestClassifier(n_estimators=100, n_jobs=-1) ```
[2020-06-15T14:32:57.253Z] <564789be16b6c7089cbab8b7> does the default FeatureAgglomeration just leave you with 2 features?
[2020-06-15T16:51:20.370Z] <567f5d7716b6c7089cc043a8> as stated in the [docs](https://scikit-learn.org/dev/modules/generated/sklearn.cluster.FeatureAgglomeration.html#sklearn.cluster.FeatureAgglomeration), `n_clusters=2` is the default value.
[2020-06-15T16:51:51.848Z] <564789be16b6c7089cbab8b7> does that mean you end up with 2 features? 
[2020-06-15T16:51:58.347Z] <564789be16b6c7089cbab8b7> I am not clear what a cluster means here
[2020-06-15T16:52:11.762Z] <564789be16b6c7089cbab8b7> @adrinjalali  (thank you)
[2020-06-15T16:54:56.728Z] <567f5d7716b6c7089cc043a8> yes, the examples and the user guide will give you a better idea on how it works and what it does: https://scikit-learn.org/dev/modules/clustering.html#hierarchical-clustering
[2020-06-15T16:55:45.826Z] <564789be16b6c7089cbab8b7> thank you
[2020-06-15T16:55:57.039Z] <564789be16b6c7089cbab8b7> I am surprised it works so well for my regression problem!
[2020-06-15T16:56:08.941Z] <54d4a1d6db8155e6700f853b> I think we could add it to the docstring as well. I think it's clear from the user guide but why not add it to the docstring?
[2020-06-15T16:57:44.834Z] <567f5d7716b6c7089cc043a8> I agree that its docstring can be substantially improved :D the examples can also see some love
[2020-06-19T20:18:11.179Z] <5eeb9b35d73408ce4fe749bc> Hullo! I took on #9602 as a first issue for the MLH Fellowship. Looking into it further, it seems like the scope of the issue is much larger than clarifying a single docstring. I'm unsure of whether to start poking away at it, or whether to start a larger discussion on the direction of multiclass/multilabel learning in sklearn. Would love to hear thoughts. :)
[2020-06-19T21:29:51.224Z] <54d4a1d6db8155e6700f853b> hm honestly I think we're pretty consistent with the terms in the glossary
[2020-06-19T21:30:40.325Z] <54d4a1d6db8155e6700f853b> >  In some places, multiclass/multilabel functionality is explicit and indicated by the name of the function.
[2020-06-19T21:30:45.869Z] <54d4a1d6db8155e6700f853b> can you give an example of that?
[2020-06-19T21:30:53.579Z] <54d4a1d6db8155e6700f853b> that's for meta-estimators, I guess?
[2020-06-19T21:58:28.167Z] <5eeb9b35d73408ce4fe749bc> Ah, I guess I went a bit overboard with my comment, seeing an issue where there was none.
[2020-06-19T22:01:06.563Z] <5eeb9b35d73408ce4fe749bc> I'll focus on clarifying the OVR docstring, then.
[2020-06-23T18:49:21.785Z] <5eeb9b35d73408ce4fe749bc> Does anyone have any tips for making an API proposal go smoothly? (e.g. the structure of a good proposal, good examples of existing proposals)  Context: I was hoping to start working on a proposal for adding Gibbs sampling to LatentDirichletAllocation, going off of Thomas's recommendations.
[2020-06-23T18:51:20.443Z] <5eeb9b35d73408ce4fe749bc> Ah, just found the SLEP template. 
[2020-06-23T18:52:20.931Z] <567f5d7716b6c7089cc043a8> I think adding features like that is usually discussed in the issues @joshuacwnewton SLEPs have been a bit more on the general API rather than specific features
[2020-06-23T18:53:28.662Z] <567f5d7716b6c7089cc043a8> it can be just an issue like this one, for example https://github.com/scikit-learn/scikit-learn/issues/15346
[2020-06-23T18:53:44.148Z] <5eeb9b35d73408ce4fe749bc> Ah, thanks for the clarification, @adrinjalali! 
[2020-06-26T05:17:37.477Z] <5ef58225d73408ce4fe7f0dc> Hello, the question I meet is the socres returned from the function 'cross_val_score'  seem to be very different from the result of actual fitting process. This is the last training process where most of the valid loss are about 0.1. However the score I get from the 'cross_val_score' is about 0.49. The score I use is the 'neg mse' which is the similar to the loss function of the network  'mse'. I want to know why it happens and how to fix it. Thanks a lot.
[2020-06-26T05:17:51.350Z] <5ef58225d73408ce4fe7f0dc> [![image.png](https://files.gitter.im/541a528c163965c9bc2053e1/rNGu/thumb/image.png)](https://files.gitter.im/541a528c163965c9bc2053e1/rNGu/image.png)
[2020-06-27T16:34:51.657Z] <582376efd73408ce4f34cba5> hola
[2020-06-29T23:10:36.162Z] <5eeb998cd73408ce4fe74924> Just submitted a new PR for the cross-validation documentation #17781 
[2020-06-30T19:01:31.749Z] <5e7c6de2d73408ce4fde10ba> Hello, guys. How can I use a custom Distance Function for OPTICS clustering algorithm?
[2020-07-01T16:43:19.727Z] <54d4a1d6db8155e6700f853b> @GF-Huang you can use the metric parameter
[2020-07-01T17:13:17.592Z] <5efcc3d8d73408ce4fe8707d> Upvote vscode issue to allow colorfull output when fitting with Sklearn. https://github.com/microsoft/vscode-python/issues/12615
[2020-07-02T20:54:54.921Z] <5de821c2d73408ce4fd31a52> Can I request I/we/someone works on getting this merged https://github.com/scikit-learn/scikit-learn/pull/15007 as part of the SciPy sprint
[2020-07-04T11:26:21.469Z] <589b9e0fd73408ce4f490ba4> @raybellwaves That PR is now merged.
[2020-07-06T14:22:14.764Z] <5e7de2b6d73408ce4fde36e6> I came across this on Twitter today and it made me think that scikit-learn also uses the word "dummy": https://twitter.com/wimlds/status/1279635475825754112 It would probably be good to move away from using this word (Google is trying to do the same btw: https://developers.google.com/style/word-list#dummy-variable), however it would be a big undertaking. A search for this word in scikit-learn gives me 479 results. I just wanted to point this out and ask what you think about it.
[2020-07-06T15:30:05.757Z] <567f5d7716b6c7089cc043a8> I guess we could call the `Dummy{Classifier/Regressor}` a `Trivial{Classifier/Regressor}`?
[2020-07-06T15:47:00.411Z] <5eeb997bd73408ce4fe7491d> in some testing files like `sklearn/cluster/tests/test_hierarchical.py` and `sklearn/gaussian_process/tests/test_gpr.py` the comments refer to creating dummy data and dummy optimizers but don't use the dummy classifier or variables. Maybe a good first step would be to change the wording in these comments as it doesn't conflict with the code?
[2020-07-06T19:12:59.338Z] <5baf7d9ad73408ce4fa9c9b2> is dummy offensive?
[2020-07-06T19:34:14.414Z] <567f5d7716b6c7089cc043a8> I looked up why it's offensive, and it seems most people think it is or may be offensive because of the way it's use as a derogatory term to call somebody stupid or an idiot. Now if we think of the people whom unfortunately are called often dumb or stupid by their friends or colleagues while many of them being very talented, we realize why the term may be a trigger for them. I personally don't find it offensive in the context which is used in our library, but general rule of thumb is that if there are many reasonable people out there who thing something is offensive, then it's offensive to them and I should avoid using the term, if that makes sense.
[2020-07-07T13:33:39.244Z] <5baf7d9ad73408ce4fa9c9b2> Could be wrong but my impression is that we mostly use the word dummy to denote "something designed to resemble and serve as a substitute for the real or usual thing; a counterfeit or sham" (taken from google definition). That might not be true in the case of DummyClassifier/Regressor, where the name might come from the fact that these estimators are over simplistic. Though the previous definition could also hold for them. IDK. Changing their names will force lots of users to change their code though,  so it's not just going to be an internal change.  As a side note we also have a bunch of "sanity checks", deemed non-inclusive by twitter, and I'll admit I'm quite puzzled by this one
[2020-07-08T06:23:14.705Z] <5f05657ed73408ce4fe9033c> thank you
[2020-07-08T08:30:59.394Z] <5a25274ed73408ce4f819b55> I have a question regarding the usage of the FeatureUnion weights.  I recently had a typo in a key of the weights dictionary, which does not lead to a warning or an error. Suppose:  ```python features = FeatureUnion([   ('f0', my_fancy_extractor_0),   ('f1', my_fanyc_extractor_1), ], transformer_weights={   'f1': 1.5,   'f2': 1.0, }) ```  I understand that tranformers without any weights (e.g., `f0`) will implicitly have assigned a weight of 1.0 (i.e., it is not multiplied with anything), which seems intuitive, but trying to assign weights to a transformer that is not part of the FeatureUnion is simply ignored.  I would argue that it would be beneficial if a warning would be shown instead, as this is a very tedious problem to debug in my opinion. What do you think?
[2020-07-08T09:47:41.325Z] <567f5d7716b6c7089cc043a8> I think this deserves an issue on the issue tracker with a small reproducible bit of code using the latest release. Input feature name validations are improving on our side, but there's still work to do.
[2020-07-08T11:41:05.926Z] <5a25274ed73408ce4f819b55> Thank you @adrinjalali , i have submitted an issue: #17863 
[2020-07-09T11:32:42.898Z] <5c3cec52d73408ce4fb4aea1> I dump with joblib a model with all cpus (njobs = -1), when I load the model and predict, not use all cpus
[2020-07-09T17:00:15.871Z] <5dbe0c1fd73408ce4fcfc84a> hi sir  how to  ignore negative floating values in a data set ?
[2020-07-09T18:56:53.947Z] <589b9e0fd73408ce4f490ba4> @FranciscoPalomares Use `estimator.set_params(n_jobs=1)` after unpickling
[2020-07-10T18:40:09.531Z] <5eeb9b35d73408ce4fe749bc> Hello! I've got one approval on an open PR -- if anyone has time, may I have a second reviewer? #17662  No rush, of course. I understand how busy things are. Thanks much! :)
[2020-07-11T00:36:20.046Z] <5eeb9b35d73408ce4fe749bc> My above request has been addressed by @NicolasHug. Thanks! :D
[2020-07-11T13:29:45.500Z] <54d4a1d6db8155e6700f853b> Good morning :)
[2020-07-11T13:36:32.797Z] <5f09bedad73408ce4fe951c0> Hello!  Is there anyone who can assist me in using scikit's normalized mutual information for real, continuous climate data?
[2020-07-11T13:37:37.780Z] <54d4a1d6db8155e6700f853b> @bfiranski as far as I know, it's only implemented for discrete data. computing mutual information for continuous data requires making distributional assumptions
[2020-07-11T13:38:34.405Z] <5f09bedad73408ce4fe951c0> I was wondering about that because I was getting non-nonsensical results
[2020-07-11T13:38:39.451Z] <5f09bedad73408ce4fe951c0> many thanks!
[2020-07-11T13:38:40.798Z] <54d4a1d6db8155e6700f853b> We actually have a non-parametric mutual information for feature selection (between a continuous and a discrete distribution). Are both your distributions discrete?
[2020-07-11T13:39:07.928Z] <5f09bedad73408ce4fe951c0> both are real i.e. temperature and pollution concentration
[2020-07-11T13:39:12.158Z] <54d4a1d6db8155e6700f853b> hm you didn't get a warning? You should have gotten a warning, I think :-/
[2020-07-11T13:39:53.316Z] <5f09bedad73408ce4fe951c0> no, i just kept on getting near unity results no matter what i tried - related data, unrelated data, two noise arrays
[2020-07-11T13:40:16.154Z] <54d4a1d6db8155e6700f853b> can you please open an issue on the issue tracker for that? I think we should provide an error or at least a warning
[2020-07-11T13:40:42.297Z] <5f09bedad73408ce4fe951c0> okay
[2020-07-11T13:40:44.189Z] <54d4a1d6db8155e6700f853b> if both of your variables are univariate, you might want to look at  https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression
[2020-07-11T13:41:02.010Z] <54d4a1d6db8155e6700f853b> however, that's just one particular estimate of the mutual information.
[2020-07-11T13:42:56.840Z] <5f09bedad73408ce4fe951c0> i tried that one as well, it seemed to behave a bit better, but as you know, is not normalized to a metric.  my problem is that, as you also likely know, estimates of entropy to normalize it are highly dependent on resolution
[2020-07-11T13:43:56.576Z] <54d4a1d6db8155e6700f853b> exactly, which is why you need some distributional model of the entropy, which is why we don't really do that
[2020-07-11T13:44:33.850Z] <54d4a1d6db8155e6700f853b> I think most people would use a regression analysis or something like that to answer the question you want to answer, unless you are relatively certain about how to model the distributions
[2020-07-11T13:44:48.498Z] <5f09bedad73408ce4fe951c0> it's not an easy thing to do it seems, thanks for your input!
[2020-07-11T13:44:49.570Z] <54d4a1d6db8155e6700f853b> btw, there's a cool non-parameteric estimate using euclidean minimum spanning trees
[2020-07-11T13:45:28.363Z] <5f09bedad73408ce4fe951c0> hahaha!  you are talking to an atmospheric scientist who has, sadly, no stats and is way in over their head :)
[2020-07-11T13:45:50.035Z] <54d4a1d6db8155e6700f853b> then I'd suggest a regression model, I think
[2020-07-11T13:47:56.230Z] <5f09bedad73408ce4fe951c0> there are some papers on using k-nearest neighbour for entropy which supposedly works well for continuous data, but i wanted to confirm that scikit wasn't appropriate before going down that rabbit hole
[2020-07-11T13:51:09.749Z] <54d4a1d6db8155e6700f853b> yes that's the default, and that's what the mutual_info_regression uses
[2020-07-11T13:51:28.782Z] <54d4a1d6db8155e6700f853b> and you can probably use that as a starting point and only have to modify it slightly
[2020-07-11T13:53:15.324Z] <5f09bedad73408ce4fe951c0> that is good news!  many thanks for providing a direction. for now i am going to report the non-warning issue you requested
[2020-07-11T13:54:25.561Z] <54d4a1d6db8155e6700f853b> thanks!
[2020-07-11T14:08:43.346Z] <5f09bedad73408ce4fe951c0> Just to be sure we are on the same page, here is what my results are:
[2020-07-11T14:08:45.143Z] <5f09bedad73408ce4fe951c0> ```noise=np.arange(500) wavelength=np.linspace(0.01,1,500)*1e-6  # testing the normalized MI score between wavelength and noise - should return near zero for totally unrelated data sets constant_normalized_mi=normalized_mutual_info_score(wavelength,noise) ``` output: 1.0 
[2020-07-11T14:09:25.521Z] <54d4a1d6db8155e6700f853b> yeah it should just error on floats, I think
[2020-07-12T08:20:53.387Z] <5f0ac63ad73408ce4fe95ce0> hey, I'm new to sklearn opensource community can anyone please help me for my first PR.
[2020-07-13T01:28:49.672Z] <54d4a1d6db8155e6700f853b> Hey @chaitanyamogal , have you already picked an issue to work on?
[2020-07-13T07:14:23.464Z] <5f0ac63ad73408ce4fe95ce0> No, but I am looking for a good first issue.
[2020-07-16T03:54:51.830Z] <5eeb9b35d73408ce4fe749bc> I have question/curiosity: generally, for new algorithms, are there any reasons that scikit-learn would prefer a Python/NumPy implementation over a Cython implementation?   The only thing I can think of is if the efficiency gain for the Cython version so minimal that it's not worth the added complexity. But, are there any other reasons?
[2020-07-16T03:55:15.954Z] <54d4a1d6db8155e6700f853b> @joshuacwnewton yes, mostly readability and maintainability
[2020-07-16T03:56:09.648Z] <54d4a1d6db8155e6700f853b> there is another potential reason in the future: using the __array_function__ protocol and possibly NEP 37, pure numpy algorithm could directly be ported to GPU or distributed dask datastructures, while that's not possible for Cython implementations.
[2020-07-16T03:56:25.680Z] <54d4a1d6db8155e6700f853b> (this doesn't say anything about how efficient that would be though)
[2020-07-16T03:57:41.248Z] <54d4a1d6db8155e6700f853b> There is even a (very hypothetical) future even where we might add both Cython and Numpy for some algorithms so we have a fallback in case the array is not a numpy array (this sounds weird; we need a numpy implementation if the array is not native numpy, but that's the way it would be lol)
[2020-07-16T04:03:49.087Z] <5eeb9b35d73408ce4fe749bc> Goodness, thank you. This is very valuable!
[2020-07-16T04:05:59.296Z] <5eeb9b35d73408ce4fe749bc> I'm writing a uni report for my co-op term comparing Numpy to Cython (specifically in the context of #9661), and it felt a little too one-sided of me to say "Cython faster, Cython better" (lol) I figured there was more nuance there, so thank you.
[2020-07-16T04:07:07.140Z] <54d4a1d6db8155e6700f853b> the main thing is really maintainability. In general, there's also the fact that you have to compile Cython, so distribution becomes much harder. But in sklearn we already made that investment so the additional burden is relatively small.
[2020-07-16T04:07:28.372Z] <54d4a1d6db8155e6700f853b> Also, new contributors might not be familiar with Cython.
[2020-07-16T04:07:40.190Z] <54d4a1d6db8155e6700f853b> A comparison with Numba might also be interesting if you want to go all out ;)
[2020-07-16T04:08:13.678Z] <5eeb9b35d73408ce4fe749bc> I've got a tab open with Numba too, ehe. 
[2020-07-16T04:08:20.433Z] <5eeb9b35d73408ce4fe749bc> Too many tabs, really!
[2020-07-16T04:09:16.157Z] <5eeb9b35d73408ce4fe749bc> If I may pick your brain a little more, what about Cython do you feel makes it more difficult to maintain?
[2020-07-16T09:27:40.784Z] <567f5d7716b6c7089cc043a8> maintainability has a lot to do with code readability and people who are comfortable with that language. Cython is both less readable (especially when you do C instead of Python in it) and far fewer people know it than Python. It's more of a people issue than a language itself issue. If you go to Shogun's community, they're very comfortable with C++ and in that community C++ is very maintainable.
[2020-07-16T10:13:33.002Z] <5baf7d9ad73408ce4fa9c9b2> another point is that while numpy is reasonably straightforward to use and understand, Cython can act in magical ways that are not necessarily intuitive even with some experience (this is even more true for Numba BTW). https://github.com/scikit-learn/scikit-learn/issues/17299 is an example 
[2020-07-16T14:48:13.131Z] <5eeb9b35d73408ce4fe749bc> @amueller, @adrinjalali, and @NicolasHug: I appreciate that you've taken the time to share your thoughts! I now have many great starting points for further reading, so thank you. :)
[2020-07-16T14:54:49.866Z] <5eeb9b35d73408ce4fe749bc> > another point is that while numpy is reasonably straightforward to use and understand, Cython can act in magical ways that are not necessarily intuitive even with some experience  I guess this might be a natural consequence of Numpy being designed for array operations and used as the backbone for Python DS/ML, while Cython can be applied more generally. So, I would imagine that Numpy has stress-tested common use-cases, but that someone might have to recreate themselves using Cython...
[2020-07-16T14:57:18.443Z] <5eeb9b35d73408ce4fe749bc> > (especially when you do C instead of Python in it)  @adrinjalali Just to clarify, is this referring to wrapping external C code? i.e. https://cython.readthedocs.io/en/latest/src/userguide/external_C_code.html
[2020-07-16T14:58:03.757Z] <54d4a1d6db8155e6700f853b>    @joshuacwnewton no he means writing code that is closer to C than Python
[2020-07-16T14:58:09.520Z] <54d4a1d6db8155e6700f853b> you can use pointers etc
[2020-07-16T14:58:12.598Z] <54d4a1d6db8155e6700f853b> in Cython
[2020-07-16T14:58:32.743Z] <5eeb9b35d73408ce4fe749bc> Ah! Good to know. Thanks. :)
[2020-07-16T14:59:06.496Z] <54d4a1d6db8155e6700f853b> in which case you have to do manual memory allocation, which Python programmers might not be familiar with
[2020-07-16T14:59:52.943Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_criterion.pyx#L260
[2020-07-16T15:02:14.438Z] <5eeb9b35d73408ce4fe749bc> Ah! This actually came up in the extension I was writing... I had been allocating space using `np.empty` and was curious about how I might do that without Python. Malloc came up in search results but I left it at the time.   Thanks for linking that line, @amueller. :D
[2020-07-16T15:02:44.722Z] <54d4a1d6db8155e6700f853b> well np.empty will create a python object which will be memory managed
[2020-07-16T15:06:08.754Z] <54d4a1d6db8155e6700f853b> This conversation probably further emphasizes the above point of cython being less obvious ;)
[2020-07-16T15:07:21.214Z] <5eeb9b35d73408ce4fe749bc> Hehehe exactly. I'm having a "don't know what I don't know" moment here, where I realize there's much more to Cython than I had thought. 
[2020-07-16T15:08:23.209Z] <54d4a1d6db8155e6700f853b> you can look at the history of the tree cython files and you'll probably find some fun bugs we fixed over the years
[2020-07-16T15:09:26.680Z] <54d4a1d6db8155e6700f853b> https://github.com/scikit-learn/scikit-learn/pull/8002/files
[2020-07-16T15:12:45.464Z] <5eeb9b35d73408ce4fe749bc> So, if I'm understanding correctly, the "Python version" (so to speak) of Cython memory management would be to create a memview into a Python object that already has its memory managed automatically. But, that Cython LOC you linked up there doesn't seem like it uses memviews at all. Just, dealing directly with a C array?  Although, IIRC from reading, memviews are relatively new to Cython, and it seems like you can use them with C arrays too.
[2020-07-16T15:13:32.342Z] <5eeb9b35d73408ce4fe749bc> > https://github.com/scikit-learn/scikit-learn/pull/8002/files  Oh ho ho, interesting. Thanks for finding that link. :D
[2020-07-16T15:14:33.349Z] <54d4a1d6db8155e6700f853b> yes and we use both ways, usually for historical reasons. I think there used to be a speed difference between raw pointers and memory views but I don't think there is any more
[2020-07-16T15:15:01.258Z] <5eeb9b35d73408ce4fe749bc> "For historical reasons" -> another point for maintainability, then, hehe :p
[2020-07-16T15:18:28.948Z] <5eeb9b35d73408ce4fe749bc> I hope the benchmarks for the enhancement I'm working on go well, then. I'd love to be able to open a PR and get a code review for what I've written... I imagine I'm making lots of newbie Cython missteps at this stage, heh. :D
[2020-07-16T15:30:02.339Z] <5eeb9b35d73408ce4fe749bc> So, I guess one last question I have is, it seems like for contributors, it might be worth exploring Numpy optimizations just as much as it is Cython optimizations? e.g. replacing for loops in an algorithm with vectorized operations when possible to try and push the pure Python implementation closer to Cython
[2020-07-16T15:30:57.485Z] <5eeb9b35d73408ce4fe749bc> Although, I guess that sometimes leads to less readable Python code, e.g. with fancy np indexing
[2020-07-16T15:32:09.233Z] <5eeb9b35d73408ce4fe749bc> So many tradeoffs... this is all very interesting, hehe.
[2020-07-16T15:33:14.620Z] <54d4a1d6db8155e6700f853b> We do prefer numpy if it's possible, and we prefer like numpy, but if we have to pick, we pick fast numpy over readable numpy, I think
[2020-07-16T15:35:16.525Z] <5eeb9b35d73408ce4fe749bc> That's good to know... I'll have to revisit the slower python/numpy implementation that I had converted to cython, then, before I can really put this to rest. :)
[2020-07-16T21:39:52.355Z] <589b9e0fd73408ce4f490ba4> In the past it happened to me to spend time on a Cython implementation, then realize that it could be as fast or faster with just numpy with a better algorithmic approach. So spending time on numpy optimization as a first step is useful in any case. And of course profiling code (with e.g. snakeviz) is very helpful to make sure that the optimized code is actually the performance bottleneck..
[2020-07-17T01:52:49.718Z] <5eeb9b35d73408ce4fe749bc> Ah, I had never heard of snakeviz! I was just using cProfile + pStats. Thank you, @rth. :)
[2020-07-17T02:05:04.842Z] <5eeb9b35d73408ce4fe749bc> I appreciate the advice, too. I did jump right into Cython, so some planning ahead of time might have saved some trouble!
[2020-07-17T04:02:18.158Z] <5b965bf1d73408ce4fa77f24> checkout computer vision pre-trained model   https://github.com/balavenkatesh3322/CV-pretrained-model
[2020-07-23T21:21:49.403Z] <5eeb997bd73408ce4fe7491d> Hi! Does anyone have any advice for tackling errors in the azure pipeline? We're failing for linux and windows and I can't find a descriptive error message as to why it's failing other than "Bash exited with code '1'." I'm on a mac. https://github.com/scikit-learn/scikit-learn/pull/17877/checks
[2020-07-24T08:45:43.213Z] <55d21ee30fc9f982beadabb8> It is bit tricky but you need to follow the links to get to this page: https://dev.azure.com/scikit-learn/scikit-learn/_build/results?buildId=20118&view=logs&j=13650d7c-49e8-54f3-0598-c3480d1c1e4f&t=97f2162d-a0c4-54dc-9fce-2fceef7172e3
[2020-07-24T08:48:41.271Z] <55d21ee30fc9f982beadabb8> So to do so: click on "details" on checks frame in the PR page. It will lead you to a page where you have only the "Bash exited with code'1'" most of the time. In this page you can go on the bottom and click on "View more details on Azure Pipelines ". It will redirect you on the azure where you can see the terminal output
[2020-07-24T08:48:55.351Z] <55d21ee30fc9f982beadabb8> and there you will get which test is failing and what are the reason
[2020-07-24T08:49:06.102Z] <55d21ee30fc9f982beadabb8> usually you can reproduce those locally afterwards
[2020-07-28T14:26:37.290Z] <5d285286d73408ce4fc5e475> Hello, I understand this is a long shot, but didn't know where else to ask. I am running scikit learn in an online judge environment (DMOJ). Such environment disallows syscalls (for security reasons). The sklearn is installed in conda environment. If I use LogisticRegression().fit(X,y) everything works fine.  However, if I use LogisticRegression(multi_class='multinomial').fit(X,y), the judge stops the process as the LR was apperently trying to make some disallowed syscall. What is the low-level difference between LR and multinomial LR? Is there a workaround for this?
[2020-07-28T14:40:12.412Z] <5d285286d73408ce4fc5e475> could th eproblem be that the multinomial version tries to spawn another processes even with n_jobs=1??
[2020-07-28T14:56:46.027Z] <5f203be0d73408ce4feabfb8> could someone help me understand how the regression tree works in sklearn, is it created in the cart, using the standard deviation to create the leaves? I did not find any manual implementation of the cart for regression.
[2020-07-28T15:52:19.113Z] <567f5d7716b6c7089cc043a8> @oplatek it's probably due to some multithreading, probably in BLAS, and I think nowadays you can control that through `threadpoolctl`. @ogrisel or @jeremiedbb know probably much better 
[2020-07-28T15:58:38.731Z] <5d285286d73408ce4fc5e475> @adrinjalali  thats other Ondrej :]. thank you, I already tried   os.environ['MKL_NUM_THREADS'] = '1' os.environ['NUMEXPR_NUM_THREADS'] = '1' os.environ['OMP_NUM_THREADS'] = '1' os.environ['OPENBLAS_NUM_THREADS'] = '1'  or eporting these variables, but with no luck so far
[2020-07-29T14:12:12.582Z] <5d285286d73408ce4fc5e475> the syscall is sched_setaffinity. is there any way hot to prevent it?
[2020-07-30T08:28:35.303Z] <564b231816b6c7089cbb06f6> Hi. If I want to do multi-label classifications based on keywords that come from a large-ish vocabulary (~5.000), how do I need to encode the keywords so that an arbitrary amount of keywords can be used as predictors? 
[2020-07-30T08:30:19.202Z] <564b231816b6c7089cbb06f6> If I one-hot encode them, how can I pass an arbitrary amount of one-hot encoded vectors to a classifier? 
[2020-07-30T09:27:49.395Z] <564b231816b6c7089cbb06f6> Or, is it possible to use the outputs of a multilabelbinarizer as inputs to a classifier?
[2020-07-31T16:06:11.823Z] <5e3f3d7cd73408ce4fd915a4> Hi all, I'm developing a wrapper that wraps Keras models with the Scikit-Learn API. I'd like some input from Scikit-Learn developers on what direction I should take the interface, I'd like to make it as aligned as possible with Scikit-Learn.
[2020-07-31T16:06:21.373Z] <5e3f3d7cd73408ce4fd915a4> The package is here: https://github.com/adriangb/scikeras
[2020-07-31T16:09:34.525Z] <5e3f3d7cd73408ce4fd915a4> Would any of you able to chat and give some input?
[2020-07-31T18:19:53.211Z] <589b9e0fd73408ce4f490ba4> @ldorigo You could  probably`' '.join(keywords)` and then use `CountVectorizer`?
[2020-07-31T18:21:10.884Z] <589b9e0fd73408ce4f490ba4> @adriangb The design choices in https://github.com/skorch-dev/skorch might be helpful, if you have specific question don't hesitate to ask.
[2020-08-01T23:28:06.021Z] <5e3f3d7cd73408ce4fd915a4> Thanks @rth. I saw how Skorch does things, it's somewhat similar to how SciKeras is doing things now.  An alternative I thought of that I wanted to get feedback on is to have the user define (1) `__init__` and parameters for this model and (2) a `build_keras_model_` function that is expected to return an instance of a Keras `Model`. So a user defined model would look something like: ```python3 class MyModel(KerasClassifier):     def __init__(         self,         random_state=None,     ):         self.random_state = random_state      def build_keras_model(self, X, n_classes_):         model = keras.models.Model         ...         return model ```
[2020-08-01T23:32:56.894Z] <5e3f3d7cd73408ce4fd915a4> Where `build_keras_model` would have access to all of the estimator attributes in addition to variables like `n_classes_` and `X/y` which `KerasClassifier.fit` passes if they exist in the signature of `build_keras_model`.
[2020-08-06T23:13:42.268Z] <5ac29bedd73408ce4f9419a3> Hi, everybody. Does this channel have a rule of conduct that I should read before commenting? 
[2020-08-07T07:07:33.575Z] <567f5d7716b6c7089cc043a8> The code of conduct (https://www.python.org/psf/conduct/) applies here, and we don't love spam or ads or promotions. Otherwise all good. Happy to answer any specific questions :)
[2020-08-09T01:20:13.650Z] <5eeb9b35d73408ce4fe749bc> Hello! For the last 2 weeks of the MLH program, I was thinking of helping to address sklearn's backlog of PRs (e.g. by doing code reviews). Does anyone have any recommendations for how best to approach that? (searching through the backlog, triaging PRs, leaving some types of PRs for core maintainers, etc.)
[2020-08-09T16:11:13.474Z] <5baf7d9ad73408ce4fa9c9b2> @joshuacwnewton reviewing is always welcome and it's a great way to learn! The things I personally look for during a review are: - backward compatibility and consistency with the current library / ecosystem. - test coverage. Ideally we want tests to be fast as well. - docs: every new feature should be documented at least in the UG. Big ones ideally come with a new example - code clarity and comments: you want your future self to be able to understand why something was done the way it was done  In terms of where to find PRs to review, we have a "waiting for reviewer" tag. Also you can try filtering by PRs which already have one approval: these might be easier to review. Feel free to review old PRs but note that there's a chance these will never be addressed.
[2020-08-10T01:48:41.033Z] <5ac29bedd73408ce4f9419a3> By seeing the sgd and sag code in https://github.com/scikit-learn/scikit-learn/sklearn/linear_model I wonder why the solvers do not use the mini-batch implementation?   
[2020-08-10T10:53:16.963Z] <5f3125ecd73408ce4febd212> Hey, everyone, I am new to Scikit-Learn and after reading this [Security & maintainability limitations](https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations) I want to know is their other safer ways to save and load sklearn models. 
[2020-08-10T11:31:13.161Z] <5baf7d9ad73408ce4fa9c9b2> @kaelgabriel  SGD processes each sample individually so by definition it cannot be a mini-batch approach
[2020-08-10T12:04:42.003Z] <5ac29bedd73408ce4f9419a3> @NicolasHug yes, you are right, I was wondering why people chosen SGD over mini-batch SGD (the one that is more common in DL). Just trying to understand.
[2020-08-10T13:58:58.627Z] <5e614c10d73408ce4fdbbb92> Hello, everybody. I hope you all's been fine. Has anyone already created a custom classifier with `sample_weight` that can share with me? I'm building my own estimator and i need `sample_weight` to make it work with AdaboostClassifier, tough i have no clue what it is
[2020-08-13T20:23:32.355Z] <57b364d540f3a6eec05fce2b> Hello, everyone. Can anyone clarify to me how `OneVsRestClassifier` performs the classification to decide the output of each input? I am coding a RBF network for classification and the output layer is trained with `n_classes` linear regressors, then the final output is given by applying a softmax function. But `OneVsRestClassifier` could be useful, i just can't confirm if it uses a similar approach.
[2020-08-15T05:44:36.991Z] <5ee61de0d73408ce4fe6d981> @rth I have addressed your review comments in #18124
[2020-08-17T11:37:11.747Z] <5f0ac63ad73408ce4fe95ce0> is it possible to directly assign: VotingClassifier.fit_transform.__doc__ = "Return class labels or probabilities for X for each estimator."  #18150 
[2020-08-23T12:09:25.700Z] <5f0ac63ad73408ce4fe95ce0> hey, someone please review my PR #18185
[2020-08-23T13:23:03.682Z] <55d21ee30fc9f982beadabb8> The tests are still not passing. You should solve this.
[2020-09-04T08:44:57.035Z] <5be4801ed73408ce4fae4cc6> Hello, anyone can explain what the format of the patches in https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.extract_patches_2d.html is? https://www.reddit.com/r/scikit_learn/comments/iinxo7/whats_the_format_of_the_patches_returned_by/
[2020-09-04T08:45:26.625Z] <5be4801ed73408ce4fae4cc6> are the returned values corner points or what? Why are there duplicates?
[2020-09-04T09:47:51.724Z] <55d21ee30fc9f982beadabb8> The documentation said: `array of shape (n_patches, patch_height, patch_width) or (n_patches, patch_height, patch_width, n_channels)`
[2020-09-04T09:47:59.867Z] <55d21ee30fc9f982beadabb8> n_patches is the number of patches
[2020-09-04T09:48:21.615Z] <55d21ee30fc9f982beadabb8> so `patches[0]` will be the small patch
[2020-09-04T09:48:32.382Z] <55d21ee30fc9f982beadabb8> on the image
[2020-09-04T09:48:39.311Z] <55d21ee30fc9f982beadabb8> 2d if this a gray image
[2020-09-04T09:48:45.629Z] <55d21ee30fc9f982beadabb8> 3d if this is a color image
[2020-09-04T11:13:34.450Z] <5be4801ed73408ce4fae4cc6> That doesn't explain what the contents of the arrays are.
[2020-09-04T12:28:50.671Z] <55d21ee30fc9f982beadabb8> The pixel values
[2020-09-04T12:31:58.302Z] <5be4801ed73408ce4fae4cc6> RGB colors? Why are there two of the same?
[2020-09-04T12:32:27.943Z] <55d21ee30fc9f982beadabb8> RGB colors -> n_channels
[2020-09-04T12:32:37.277Z] <55d21ee30fc9f982beadabb8> > Why are there two of the same?
[2020-09-04T12:32:43.115Z] <55d21ee30fc9f982beadabb8> what do you mean?
[2020-09-04T12:32:52.167Z] <55d21ee30fc9f982beadabb8> which things are the same?
[2020-09-04T12:33:36.556Z] <5be4801ed73408ce4fae4cc6> each patch is a [ [[RGB_1] [RGB_1]] [[RGB_2] [RGB_2]]]
[2020-09-04T12:34:06.020Z] <5be4801ed73408ce4fae4cc6> so why are there two times RGB_1?
[2020-09-04T12:34:12.343Z] <55d21ee30fc9f982beadabb8> it depens of your input
[2020-09-04T12:34:21.790Z] <55d21ee30fc9f982beadabb8> if you are passing a numpy array with 3 dimension
[2020-09-04T12:34:41.802Z] <55d21ee30fc9f982beadabb8> with shape `(height, width, 3)` (because it is RGB
[2020-09-04T12:35:05.078Z] <55d21ee30fc9f982beadabb8> you will get an array of `(n_patches, patch_height, patch_width, 3)`
[2020-09-04T12:35:28.546Z] <5be4801ed73408ce4fae4cc6> so the arrays returned are "2x2"
[2020-09-04T12:35:30.993Z] <5be4801ed73408ce4fae4cc6> because that's patch size
[2020-09-04T12:35:45.646Z] <5be4801ed73408ce4fae4cc6> but I don't understand what RGB_1 and RGB_2 refer to?
[2020-09-04T12:36:05.502Z] <5be4801ed73408ce4fae4cc6> if one takes a 2x2 sample from the image then it should have 4 pixels?
[2020-09-04T12:36:07.532Z] <5be4801ed73408ce4fae4cc6> so 4 values
[2020-09-04T12:36:26.758Z] <55d21ee30fc9f982beadabb8> but there is no RGB1 in the documentation?
[2020-09-04T12:36:48.551Z] <55d21ee30fc9f982beadabb8> > if one takes a 2x2 sample from the image then it should have 4 pixels?
[2020-09-04T12:36:50.466Z] <5be4801ed73408ce4fae4cc6> I refer to the values in the example https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.extract_patches_2d.html
[2020-09-04T12:37:08.205Z] <55d21ee30fc9f982beadabb8> it will be an array `(n_patches, 2, 2, 3)`
[2020-09-04T12:37:13.133Z] <55d21ee30fc9f982beadabb8> if this is an RGB image
[2020-09-04T12:37:25.906Z] <55d21ee30fc9f982beadabb8> or `(n_patches, 2, 2)` if this is gray-scale
[2020-09-04T12:37:39.720Z] <5be4801ed73408ce4fae4cc6> so it takes a 2x2 sample from the image and describes its pixel colors?
[2020-09-04T12:37:43.832Z] <5be4801ed73408ce4fae4cc6> this is what I assumed
[2020-09-04T12:38:06.464Z] <55d21ee30fc9f982beadabb8> it is just extracting a sub-image
[2020-09-04T12:38:21.714Z] <55d21ee30fc9f982beadabb8> with the same number of dimension
[2020-09-04T12:38:42.322Z] <5be4801ed73408ce4fae4cc6> but what are the 2d subarrays?
[2020-09-04T12:38:53.007Z] <5be4801ed73408ce4fae4cc6> [[RGB_1] [RGB_1]] [[RGB_2] [RGB_2]]
[2020-09-04T12:39:04.894Z] <55d21ee30fc9f982beadabb8> > [[RGB_1] [RGB_1]] [[RGB_2] [RGB_2]]
[2020-09-04T12:39:16.308Z] <5be4801ed73408ce4fae4cc6> do they correspond to columns or rows perhaps?
[2020-09-04T12:39:19.603Z] <5be4801ed73408ce4fae4cc6> in 2x2 matrix sense
[2020-09-04T12:39:19.722Z] <55d21ee30fc9f982beadabb8> I am sorry but this not specify anywhere in the doc
[2020-09-04T12:39:41.723Z] <5be4801ed73408ce4fae4cc6> how to know then what RGB_1 then refers to
[2020-09-04T12:39:46.794Z] <5be4801ed73408ce4fae4cc6> it's some pixel color, but which pixel is it?
[2020-09-04T12:39:51.025Z] <55d21ee30fc9f982beadabb8> `[[RGB_1] [RGB_1]] [[RGB_2] [RGB_2]]` This is a (2, 2) numpy array
[2020-09-04T12:40:04.214Z] <55d21ee30fc9f982beadabb8> and this is is not RGB
[2020-09-04T12:41:58.815Z] <55d21ee30fc9f982beadabb8> they are only gray scale (because you have only one channel)
[2020-09-04T12:42:13.267Z] <55d21ee30fc9f982beadabb8> (2, 2, 3) would be 3-channel
[2020-09-04T12:42:34.387Z] <5be4801ed73408ce4fae4cc6> if one uses the python list index convention, then one finds (0,0), (0,1), (1,0), (1,1)
[2020-09-04T12:42:36.465Z] <55d21ee30fc9f982beadabb8> `img[:, :, 0]` will be the red channel
[2020-09-04T12:43:01.426Z] <5be4801ed73408ce4fae4cc6> but I don't understand why (0,0)=(0,1) and (1,0)=(1,1)
[2020-09-04T12:43:10.352Z] <5be4801ed73408ce4fae4cc6> or is it just coincidence in this sample picture
[2020-09-04T12:43:16.791Z] <55d21ee30fc9f982beadabb8> > but I don't understand why (0,0)=(0,1) and (1,0)=(1,1)
[2020-09-04T12:43:20.779Z] <55d21ee30fc9f982beadabb8> it does not 
[2020-09-04T12:43:29.448Z] <55d21ee30fc9f982beadabb8> it is a coincidence
[2020-09-04T12:43:33.772Z] <55d21ee30fc9f982beadabb8> for your specific image
[2020-09-04T12:43:46.304Z] <5be4801ed73408ce4fae4cc6> I see
[2020-09-04T12:47:20.986Z] <5be4801ed73408ce4fae4cc6> that's a bad example I find then
[2020-09-04T12:47:24.986Z] <5be4801ed73408ce4fae4cc6> given in the doc
[2020-09-04T12:47:42.243Z] <55d21ee30fc9f982beadabb8> I don't agree
[2020-09-04T12:48:06.316Z] <5be4801ed73408ce4fae4cc6> I think a good example would have very distinct values
[2020-09-04T12:48:12.202Z] <5be4801ed73408ce4fae4cc6> as in order to not suggest that they're somehow "ordered"
[2020-09-04T12:48:20.729Z] <55d21ee30fc9f982beadabb8> This is just a real life example
[2020-09-04T12:48:45.420Z] <5be4801ed73408ce4fae4cc6> because those symmetries got me thinking about whether I'm even looking at a 2x2 patch in the actual image
[2020-09-04T12:48:49.798Z] <5be4801ed73408ce4fae4cc6> or some sklearn abstraction about it
[2020-09-04T12:49:59.539Z] <55d21ee30fc9f982beadabb8> The docstring give a real example
[2020-09-04T12:50:02.155Z] <55d21ee30fc9f982beadabb8> and the user guide
[2020-09-04T12:50:03.559Z] <55d21ee30fc9f982beadabb8> https://scikit-learn.org/stable/modules/feature_extraction.html#patch-extraction
[2020-09-04T12:50:25.252Z] <55d21ee30fc9f982beadabb8> is giving a synthetic example with fake RGB data
[2020-09-04T12:51:58.610Z] <5be4801ed73408ce4fae4cc6> is there an equivalent function that would spit out "rectangles"?
[2020-09-04T12:52:09.291Z] <5be4801ed73408ce4fae4cc6> like the geometries of the pixels
[2020-09-04T12:52:29.386Z] <55d21ee30fc9f982beadabb8> What do you mean rectangle?
[2020-09-04T12:52:40.178Z] <55d21ee30fc9f982beadabb8> here you can specify height and width
[2020-09-04T12:53:00.583Z] <55d21ee30fc9f982beadabb8> so you can specify the rectangle shape
[2020-09-04T12:53:16.448Z] <5be4801ed73408ce4fae4cc6> Yes it's possible with known pixel size to infer it
[2020-09-04T12:53:26.557Z] <5be4801ed73408ce4fae4cc6> but I was asking whether there exists such function already
[2020-09-04T12:53:55.486Z] <5be4801ed73408ce4fae4cc6> I've found this kind of application when one wants to crop pixel areas
[2020-09-04T12:54:02.461Z] <5be4801ed73408ce4fae4cc6> then one has to specify the area 
[2020-09-04T12:54:47.793Z] <55d21ee30fc9f982beadabb8> I don't understand what you want sorry
[2020-09-04T12:56:31.501Z] <5be4801ed73408ce4fae4cc6> extract_2d_patches that returns [[[corner1 corner2 length] ...
[2020-09-04T12:56:55.720Z] <5be4801ed73408ce4fae4cc6> so one knows what area the pixel covers
[2020-09-04T12:58:15.501Z] <55d21ee30fc9f982beadabb8> You will not find in scikit-learn
[2020-09-04T12:58:28.526Z] <55d21ee30fc9f982beadabb8> you might want to look at scikit-image thought
[2020-09-04T17:14:00.916Z] <5f52759ed73408ce4fee177a> Hi, does anyone know more about this efficiency warning?
[2020-09-04T17:14:02.280Z] <5f52759ed73408ce4fee177a> scikit-learn/sklearn/neighbors/_base.py:167: EfficiencyWarning: Precomputed sparse input was not sorted by data.   warnings.warn('Precomputed sparse input was not sorted by data.'
[2020-09-04T17:14:43.851Z] <5f52759ed73408ce4fee177a> so im passing in a csr_matrix, but the csr_matrix is not sorted by data  (it's sorted by indices). i looked at  the code, and it seems this warning is thrown whenever each row in the csr_matrix is not sorted, low->high
[2020-09-04T17:15:13.558Z] <5f52759ed73408ce4fee177a> however,  i can't figure out how to sort the matrix. no matter how i initialize it, the matrix sorts it by index, even if i pass  it in sorted by data
[2020-09-04T17:15:40.854Z] <5f52759ed73408ce4fee177a> does anyone know how to pass in the right data to get rid of this efficiency warning?
[2020-09-05T04:20:52.697Z] <5ee61de0d73408ce4fe6d981> Would be nice to have scikit at @pyconindia sprints this year! Link to submit https://t.co/LZ0Hz0fa2I?amp=1
[2020-09-05T10:41:20.203Z] <5f5369edd73408ce4fee2138> Suppose,i want to run a grid search  using KNN as te estimator with 5 to 6 k values and i want to see "accuracy" for each K values,is there any way?
[2020-09-05T17:20:31.326Z] <5f5369edd73408ce4fee2138> Anyone?
[2020-09-12T07:05:25.099Z] <56bb7a56e610378809c0cb2c> `algo_max` Mohammad Masudul Alam (Gitter): have you take results = GridSearchCV, results has a cv_results_ variable.. it should contain what you're looking for.
[2020-09-14T19:33:20.821Z] <57b364d540f3a6eec05fce2b> Hello, can anyone explain why my custom estimator fails when used with `cross_val_score`? The error message is not clear: `ValueError: output_type='binary', but y.shape = (30, 3)`
[2020-09-14T19:33:49.438Z] <57b364d540f3a6eec05fce2b> My estimator has its own `score()` function which computes the accuracy
[2020-09-16T20:01:58.073Z] <54d4a1d6db8155e6700f853b> @henrique-voni can you try running check_estimator on your estimator?
[2020-09-18T03:31:56.866Z] <551710ad15522ed4b3ddfadb> Hi all, I was wondering, does scikit support GPU accelerating?
[2020-09-18T12:16:54.757Z] <5baf7d9ad73408ce4fa9c9b2> no https://scikit-learn.org/stable/faq.html#will-you-add-gpu-support
[2020-09-18T16:30:44.871Z] <5f64da0cd73408ce4fef4a7c> Hi all, Ive been wanting to make use of the varimax rotation argument for sklearn.decomposition.FactorAnalysis (version 0.24dev0). So I created a conda environment with this version of sklearn (I have checked conda list, so definitely have the correct version installed), alongside hyperspy.  However when calling FactorAnalysis as follows: skl.decomposition.FactorAnalysis(rotation='varimax') I receive the following error: TypeError: __init__() got an unexpected keyword argument 'rotation'  The documentation for version 0.24 states:  <unconvertable> decomposition.FactorAnalysis now supports the optional argument rotation, which can take the value None, 'varimax' or 'quartimax'. <unconvertable>  Any ideas for what the problem might be? 
[2020-09-18T16:35:00.866Z] <5baf7d9ad73408ce4fa9c9b2> what does `sklearn.__version__` say?
[2020-09-18T16:36:18.961Z] <5baf7d9ad73408ce4fa9c9b2> (It works on `master` so you likely don't have the very latest version)
[2020-09-18T16:38:33.477Z] <5f64da0cd73408ce4fef4a7c> Oh that's odd, it says my current version is 0.23.2  although conda says version is 0.24dev0
[2020-09-20T11:07:24.136Z] <57330f91c43b8c6019723dab> Hi, everybody.  I wouild like to make a system to recognize coins. I have made database with coins text information and a couple images for every coin. My hypothesis is to use dectloscopic approach to recognize coins. May be someone know componen or library that I can use?  Thanks.
[2020-09-22T08:37:09.161Z] <56bb7a56e610378809c0cb2c> `algo_max` Will coins be always nicely centered and rotated in the same direction? Or scattered around the whole image and randomly rotated? Also one coin per image or multiple?
[2020-09-22T08:40:19.867Z] <56bb7a56e610378809c0cb2c> `algo_max` Found it.. there was a template matching example for coins in skimage. Is this of any help? https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_template.html
[2020-10-02T15:05:05.411Z] <56a7cd59e610378809be543d> Hello, I would like to talk to the maintainers of scikit-learn about their infrastructure needs: https://scikit-learn.org/dev/about.html#infrastructure-support are you currently all set? Or are you looking for a cloud service provider to offer cloud infrastructures?
[2020-10-02T16:19:04.317Z] <55d21ee30fc9f982beadabb8> We are currently using Microsoft Azure/ CircleCI / Travis for our continuous integration and I think that we are pretty happy with the current services.
[2020-10-02T16:25:44.372Z] <55d21ee30fc9f982beadabb8> we might actually improve the testing for ARM but I think that some work has been done using Travis recently
[2020-10-02T16:30:29.292Z] <541a528b163965c9bc2053de> @remyleone I wouldn't mind having ssh access to ARM nodes from time to time to be able to interactively debug stuff. I the moment we use https://scikit-learn.org/dev/developers/tips.html#building-and-testing-for-the-arm64-platform-on-a-x86-64-machine which is kind of slow.
[2020-10-02T16:32:46.614Z] <541a528b163965c9bc2053de> hum I just read: https://www.theregister.com/2020/04/21/scaleway_arm64_cloud_end_of_life/
[2020-10-02T16:32:56.801Z] <541a528b163965c9bc2053de> so probably not interested in this :)
[2020-10-02T16:56:00.617Z] <56a7cd59e610378809be543d> Ok. Thank you very much :)
[2020-10-04T11:18:38.703Z] <5dd4e82bd73408ce4fd18d22> Hi Guys 
[2020-10-07T19:01:06.535Z] <54d4a1d6db8155e6700f853b> @ogrisel but Amazon did a huge investment in arm, rihgt?
[2020-10-08T20:19:23.674Z] <5f7f7040d73408ce4ff1073b> I just joined open source community and wanted to contribute in some open source project please suggest me some I have hands on experience on python and Machine learning
[2020-10-09T07:41:48.066Z] <541a528b163965c9bc2053de> @anantgna here is the place to start: https://scikit-learn.org/dev/developers/contributing.html . This doc presents how to browse the issue tracker to find issues to tackle. Ideally, it's best to start with a small issue or improvement to an estimator class or function that you use yourself on a regular basis.
[2020-10-09T07:43:27.629Z] <541a528b163965c9bc2053de> @amueller  yes but Remy does not work at Amazon :) I remembered that scaleway had an ARM-based cloud and it could have been useful to better support scikit-learn on ARM but it's no longer the case apparently.
[2020-10-09T09:25:35.003Z] <5f7f7040d73408ce4ff1073b> @ogrisel thank you
[2020-10-12T14:42:29.876Z] <5770e32dc2f0db084a201d09> Hello everyone, is there a known dependency issue with Numpy? I am trying to install Scikit-learn in editable mode following the guide on the `contributing to scikit-learn` page but I get a `ModuleNotFoundError` for Numpy during the  build process. The call that triggers this error is `from numpy.distutils.compiler import new_compiler`. I have gotten this on multiple versions of Python 3.8.x and 3.9 virtual environments on a machine running Ubuntu 20.04. Any help trouble-shooting this will be much appreciated.
[2020-10-17T07:20:00.086Z] <5f7ac1dcd73408ce4ff0af34> Hello, everyone! I aim to implement an experimental Artificial Neuron-Glia Network (ANGN) for a  research project. I am not sure why (despite being 13 years in research community) I was not able to find any code for it. Any insights would be highly appreciated.
[2020-10-17T07:26:46.613Z] <5f7ac1dcd73408ce4ff0af34> For those of you unfamiliar with ANGN. Following image is the proposed architecture of a single unit of the network. [![image.png](https://files.gitter.im/541a528c163965c9bc2053e1/geth/thumb/image.png)](https://files.gitter.im/541a528c163965c9bc2053e1/geth/image.png)
[2020-10-19T20:58:57.742Z] <5dbd6437d73408ce4fcfbf0f> @kushaangupta have you tried with Tensorflow or PyTorch? You should be more able to implement customised topologies for network even at level of single neuron.
[2020-10-20T06:34:37.935Z] <5f8e7722d73408ce4ff1f8ea> HI Team,  I am trying to make a recommendation engine for a food delivery app. I was going through different things like Market Basket Analyisis etc.. Company have huge amount of data for orders from different customers. Could you please help me on where to start?
[2020-10-20T12:59:05.509Z] <5c790377d73408ce4fb94f40> hello, I am trying to use sklearn linear regression to predict bonuses from enron dataset, and when chaching the score of prediction, I am getting a negative answer, can anyone please tell me the meaning of this
[2020-10-21T03:34:53.313Z] <5f8fac00d73408ce4ff2116d> Hello
[2020-10-22T07:31:05.962Z] <5b58594ed73408ce4fa23ee3> Hi everyone, does anyone know any good references that discuss the importance of framework toolboxes like scikit-learn for reproducible data science?
[2020-10-27T20:24:20.010Z] <5f7ae264d73408ce4ff0b263> Hi! Ive built an interactive git cli - igit. Check it out: https://github.com/kobibarhanin/igit to install: pip install igit
[2020-10-30T16:40:11.119Z] <5f9c412fd73408ce4ff2ed47> Hello everyone, does anyone know how to solve nonlinear equations of a trained sklearn model?? I mean I have a trained sklearn model `f(x)` and I want to solve equations like `f(x)=c` where c is a constant?
[2020-10-31T19:29:14.059Z] <569f975ce610378809bd48e8> I am trying to use sklearn.decomposition.FastICA on the  audio files from https://cnl.salk.edu/~tewon/Blind/blind_audio.html  by Te-Won Lee. These have  been referenced in Prof. Andrew Ng's old lectures  on Independent component analysis. The unmixing does not seem to work with FastICA. All the code examples that I could find mix simple waveforms like sine, sawtooth with a simple mixing matrix and try to recover it back.   Does any one  have any  insights on this  ?
[2020-11-06T10:42:34.421Z] <5e7de2b6d73408ce4fde36e6> Hi scikit-learn team! I'll start a new job on 16 November and have some free time until then. I just wanted to let you know that I'll try to add all missing documentation for attributes by then (see #14312). There are only a few undocumented attributes left. So if anyone has time to review my PRs you (hopefully) could have all attributes documented by the end of next week. :) Nicolas and Adrin have already kindly started reviewing the PRs I sent in for this in the last few days. 
[2020-11-06T11:42:35.105Z] <5c8bb176d73408ce4fbac89c> Thanks @marenwestermann right in time for 0.24!
[2020-11-10T09:00:29.619Z] <5c62c8f4d73408ce4fb791fb> Hi everyone, I need some help in implementing sklearn.decomposition.SparseCoder in c++. I've been searching it for a while but couldn't find good resource/library so far. Is there any library out there which can solve sparse decomposition in c++?
[2020-11-10T09:06:56.113Z] <567f5d7716b6c7089cc043a8> Have you checked Shogun? They might have something
[2020-11-10T09:34:00.481Z] <5c62c8f4d73408ce4fb791fb> Not yet, will check
[2020-11-10T11:30:42.735Z] <5da2a33dd73408ce4fcdacee> @KartikShrivastava , there is MLPack, https://mlpack.org/doc/mlpack-3.1.0/doxygen/cftutorial.html, I haven't read the complete article, but it does have the phrase "Sparse Matrix" in it.
[2020-11-10T13:53:24.328Z] <5c62c8f4d73408ce4fb791fb> Yup, I've tried the sparse coding module of that but couldn't get the right results from as, not as good as sklearn, so I thought that it might not be the way to go
[2020-11-10T15:11:14.451Z] <5da2a33dd73408ce4fcdacee> Ah, okay! What other solutions have you tried? Would like to know.
[2020-11-10T16:57:05.504Z] <5c62c8f4d73408ce4fb791fb> I'm also trying nnls solver of eigen library. I've used it in a similar application
[2020-11-10T17:09:00.671Z] <5da2a33dd73408ce4fcdacee> That's cool!
[2020-11-10T17:22:58.355Z] <5c62c8f4d73408ce4fb791fb> Took help of mlpack people and it worked using the sparse coder interface :) Just to mention it requires initializing dictionary and a call to encode. I realized that it's very similar to sklearn sparse coder
[2020-11-10T21:22:32.513Z] <5fa72f4dd73408ce4ff383e4> Hi! I am new
[2020-11-14T19:36:39.102Z] <5fb02cd9d73408ce4ff4111a> hey
[2020-11-16T13:06:21.547Z] <5f2fbda7d73408ce4febbf62> Hi! I want to ask here before bothering people on GitHub: Is there a reason for the submoduled import structure of sklearn? I often find myself importing only to have to search for the submodule name of a thing I already know. For example, I might need "PCA", but I won't remember that it is under "decomposition". Is it worth having each collection of functions and classes under their own module? Granted, there are many submodules, each containing many more things to import, but surely maintaining a list of imports at the top level of sklearn wouldn't be too big of a hurdle, so that `from sklearn import PCA` would be possible. It would be a huge usability boost in my humble opinion. But I might also be dumb. Am I missing something obvious here? Cheers!
[2020-11-16T13:11:45.418Z] <567f5d7716b6c7089cc043a8> I'm not a big fan of heavy import statements, and having all those classes and functions as a top level import would make "import sklearn" very very heavy (since it would load every user-facing API immediately). Also, sometimes there may be conflicts between modules. Other than that, I find the code more readable and understandable when  imports are from the sub-modules instead of a top level import.
[2020-11-16T13:15:31.141Z] <5f2fbda7d73408ce4febbf62> Oh that's true! I don't really have a grasp on the full scope of sklearn, so I can imagine the import could be huge. I'm quite satisfied with this being the main explanation. Thanks a bunch!
[2020-11-18T12:37:15.563Z] <5da2a33dd73408ce4fcdacee> Hi, guys. Just a quick question.
[2020-11-18T12:37:45.751Z] <5da2a33dd73408ce4fcdacee> I'm seriously considering investing my time to solving issues on Scikit, so as to work my way towards becoming a maintainer of the project itself. 
[2020-11-18T12:38:36.992Z] <5da2a33dd73408ce4fcdacee> I really think I would learn a lot in the process,  and something I really like doing - contributing. For now, I think the best way for me is to send PRs and try to solve issues as much as I can.
[2020-11-18T12:38:59.888Z] <5da2a33dd73408ce4fcdacee> should I keep something specific in mind while doing so, is what I wanted to ask. thanks. :D
[2020-11-18T13:09:04.934Z] <55d21ee30fc9f982beadabb8> > For now, I think the best way for me is to send PRs and try to solve issues as much as I can.
[2020-11-18T13:09:24.623Z] <55d21ee30fc9f982beadabb8> yes. Just be sure to read the contributing guideline to be sure to not miss anything :)
[2020-11-18T13:13:00.565Z] <5da2a33dd73408ce4fcdacee> I've gone through it 5-6 times now. xD Even went ahead with the asv thing, but still have to really understand how to really use it.
[2020-11-18T19:30:08.847Z] <5e3f3d7cd73408ce4fd915a4> Hi, we're trying to decide how to handle a Keras / sklearn API integration issue over at https://github.com/adriangb/scikeras/issues/131, I wanted to see if anyone in this group can chime in. The jist of it is how to support passing validation data to the estimators. Skorch solves this by having a an `__init__` parameter, but as is pointed out in that issue that means that calling with a different `X, y` would give you different results (since the validation losses would be totally off).
[2020-11-18T20:03:14.632Z] <55d21ee30fc9f982beadabb8> I think that right now we cannot do that. I vaguely recall a discussion where we discuss something linked with something close to the callback mechanism
[2020-11-18T20:03:48.979Z] <5e3f3d7cd73408ce4fd915a4> Yeah I could not find any sklearn estimator that accepts extra data as a fit kwarg
[2020-11-18T20:04:07.463Z] <5e3f3d7cd73408ce4fd915a4> Or as an `__init__` param for that matter
[2020-11-18T20:05:21.271Z] <55d21ee30fc9f982beadabb8> yep. I see that we have a recent feature request https://github.com/scikit-learn/scikit-learn/issues/18748
[2020-11-18T20:05:34.578Z] <55d21ee30fc9f982beadabb8> I will try to find the discussion back
[2020-11-18T20:06:28.041Z] <55d21ee30fc9f982beadabb8> We also put it in the road map: https://scikit-learn.org/dev/roadmap.html
[2020-11-18T20:06:53.705Z] <55d21ee30fc9f982beadabb8> The issue will be to find the right API.
[2020-11-18T20:10:09.688Z] <5e3f3d7cd73408ce4fd915a4> Yep. If I had to pick between the options that I currently see available, my gut feeling would be to make it a fit kwarg, but that's just a knee jerk reaction
[2020-11-18T20:10:32.548Z] <5e3f3d7cd73408ce4fd915a4> which is why I'm asking here :laughing: 
[2020-11-18T20:13:11.526Z] <5baf7d9ad73408ce4fa9c9b2> We don't have that in scikit-learn and our validation data is always a subset of X-y as passed to fit. IIRC LightGBM adds new arguments to `fit`
[2020-11-18T20:15:29.891Z] <5e3f3d7cd73408ce4fd915a4> Yeah I do see they have `eval_set`: `(list or None, optional (default=None)) <unconvertable> A list of (X, y) tuple pairs to use as validation sets`
[2020-11-19T05:58:48.107Z] <5fb60715d73408ce4ff46856> hey, I need help with plotting rbf kernel's output in svm.SVC. Where do I go for help?
[2020-11-19T06:35:40.625Z] <5fb60715d73408ce4ff46856> [![image.png](https://files.gitter.im/541a528c163965c9bc2053e1/Y9W4/thumb/image.png)](https://files.gitter.im/541a528c163965c9bc2053e1/Y9W4/image.png)  Any material on rbf kernel will help. I am looking for the above function.
[2020-11-19T13:25:26.328Z] <5da2a33dd73408ce4fcdacee> @salih.four_gitlab are you looking for this, https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html?
[2020-11-20T02:02:18.610Z] <5fb60715d73408ce4ff46856> Actually, I tried that module yesterday. For a 100x1 array X as input, the RBF.__call__(X) is returning a 100x100 array. I was looking for a 100x1 array that can be used to create a new axis to the existing 1d data resulting in 2d data. But, by reading the docs I could not make sense of the returned 100x100 array. That is why I came here. > @salih.four_gitlab are you looking for this, https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html?  
[2020-11-20T02:05:30.158Z] <5fb60715d73408ce4ff46856> @Rubix982 
[2020-11-20T04:05:34.905Z] <5da2a33dd73408ce4fcdacee> Oh, okay, got your problem.  May or may not be able to check this out. Busy with University right now. Exams on the way next week. @salih.four_gitlab 
[2020-11-20T08:24:08.314Z] <5fb60715d73408ce4ff46856> Do well :thumbsup: . 
[2020-11-20T09:42:53.113Z] <5da2a33dd73408ce4fcdacee> Thank you.
[2020-11-20T22:44:51.689Z] <54d4a1d6db8155e6700f853b> @salih.four_gitlab for the RBF(X) you will always get a square matrix because it's the formula above between all rows in X. If you have a single vector, it should be 1x100. If you want to have the kernels with an existing set, it should be RBF(X, Y)
[2020-11-20T22:46:07.852Z] <54d4a1d6db8155e6700f853b> though I'm not sure what you're trying to achieve. That is indeed for the GP. we also have a rbf_kernel function (which does the same thing) if you just want to compute the kernel values
[2020-11-23T09:19:25.980Z] <5f9fce72d73408ce4ff3159b> Hi. I am looking at the [Classification example](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mnist_filters.html). Do we only support `Dense` layer for neural networks for now? I was hoping to try some `AutoML` features of `scikit-learn` to create some convolution networks.
[2020-11-23T09:22:44.842Z] <541a528b163965c9bc2053de> convolution neural networks are indeed not supported and out of the scope of scikit-learn. Please use a library dedicated to deep learning for this. If you need scikit-learn API compatibility, you can try: https://github.com/skorch-dev/skorch or https://www.tensorflow.org/api_docs/python/tf/keras/wrappers/scikit_learn .
[2020-11-23T09:25:28.961Z] <5f9fce72d73408ce4ff3159b> Thanks. I think I will stick with tensorflow for now.
[2020-11-24T23:34:43.432Z] <5fbd959ad73408ce4ff4db63> hi guys i'm  new to the contributors community and i want to start contributing to scikit-learn, but really i don't know how to start, and to be more specific when i check an issue and feel like i want to start working on it i don't know how to communicate with the developers there, like what should i say or shouldn't and what are the best practices or the ethics i should know before start working, any advices please ?. thank you
[2020-11-25T01:39:42.904Z] <5e3f3d7cd73408ce4fd915a4> @ichisadashioko if you want to use Keras + sklearn check out SciKeras: https://github.com/adriangb/scikeras
[2020-11-25T07:49:32.104Z] <55d21ee30fc9f982beadabb8> @adriangb I was wondering if you could mention what is the benefit of scikeras compared to the KerasClassifier and KerasRegressor?
[2020-11-25T14:20:22.924Z] <5e3f3d7cd73408ce4fd915a4> It's a pretty long list. Some Scikit-Learn specific ones are:
[2020-11-25T14:47:46.031Z] <5e3f3d7cd73408ce4fd915a4> (was on mobile) * Allows pickling of estimators, allow ensembles and gridsearch to work properly * Allows you to use multi-input/output models to sklearn (especially important since some pre-trained models have "extra" outputs) * Working random_state (random state in Keras is pretty complicated) * Adds `partial_fit` and `predict_proba` * Your models can dynamically adjust the Keras input/output shape to the data (previously, that had to be hardcoded) * Support for `class_weights` in the same format as other sklearn estimators (including `class_weights="auto"`). * A lot of compatibility improvements, stuff like implementing `n_features_in_` and `_estimator_type` * Allows you to grid-search parameters for optimizers and losses via [routed params](https://scikeras.readthedocs.io/en/latest/advanced.html#routed-parameters). 
[2020-11-25T14:55:14.029Z] <5e3f3d7cd73408ce4fd915a4> Some not Sklearn specific advantages: * Is actively maintained (the TF team may [deprecate](https://github.com/tensorflow/tensorflow/pull/37201#pullrequestreview-391650001) the wrappers in TF) * Has actual [documentation](https://scikeras.readthedocs.io/en/latest/index.html)
[2020-11-25T14:55:35.984Z] <5e3f3d7cd73408ce4fd915a4> I should write this stuff down somewhere in a docs page :sweat_smile: 
[2020-11-25T14:57:07.405Z] <55d21ee30fc9f982beadabb8> OK so this us super useful :). Thanks for maintaining such wrapper
[2020-11-25T15:00:18.955Z] <55d21ee30fc9f982beadabb8> Basically, it would be great to have the info (regarding the deprecation and full-compatibility) in the landing page.  When reading it I was kinda currious about it :)
[2020-11-25T15:00:58.672Z] <5e3f3d7cd73408ce4fd915a4> I hope it's useful! And yep totally agreed, I opened myself an issue to add it to our docs / README.md
[2020-11-25T15:24:41.211Z] <567f5d7716b6c7089cc043a8> we could also add this to our "related projects"
[2020-11-25T15:54:01.295Z] <5e3f3d7cd73408ce4fd915a4> It would be great if you did! Probably could also update `keras Deep Learning library capable of running on top of either TensorFlow or Theano` -> `Keras, the official high-level Deep Learning API for TensorFlow`
[2020-12-03T01:32:43.572Z] <5977a991d73408ce4f6ebde7> hello, I'm wondering if anyone has ever used ElasticNet with both a `sample_weight` argument and a precomputed gram matrix before. I'm trying a simple experiment to run a fit with and without the gram matrix passed in and they end up with different coefficients. I'm using the default setting of 'cyclic' for the coordinate descent so there shouldn't be any randomness.  without gram: ``` en = ElasticNet(alpha=0.001) en.fit(X, y, sample_weight=swgt) ```  with gram: ``` # pre-center data to avoid warning about gram matrix being tossed away # when data is centered in _pre_fit X_cent = X - np.average(X, axis=0, weights=swgt) gram_mat = X_cent.T @ X_cent  en_gram = ElasticNet(alpha=0.001, precompute=gram_mat) en_gram.fit(X_cent, y, sample_weight=swgt) ```  am I doing something dumb here?
[2020-12-03T10:56:23.559Z] <541a528b163965c9bc2053de> maybe this is related to data normalization but I am not sure. Could you please open and issue with a full minimal reproducer (e.g. using data generated on the fly with `numpy.random` for instance?
[2020-12-03T14:19:03.270Z] <5977a991d73408ce4f6ebde7> Will do. 
[2020-12-03T18:17:57.228Z] <541a528b163965c9bc2053de> Please help test scikit-learn 0.24.0rc1 and help us spread the news: https://twitter.com/scikit_learn/status/1334562221498753026
[2020-12-04T00:01:13.782Z] <5977a991d73408ce4f6ebde7> regarding my earlier question, i managed to figure it out, a bit tricky but makes sense after closely reading through some of the preprocessing code in _base.py. See example below, perhaps it could be adapted in to a unit test?  ``` from sklearn.linear_model import ElasticNet from sklearn.datasets import make_regression from numpy.testing import assert_almost_equal import numpy as np  X, y = make_regression(n_samples=int(1e5), noise=0.5)  # random lognormal weight vector. weights = np.random.lognormal(size=y.shape)  en = ElasticNet(alpha=0.01, fit_intercept=True, normalize=False, precompute=False) en.fit(X, y, sample_weight=weights)  X_c = (X - np.average(X, axis=0, weights=weights)) # row wise multiply X_r = X_c * np.sqrt(weights)[:, np.newaxis]  en_precompute = ElasticNet(alpha=0.01, fit_intercept=True, normalize=False, precompute=X_r.T@X_r) en_precompute.fit(X_c, y, sample_weight=weights)  assert_almost_equal(en.coef_, en_precompute.coef_) ```
[2020-12-05T23:15:57.331Z] <541a528b163965c9bc2053de> Thanks for the follow-up, indeed is not very intuitive. Maybe it's normal, maybe the documentation of the precompute argument could explain better how to deal with the sample_weight. Maybe this could be part of a new tests / doc improvements related to https://github.com/scikit-learn/scikit-learn/pull/17785.
[2020-12-05T23:54:27.871Z] <5977a991d73408ce4f6ebde7> @ogrisel I'm happy to try to make the change myself - do you think it could be done as a PR to the docs for ElasticNet (and the other linear models that take precompute as an argument to their constructors and accept a sample_weight arg to `fit`)
[2020-12-06T18:15:37.754Z] <541a528b163965c9bc2053de> @amidvidy maybe open an issue that states that the documentation is not clear enough on how to use `sample_weight` an `precompute` together. Maybe we could add a new dedicated section to the user guide and reference that section from the docstring for the precompute parameters of those models.
[2020-12-06T18:16:28.929Z] <541a528b163965c9bc2053de> And we probably also need a new test to check that this will never be unintentionally broken by other changes in the code base.
[2020-12-06T20:11:57.102Z] <5977a991d73408ce4f6ebde7> sounds good - will do!
[2020-12-14T09:17:30.842Z] <5fa98f30d73408ce4ff3a641> Byo.ai an intelligent assistant to make people carbon neutral/positive. Anyone with experience with one or more general purpose programming languages including but not limited to: Python, Java, C/C++ (also Pytorch,) feel free to send your CV to work@byo.ai (passion for the environment, clean technologies and artificial intelligence is a plus!)
[2020-12-15T02:58:18.105Z] <5977a991d73408ce4f6ebde7> hey @ogrisel , I put up a PR for the issue we discussed. thanks for the help.
[2020-12-17T13:23:09.744Z] <5fdb56f7d73408ce4ff6c2f5> Hi all, I implemented a new feature for gaussian mixture models and I'm wondering whether it would be useful to have it integrated in scikit-learn. Should I open an issue to discuss this or can it be discussed here? In brief, I implemented the mixture entropy estimators (lower and upper bound) introduced in this paper https://arxiv.org/pdf/1706.02419.pdf
[2020-12-17T13:58:11.099Z] <567f5d7716b6c7089cc043a8> hi @giuliolovisotto , please have a look at our inclusion criteria: https://scikit-learn.org/dev/faq.html?highlight=inclusion%20criteria#what-are-the-inclusion-criteria-for-new-algorithms
[2020-12-17T14:14:40.994Z] <5fdb56f7d73408ce4ff6c2f5> Hi Adrin, thanks for that, so if I check, I get:     * [x] 3 years since publication: (2017)   * [ ] 200+ citations: no, 57 at the moment.   * [?] wide use and usefulness: this is a bit arbitrary.   * [?] clear cut improvement: for some settings (in particular with larger no. of features and no. of GMM components) using those bounds gives more efficient and more accurate entropy estimation than using a Monte Carlo sampling approach (which can be done with the GMM.score method).  By seeing this would you say I should open an issue to discuss this on github or just leave it?   
[2020-12-17T15:44:38.943Z] <5547dd8a15522ed4b3dfed5a> Colleagues: looking for best practice tips to get logging output from sklearn, in particular from KNN clustering where Im having trouble figuring out how to use `verbose=1` (parameter doesnt seem to exist on `sklearn.neighbors.KNeighborsRegressor` nor on the `.fit()` method)  Have reviewed lots of issues on the subject but unclear current status of logging context managers or similar.
[2020-12-17T16:36:49.718Z] <55d21ee30fc9f982beadabb8> @ijstokes We don't have any logging. The verbose is only printing on the stdout.
[2020-12-17T16:37:22.062Z] <55d21ee30fc9f982beadabb8> We are currently looking at improving this part with a real logging system
[2020-12-17T16:50:15.311Z] <5547dd8a15522ed4b3dfed5a> @glemaitre thank you for the prompt response. I dont see a way to get *any* output from KNeighborsRegressor.  Am I missing something?
[2020-12-17T16:51:30.010Z] <55d21ee30fc9f982beadabb8> There is no such parameter for a `KNeighborsRegressor`
[2020-12-17T16:51:45.196Z] <55d21ee30fc9f982beadabb8> Indeed the regressor does not anything during `fit` apart of storing the dataset
[2020-12-17T17:02:49.498Z] <567f5d7716b6c7089cc043a8> @giuliolovisotto I'd probably open an issue to discuss it. My gut feeling is that it doesn't pass the inclusion criteria, but it'd be nice to also here what other maintainers think on the issue tracker
[2020-12-17T19:09:38.609Z] <5fdbaa88d73408ce4ff6cb87> Hey folks <unconvertable> Want to talk with you about pipelines <unconvertable>
[2020-12-17T19:09:59.167Z] <5fdbaa88d73408ce4ff6cb87> What is the use case they were created to cover? 
[2020-12-17T19:10:52.941Z] <5fdbaa88d73408ce4ff6cb87> In most of the examples, people groups processing "branches" by feature types (num/cat)
[2020-12-17T19:11:15.789Z] <5fdbaa88d73408ce4ff6cb87> Is this the main use case pipelines were designed for?
[2020-12-17T19:12:55.795Z] <5fdbaa88d73408ce4ff6cb87> What I was trying to do, but got frustrated is convert my Pandas-based data preprocessing into sklearn pipelines: 
[2020-12-17T19:19:10.879Z] <5fdbaa88d73408ce4ff6cb87> ``` # just copied some parts of the notebook to illustrate   # 1. data cleaning like this for feature in (     'PoolQC',      'FireplaceQu',      'Alley',      'Fence',      'MiscFeature',      'BsmtQual',      'BsmtCond',      'BsmtExposure',      'BsmtFinType1',      'BsmtFinType2',     'GarageType',      'GarageFinish',      'GarageQual',      'GarageCond',     'BsmtQual',      'BsmtCond',      'BsmtExposure',      'BsmtFinType1',      'BsmtFinType2',     'MasVnrType', ):     train_df[feature] = train_df[feature].fillna('None')     test_df[feature] = test_df[feature].fillna('None')     full_df[feature] = full_df[feature].fillna('None')  for dataframe in [train_df, test_df, full_df]:     dataframe['MSZoning'] = dataframe.groupby(['Neighborhood'])['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))     dataframe['MSSubClass'] = dataframe.groupby(['HouseStyle'])['MSSubClass'].transform(lambda x: x.fillna(x.mode()[0]))     dataframe['LotFrontage'] = dataframe.groupby(['Neighborhood', 'MSSubClass'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))     dataframe['Functional'] = dataframe['Functional'].fillna('Typ')  # 2. Some ordinal encoding   ordinal_feature_mapping = {     'ExterQual': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},      'ExterCond': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},     'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},     'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},     'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},     'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},     'HeatingQC': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},     'KitchenQual': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},     'FireplaceQu': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},     'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},     'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},     'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},     'PoolQC': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},     'Fence': {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4},     'PavedDrive': {'N': 0, 'P': 1, 'Y': 2},     'CentralAir': {'N': 0, 'Y': 1},     'Alley': {'None': 0, 'Pave': 1, 'Grvl': 2},     'Street': {'Pave': 0, 'Grvl': 1},     'BsmtExposure': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},     'Functional': {'Sal': 0, 'Sev': 1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7} }  non_ordinal_cat_features = list(set(cat_features) - set(ordinal_feature_mapping.keys()))  for cat_feature in non_ordinal_cat_features:     train_df[cat_feature + 'Enc'] = LabelEncoder().fit_transform(train_df[cat_feature])     test_df[cat_feature + 'Enc'] = LabelEncoder().fit_transform(test_df[cat_feature])     full_df[cat_feature + 'Enc'] = LabelEncoder().fit_transform(full_df[cat_feature])  for ordinal_feature, feature_mapping in ordinal_feature_mapping.items():     train_df[ordinal_feature + 'Enc'] = train_df[ordinal_feature].map(feature_mapping)     test_df[ordinal_feature + 'Enc'] = test_df[ordinal_feature].map(feature_mapping)     full_df[ordinal_feature + 'Enc'] = full_df[ordinal_feature].map(feature_mapping)  # 3. Excessive feature engineering  for dataframe in [train_df, test_df, full_df]:     dataframe['HasFireplace'] = dataframe['Fireplaces'].apply(lambda x: int(x > 0))     dataframe['HouseAge'] = dataframe['YrSold'].astype('int') - dataframe['YearBuilt'].astype('int')      dataframe['TotalBathrooms'] = (dataframe['FullBath'] + (0.5 * dataframe['HalfBath']) +                                 dataframe['BsmtFullBath'] + (0.5 * dataframe['BsmtHalfBath']))      dataframe['OverallHouseQC'] = dataframe['OverallQual'] + dataframe['OverallCond']     dataframe['IsPavedDrive'] = (dataframe['PavedDrive'] == 'Y') * 1      dataframe['IsNeighborhoodElite'] = (dataframe['Neighborhood'].isin(['NridgHt', 'CollgeCr', 'Crawfor', 'StoreBr', 'Timber'])) * 1    # bunch of other features ```
[2020-12-17T19:20:38.802Z] <5fdbaa88d73408ce4ff6cb87> These three stages are the main in my data processing flow. 
[2020-12-17T19:22:22.862Z] <5fdbaa88d73408ce4ff6cb87> So ideally I would like to process data in the same order in the pipeline as well. Then it would be converted naturally to pipeline definition 
[2020-12-17T19:25:47.898Z] <5fdbaa88d73408ce4ff6cb87> So I would imagine a pipeline definition like this: ``` Pipeline([     ('missing_value_imputing', ColumnTransformer([...])),     ('feature_engineering', FeatureUnion([...])),     ('feature_transforming', ColumnTransformer([...])), ]) ```
[2020-12-17T19:28:56.990Z] <5fdbaa88d73408ce4ff6cb87> However, this doesn't work, because missing_value_imputing step would return me numpy array which is hard to work with on the following stages 
[2020-12-17T19:33:51.947Z] <5fdbaa88d73408ce4ff6cb87> In the same time, my data processing has  constrains (feature_engineering step requires all values in place (missing_value_imputing) and feature_transforming requires all set of features (feature_engineering)). There are also operations I could apply on a multiple columns (and would love to do) like "None" constant imputing or ordinal encoding  and single column specific actions like MSZoning imputing 
[2020-12-17T19:35:05.838Z] <5fdbaa88d73408ce4ff6cb87> Please let me know if all of this makes any sense 
[2020-12-17T19:36:03.693Z] <5fdbaa88d73408ce4ff6cb87> With that being said, I'm wondering what is the cleanest way to define sklearn pipeline for this task?
[2020-12-18T09:00:56.483Z] <5baf7d9ad73408ce4fa9c9b2> > What is the use case they were created to cover?   To pipe an arbitrary number of pre-processing steps (i.e. transformers) with a final estimator. E.g. `make_pipeline(StandardScaler(), LogisticRegression())`  > In most of the examples, people groups processing "branches" by feature types (num/cat) > Is this the main use case pipelines were designed for?  Not really. Mapping different features to different transformers is the role of the `ColumnTranformer` (CT).  The CT is a meta-transformer that will apply different pre-processing steps to specific features. These pre-processing steps can also be pipelines themselves. A CT is often used as the first step of a pipeline.  
[2020-12-18T09:01:25.574Z] <5baf7d9ad73408ce4fa9c9b2> Take a look at https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#use-columntransformer-by-selecting-column-by-names for a typical pipeline + CT example.
[2020-12-18T10:23:16.769Z] <5fdbaa88d73408ce4ff6cb87> Hey @NicolasHug thank you for answering!
[2020-12-18T10:26:51.478Z] <5fdbaa88d73408ce4ff6cb87> Is not this example with Titanic database or one with Ames dataset (https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html) actually what I'm saying by "In most of the examples, people groups processing "branches" by feature types (num/cat)"? <unconvertable>
[2020-12-18T10:32:42.341Z] <5fdbaa88d73408ce4ff6cb87> "The CT is a meta-transformer that will apply different pre-processing steps to specific features. These pre-processing steps can also be pipelines themselves. A CT is often used as the first step of a pipeline." - this perfectly works if you don't need to engineer your features.
[2020-12-18T10:33:35.672Z] <5fdbaa88d73408ce4ff6cb87> Once engineering enters the process, it becomes much hard to imagine a clean way to define the pipeline. 
[2020-12-18T10:37:56.622Z] <55d21ee30fc9f982beadabb8> You can always have your feature engineering as a preprocessing stage within your pipeline and then call the CT
[2020-12-18T10:38:07.815Z] <55d21ee30fc9f982beadabb8> As an example: https://github.com/ramp-kits/air_passengers/blob/master/submissions/use_external_data/estimator.py
[2020-12-18T10:38:22.782Z] <55d21ee30fc9f982beadabb8> here the data encoding happen before the column dispatching in the CT
[2020-12-18T10:38:59.537Z] <55d21ee30fc9f982beadabb8> knowing that your feature-engineering could also be a `Pipeline` itself
[2020-12-18T10:44:21.034Z] <5fdbaa88d73408ce4ff6cb87> @glemaitre great example, thank you for sharing!
[2020-12-18T10:45:19.368Z] <55d21ee30fc9f982beadabb8> This said I think that they are multitude way to combined both `Pipeline` and `ColumnTransformer` and this is not sometimes clear which way to go
[2020-12-18T10:49:26.535Z] <5fdbaa88d73408ce4ff6cb87> @glemaitre what is your strategy to pipelinize? :D
[2020-12-18T10:49:56.165Z] <55d21ee30fc9f982beadabb8> Code review by peers :)
[2020-12-18T10:50:41.431Z] <5fdbaa88d73408ce4ff6cb87> You learn from them or they suggest you? :)
[2020-12-18T10:50:42.682Z] <55d21ee30fc9f982beadabb8> But my first draft would be to do whatever feature engineering that is stateless
[2020-12-18T10:50:52.610Z] <55d21ee30fc9f982beadabb8> before making a columntransformer
[2020-12-18T10:51:59.846Z] <55d21ee30fc9f982beadabb8> then I would probably write my own `FeatureEngineering` estimator if a `fit` is necessary and use it in the CT
[2020-12-18T10:52:29.905Z] <5fdbaa88d73408ce4ff6cb87> @glemaitre yeah that makes sense. What about data imputing? Normally, it's needed to see all data in place on FE stage
[2020-12-18T10:53:42.472Z] <55d21ee30fc9f982beadabb8> I usually have the case as in Titanic
[2020-12-18T10:53:52.030Z] <55d21ee30fc9f982beadabb8> where you want to impute
[2020-12-18T10:53:59.459Z] <55d21ee30fc9f982beadabb8> with some other processing
[2020-12-18T10:54:37.292Z] <55d21ee30fc9f982beadabb8> But your imputer should be able to work by being fitting only on the training data
[2020-12-18T10:55:08.817Z] <55d21ee30fc9f982beadabb8> without the need to see the full dataset (otherwise you are leaking some data from test to train)
[2020-12-18T10:56:53.829Z] <55d21ee30fc9f982beadabb8> > In the same time, my data processing has  constrains (feature_engineering step requires all values in place (missing_value_imputing) and feature_transforming requires all set of features (feature_engineering)). There are also operations I could apply on a multiple columns (and would love to do) like "None" constant imputing or ordinal encoding  and single column specific actions like MSZoning imputing   So whenever you want to dispatch on column you will use a CT that can contain your imputer + preprocessing
[2020-12-18T11:03:23.632Z] <5fdbaa88d73408ce4ff6cb87> @glemaitre here is an example: feature "Neighborhood" may have missing values. Based on this feature values, I would like to engineer a new feature "IsNeighborhoodElite". AFAIG I need to implement a custom FeatureEngineeringEstimator (or use FunctionTransformer). On which stage imputing should happen?
[2020-12-18T11:08:04.119Z] <55d21ee30fc9f982beadabb8> You might want to use the imputation from scikit-learn and use  `add_indicator=True` that will do the job for you
[2020-12-18T11:08:34.923Z] <55d21ee30fc9f982beadabb8> If you want to dispatch only some columns then you need a CT
[2020-12-18T11:09:06.287Z] <55d21ee30fc9f982beadabb8> And on the question where to put it in the pipeline, it actually depends of the processing steps in your pipeline
[2020-12-18T11:09:44.872Z] <55d21ee30fc9f982beadabb8> once you did the imputation, the subsequent stage might use the imputed value and the question is: do you want it or not 
[2020-12-18T11:10:08.645Z] <55d21ee30fc9f982beadabb8> To give an example, you would like to standardize data but you have missing values
[2020-12-18T11:11:17.589Z] <55d21ee30fc9f982beadabb8> if you impute data by the mean and then standardize, you will introduce a bias. Hopefully, the StandardScaler allows to passthrough missing value and ignore them during computation. So if you don't want a bias, you will first standardize and then impute
[2020-12-18T11:21:14.092Z] <5fdbaa88d73408ce4ff6cb87> @glemaitre hmmmm <unconvertable> if we go back to that example with Neighborhood. I imagine the following pseudo-pipeline: ``` Pipeline([     ('imputing', Pipeline([         ('neighborhood_impute', SimpleImputer(), ['Neighborhood']), # impute the exising feature that will be used in feature engineering     ]),     ('engineering', FeatureEngineeringEstimator()), # create additional feature     ('transforming', ColumnTransformer([ ... ]), # transform the additional feature ]) ```
[2020-12-18T11:24:14.886Z] <5fdbaa88d73408ce4ff6cb87> This example is simpler in a way there is no deps on the column values. Just need to have no NaN values on the rest of the stages after imputing. 
[2020-12-18T11:25:09.358Z] <55d21ee30fc9f982beadabb8> So you don't want to impute `Neighborhood`?
[2020-12-18T11:25:18.597Z] <55d21ee30fc9f982beadabb8> you only want a mask?
[2020-12-18T11:25:57.720Z] <5fdbaa88d73408ce4ff6cb87> I would hope to impute on this stage <unconvertable> ``` ('imputing', Pipeline([         ('neighborhood_impute', SimpleImputer(), ['Neighborhood']), # impute the exising feature that will be used in feature engineering     ]), ```
[2020-12-18T11:26:06.214Z] <55d21ee30fc9f982beadabb8> Oh sorry I misread
[2020-12-18T11:26:29.343Z] <55d21ee30fc9f982beadabb8> so if you have no dependence between columns
[2020-12-18T11:26:34.075Z] <55d21ee30fc9f982beadabb8> this is fine
[2020-12-18T11:26:37.831Z] <5fdbaa88d73408ce4ff6cb87> And then have Neighborhood read for  `('engineering', FeatureEngineeringEstimator())`
[2020-12-18T11:26:44.922Z] <5fdbaa88d73408ce4ff6cb87> yeah no deps
[2020-12-18T11:27:17.769Z] <55d21ee30fc9f982beadabb8> > And then have Neighborhood read for  `('engineering', FeatureEngineeringEstimator())`  With or without missing data
[2020-12-18T11:27:41.959Z] <55d21ee30fc9f982beadabb8> because the `Neighborhood` column in the `engineering` column will contain `NaN`
[2020-12-18T11:28:02.823Z] <5fdbaa88d73408ce4ff6cb87> Without <unconvertable>
[2020-12-18T11:28:09.869Z] <55d21ee30fc9f982beadabb8> if you don't want it means, that you need to make the imputation before 
[2020-12-18T11:29:10.700Z] <55d21ee30fc9f982beadabb8> and this imputation would require a column transformer itself if you really want to only limited it to the `Neighborhood` column   
[2020-12-18T11:29:52.574Z] <55d21ee30fc9f982beadabb8> Basically you are in the case that you need to impute first the value because you want your subsequent step to use imputed feature
[2020-12-18T11:31:01.754Z] <5fdbaa88d73408ce4ff6cb87> Hm, but I defined imputation step to be the first in the pipeline, would not that help?
[2020-12-18T11:32:39.945Z] <5fdbaa88d73408ce4ff6cb87> Probably the same level steps would be executing in parallel, so I would not get the result 
[2020-12-18T11:33:37.692Z] <5fdbaa88d73408ce4ff6cb87> Would this adjustment help?  ``` Pipeline([     ('engineering', Pipeline([         ('neighborhood_impute', SimpleImputer(), ['Neighborhood']), # impute the exising feature that will be used in feature engineering         ('neighborhood_engineering', FeatureEngineeringEstimator()), # create additional feature     ]),     ('transforming', ColumnTransformer([ ... ]), # transform the additional feature ]) ```
[2020-12-18T11:33:42.917Z] <55d21ee30fc9f982beadabb8> ``` Pipeline(steps=[     ('imputation', make_column_transformer((SimpleImputer(), ['Neighborhood'], remainder='passthrough'))),     ('engineering', FeatureEngineeringEstimator()), # create additional feature     ('transforming', ColumnTransformer([ ... ]), # transform the additional feature ]) ```
[2020-12-18T11:34:24.130Z] <55d21ee30fc9f982beadabb8> imputation -> enginerring -> dispatching column to different transformer
[2020-12-18T11:35:04.283Z] <55d21ee30fc9f982beadabb8> the first imputation make sure that there is not missing value in `Neighborhood` only (and other columns are just passthrough)
[2020-12-18T11:35:13.311Z] <5fdbaa88d73408ce4ff6cb87> Yeah, and CT from the imputation step would remove columns, right? 
[2020-12-18T11:35:38.861Z] <55d21ee30fc9f982beadabb8> nop `remainder="passthrough"` is used to let columns pass
[2020-12-18T11:35:50.378Z] <55d21ee30fc9f982beadabb8> by default `remainder="drop"` that drop the columns
[2020-12-18T11:36:16.861Z] <5fdbaa88d73408ce4ff6cb87> I mean would it possible to refer Neighborhood feature by its name on engineering step? 
[2020-12-18T11:37:41.070Z] <5fdbaa88d73408ce4ff6cb87> [![IMG_1278.jpg](https://files.gitter.im/541a528c163965c9bc2053e1/z216/thumb/IMG_1278.jpg)](https://files.gitter.im/541a528c163965c9bc2053e1/z216/IMG_1278.jpg)
[2020-12-18T11:37:42.986Z] <55d21ee30fc9f982beadabb8> arff true, we will drop the name of the feature
[2020-12-18T11:38:20.105Z] <5fdbaa88d73408ce4ff6cb87> I saw some wild stuff with feature position indexing instead of column names <unconvertable>
[2020-12-18T11:38:37.438Z] <55d21ee30fc9f982beadabb8> there is an easier thing
[2020-12-18T11:38:56.455Z] <55d21ee30fc9f982beadabb8> you pass a `FunctionTransformer` that we recreate a `dataframe` with the right column name
[2020-12-18T11:39:35.653Z] <55d21ee30fc9f982beadabb8> However, the first `ColumnTransfomer` will reorder the column with `Neighborhood` column as the first column
[2020-12-18T11:39:43.030Z] <55d21ee30fc9f982beadabb8> that is really annoying
[2020-12-18T11:40:41.034Z] <55d21ee30fc9f982beadabb8> `ColumnTransformer` provide a `get_feature_names` but it will only work if the underlying transformer is implementing it
[2020-12-18T11:40:58.815Z] <5fdbaa88d73408ce4ff6cb87> is it  possible to use IdentityFunctionTransformer instead of CT? ``` Pipeline(steps=[     ('imputation', make_column_transformer((SimpleImputer(), ['Neighborhood'], remainder='passthrough'))),     ('engineering', FeatureEngineeringEstimator()), # create additional feature     ('transforming', ColumnTransformer([ ... ]), # transform the additional feature ]) ```
[2020-12-18T11:42:01.321Z] <55d21ee30fc9f982beadabb8> The issue here is that your `SimpleImputer` as a state depending of the strategy
[2020-12-18T11:42:15.795Z] <55d21ee30fc9f982beadabb8> if you strategy is to replace by a constant
[2020-12-18T11:42:40.444Z] <55d21ee30fc9f982beadabb8> then yes you can use a `FunctionTransformer` and fill by a constant and make sure to return a dataframe
[2020-12-18T11:43:29.657Z] <55d21ee30fc9f982beadabb8> However, if you "learn" (e.g. mean, etc.) then `FunctionTransformer` is not what you want because it is stateless (you will compute the mean on the train and test instead of using the train on the test).
[2020-12-18T11:44:53.927Z] <55d21ee30fc9f982beadabb8> Otherwise you write a custom Imputer that recreate the dataframe when calling transform
[2020-12-18T11:46:08.065Z] <55d21ee30fc9f982beadabb8> There is a lot of boilerplate there and not an easy solution :)
[2020-12-18T11:46:51.288Z] <55d21ee30fc9f982beadabb8> things will get better once we support feature names and allows to track feature name along a pipeline
[2020-12-18T11:46:59.756Z] <5fdbaa88d73408ce4ff6cb87> Yeah, why is that? I feel like I'm the only one who have such an issue :D
[2020-12-18T11:47:36.460Z] <5fdbaa88d73408ce4ff6cb87> Yes, that will be a paradise <unconvertable>
[2020-12-18T11:47:49.288Z] <55d21ee30fc9f982beadabb8> > Yes, that will be a paradise <unconvertable>  It is ongoing ;)
[2020-12-18T11:48:35.994Z] <55d21ee30fc9f982beadabb8> > Yeah, why is that? I feel like I'm the only one who have such an issue :D  I think that usually, people make the feature engineering even before to start a scikit-learn pipeline
[2020-12-18T11:48:52.319Z] <55d21ee30fc9f982beadabb8> basically you do your feature engineering in pandas get your design matrix 
[2020-12-18T11:49:01.254Z] <55d21ee30fc9f982beadabb8> and then start processing.
[2020-12-18T11:49:42.111Z] <55d21ee30fc9f982beadabb8> So when the preprocessing is simple (like the air_passengers example), you can even integrate the preprocessing within the first stage of the pipeline.
[2020-12-18T11:49:47.059Z] <5fdbaa88d73408ce4ff6cb87> So I did and then decided to try to incorporate that into a pipeline to just pass raw X into fit() 
[2020-12-18T11:50:13.691Z] <5fdbaa88d73408ce4ff6cb87> <unconvertable>
[2020-12-18T11:50:26.828Z] <55d21ee30fc9f982beadabb8> so you just found the limitation :)
[2020-12-18T11:51:10.889Z] <5fdbaa88d73408ce4ff6cb87> Okayokay, sklearn is awesome anyways 
[2020-12-18T11:51:30.943Z] <5fdbaa88d73408ce4ff6cb87> Eager to try to contribute something to the project 
[2020-12-18T11:52:23.790Z] <5fdbaa88d73408ce4ff6cb87> Do you have any community hangouts? 
[2020-12-18T11:53:59.291Z] <55d21ee30fc9f982beadabb8> For the moment, this channel for usage related stuff, and GitHub with issues tracker for making the project evolve.
[2020-12-18T11:55:27.614Z] <5fdbaa88d73408ce4ff6cb87> Got it, thank you for the help <unconvertable>
[2020-12-19T03:05:20.347Z] <5de821c2d73408ce4fd31a52> Any thoughts on this? Just added an MCVE example to an old Q on SO. https://stackoverflow.com/a/65366293/6046019 
[2020-12-19T03:06:24.178Z] <5de821c2d73408ce4fd31a52> [![image.png](https://files.gitter.im/541a528c163965c9bc2053e1/Peus/thumb/image.png)](https://files.gitter.im/541a528c163965c9bc2053e1/Peus/image.png)
[2020-12-22T17:07:15.406Z] <541a528b163965c9bc2053de> scikit-learn 0.24.0 is out! https://twitter.com/scikit_learn/status/1341429250696630276
[2020-12-27T19:51:12.917Z] <5e3f3d7cd73408ce4fd915a4> Are there any plans to allow estimators to customize their expected precision for your estimator checks? The checks are great, but I've found that estimators I have fail because of precision issues (like a single element of a 60 element array being off by 5e-8). It would be nice to be able to at least have some rough measure of precision as an estimator attribute that the tests could then use to adapt their behavior.
[2020-12-30T11:37:56.870Z] <5fec660ed73408ce4ff7a933> Hey people
[2020-12-30T11:38:02.299Z] <5fec660ed73408ce4ff7a933> Is this place active?
[2020-12-30T11:38:17.677Z] <5fec660ed73408ce4ff7a933> Is there a real time communication platform for scikit learn?
[2020-12-30T11:38:35.150Z] <5fec660ed73408ce4ff7a933> Thanks!!
[2020-12-31T12:38:03.363Z] <5dbd6437d73408ce4fcfbf0f> @AdityaPujara23 ask here, somebody will reply you if possible.
[2021-01-01T07:21:02.912Z] <5fec660ed73408ce4ff7a933> Cool thanks!
[2021-01-06T12:43:24.237Z] <584177bed73408ce4f3a3d87> Hi there! I'm developing an online ensemble learning thingy, and I just wanted to praise you guys for the quality of your code. It's always a pleasure to read! (Even though I always weep looking at `BaseEstimator` and its cool `get/set_params`, wondering whether I should rewrite something similar or re-use your code -- and *wanting* to do neither :P )
[2021-01-06T13:29:07.741Z] <541a528b163965c9bc2053de> Thanks :)
[2021-01-08T12:23:12.501Z] <564789be16b6c7089cbab8b7> do any classifiers in scikit-learn handle categorical features directly? I feel there were some PRs about this a long time ago
[2021-01-08T13:37:04.513Z] <5baf7d9ad73408ce4fa9c9b2> You're in luck @lesshaste https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_24_0.html#native-support-for-categorical-features-in-histgradientboosting-estimators
[2021-01-08T13:50:05.245Z] <564789be16b6c7089cbab8b7> @NicolasHug  that's great. I will try it in a few minutes
[2021-01-08T14:26:46.371Z] <5ff86ab4d73408ce4ff853dc> Hi guys! I wrote a document which is "Hello Kaggle". I hope to get some feedback about the document such as a typo, grammar error, wrong information, etc. https://github.com/stevekwon211/Hello-Kaggle thank you :)
[2021-01-08T14:38:28.432Z] <564789be16b6c7089cbab8b7> @NicolasHug  it works which is great. 
[2021-01-08T14:42:50.569Z] <564789be16b6c7089cbab8b7> hmm. except I can't get it to work with categorical features
[2021-01-08T14:44:30.476Z] <564789be16b6c7089cbab8b7> what am I doing wrong? https://bpa.st/IXRQ
[2021-01-08T14:44:54.666Z] <564789be16b6c7089cbab8b7> why is it trying to convert a string to a float?
[2021-01-08T15:19:15.878Z] <5baf7d9ad73408ce4fa9c9b2> @lesshaste categorical features are supported but the estimators themselves only understand integer values in [0, 255]. You'll need to encode hte categorical features with an OrdinalEncoder before passing them to the predictor. You can take a look at https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_categorical.html#gradient-boosting-estimator-with-native-categorical-support for an example
[2021-01-08T15:20:58.263Z] <5baf7d9ad73408ce4fa9c9b2> In your case since it seems that you only have categorical features, you can bypass the ColumnTransformer and just  do `clf  = make_pipeline(OrdinalEncoder(), HistGradientBoostingClassifier())`
[2021-01-08T15:46:02.410Z] <564789be16b6c7089cbab8b7> @NicolasHug  ah ok. And then I list which features are categorical using categorical_features=cat_features? As in clf = make_pipeline(OrdinalEncoder(), HistGradientBoostingClassifier(categorical_features=cat_features)) ?
[2021-01-08T15:46:35.401Z] <564789be16b6c7089cbab8b7> @NicolasHug  I should say that catboost has some very clever tricks for categorical features that would be awesome if included in scikit-learn
[2021-01-08T15:51:17.695Z] <564789be16b6c7089cbab8b7> the default for HistGradientBoostingClassifier seems to  be no categorical features unless I misunderstood it
[2021-01-08T17:15:32.877Z] <5baf7d9ad73408ce4fa9c9b2> > @NicolasHug  ah ok. And then I list which features are categorical using categorical_features=cat_features? As in clf = make_pipeline(OrdinalEncoder(), HistGradientBoostingClassifier(categorical_features=cat_features)) ?  Yes, or you can use `clf.set_params(histgradientboostingclassifier__categorical_features=...)` after `clf` is defined. And yes, by default all features are treated as continuous, as is the case for the overwhelming majority of estimators (only a few tranformers like OneHotEncoder expect categorical features by default). Regarding CatBoost:  I think  they do target encoding for high-cardinality categorical features. This is in the works https://github.com/scikit-learn/scikit-learn/pull/17323
[2021-01-08T17:54:58.681Z] <564789be16b6c7089cbab8b7> @NicolasHug  thanks.. they actually have two tricks
[2021-01-08T17:55:40.800Z] <564789be16b6c7089cbab8b7> https://arxiv.org/pdf/1706.09516.pdf  explains it better than I could
[2021-01-08T17:56:50.723Z] <564789be16b6c7089cbab8b7> but essentially the first and more most important trick is Ordered boosting   (section 4.2) and the second is Feature combinations
[2021-01-11T05:56:30.303Z] <5e532f4fd73408ce4fda84b2> https://github.com/scikit-learn/scikit-learn/issues/19092
[2021-01-11T05:56:41.953Z] <5e532f4fd73408ce4fda84b2> Hey,
[2021-01-11T05:57:34.832Z] <5e532f4fd73408ce4fda84b2> Can someone help me understand if I can start working on this?
[2021-01-11T11:18:06.145Z] <564789be16b6c7089cbab8b7> how exactly does prediction work for gradient boosted trees? In a random forest you just get a prob from every tree and average them I think. Is this different for gradient boosted trees?
[2021-01-11T13:29:26.760Z] <5baf7d9ad73408ce4fa9c9b2> @lesshaste in gradient boosting, one directly optimizes a loss function. For binary classification in sickit-learn this is the log loss, much like logistic regression. What the trees predict is the log-odds ratio (decision_function()) and it's passed into a sigmoid to get a probability (predict_proba())
[2021-01-11T13:30:51.597Z] <5baf7d9ad73408ce4fa9c9b2> this is a self plug but this might help: http://nicolas-hug.com/blog/around_gradient_boosting
[2021-01-11T13:33:45.918Z] <564789be16b6c7089cbab8b7> @NicolasHug  thank you. In low level terms, what happens at prediction time? Is something computed for every tree separately and then averaged?
[2021-01-11T13:56:28.793Z] <5baf7d9ad73408ce4fa9c9b2> decision_function is the sum of all the tree values, not the average
[2021-01-11T13:57:38.504Z] <5baf7d9ad73408ce4fa9c9b2> see https://nbviewer.jupyter.org/github/NicolasHug/nicolashug.github.io/blob/master/assets/gradient_boosting_descent/GradientBoosting.ipynb
[2021-01-11T14:27:25.456Z] <59bc1baad73408ce4f75eec5> I've cross-compiled scikit-learn for an armv7h system and I'm receiving the following error when testing, does anyone have any suggestions for where the issue may lie?
[2021-01-11T14:27:33.150Z] <59bc1baad73408ce4f75eec5> ``` File "sklearn/cluster/_dbscan_inner.pyx", line 40, in sklearn.cluster._dbscan_inner.dbscan_inner ValueError: Buffer dtype mismatch, expected 'npy_intp' but got 'long long'  ```
[2021-01-11T14:28:24.843Z] <59bc1baad73408ce4f75eec5> It looks like it could be something 32bit vs 64bit related but from what I can see the `setup.py` build system just imports from `numpy` which I would expect to handle this all properly
[2021-01-11T14:29:02.743Z] <59bc1baad73408ce4f75eec5> so I'm wondering if this isn't a cross compile issue and is maybe just an assumption made in the code that the argument will be 64bit?
[2021-01-11T14:51:37.807Z] <564789be16b6c7089cbab8b7> @NicolasHug thanks
[2021-01-14T17:18:58.314Z] <541a528b163965c9bc2053de> @jackmitch this looks like a bug indeed. I don't have a quick fix from the tip of my head but could you please open an issue on github to avoid forgetting about it? It's probably a temporary buffer that is assigned with an `np.int` instead of `np.intp` in our Cython code or wrapping Python code.
[2021-01-14T17:19:41.410Z] <541a528b163965c9bc2053de> Here is a similar bug we had in the past (a long time ago): https://github.com/scikit-learn/scikit-learn/commit/627c564faec36c783788b7488b4cf19a2535916c
[2021-01-14T17:20:41.433Z] <541a528b163965c9bc2053de> Ideally a PR would be appreciated because none of us will be able to reproduce it because we do not have access to such hardware.
[2021-01-14T17:22:25.561Z] <541a528b163965c9bc2053de> Also if you want to submit a PR for our doc that documents how you cross-compile scikit-learn for armv7h, that could be useful knowledge to share. For instance it could be a new section at the end of this page: https://scikit-learn.org/dev/developers/advanced_installation.html
[2021-01-15T15:55:02.162Z] <54a6f79fdb8155e6700e5114> How to train neural network and what i the best design of it if I have discrete/continual input and continual output?
[2021-01-16T06:55:24.549Z] <5e3f3d7cd73408ce4fd915a4> Hi, I'm wondering why this test is checking for float64 specifically (as opposed `dtype.kind == "f"`)? https://github.com/scikit-learn/scikit-learn/blob/2218ec46227c92301ac6837c4a8ae9b8dc5d3960/sklearn/utils/estimator_checks.py#L1735
[2021-01-16T19:39:26.286Z] <5baf7d9ad73408ce4fa9c9b2> @adriangb no real reason. This is typically the kind of check that's probably a bit too strict for non-internal estimators. We're working on making the `check_estimator` suite less restrictive (https://github.com/scikit-learn/scikit-learn/issues/13969). BTW @glemaitre , any progress on that? (I don't mean to rush you by any means, just wondering  :) )
[2021-01-16T21:10:58.802Z] <5e3f3d7cd73408ce4fd915a4> Great, I left a comment on that PR for the record.
[2021-01-16T21:12:06.649Z] <5e3f3d7cd73408ce4fd915a4> Would there be any chance that tolerances might be relaxed as well? There are several checks that check rtol/atol to <1e-7, which makes it very flaky when the estimator internally uses <=32 bit precision.
[2021-01-16T21:16:22.353Z] <5e3f3d7cd73408ce4fd915a4> @urosn do you mean like this: ```python estimator.fit(X, [1, 2, 3, 4.5]) estimator.predict(X)  # [1.1, 2.3, 2.7, 4.4] ``` ?
[2021-01-17T08:35:09.202Z] <59076a40d73408ce4f5c34b4> Hi. I want to learn scikit-learn from scratch. Do we have an official book or guide?
[2021-01-17T08:35:24.016Z] <59076a40d73408ce4f5c34b4> If not, I will be making notes. Can I contribute one?
[2021-01-17T12:28:19.354Z] <58de4778d73408ce4f551e04> Hi @D3V4N5H, there is plenty on resources in the docs. You can start with the ["Getting Started" pages](https://scikit-learn.org/stable/getting_started.html).
[2021-01-17T12:33:28.354Z] <59076a40d73408ce4f5c34b4> Thank you
[2021-01-18T08:52:20.618Z] <55d21ee30fc9f982beadabb8> @NicolasHug I was a focus on the release recently but I think that we are going to branch today so it would be one of the task pretty soon.
[2021-01-19T19:00:20.640Z] <564789be16b6c7089cbab8b7> I am building a classifier and have 10,000 examples of the positive class. I can generate any amount from the negative class. Is there a standard way to take advantage of the unlimited amount of data from the negative class?
[2021-01-20T08:36:06.379Z] <55d21ee30fc9f982beadabb8> I am thinking about taking advantage only about the positive class with novelty detection algorithms :)
[2021-01-20T08:37:07.657Z] <55d21ee30fc9f982beadabb8> Second thoughts would be to create an ensemle of learner that would learnt from balanced positive/negative samples
[2021-01-20T08:37:24.975Z] <55d21ee30fc9f982beadabb8> but each time the negative samples can change
[2021-01-20T08:38:22.981Z] <55d21ee30fc9f982beadabb8> But to be honest, these are 2 strategies that come to mind but I did not look at the literature and what actually work in practise
[2021-01-20T09:34:18.263Z] <564789be16b6c7089cbab8b7> I like the second method. I think it might make sense to sample 90% of the positive class each time randomly and include the same number is newly sampled negative samples 
[2021-01-20T09:34:37.931Z] <564789be16b6c7089cbab8b7> Does scikit learn have a way to do this?
[2021-01-20T09:35:05.173Z] <564789be16b6c7089cbab8b7> @glemaitre I will look up novelty detection
[2021-01-20T09:35:58.985Z] <55d21ee30fc9f982beadabb8> https://imbalanced-learn.org/stable/auto_examples/applications/plot_impact_imbalanced_classes.html#use-of-balancedrandomforestclassifier-and-balancedbaggingclassifier
[2021-01-20T09:36:15.956Z] <55d21ee30fc9f982beadabb8> This is something that we "kinda" of use for the imbalanced problem
[2021-01-20T09:37:07.838Z] <55d21ee30fc9f982beadabb8> we train a `HistGradientBoostingClassifier` on balanced bootstrap that are given by either a `BalancedRandomForestClassifier` or a `BalancedBaggingClassifier`
[2021-01-20T09:50:33.035Z] <564789be16b6c7089cbab8b7> Thanks. So I guess I am doing this at one higher level. That is making an ensemble lots of histgradientboostingclassifiers
[2021-01-20T09:50:51.263Z] <564789be16b6c7089cbab8b7> I feel my problem setup can't be that rare 
[2021-01-20T10:05:15.702Z] <564789be16b6c7089cbab8b7> Or maybe I can follow your example more closely in fact 
[2021-01-20T10:26:45.514Z] <564789be16b6c7089cbab8b7> If I were to pose this question online, which stackexchange site is best for scikit learn?
[2021-01-20T10:35:32.383Z] <5baf7d9ad73408ce4fa9c9b2> @lesshaste you may try https://github.com/scikit-learn/scikit-learn/discussions
[2021-01-20T10:43:08.235Z] <564789be16b6c7089cbab8b7> Thanks!
[2021-01-20T11:46:35.409Z] <5571fe1015522ed4b3e17d90> Side-comment for expectation management :wink: : we enabled Github Discussions quite recently so it is kind of in bootstrap mode i.e. you may not get a great answer right away, let's see!
[2021-01-20T11:47:19.717Z] <5571fe1015522ed4b3e17d90> I guess creating a Github discussion about which stackexchange (or other ressources e.g. some Discourse forum or Reddit somewhere) is the best depending on the type of scikit-learn related question could be a good idea too :smile: 
[2021-01-20T14:05:23.635Z] <564789be16b6c7089cbab8b7> @lesteve thanks.  I will ask a couple of questions and hope no one gets annoyed
[2021-01-20T14:11:49.859Z] <564789be16b6c7089cbab8b7> @lesteve first question asked
[2021-01-20T14:23:39.015Z] <564789be16b6c7089cbab8b7> second question asked :)
[2021-01-20T17:38:47.954Z] <5571fe1015522ed4b3e17d90> This is kind of the beginning of Github Discussions in scikit-learn so nobody is going to get annoyed (hopefully :wink:)
[2021-01-20T19:08:48.279Z] <5fa98f30d73408ce4ff3a641> Hi i need a programmer with experience in nlp that is willing to work for a few hours a week? DM me if you are interested
[2021-01-22T08:53:13.332Z] <564789be16b6c7089cbab8b7> @byo-ai  pay?
[2021-01-22T08:53:21.364Z] <564789be16b6c7089cbab8b7> @lesteve  :)
[2021-01-22T08:54:25.950Z] <564789be16b6c7089cbab8b7> a really simple question. Currently I do clf.score(Xordinal_test, y_test). If I want to use balanced accuracy instead, is there a similar one line solution?
[2021-01-22T09:28:03.796Z] <55d21ee30fc9f982beadabb8> `balanced_accuracy_score(clf.predict(X_ordinal_test), y_test)`
[2021-01-22T09:28:29.706Z] <55d21ee30fc9f982beadabb8> This is a one liner solution if you omit the import :)
[2021-01-22T09:29:00.170Z] <55d21ee30fc9f982beadabb8> We don't allow to switch the default score in `clf.score` to be more explicit
[2021-01-22T09:29:17.734Z] <55d21ee30fc9f982beadabb8> so you need to get the prediction and call the score function
[2021-01-22T09:31:17.491Z] <55d21ee30fc9f982beadabb8> You also have the possibility to use the scorer API but this is not a one liner
[2021-01-22T09:31:25.361Z] <564789be16b6c7089cbab8b7> thanks!
[2021-01-22T09:32:38.196Z] <55d21ee30fc9f982beadabb8> ``` scorer = get_scorer("balanced_accuracy") scorer(clf, X, y) ```  
[2021-01-22T09:33:18.205Z] <55d21ee30fc9f982beadabb8> Actually you could `get_scorer("balanced_acccuracy")(clf, X, y)` but I think that we don't head toward readable code :)
[2021-01-22T09:42:00.935Z] <564789be16b6c7089cbab8b7> @glemaitre I like it. Thank you
[2021-01-22T09:43:11.893Z] <564789be16b6c7089cbab8b7> I have a different more general question. I am doing binary classification. I would like to maximize the number of items in the positive class that get a probability higher than any probability from the negative class. Does this correspond to a known loss function?
[2021-01-22T09:46:38.510Z] <564789be16b6c7089cbab8b7> let me edit it to get rid of the word score...
[2021-01-22T09:49:26.050Z] <55d21ee30fc9f982beadabb8> https://github.com/scikit-learn/scikit-learn/pull/16525
[2021-01-22T09:49:37.941Z] <55d21ee30fc9f982beadabb8> You might want this things maybe
[2021-01-22T09:50:12.105Z] <55d21ee30fc9f982beadabb8> Basically, this is tuning the threshold of the argmax when doing the predict from the predict_proba
[2021-01-22T09:50:41.738Z] <55d21ee30fc9f982beadabb8> Otherwise, `sample_weigth` or `class_weigth` will allow you to play on the inner loss
[2021-01-22T09:50:45.839Z] <55d21ee30fc9f982beadabb8> while training
[2021-01-22T09:55:17.250Z] <564789be16b6c7089cbab8b7> @glemaitre thank you. I haven't fully understood how to use your suggestions for my problem but I will have a think
[2021-01-22T09:55:40.633Z] <564789be16b6c7089cbab8b7> maybe it could go on scikit-learn discussions as well :)
[2021-01-22T09:55:55.009Z] <55d21ee30fc9f982beadabb8> I think so
[2021-01-22T09:56:17.799Z] <55d21ee30fc9f982beadabb8> I might have misunderstood the use-case (a small example with specific number might help :))
[2021-01-22T10:00:11.383Z] <564789be16b6c7089cbab8b7> I can give one in about 90 minutes
[2021-01-22T10:12:00.374Z] <5571fe1015522ed4b3e17d90> > maybe it could go on scikit-learn discussions as well :)  +1. As mentioned in https://github.com/scikit-learn/scikit-learn/discussions/19220#discussioncomment-298015 my feeling (and probably others feeling) is that gitter is not the best place for Q&A. I guess a reasonable approach is to create a discussion and then ping on gitter if you feel you have not received an answer after some time
[2021-01-22T10:16:25.427Z] <564789be16b6c7089cbab8b7> @lesteve thanks. I do like the interactive nature of gitter to a) improve the question and/or b) realise I shouldn't have asked it in the first place :)
[2021-01-22T10:29:32.137Z] <5571fe1015522ed4b3e17d90> Yeah I agree the threshold about "what is OK to ask on gitter" is not very clear. I would favour an approach as I mention above discussion + ping on gitter after some time. It is not as much interactive but it is a better investment of answerer time since the question + answer will be findable by googling (contrary to gitter)
[2021-01-22T10:29:53.384Z] <564789be16b6c7089cbab8b7> makes sense
[2021-01-22T10:31:42.993Z] <55d21ee30fc9f982beadabb8> Gitter should come with a feature that you cannot scroll-up in your discussion feed
[2021-01-22T10:32:00.068Z] <55d21ee30fc9f982beadabb8> because this is a bit what happens in reality :)
[2021-01-22T10:33:04.548Z] <564789be16b6c7089cbab8b7> :)
[2021-01-22T10:35:51.843Z] <564789be16b6c7089cbab8b7> This isn't a full example but hopefully it will help clarify. Say my positive class items get 0.1, 0.3, 0.7, 0.9 from predict_proba and my negative class items get 0.01, 0.2, 0.2, 0.5. Then two of the positive class items get a prob (0.7, 0.9) larger than the largest prob (0.5) from the negative class. 
[2021-01-22T10:35:59.047Z] <564789be16b6c7089cbab8b7> @glemaitre does that make it any clearer?
[2021-01-22T10:39:31.943Z] <55d21ee30fc9f982beadabb8> So the cutoff classifier intend to change the probability from 0.5 to another threshold
[2021-01-22T10:39:53.084Z] <55d21ee30fc9f982beadabb8> such that you can for instance the maximum number of predictions of the positive label
[2021-01-22T10:41:17.034Z] <564789be16b6c7089cbab8b7> @glemaitre  yes. But the cutoff is a function of the probs that the negative class items are given 
[2021-01-22T10:41:58.982Z] <564789be16b6c7089cbab8b7> my example of 0.5 above wasn't a great choice :)
[2021-01-22T10:43:25.864Z] <55d21ee30fc9f982beadabb8> Oh you want to reinforce your learning step
[2021-01-22T10:43:27.395Z] <55d21ee30fc9f982beadabb8> I see 
[2021-01-22T10:45:08.502Z] <55d21ee30fc9f982beadabb8> In some way, I could think about a boosting strategy as AdaBoost, but instead of learning new learner favoring misclassified samples, you want to favor specific samples from the positive class.
[2021-01-22T10:51:42.753Z] <55d21ee30fc9f982beadabb8> I don't know if there is something in active learning allowing such stuff
[2021-01-22T10:52:30.729Z] <55d21ee30fc9f982beadabb8> But I am not knowing so much in this area
[2021-01-22T10:59:34.155Z] <564789be16b6c7089cbab8b7> thanks. I was going to post on discussions but I can't think of a suitable title :)
[2021-01-22T11:00:48.760Z] <55d21ee30fc9f982beadabb8> "Reinforce sample weight for online learning"
[2021-01-22T11:21:33.302Z] <564789be16b6c7089cbab8b7> posted
[2021-01-22T11:34:35.582Z] <5571fe1015522ed4b3e17d90> with the link there is even more chances that someone answers :wink: https://github.com/scikit-learn/scikit-learn/discussions/19239
[2021-01-22T11:36:07.827Z] <564789be16b6c7089cbab8b7> @lesteve thanks :)
[2021-01-22T11:45:38.029Z] <564789be16b6c7089cbab8b7> argh... I hate how easy it is to be confusing.
[2021-01-22T11:46:02.986Z] <564789be16b6c7089cbab8b7> @lesteve do you think my post is clear now?
[2021-01-22T12:43:54.143Z] <564789be16b6c7089cbab8b7> I guess it's equivalent to maximizing true positives when you have 0 false positives...?
[2021-01-22T16:30:58.576Z] <564789be16b6c7089cbab8b7> now I am tempted to try one of the options mentioned in the discussions. Now really sure which one though
[2021-01-22T16:46:35.506Z] <564789be16b6c7089cbab8b7> *Not
[2021-01-23T15:59:21.999Z] <564789be16b6c7089cbab8b7> Can any of the classifiers in scikit learn directly optimize auc as the loss function?
[2021-01-23T23:01:00.963Z] <6008674dd73408ce4ff94a9b> Hello all! I'm not a library developer, I'm a student developer and user of scikit-learn. Is there any work going on for scikit-learn to use Apple's ML Compute frameworks so that ML calculations can be accelerated by the 16-core neural engine in the recent Apple Silicon macs?
[2021-01-25T11:54:05.366Z] <52f100f45e986b0712ef4def> Hi All. Had a question about a possible discrepancy between user guide and autogenerated docs for LASSO Linear model. Auto-gen docs (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) says that:  ``` (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1 ```  Is minimised.  However, the user guide seems to to imply that it's `||Xw - y||` rather than `||y-Xw||` (https://scikit-learn.org/stable/modules/linear_model.html#lasso).  `y-Xw` makes more sense to me. Am I reading something incorrectly, or is the user guide wrong? 
[2021-01-25T12:57:43.604Z] <5b4c9e4bd73408ce4fa10b88> @JosephRedfern both are the same. ||-x|| = ||x||
[2021-01-25T12:57:47.343Z] <55d21ee30fc9f982beadabb8> I think the common way would be `y - y_hat = y - Xw`
[2021-01-25T12:57:52.444Z] <55d21ee30fc9f982beadabb8> but they lead to the same
[2021-01-25T12:58:05.748Z] <55d21ee30fc9f982beadabb8> as @jeremiedbb just mentioned :)
[2021-01-25T16:04:35.527Z] <52f100f45e986b0712ef4def> oh boy, what a brain fart! apologies, I should have thought before posting. 
[2021-01-27T14:23:06.004Z] <564789be16b6c7089cbab8b7> I am trying HistGradientBoostingClassifier for multiclass classification. It seems to stop too early. I.e. I get [22/200] 26 trees, 806 leaves (31 on avg), max depth = 12, train loss: 4.36169, val loss: 2.27454, in 0.114s [23/200] 26 trees, 806 leaves (31 on avg), max depth = 12, train loss: 5.42246, val loss: 2.60417, in 0.113s [24/200] 26 trees, 806 leaves (31 on avg), max depth = 13, train loss: 5.19449, val loss: 3.30153, in 0.113s Fit 624 trees in 2.951 s, (19300 total leaves)
[2021-01-27T14:23:28.432Z] <564789be16b6c7089cbab8b7> you can get a much smaller loss using catboost for example
[2021-01-27T14:23:47.625Z] <564789be16b6c7089cbab8b7> but it is much faster than catboost for multiclass classification
[2021-01-27T14:32:49.690Z] <564789be16b6c7089cbab8b7> hmm.. is multiclass classification meant to work yet with HistGradientBoostingClassifier ?
[2021-01-27T22:24:40.624Z] <5e3f3d7cd73408ce4fd915a4> I'm trying to modify the sklearn transformer interface for transformers that need to transform `X`, `y` and `sample_weight` together, i.e. the entire dataset. This is the signature I came up with that allows chaining these transformers with a `Pipeline`, I'm wondering if anyone has any better ideas? I really don't like having a `dummy` parameter.  ```python3     class DatasetTransformer(BaseEstimator, TransformerMixin):         def fit(self, data, dummy=None) -> "DatasetTransformer":             X, y, sample_weight = data             ...             return self          def transform(self, data):             X, y, sample_weight = data             ...             return (X, y, sample_weight) ```
[2021-01-27T23:44:30.173Z] <5e3f3d7cd73408ce4fd915a4> One alternative I see is to not have the `dummy` parameter, and instead specify `"passthrough"` as the last estimator in pipelines. I think this may be better? `dummy` is only there because it would be confusing to have a `y` parameter when `y` is part of `data`.
[2021-01-28T17:26:02.220Z] <5fa98f30d73408ce4ff3a641> Byo.ai an intelligent assistant to make people carbon neutral/positive. Anyone with experience with one or more general purpose programming languages including but not limited to: Python, Java, C/C++ (also Pytorch,) feel free to send your CV to work@byo.ai (equity only) - passion for the environment, clean technologies and artificial intelligence is a plus!
[2021-01-31T01:17:03.642Z] <601604b6d73408ce4ffa348b> Hi, is there any way to make it so that sklearn doesn't normalize the columns in PCA?
[2021-01-31T21:13:56.740Z] <55d21ee30fc9f982beadabb8> I don't think that we have a parameter to do that.
[2021-01-31T21:16:00.062Z] <55d21ee30fc9f982beadabb8> It would be weird to not normalize the columns since it is an assumption of PCA if I am not wrong
[2021-01-31T21:28:08.082Z] <55d21ee30fc9f982beadabb8> Not centering will make that you will get an intercept while transforming
[2021-01-31T21:33:10.170Z] <55d21ee30fc9f982beadabb8> Uhm now that I think about it, there is the TruncatedSVD
[2021-01-31T21:33:11.009Z] <55d21ee30fc9f982beadabb8> https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html
[2021-01-31T21:33:23.383Z] <55d21ee30fc9f982beadabb8> This should do the job
[2021-02-02T10:06:22.552Z] <60190f016da037398460db58> Hi! I have a quick question about the capabilities of Scikit-Learn's Pipeline (also asked in the other channel): Currently my data looks like the following 0 20 1 23 2 25 3 29 4 24 ... Where the index is a step in time, and the value is the value associated with that timestep. I am transforming it into 0 [20, 23, 25] [29, 24] 1 [29, 24, 24] [23, 22] 2 [23, 22, 26] [23, 25] ... By running a sort of window function over it. The index then is sample number, the first array is the input features, and the second array is the target.  If I input my data values as X into a pipeline, how to address the following: my custom transformer generates y from the input X, but the pipeline requires a y to begin with my custom transformer changes the length of X, which I think the pipeline also complains about.  Especially the latter is really important to me, as I want to be able to change the amount of features in X. Other options for example would be: 0 [20, 23] [25, 29] 1 [25, 29] [24, 29] ... or even 0 [20, 23, 25, 29] [24, 29] 1 [24, 29, 24, 24] [23, 22] etc.  Is there a standard solution for this, or should I write a wrapper for this? Thanks in advance!
[2021-02-02T10:10:43.799Z] <541a528b163965c9bc2053de> Our pipelines are unfortunately no meant to change the number of samples or the target. So I guess this kind of preprocessing will have to happen outside of the pipeline it-self...
[2021-02-02T10:13:25.302Z] <60190f016da037398460db58> Is there a specific reason why that is prevented from being changed?
[2021-02-02T10:13:28.760Z] <541a528b163965c9bc2053de> If the goal of the pipeline is to do parameter tuning for size of the time-window of the feature extraction preprocessor in a Grid/RandomizedSearchCV (for instance), then I think it's better to switch to a parameter tuner with a more flexible / less opinionated API such as https://optuna.org/ for instance.
[2021-02-02T10:13:50.337Z] <60190f016da037398460db58> Thank you!
[2021-02-02T10:14:59.942Z] <541a528b163965c9bc2053de> > Is there a specific reason why that is prevented from being changed?  Our transformers where never meant to change y. This is an early design decision that is really hard to change now (without breaking users code). And changing the number of samples without changing y is meaningless.
[2021-02-02T10:19:03.276Z] <60190f016da037398460db58> That's a shame, because I can imagine resampling / different sampling strategies / generating additional samples with differing noise levels would be a very useful thing to put in a pipeline so it can be gridsearched.
[2021-02-02T10:20:04.810Z] <60190f016da037398460db58> I'll have a look at optuna, thanks for your answers!
[2021-02-02T10:47:06.151Z] <541a528b163965c9bc2053de> But's really trick to get right, especially with the metrics. For instance when dealing with imbalanced classification problems, you want to resample at training time but not at test  validation / prediction / score time.  Imbalanced Learn has a custom pipeline and a custom API for resampling transformers with the fit_resample method: https://imbalanced-learn.org/  However this is not what you want for your use case: you want to perform the same transformation both at fit and predict time. It's hard to express all those use cases in a simple and intuitive unified API that would not led to users to shoot themselves in the foot. And there the backward compat constraints to take into account which makes it really hard to make our API evolve in that regard.
[2021-02-02T10:48:28.242Z] <541a528b163965c9bc2053de> @KylevdLangemheen would you mind reposting this question to github discussions: https://github.com/scikit-learn/scikit-learn/discussions   I think this would make it more googleable and linkable for others that have related issues.
[2021-02-02T11:33:35.960Z] <60190f016da037398460db58> Very understandable! I'm just sad I couldn't get an easy way out :P  I'll repost it there when I can, likely later today.
[2021-02-04T09:45:11.822Z] <5d6e5defd73408ce4fc9e1a2> Hello all
[2021-02-04T09:45:18.966Z] <5d6e5defd73408ce4fc9e1a2> I am new to this chatroom
[2021-02-04T09:45:51.177Z] <5d6e5defd73408ce4fc9e1a2>  i have a question regarding dataset imbalance, can someone help me out ?
[2021-02-04T10:11:46.811Z] <55d21ee30fc9f982beadabb8> @SyedMuhamadYasir  You can freely ask your question and you might get an answer
[2021-02-04T10:12:21.048Z] <5d6e5defd73408ce4fc9e1a2> @glemaitre  thank you, i am going to ask right now
[2021-02-04T10:12:58.659Z] <5d6e5defd73408ce4fc9e1a2> I have a dataset which is for binary classification ( or at least we are approaching it from a binary classification perspective )  There are a total of 2.5 million rows, with label 0 belonging to around 220000 (2.2 million) rows and label 1 belonging to around 321000 (0.3 million) rows , there are around 45 features.  The imbalance approaches a ratio of around 1 : 7  My problem is very straightforward, even WITHOUT any data preprocessing if i try to classify the data  the classification algorithms, no matter what parameters are set, give around 99% in ALL performance metrics ( accuracy, precision, recall, f1 score etc )  This would probably suggest a bad case of overfitting but i am not sure, feel free to explain and add your opinion regarding what could be the reason  I tried to visualize the graph using TSNE and saw that the entire data is shaped like an ellipse and there is heavy overlap between both the labels. This means that (1) data is badly imbalanced (2) data is badly overlapped , i highly doubt i can use anomaly detection there as all the 'anomalies' (label 1) are sitting close with the 'normal' (label 0) data  any suggestions on how i should proceed ?  
[2021-02-04T10:18:11.162Z] <55d21ee30fc9f982beadabb8> I am not sure that I would give to much weight with what you observe with TSNE.
[2021-02-04T10:19:18.501Z] <55d21ee30fc9f982beadabb8> While accuracy will be boost for sure, the precision and recall will be good measure with imbalance problem.
[2021-02-04T10:19:41.104Z] <55d21ee30fc9f982beadabb8> You can use the `balanced_accuracy_score` instead of `accuracy_score` as a baseline.
[2021-02-04T10:21:26.571Z] <55d21ee30fc9f982beadabb8> I would say that one potential error would be to forget to set `pos_label` in precision/recall if it is not `1` (that does not seem to be the case).
[2021-02-04T10:21:53.665Z] <55d21ee30fc9f982beadabb8> You can probably look at the entire confusion matrix to be sure that the stats seem correct
[2021-02-04T10:23:05.772Z] <55d21ee30fc9f982beadabb8> Then if you still get good results by properly cross-validated your experiment, everything should be fine.
[2021-02-04T10:25:10.762Z] <5d6e5defd73408ce4fc9e1a2> thank you, i see some really good points in your answer than i can experiment with
[2021-02-04T10:25:23.987Z] <5d6e5defd73408ce4fc9e1a2> however, it is important to tell you the context of the problem
[2021-02-04T10:25:37.158Z] <5d6e5defd73408ce4fc9e1a2> so you can understand what i am trying to do exactly
[2021-02-04T10:26:03.474Z] <5d6e5defd73408ce4fc9e1a2> I am trying to do a Feature Selection / Feature Reduction task 
[2021-02-04T10:27:24.231Z] <5d6e5defd73408ce4fc9e1a2> since the original dataset, without any preprocessing and with ALL features, gives near perfect results, it will annul the validity of using any type of Feature Reduction techniques
[2021-02-04T10:28:36.152Z] <5d6e5defd73408ce4fc9e1a2> i will try out what you said in your answer, but i thought that it would be better to let you know the entire context and the actual reason for why exactly we need 'bad' results before applying any feature reduction
[2021-02-04T10:28:36.802Z] <55d21ee30fc9f982beadabb8> It might still allow you to fit and predict faster and this probably what feature selection is best at.
[2021-02-04T10:30:22.937Z] <5d6e5defd73408ce4fc9e1a2> > It might still allow you to fit and predict faster and this probably what feature selection is best at.  that .. is actually a very good point, thanks !
[2021-02-04T10:31:59.323Z] <5d6e5defd73408ce4fc9e1a2> @glemaitre  Je vous remercie  :)
[2021-02-05T17:57:02.539Z] <5b444ca2d73408ce4fa03e12> hi, quick question, is there a preprocessor in sci-kit that allows me to split a feature into two?
[2021-02-05T18:18:40.152Z] <5b444ca2d73408ce4fa03e12> ok, there's column transformer, I can use that
[2021-02-06T11:28:09.247Z] <564789be16b6c7089cbab8b7> has anyone started a PR on dirichlet calibration of probabilities?
[2021-02-06T11:28:19.287Z] <564789be16b6c7089cbab8b7> I couldn't find it if they have
[2021-02-06T11:28:37.569Z] <564789be16b6c7089cbab8b7> as in this paper https://arxiv.org/abs/1910.12656
[2021-02-06T11:50:58.447Z] <567f5d7716b6c7089cc043a8> That's rather a new paper, and I'm not sure if it passes our inclusion criteria.
[2021-02-06T17:18:18.982Z] <5ee61de0d73408ce4fe6d981> I am getting some unrelated errors (azure pipeline stack trace) for a PR I just pushed. Anyone who can check and let me know how I can fix? https://github.com/scikit-learn/scikit-learn/pull/19387
[2021-02-07T08:09:17.436Z] <564789be16b6c7089cbab8b7> @adrinjalali  yes. I was just wondering if anyone thought it was interesting.
[2021-02-07T17:25:19.460Z] <5e43c3d3d73408ce4fd969da> Why column transformer convert datatype to objects after calling fit_transform?
[2021-02-09T15:57:20.454Z] <matrix-benny:michael-enders.com> I have a general question: If for my dataset a kneighbor classifier works well (compared to e.g. SVC and Random Forest),  are there other classifiers that might also work equally well?
[2021-02-09T17:04:07.851Z] <55d21ee30fc9f982beadabb8> @benny Stuff based on distances then
[2021-02-09T18:33:44.368Z] <matrix-benny:michael-enders.com> can you give some examples?
[2021-02-09T23:20:47.789Z] <60223b726da0373984618209> Hi everyone, I am not certain if this is the right place to ask. I am a first-time contributor. I love the library and it has helped me immensely in my studies so far. I was hoping to work on this issue as my first issue: https://github.com/scikit-learn/scikit-learn/issues/18338  As far as I can understand, this issue requires that the documentation be updated, does that indicate the docstring within the function definition only, or is that referring to another piece of documentation?  One of the commentators on the issue also mentions ensuring there are tests that break if this documentation doesn't exist, how do I go about doing that effectively? 
[2021-02-10T00:21:14.720Z] <60223b726da0373984618209> > I have a general question: If for my dataset a kneighbor classifier works well (compared to e.g. SVC and Random Forest),  are there other classifiers that might also work equally well?  I think it will depend on the data set.  It also depends on how you are pre-processing your data. So kinda hard to say without knowing more. 
[2021-02-11T10:07:47.122Z] <564789be16b6c7089cbab8b7> when I do OrdinalEncoder on my matrix X how can I make the mapping the same for each column?
[2021-02-11T10:10:08.559Z] <564789be16b6c7089cbab8b7> currently it is different if there is one new value in a column that doesn't occur in another column
[2021-02-11T11:03:17.092Z] <5479972adb8155e6700d9370> Hello Happy scikit-learners ! I need some help please. I want to serve an onnx model.  Input = 144 columns ( medical records, some categoricals, some  not ).  Output = classification.  Pipeline = StandardScaler + LabelEncoder + LightGBM.  I am stuck with the LabelEncoder. Any example of such configuration somewhere ? Google was not my friend. I was able to produce an onnx model when bypassing the LabelEncoder... but I need it and want to avoid 1HE because LightGBM performs much better without 1HE.  Anyone ?
[2021-02-11T13:22:32.875Z] <matrix-rthy:matrix.org>  @citron You probably want OneHotEncoder not the LabelEncoder
[2021-02-11T13:23:04.203Z] <matrix-rthy:matrix.org> Also tree based models it's better to use OrdinalEncoder instead for categorical features
[2021-02-11T15:14:16.269Z] <5baf7d9ad73408ce4fa9c9b2> > Also tree based models it's better to use OrdinalEncoder instead for categorical features  I'm not sure that's true, using OE will make the trees treat categories as ordered values, but they're not. Native categorical support (as in LightGBM) properly treats categories as un-ordered and can yield the same splits with less tree depth
[2021-02-11T15:28:35.161Z] <matrix-rthy:matrix.org> Yes, you are right. I guess I'm too used to scikit-learn tree based models not having native categorical support )
[2021-02-11T16:38:44.401Z] <541a528b163965c9bc2053de> I agree with @NicolasHug in theory, but in practice the difference with `OrdinalEncoder` (with tuned hyperparams) is typically negligible ;)
[2021-02-11T16:39:58.279Z] <541a528b163965c9bc2053de> @citron Using `OrdinalEncoder` is probably the pragmatic solution. `OneHotEncoder` is only efficient if you use sparse output which are currently not supported by ONNX as far as I know.
[2021-02-11T16:46:16.305Z] <5de8bd5ad73408ce4fd32399> @citron: what's the issue with LabelEncoder and ONNX? (I'm the main author of sklearn-onnx).
[2021-02-11T16:46:47.344Z] <541a528b163965c9bc2053de> @citron also you said "Pipeline = StandardScaler + LabelEncoder + LightGBM." but I assume you use  a column transformer to separate to only scale the numerical features and encode the categorical feature separately: https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data  BTW, StandardScaling the numerical features if often useless for tree-based models in general, and even more so for implementations such as LightGBM than bin the features.
[2021-02-11T17:02:47.166Z] <5479972adb8155e6700d9370> Bonjour @xadupre , @ogrisel, @rthy:matrix.org, @NicolasHug . Yes I do use a ColumnTransformer. Maybe I should better express my needs.  The training set is made of 300000 rows.  Colums types are either floating points, integers ( and sadly Pandas does not provide the R Dataframe handling of N/A ), booleans, categories or list of categories. For instance, some category columns may have 2 or 10 numerical categories, some only have "string" categories, some have a list of medicaments or a list of pathologies.  I have tried plenty of frameworks and among them, lightGBM was the best. Now, as I need to export the model and the pipeline in ONNX/ONNX-ML format, I need to wrap lightGBM in something to keep the pipeline around. 
[2021-02-11T17:05:25.579Z] <541a528b163965c9bc2053de> pandas 1.0 and later has support for explicit missing values in integer columns: https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html
[2021-02-11T17:06:00.757Z] <541a528b163965c9bc2053de> scikit-learn however will convert this to a float anyway (but no big deal).
[2021-02-11T17:06:54.434Z] <5479972adb8155e6700d9370> @ogrisel Yes, no problem with pure int columns. 
[2021-02-11T17:08:13.376Z] <541a528b163965c9bc2053de> For the categorical columns, try to use OrdinalEncoder. In 0.24+ we have better support for unknown categories at test time:  https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html  Although I am not sure that sklearn-onnx has replicated that feature yet.
[2021-02-11T17:08:45.219Z] <5479972adb8155e6700d9370> @ogrisel maybe @xadupre knows ?
[2021-02-11T17:09:07.245Z] <541a528b163965c9bc2053de> If you have specific problems exporting a pipeline with OrdinalEncoder to onnx, better report the exact error message with a simple reproduction case to https://github.com/onnx/sklearn-onnx
[2021-02-11T17:22:39.111Z] <5de8bd5ad73408ce4fd32399> I wrote this example about converting a pipeline including a lightgbm model in a scikit-learn pipeline: http://onnx.ai/sklearn-onnx/auto_tutorial/plot_gexternal_lightgbm.html.
[2021-02-11T17:36:09.618Z] <5479972adb8155e6700d9370> @xadupre Thanks! The binder link at the end of the page has a problem. In fact, that's the example I started with. Works fine without labelEncoder.
[2021-02-11T17:59:33.897Z] <5479972adb8155e6700d9370> I forgot to tell an important thing : I do use FLAML to select the best hyperparameters and thus the best model.
[2021-02-11T18:11:27.840Z] <5de8bd5ad73408ce4fd32399> I'll investigate the issue with LabelEncoder then. What is the error you get?
[2021-02-12T09:01:39.066Z] <5571fe1015522ed4b3e17d90> I think it would be a good idea to encourage creating a Github Discussion (rather than gitter) for anything else than simple questions/answers: https://github.com/scikit-learn/scikit-learn/discussions/new. gitter is not properly indexed by search engines so it is not a great use of time for people who answer questions.
[2021-02-12T09:02:52.173Z] <5571fe1015522ed4b3e17d90> I agree that "simple qestion/answer" does not have a very-well defined boundary but in the case of @citron's questions I think we have crossed this boundary a long time ago ...
[2021-02-12T09:16:16.868Z] <5479972adb8155e6700d9370> @lesteve I understand and agree.
[2021-02-12T10:40:31.877Z] <5571fe1015522ed4b3e17d90> @citron then if you find the time maybe create a Github Discussion and post the link in the gitter so that the discussion can continue in the Github Discussion?
[2021-02-12T22:04:52.837Z] <6026fa066da037398461e161> Hello guys! Me and my friends are looking to tackle some open issues on scikit-learn soon. We're very new so I would love a high level overview of the architecture.
[2021-02-12T22:05:05.643Z] <6026fa066da037398461e161> Can anyone help or point to some resources?
[2021-02-13T16:29:59.118Z] <matrix-rthy:matrix.org> Have a look at https://scikit-learn.org/stable/developers/contributing.html for a getting starting guide.
[2021-02-16T18:17:07.714Z] <5479972adb8155e6700d9370> Hello ( I am back and I will try not to flood the your screen )
[2021-02-16T18:25:02.996Z] <5479972adb8155e6700d9370> Using Scikit-learn 0.24.1 and sklearn-onnx 1.7.0, I try to export a pipeline embedding an HistGradientBoostingClassifier. The data contains only StandardScaled floating point features.  convert_sklearn prompts an error : 'numpy.bool' object has no attribute 'encode'StringTensorTypeStringTensorType Any idea please ?
[2021-02-22T08:35:14.584Z] <5cdeaebed73408ce4fc08df3> Hello,  I'm trygin to use `SimpleImputer(strategy='most_frequent')` in Pipeline on dataframe with ~ 1.5 M samples but I take a lot of time  Is it normal ? If so, are there some alternatives to solve this issue ?  ``` def vectorizer_df(input_data, categorical_cols, numerical_cols):  	categorical_pipe = Pipeline([ 	    ('imputer', SimpleImputer(strategy='most_frequent')) 	])  	numerical_pipe = Pipeline([ 	    ('imputer', SimpleImputer(strategy='median')), 	    ('bucketizer', KBinsDiscretizer(n_bins=10, strategy='uniform', encode='ordinal'))  # ordinal 	])  	preprocessing = ColumnTransformer( 	    [('cat', categorical_pipe, categorical_cols), 	     ('num', numerical_pipe, numerical_cols) 	     ])  	vectorizer_pipeline = Pipeline([ 	    ('vectorize', preprocessing) 	])  	return vectorizer_pipeline.fit_transform(input_data) ```  Thanks
[2021-02-22T10:42:54.508Z] <55d21ee30fc9f982beadabb8> @razou which version of scikit-learn are you using?
[2021-02-22T10:43:06.759Z] <55d21ee30fc9f982beadabb8> We merged the following improvement in 0.24 -> https://github.com/scikit-learn/scikit-learn/pull/18987
[2021-02-22T10:43:29.533Z] <55d21ee30fc9f982beadabb8> that make it efficient to work with string while it was not really possible before
[2021-02-22T10:45:11.031Z] <55d21ee30fc9f982beadabb8> because it was too slow
[2021-02-22T11:00:04.133Z] <5cdeaebed73408ce4fc08df3> Thanks @glemaitre  I'm using ``` scikit-learn==0.22.2.post1 sklearn-crfsuite==0.3.6 ``` 
[2021-02-22T11:03:29.362Z] <55d21ee30fc9f982beadabb8> yep so this should be the reason. You can update to 0.24 via conda-forge or PyPI and it should work better
[2021-02-22T11:20:20.724Z] <5cdeaebed73408ce4fc08df3> Thanks @glemaitre  for your answers (y)
[2021-02-23T07:46:51.652Z] <5f7ac1dcd73408ce4ff0af34> Could anyone help me with this error? https://www.reddit.com/r/learnpython/comments/ibk04a/linalgerror_svd_did_not_converge_in_linear_least/
[2021-02-24T09:24:27.392Z] <matrix-benny:michael-enders.com> Hello, can you tell me why GridSearchCV .best_score_ is worse than when I evaluate the same dataset with .score() ?
[2021-02-24T09:24:41.168Z] <matrix-benny:michael-enders.com> shouldn't those be the same?
[2021-02-24T09:32:08.201Z] <matrix-benny:michael-enders.com> or is it because .best_score_ is only evaluated on the test-cross validation split?
[2021-02-25T13:08:08.493Z] <6018a9a26da037398460d5ca> Hello, when I run pytest -Werror::RuntimeWarning  sklearn/ensemble/tests/test_iforest.py I get an 'ImportError while loading confest' error.  How can I bypass this?
[2021-02-25T14:12:33.126Z] <55d21ee30fc9f982beadabb8> Could you provide the traceback @icky254 
[2021-02-25T14:15:07.559Z] <55d21ee30fc9f982beadabb8> @benny:michael-enders.com By checking the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), `grid_search.best_score_` is mean cross-validated score of the best_estimator.
[2021-02-25T14:15:52.132Z] <55d21ee30fc9f982beadabb8> So the `best_estimator.score` is called on each fold (supposing that you do `KFold`) and averaged.
[2021-02-25T14:20:06.140Z] <55d21ee30fc9f982beadabb8> > when I evaluate the same dataset with .score()  It depends what you mean. You might do something wrong here. Calling a single time `score` will not give you an estimate of the variability of your model. If you reuse `best_estimator_` (with best parameter set), you need to evaluate on some left-out data . You might want to look the following example regarding why you need to nest grid-search and cross-validation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py
[2021-02-25T16:12:33.813Z] <6018a9a26da037398460d5ca> [![Screenshot from 2021-02-25 19-06-35.png](https://files.gitter.im/541a528c163965c9bc2053e1/3Pzi/thumb/Screenshot-from-2021-02-25-19-06-35.png)](https://files.gitter.im/541a528c163965c9bc2053e1/3Pzi/Screenshot-from-2021-02-25-19-06-35.png)
[2021-02-25T16:15:35.687Z] <6018a9a26da037398460d5ca> @glemaitre 
[2021-02-25T18:38:30.860Z] <55d21ee30fc9f982beadabb8> As the message mentioned, it seems that scikit-learn was not build
[2021-02-25T18:39:01.897Z] <55d21ee30fc9f982beadabb8> Be sure to have activated the environment where you installed and built scikit-learn
[2021-02-25T18:39:26.067Z] <55d21ee30fc9f982beadabb8> FYI: https://scikit-learn.org/stable/developers/advanced_installation.html#building-from-source
[2021-02-25T18:40:01.089Z] <55d21ee30fc9f982beadabb8> basically to install and build: `pip install --verbose --no-build-isolation --editable .`
[2021-02-25T18:40:30.328Z] <55d21ee30fc9f982beadabb8> could work if the previous message steps where already done
[2021-02-25T22:51:16.681Z] <53d67ca7107e137846ba83ca> Apologies for the PSA style post, but in a collaboration with Microsoft, we just published a blog post on using compilation techniques to accelerate SKLearn models for production, it's also another route to run models on GPUs (and potentially other accelerators) as well! Check it out if interested: https://medium.com/octoml/compiling-classical-ml-for-up-to-30x-performance-gains-and-hardware-portability-2aef760af694 
[2021-02-26T04:50:28.831Z] <6018a9a26da037398460d5ca> @glemaitre, solved. Thank you.
[2021-02-26T08:58:06.083Z] <matrix-rthy:matrix.org> @binarybana: Interesting, you may want to send it on the mailing list (or in github discussions). I don't think that many people people check gitter..
[2021-02-26T10:40:26.106Z] <567f5d7716b6c7089cc043a8> @binarybana really nice!
[2021-02-27T05:05:46.639Z] <6030f5b06da0373984627f56> Hey there!  I am trying to develop a new python module for video chatting with a bot. (You may also collaborate)  Repo: https://github.com/avaish1409/VideoChatBot/ Gitter: https://gitter.im/VideoChatBot/community  Downloads: 429 (in first 2 days of launch)  ''' pip install VideoChatBot ''' or ''' pip install https://files.pythonhosted.org/packages/5b/cc/9dbb790525fe3daa8f0822e60eec38dfea8af5e33af0334dc66b4a022ac4/VideoChatBot-0.0.2.tar.gz '''  Do contribute on github, let's build it together!  Plz star the repository if you like it .. you can also contribute on github <unconvertable>
[2021-03-06T20:52:52.405Z] <6043eb366da037398465c260> Hello, everyone. I am new here. I have found that the user guide of sklearn 0.24 is well-structured. Is there any way for me to download a pdf version of it? I could only find those of the older versions. Thank you.
[2021-03-07T10:00:15.515Z] <5baf7d9ad73408ce4fa9c9b2> @lester1027 I think we stopped generating pdf versions and simply provide the html files, so the docs look like just as on the website. Generating pdfs involved Latex and it was difficult to maintain (random failures every now and then, etc)
[2021-03-07T10:00:46.434Z] <5baf7d9ad73408ce4fa9c9b2> if you really want pdfs you can try converting the docs to pdf with pandoc
[2021-03-12T10:14:16.959Z] <5cdeaebed73408ce4fc08df3> Hello, I'm using `sklearn.neighbors.NearestNeighbors` (scikit-learn==0.24.0) to find nearest neighbors   ``` knnModel = NearestNeighbors(n_neighbors=5, algorithm='auto',  metric='minkowski', p=2, n_jobs=-1) tes_df.apply(lambda u: knnModel.kneighbors(X=u.values.reshape(1, -1),  n_neighbors=5, return_distance=False).ravel().tolist(), axis=1) ```  `test_df` contains 5K rows and 77 columns (from one hot encoding) and  the execution is around `32 minutes`  (train_df's shape => (1754249, 77))  Is it normal to have this high execution ? Any tips to improve the performance and educe this execution time) ? Thanks  
[2021-03-12T11:22:39.775Z] <55d21ee30fc9f982beadabb8> For each sample in `test_df` you have to compute the distances with each sample in `train_df`. So it is the reason why it is pretty costly.
[2021-03-12T11:23:32.410Z] <55d21ee30fc9f982beadabb8> Potential workaround: if you have some chance, you might want to create prototype by clustering your training data and compute KNN to the centroids instead of the original data
[2021-03-12T11:24:27.655Z] <55d21ee30fc9f982beadabb8> Another solution would be to use an approximative nearest neighbors instead. Something like annoy: https://github.com/spotify/annoy
[2021-03-12T11:25:08.080Z] <5cdeaebed73408ce4fc08df3> Thanks @glemaitre for your helpful answer 
[2021-03-12T16:12:44.331Z] <5cdeaebed73408ce4fc08df3> Does it exists an implementation of  `Hit Rate (or Hit Ratio)`  (generally used in recommendation engines) metric in scikit-learn ?
[2021-03-15T09:35:57.594Z] <564789be16b6c7089cbab8b7> I have one hot encoded feature vectors which I am using for multiclass classification.  If in my training set there is a feature which is always 0, what happens in testing when it comes across one that is a 1 for the feature?
[2021-03-15T11:33:07.249Z] <matrix-rthy:matrix.org> @lesshaste: By default OHE would error. You would need to set `handle_unknown='ignore'` to ignore it.
[2021-03-15T13:58:54.412Z] <564789be16b6c7089cbab8b7> @rthy:matrix.org thanks.  Do you know if that would be the same for logistic regression for example?
[2021-03-15T15:34:10.937Z] <564789be16b6c7089cbab8b7> can sklearn.metrics.pairwise be made to work for hamming or levenshtein distance?
[2021-03-24T19:46:21.630Z] <564789be16b6c7089cbab8b7> what are good options for supervised categorical encoding when the target is also categorical?  target encoding looks attractive but doesn't really make sense when the target is categorical
[2021-03-29T16:35:14.733Z] <5afe987cd73408ce4f99ce3b> Hi everyone, I am a developer who's trying to test multiple models in different frameworks. I just want to know if this idea makes sense - I want to create a single sklearn pipeline script for testing various models (all mapped to the sklearn-keras interface or using skorch). But from what I understand is that models are not just plain classifiers or regressors. The models are a combination and sklearn pipeline doesn't apparently support it. Is my understanding correct? Is this a futile effort? Can someone please help me out with this issue. Thank you. If there's an alternative, please let me know. I'm talking about object detection models. I really like the pipeline method/interface and would like to extend my models to match the same .fit, .predict interface
[2021-03-31T09:53:24.911Z] <564789be16b6c7089cbab8b7> HistGradientBoostingClassifier seems to have no n_jobs argument.  Is there any way set the number of threads/cores?
[2021-03-31T16:31:35.944Z] <5baf7d9ad73408ce4fa9c9b2> You should use the  OMP_NUM_THREADS env variable https://scikit-learn.org/stable/computing/parallelism.html#openmp-based-parallelism
[2021-03-31T16:35:22.588Z] <564789be16b6c7089cbab8b7> @NicolasHug  thank you. Is anyone working on adding n_jobs for this classifier?
[2021-03-31T16:35:35.777Z] <564789be16b6c7089cbab8b7> it would make it inline with the other classifiers
[2021-03-31T16:36:01.864Z] <564789be16b6c7089cbab8b7> and can it be done in the script itself?
[2021-03-31T18:01:03.779Z] <5baf7d9ad73408ce4fa9c9b2> it's been discussed but we ended up staying with the status quo https://github.com/scikit-learn/scikit-learn/issues/14265
[2021-04-01T07:15:10.108Z] <564789be16b6c7089cbab8b7> @NicolasHug  that is surprising. I normally agree with all the decisions of scikit learn devs
[2021-04-01T07:17:50.052Z] <564789be16b6c7089cbab8b7> I have two questions about HistGradientBoostingClassifier.  a) When using early stopping do you end up with the "best model" according to the validation loss or the most recent one after it stops?
[2021-04-01T07:18:25.441Z] <564789be16b6c7089cbab8b7> b) Is the validation set chosen by  HistGradientBoostingClassifier chosen at random and is it the same set for every iteration of the training?
[2021-04-01T07:18:57.763Z] <564789be16b6c7089cbab8b7> maybe these should be asked on github as an issue?
[2021-04-01T08:33:11.336Z] <5baf7d9ad73408ce4fa9c9b2> a) there's no notion of best model. early stopping stops the training process  if the score hasn't improved by more than `tol` in the last  `n_iter_no_change` iterations. The score can be the loss or an arbitrary scorer and it can be computed on the training set or on the validation set b) yes and yes
[2021-04-03T07:08:40.411Z] <564789be16b6c7089cbab8b7> Thank you.  Maybe best model couid be a good addition?
[2021-04-03T08:46:21.224Z] <5baf7d9ad73408ce4fa9c9b2> I'm not sure what you mean by best model. There's no notion of best model, only one model is built. If you mean "model with the lowest training loss" that's basically the model at the last iteration,  under the assumption that the training loss is always supposed to decrease (unless your learning rate becomes too high). If you mean "model with the lowest training loss that doesn't make the validation loss go up", that's what early stopping is supposed to give you (and it's preferable to the former)
[2021-04-10T13:05:29.352Z] <564789be16b6c7089cbab8b7> @NicolasHug  let's say the latter example you gave. The problem is that with early stopping you wait some number of iteration before deciding to stop. So the final iteration is not the best. That's why catboost for example has a use_best parameter.
[2021-04-10T13:07:43.082Z] <564789be16b6c7089cbab8b7> It is common in early stopping for the final valudation loss to be higher than the loss a few epochs before.  How long you wait to see if the loss will start going down again is sometimes called "patience" . I think that's what pytorch lightning calls it 
[2021-04-13T13:59:09.037Z] <6075a37e6da03739847a0d9b> does using the fit function on a fitted model replace the fitted model, or update it?
[2021-04-13T14:01:27.201Z] <6075a37e6da03739847a0d9b> I'm trying to use a Lasso in a machine learning context, and I want to keep updating it with each test run I do
[2021-04-13T14:05:16.577Z] <6075a37e6da03739847a0d9b> obviously, I could in theory, take the model, and train it with the results of the particular test run, then merge the coefficents with the last model myself, but it would be better if I could avoid that
[2021-04-13T15:05:06.111Z] <55d21ee30fc9f982beadabb8> `fit` make a full training from scratch
[2021-04-13T15:05:13.989Z] <55d21ee30fc9f982beadabb8> `partial_fit` is doing an update
[2021-04-13T15:10:09.066Z] <6075a37e6da03739847a0d9b> @glemaitre thank you.  what kinds of models is partial_fit available for?
[2021-04-13T15:13:57.313Z] <6075a37e6da03739847a0d9b> hrm... it seems like all of the ones with that method only are for classification, not for regressed output.
[2021-04-13T15:16:42.059Z] <55d21ee30fc9f982beadabb8> SGD estimator is one of them
[2021-04-13T15:17:19.569Z] <6075a37e6da03739847a0d9b> oh perfect
[2021-04-13T15:19:14.514Z] <6075a37e6da03739847a0d9b> I will use that in the project my team is doing. Thanks for helping
[2021-04-19T07:03:56.932Z] <603cd4cc6da0373984649165> I wrote a [short blog post](https://www.bodyworkml.com/posts/scikit-learn-meet-production) that might be of interest to the community - deploying Scikit-Learn models to Kuberentes using [Bodywork](https://github.com/bodywork-ml/bodywork-core) (an open source deployment tool that I have developed).
[2021-04-28T10:54:11.336Z] <54a6f79fdb8155e6700e5114> I would like to ask how to join two pereprocessors I did saved in two separate files. I have one file with a model and another with prerpocessor (doing average and filling NaN boxes)  then another file with a model (same estimator) and forth file is preprocessor for second model? I would like to merge these four files into two (one joint model and one joint estimator).
[2021-04-28T16:15:05.767Z] <matrix-urosn:matrix.org> I have transformer1.file, model1.file, transformer2.file and model2.file (same estimator in model1 and model2). I would like to have tranformer_composite.file and model_composite.file.
[2021-04-29T18:30:10.736Z] <608ace656da03739847b4a14> Yo
[2021-05-07T02:45:20.682Z] <6094a87f6da03739847c04de> Hi everyone, I'm a graduate student at Cornell and I had a paper (https://dl.acm.org/doi/abs/10.1145/3429445) published a while ago in correcting the bias of feature importance in tree-based methods. Impurity-based feature importances can be misleading for high cardinality features (many unique values), which is already noted in the docstring of feature_importances_ in RandomForest. I just opened a new pull request #20058 to implement a new feature importance measurement based on out-of-bag samples, which is guaranteed to remove this bias.  I think this feature is going to be useful for scikit-learn users. Any comments or suggestions will be helpful!
[2021-05-11T12:00:31.100Z] <56d028dbe610378809c39bd5> Hi! What week scheduled for release scikit-learn 1.0?
[2021-05-11T13:09:31.757Z] <5baf7d9ad73408ce4fa9c9b2> There is no specific week scheduled @PetrovKP , but we try to release every 6 months  and the previous one was released in december
[2021-05-11T13:11:36.056Z] <55d21ee30fc9f982beadabb8> So perfectly June but I think that for 1.0 we want a couple of feature to be inside the release so we might be delayed.
[2021-05-13T17:01:18.424Z] <609c828b6da03739847c7c73> Hi, my name is Zoe Prieto. I am currently working on neutron and photon transport problems. I have some questions and maybe one of you can help me.
[2021-05-13T17:04:01.747Z] <matrix-rthy:matrix.org> Sure, don't hesitate to write them here.
[2021-05-13T17:12:09.734Z] <609c828b6da03739847c7c73> Thanks! I have a list of particles with their caracteristics (position, direction, energy and stadistic weight). This variables are correlated. I want to fit that curves and later sample new particles. I want to know how scikit-learn keep the correlation. I'm sorry if it is a beginner question. And thanks again.
[2021-05-14T13:19:24.674Z] <matrix-rthy:matrix.org> Well you need to define what are your feature variables and the target variable. So for instance you could try to predict the position from all the other variables. Correlations would be taken into account depending on the model. So for instance if your model is linear the target would be a linear combination of the features. If you do have a known analytical relation between your variables it might be easier and more reliable to use scipy.optimize or scipy.odr to find the coefficients you would like to learn though.
[2021-05-14T20:31:55.872Z] <609c828b6da03739847c7c73> Thanks for your answer, I forgot to mention that I fit my data with KDE and I sample new particles from this model. Is this model keeping the correlation between the different variables? Or it assumes the variables are independent from each other? Thanks again!
[2021-05-16T10:46:01.120Z] <6018a9a26da037398460d5ca> Hi everyone, I'm trying to create a streamlit app but face the following message when I run `streamlit run <file.py>`: `Make this Notebook Trusted to load map: File -> Trust Notebook`. I Googled this issue, and even after making Chrome my default browser, nothing changes. Please help. 
[2021-05-17T11:37:13.850Z] <matrix-nyanpasu:matrix.org> Hello! in `sklearn.decomposition.PCA`, how do I tell it which column represents the label?  For example, I have a dataframe with the following columns:  `feature_0 feature_1 feature_2 label`  How do I tell PCA that `label` is the dependent variable?
[2021-05-17T14:32:21.221Z] <5baf7d9ad73408ce4fa9c9b2> @nyanpasu:matrix.org you don't, PCA is unsupervised and doesn't take the labels as input, only the features.
[2021-05-19T10:04:15.203Z] <5cdeaebed73408ce4fc08df3> Hello Is the `accuracy_at_k` (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.top_k_accuracy_score.html#sklearn.metrics.top_k_accuracy_score) an implementation of the `hit ratio at k`(https://www.researchgate.net/publication/344486356_Hit_ratio_An_Evaluation_Metric_for_Hashtag_Recommendation) Thanks 
[2021-06-03T14:43:15.148Z] <55cbc84e0fc9f982bead32a4> Hi folks, I am a master's student in CS and I have a question for you.  I am working on a multi-class text classification problem, and I am using scikit-learn to implement my solution. I want to predict for a paragraph x if x belongs to one out of seven categories of information. I already implemented my solution using your library, but I am not confident if the steps I am following are correct or not, or if I am missing something. Could you please take a look at the image below and give your opinion? If this is not the right place for this kind of question, please let me know. Thank you in advance for your contribution!  ![Image](https://i.imgur.com/ZSr7jAT.png)
[2021-06-07T23:45:59.014Z] <60be9c186da03739847e6279> Hi, I want to start working on the Sci-kit learn bug fixes. Anyone who is already working can I team up with you?
[2021-06-11T07:27:52.870Z] <60c1c1146da03739847e93c1> Hi all! We're working on a generic implementation of a discrete time survival model for random forests. Similar to [this](https://link.springer.com/article/10.1007/s10618-020-00682-z) and [this](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-019-0863-0). Basically, the idea is to split on hazard curves which are a bit like the class probabilities of regular classification random forests but then stratified per duration since inception of an observation. We want to use scikit-learn for a base. Is anyone here familiar with the random forest code? Also tips for a good PR are very welcome.
[2021-06-13T17:31:36.486Z] <matrix-um_duaa:matrix.org> hi
[2021-06-13T17:49:16.071Z] <60c644cd6da03739847ecce2> I have only one question, please!!!
[2021-06-14T10:49:51.826Z] <564789be16b6c7089cbab8b7> What would people recommend for clustering strings (e.g. english words) of the same length?
[2021-06-14T10:57:40.670Z] <564789be16b6c7089cbab8b7> or is this better off at github discuss?
[2021-06-14T11:05:42.190Z] <5baf7d9ad73408ce4fa9c9b2> It really depends on the kind of data that you have. If you have a corpus of documents LDA would be one way to get cluster/topics https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html You could also try pre-trained embeddings like word2vec and the likes  why do they have to be of the same length?
[2021-06-17T01:45:43.997Z] <5f1bb183d73408ce4fea7ec7> Hello ... Greetings to all..!!! I will participate in the Sprint on Saturday June 26..!!!
[2021-06-17T10:28:04.991Z] <5baf7d9ad73408ce4fa9c9b2> Welcome @asnramos !
[2021-06-19T23:15:57.217Z] <60ce79cf6da03739847f4458> Hello all . I'm also participating in the sprint next saturday,i'm  excited to be able to help checking and fixing an issue!
[2021-06-20T08:23:57.856Z] <608f617d6da03739847b9aac> Hello, how can I join the sprint?
[2021-06-22T09:18:43.566Z] <60d1a8256da03739847f6fe8> @um_duaa123_twitter sure ask
[2021-06-22T13:15:43.994Z] <608f617d6da03739847b9aac> Thanks
[2021-07-02T12:51:29.244Z] <575b0eccc2f0db084a1d3a41> why isn't the website working?
[2021-07-02T12:59:15.000Z] <567f5d7716b6c7089cc043a8> works for me
[2021-07-03T05:00:54.636Z] <575b0eccc2f0db084a1d3a41> Now it also works for me. Had tried with two different networks yesterday... didn't work that time..
[2021-07-03T05:01:51.020Z] <575b0eccc2f0db084a1d3a41> anyway, I wanted to ask what version of LAPACK (libblas.so) does sklearn use (assuming it uses it. If not, what blas library is used)?
[2021-07-03T16:41:10.086Z] <564789be16b6c7089cbab8b7> If I have a neural network classifier I can easily simulate data from the probability distribution implied by the classifier. Can this be done for any of the classifiers in scikit learn?
[2021-07-04T04:05:49.813Z] <575b0eccc2f0db084a1d3a41> scikit-learn custom compilation: Is it possible to pass custom gcc flags during scikit-learn build as described here  https://scikit-learn.org/stable/developers/advanced_installation.html 
[2021-07-04T04:06:59.603Z] <575b0eccc2f0db084a1d3a41> the documentation uses pip install. But since the pyx files get compiled in a C file first before finally compiled into a SO file, I wondered if it was possible to pass custom gcc flags in the intermediate stage
[2021-07-05T06:59:26.172Z] <575b0eccc2f0db084a1d3a41> Is there any option to build scikit-learn with DEBUG symbols?
[2021-07-05T11:55:30.708Z] <matrix-rthy:matrix.org> Yes, you can pass `CFLAGS` env variable https://stackoverflow.com/a/10867041/1791279
[2021-07-05T12:23:00.395Z] <575b0eccc2f0db084a1d3a41> thanks @rthy:matrix.org 
[2021-07-07T19:37:26.041Z] <5baebfaed73408ce4fa9bd25> Hello, I am wondering why this PR (https://github.com/scikit-learn/scikit-learn/pull/18758) doesn't show up at the top here: https://github.com/scikit-learn/scikit-learn/pulls  Is it because I had submitted it a long time ago, but my recent changes are considered updates?
[2021-07-07T19:38:50.729Z] <55d21ee30fc9f982beadabb8> I think that PRs are ordered by PR numbers by default in github
[2021-07-07T19:42:19.824Z] <5baebfaed73408ce4fa9bd25> Oh, wow, that's interesting.  Not what I would have expected.  
[2021-07-07T19:44:01.942Z] <55d21ee30fc9f982beadabb8> However, you have the option of "Sort by recently updated". This would actually be a good default while reviewing :)
[2021-07-07T20:11:12.029Z] <5baebfaed73408ce4fa9bd25> Yes, that's what I was looking for (and expecting as a default). Thanks!
[2021-07-08T20:31:34.871Z] <matrix-rthy:matrix.org> The "Refined GitHub" browser extension makes it the default among other improvements.
[2021-07-09T11:58:52.231Z] <575b0eccc2f0db084a1d3a41> I see that the binary_tree.pxi passes the value num_samples in the _recursive_build() procedure as an argument. The num_samples is calculated using self.data_arr.shape[0] whereas _recursive_build() expects an ITYPE_t argument. ITYPE_t is defined as np.intp_t which I assume is only 32 bit signed integer. So how is the binary tree built in cases when n_samples is greater than this value - let's say 10million data points? 
[2021-07-09T12:00:14.204Z] <575b0eccc2f0db084a1d3a41> In default python, this would've been handled by increasing the data size to long long implicitly. Does cython take care of it? I don't see any methods to take care of such scenario in the scikit-learn implementation code.
[2021-07-09T12:07:59.331Z] <575b0eccc2f0db084a1d3a41> Except for that idx_end - idx_start < 2 will be true in this case (due to signed integer overflow?) and the node 0 will be made a leaf node. But this is an unexpected behaviour, right?
[2021-07-09T12:59:43.887Z] <matrix-rthy:matrix.org> @HarshVardhanKumar: maximum value for int32 is ~2e9 not 2e6. So probably no one has tried using it with more than 2 billion samples.  Not sure it's really an issue for the near future.
[2021-07-09T13:01:32.006Z] <matrix-rthy:matrix.org> +1 to check for that overflow though.
[2021-07-09T13:04:48.571Z] <575b0eccc2f0db084a1d3a41> @rthy:matrix.org  thanks for pointing it out. A silly mistake on my part.
[2021-07-14T18:02:02.194Z] <5baebfaed73408ce4fa9bd25> Hello, I ran `pytest sklearn` and see the following.  Is this ok, or is there something wrong with my build: ``` SKIPPED [16] sklearn/utils/tests/test_validation.py:1374: could not import 'pandas': No module named 'pandas' ==== 355 failed, 19625 passed, 1443 skipped, 117 xfailed, 37 xpassed, 3371 warnings in 2380.84s (0:39:40) ==== (sklearn-dev)  ```
[2021-07-14T23:56:19.520Z] <5baebfaed73408ce4fa9bd25> OK, it works now.  Thanks Thomas Fan.  
[2021-07-19T03:36:47.984Z] <5f7499a2d73408ce4ff04fe5> Hello, I was working on this issue https://github.com/scikit-learn/scikit-learn/issues/20435
[2021-07-19T03:37:45.671Z] <5f7499a2d73408ce4ff04fe5> However I was not able to find the file to contribute the documentation into, can someone please help me with that
[2021-07-19T13:42:16.182Z] <567f5d7716b6c7089cc043a8> @yashasvimisra2798 the documentation is generated from the docstrings in the `.py` files where those classes are implemented. You should look for classes which inherit that class, and find the relevant part of the docstring there.
[2021-07-19T18:49:39.177Z] <5f7499a2d73408ce4ff04fe5> Thanks, @adrinjalali I will look into it.
[2021-08-07T16:30:44.417Z] <matrix-bmoroz82:matrix.org> Does Scikit support regression parameters with multidimensional data structure, e.g., 3-dimensional point data? I would like to perform a regression to predict the position of a 3-dimensional point (x,y,z) using other known 3-dimensional points while weighting by inverse-distance. I have a small sample of dependents Y comprised (xi, yi, zi) and a complete set of independents X1, X2, X3, ... each comprised of (xi, yi, zi). I would like to test a simple model Y = X1 + X2 + ...
[2021-08-07T17:59:09.203Z] <55d21ee30fc9f982beadabb8> you probably want to look at the following: https://scikit-learn.org/stable/modules/multiclass.html#multioutput-regression
[2021-08-07T18:18:29.456Z] <matrix-bmoroz82:matrix.org> <unconvertable> appreciated
[2021-08-09T08:05:10.320Z] <610a83356da03739848276fc> Can I use a confusion  matrix to see the accuracy of SVR(support vector regression) ?
[2021-08-09T08:05:26.909Z] <610a83356da03739848276fc> or is it only for classification ?
[2021-08-09T09:12:15.751Z] <55d21ee30fc9f982beadabb8> confusion matrix and derived metrics are only for classification
[2021-08-09T09:12:34.554Z] <55d21ee30fc9f982beadabb8> look at the regression metrics instead
[2021-08-16T18:36:45.720Z] <5b58594ed73408ce4fa23ee3> Hi all, how do you manage your changelog? Any useful tools or files that you could point me too? 
[2021-08-17T09:24:46.840Z] <5baf7d9ad73408ce4fa9c9b2> @mloning most PRs come with a changelog entry, e.g. https://github.com/scikit-learn/scikit-learn/pull/20727/files Then we have scripts to process / check it which are described in https://scikit-learn.org/stable/developers/maintainer.html (we call the change log a "What's new")
[2021-08-17T12:01:22.787Z] <5b58594ed73408ce4fa23ee3> @NicolasHug thanks - that's very helpful!
[2021-08-17T17:32:42.938Z] <5fd8fff2d73408ce4ff69a39> A very good evening everyone!! I am trying to setup scikit-learn project into my development env but encountered with an error when I try to run "pip install --verbose --no-build-isolation --editable ."  
[2021-08-17T17:33:18.644Z] <5fd8fff2d73408ce4ff69a39> Can someone help me to fix this error?
[2021-08-18T08:51:05.716Z] <567f5d7716b6c7089cc043a8> @RAVANv2 can only help if you tell us what the issue is :) 
[2021-08-18T13:02:19.913Z] <5fd8fff2d73408ce4ff69a39> Hi @adrinjalali, Actually, I solve it on my own :)
[2021-08-18T20:02:52.200Z] <5fd8fff2d73408ce4ff69a39> Hi all, I made one PR on issue #20754 but it failing the linting job of black and showing the error "##[error]Bash exited with code '1'". Can anyone tell me where I am doing wrong? I am totally a newbie in open-source but I m really enjoying :)
[2021-08-18T21:31:03.733Z] <567f5d7716b6c7089cc043a8> You can see how to fix that here: https://scikit-learn.org/dev/developers/contributing.html#pull-request-checklist You need to run black on your code
[2021-08-20T10:38:21.059Z] <611f80036da03739848392b1> Hello Everyone, I am a newbie to open source with basic knowledge about scikit-learn and want to contribute to this repository. Can anyone tell me how should I start? I have basic knowledge about generating my first PR and solving good first issues. Now I want to fix bugs and do some code contributions but I am unable to understand the issues. Can anyone guide me?
[2021-08-20T18:04:59.223Z] <54d4a1d6db8155e6700f853b> Hi @KiranHipparagi , thanks for wanting to contribute! Have you read the contributor's guide? I would suggest you look for issues tagged "good first issue". Many of those are multi-part issues where you can pick just a part to work on
[2021-08-20T18:05:53.326Z] <54d4a1d6db8155e6700f853b> see https://scikit-learn.org/dev/developers/contributing.html and https://github.com/scikit-learn/scikit-learn/labels/good%20first%20issue for good first issues
[2021-08-20T18:07:43.390Z] <54d4a1d6db8155e6700f853b> this one might be good to get started: https://github.com/scikit-learn/scikit-learn/issues/20308
[2021-08-23T14:29:38.347Z] <6102db756da0373984821b80> Hello i am starting out this one project and some of the parts are really complicated . And i am happy to learn during the complicated parts. But i feel i need more people. If anyone is interested in working together and learning together feel free to dm me 
[2021-08-23T14:29:41.806Z] <6102db756da0373984821b80> my discord is Aura#5549
[2021-09-01T14:11:06.945Z] <5baebfaed73408ce4fa9bd25> Deleted this message from the /dev/ channel.  Copying and pasting here: >I am Bhavya Bhardwaj (https://github.com/Bhavya1705). I am a student of Electronics and Communication at Amrita Vishwa Vidyapeetham, India. My thanks to you and the team for sklearn. I have been try to make some contributions to the scikit-learn library - scikit-learn/scikit-learn#5516. I have made the code, and the necessary changes to the init file and test files, in addition to the _classification file. This is the links to my commits - scikit-learn/scikit-learn#20861, as you will see, there are many mistakes, that I have made, Any help that you can render to me would be much appreciated and would be a wonderful learning experience. Thank You
[2021-09-01T15:35:58.932Z] <61291ef16da03739848428f6> @reshamas Thank You, I have managed to solve the issue.
[2021-09-07T16:57:42.986Z] <5cb5d739d73408ce4fbdddff> Hi. I am trying to develop my own Estimator based on TransformerMixin and BaseEstimator. To make sure I am doing things right I have added a test to my project : ``` import MyEstimator from sklearn.utils.estimator_checks import check_estimator def test () :      me = MyEstimator(**params)     check_estimator(me) ``` If I run the test, I get the following error message :  ``` AssertionError: The error message should contain one of the following patterns:                0 feature\(s\) \(shape=\(\d*, 0\)\) while a minimum of \d* is required. ```  I don't understand how I am supposed to take care of that. I am even more surprise because my fit_transorm method uses self._validate_data at the beginning. I would expect that function to take care of case like these. Could someone help me with that issue ?
[2021-09-07T22:26:36.574Z] <matrix-rthy:matrix.org> @adriente: Could you please open a Github issue with full traceback and tag me (@rth) in?
[2021-09-08T18:59:52.118Z] <5f31510fd73408ce4febd603> Hello! I opened this feature request a week ago. Just bumping it here in case it got lost: https://github.com/scikit-learn/scikit-learn/issues/20890
[2021-09-09T07:05:05.426Z] <55d21ee30fc9f982beadabb8> @freddyaboulton I can assure you it is not lost :) I saw it but I did not look at it yet because we are kind of working on releasing 1.0. Once the release done, you might get some attention from core-devs
[2021-09-13T10:28:22.777Z] <613f27626da0373984858a1f> Morning all 
[2021-09-13T10:30:08.337Z] <613f27626da0373984858a1f> I was kind of curious . Ive been dragging my feet using torch and I was wondering does this lib offer anything over torch ? Maybe this is better suited for the low level scientist trying to learn theory ? Or is it just an alternative ?
[2021-09-13T10:31:06.798Z] <613f27626da0373984858a1f> Omg Im trapped
[2021-09-13T16:15:15.584Z] <5baf7d9ad73408ce4fa9c9b2> @makingglitches pytorch and scikit-learn operate at different levels of abstractions but simply put in terms of scope, pytorch is for deep-learning while scikit-learn is for the rest of ML that's *not* deep learning. So one might be better suited than the other, depending on the theory that you're interested in.
[2021-09-15T12:36:42.253Z] <5e1a8a04d73408ce4fd66bde> [FEATURE REQUEST] Add GitHub Organisation README profile  Just found out this new GitHub feature on GitHub org.  Like this: https://twitter.com/vinzvinci/status/1438033675313025024 
[2021-09-25T23:47:56.052Z] <614fb4c06da03739848687d4> When a PR generates html doc, where to see it?
[2021-09-27T07:53:25.961Z] <567f5d7716b6c7089cc043a8> @lobpcg do you have a PR number?
[2021-09-28T18:06:46.738Z] <614fb4c06da03739848687d4>  @adrinjalali #21148
[2021-09-28T19:28:49.893Z] <55d21ee30fc9f982beadabb8> When the documentation CIs are finished
[2021-09-28T19:29:17.949Z] <55d21ee30fc9f982beadabb8> there will be a "ci/circleci: doc artifact <unconvertable> Link to 0/doc/_changed.html " line
[2021-09-28T19:29:24.660Z] <55d21ee30fc9f982beadabb8> You can clicked on "Details"
[2021-09-28T19:29:47.196Z] <55d21ee30fc9f982beadabb8> It will redirect to an HTML page where you will have hyperlinks to each documentation page that has been generated
[2021-09-28T19:30:06.745Z] <55d21ee30fc9f982beadabb8> in PRs we only generate documentation pages where there is a modification
[2021-09-28T21:35:36.538Z] <614fb4c06da03739848687d4> @glemaitre great, found it - thanks! 
[2021-10-04T08:50:05.685Z] <5cafacbfd73408ce4fbd7ec2> Morning all I want to know if scikit-learn 1.1 will be released in late 2021?
[2021-10-04T09:17:03.090Z] <567f5d7716b6c7089cc043a8> There will be minor releases this year (1.0.1 for instance), but the next major release will be next year.
[2021-10-08T15:09:40.330Z] <541a528b163965c9bc2053de>  Hello everyone, we are having a live community office hour on discord. Feel free to join to discuss your PRs! 
[2021-10-08T15:09:43.086Z] <541a528b163965c9bc2053de> https://discord.gg/YBdN45kD
[2021-10-08T15:14:35.215Z] <58de4778d73408ce4f551e04> :boom: :+1: 
[2021-10-11T19:12:50.166Z] <6069ea306da0373984793e79> has anyone tried to implement GAM's via sklearn pipeline's before?
[2021-10-12T09:45:16.659Z] <5cdeaebed73408ce4fc08df3> Hello I'm using scikit-learn `0.22.2.post1` and getting the following error  ` AttributeError: '_CalibratedClassifier' object has no attribute 'classes_' `when I try to use `predict_proba`on calibrated classifier  Do you you know if this issue is related to the scikit-learn's version ? Thanks  
[2021-10-12T10:27:47.936Z] <613b2abc6da0373984853e44> Hi, can I post a call for participants in an interview study on open source projects here? If any mod wants more details via DM first, then I'm happy to oblige :)
[2021-10-12T15:50:12.196Z] <5c9a8be3d73408ce4fbbe82f> Is cohen kappa score and balanced accuracy score supposed to work w/ multiclass labels?  I have a 3-class classification and I'm trying to use `cross_validate`, but it returns nans for all my scores. I tested the problem by running `cross_val_score` on all scores individually and isolated it to those 2 metrics.  X = (100, 5) y = (100, 3) clf is a Random Forest Classifier ``` from sklearn.model_selection import cross_val_score  cross_val_score(clf, X, y, cv=5, scoring='balanced_accuracy') ```
[2021-10-13T08:05:26.313Z] <567f5d7716b6c7089cc043a8> @razou could you please paste a fully reproducible piece of code?
[2021-10-13T08:07:03.857Z] <567f5d7716b6c7089cc043a8> @NoahWoehler_twitter we get quite a bit of these requests these days (which is a good thing, shows people are looking into issues). But it would help people decide if they want to spend time on it, if you give a tiny bit of intro on what it is. Also, feel free to send an email to the mailing list with that information if you want to reach more people.
[2021-10-13T08:13:53.710Z] <613b2abc6da0373984853e44> Sure, I wasn't sure whether this falls under advertising. We are looking for open source contributors who are willing to talk to us about how security and trust are handled within their projects' communities. This is the landing page with more info: https://research.teamusec.de/2021-interviews-oss/
[2021-10-13T08:15:13.707Z] <567f5d7716b6c7089cc043a8> ah interesting. I don't think we do much of that in this project, but others may think differently.
[2021-10-13T08:17:48.797Z] <5cdeaebed73408ce4fc08df3> > @razou could you please paste a fully reproducible piece of code?  ``` from sklearn.calibration import CalibratedClassifierCV from sklearn.multioutput import ClassifierChain from lightgbm import LGBMClassifier  base_estimator = LGBMClassifier() calibrator = CalibratedClassifierCV(base_estimator=base_estimator) clf = ClassifierChain(base_estimator=calibrator, order='random', random_state=20) clf.fit(X=train_x, Y=train_y)  y_pred_proba = clf.predict_proba(validation_x) ``` 
[2021-10-13T08:21:21.580Z] <5cdeaebed73408ce4fc08df3> The aim was to perform multi-label classifier and retourn probability scores for each (label, profile) pair. NB: y was encoded wit h MultiLabelBinarizer 
[2021-10-13T08:27:40.156Z] <541a528b163965c9bc2053de> @razou please provide a minimal reproducible piece of code, that is a piece a piece of code that we can just copy and paste in a python shell or python script and run to trigger the problem. Here the code you provide does not include the definition of `train_x` and `train_y` which is probably the core of the problem. Using minimal random data from np.random.normal(size=(n_samples, n_features) or np.random.randint(low=0, high=10, size=n_samples)
[2021-10-13T08:29:04.818Z] <541a528b163965c9bc2053de> and also add the necessary code to preprocess train_y and the code that computes the cross validation with the score you want.
[2021-10-13T08:30:58.616Z] <541a528b163965c9bc2053de> Minimal stands for removing anything that is not necessary. For instance are CalibratedClassifierCV ClassifierChain necessary to reproduce the problem? Or can you just reproduce the problem by cross validating the base estatimtor directly? If so simplify the code snippet.
[2021-10-13T08:31:12.278Z] <541a528b163965c9bc2053de> https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports
[2021-10-13T09:04:46.168Z] <5cdeaebed73408ce4fc08df3> Thanks you guys for your answers  1. libraries ``` pip install lightgbm==3.2.1 pip install scikit-learn==0.22.2.post1 ```  2. Code snipet  ``` from sklearn.datasets import make_multilabel_classification from sklearn.model_selection import train_test_split from sklearn.preprocessing import MultiLabelBinarizer from sklearn.calibration import CalibratedClassifierCV from sklearn.multioutput import ClassifierChain  from lightgbm import LGBMClassifier  X, y = make_multilabel_classification(n_samples=2000, n_classes=10, n_labels=2, allow_unlabeled=True) train_x, validation_x, train_y, validation_y = train_test_split(X, y, test_size=0.25)  mlb = MultiLabelBinarizer() train_y_encoded = mlb.fit_transform(train_y) validation_y_encoded = mlb.transform(validation_y)  base_estimator = LGBMClassifier() calibrator = CalibratedClassifierCV(base_estimator=base_estimator) clf = ClassifierChain(base_estimator=calibrator, order='random', random_state=20) clf.fit(X=train_x, Y=train_y_encoded)  y_pred_proba = clf.predict_proba(validation_x) print(y_pred_proba[:3]) ```
[2021-10-13T14:09:20.568Z] <541a528b163965c9bc2053de> I don't understand why you are using `MultiLabelBinarizer` here because `y` is already a binary representation of the target variable since in this snippet you used `make_multilabel_classification`. Please provide a snippet that causes the same error message as the problem you observe with cross-validation cohen kappa score.  Anyways by reading the scikit-learn documentation https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa I don't see how this would work for binary encoded multilabeled data.
[2021-10-13T14:10:38.173Z] <541a528b163965c9bc2053de> The scikit-learn error message is actually quite explicit:  ```python >>> from sklearn.metrics import cohen_kappa_score >>> cohen_kappa_score([[0, 1], [1, 1]], [[0, 0], [1, 0]]) Traceback (most recent call last):   File "<ipython-input-19-2a87559cbf88>", line 1, in <module>     cohen_kappa_score([[0, 1], [1, 1]], [[0, 0], [1, 0]])   File "/Users/ogrisel/code/scikit-learn/sklearn/metrics/_classification.py", line 639, in cohen_kappa_score     confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)   File "/Users/ogrisel/code/scikit-learn/sklearn/metrics/_classification.py", line 304, in confusion_matrix     raise ValueError("%s is not supported" % y_type) ValueError: multilabel-indicator is not supported ```
[2021-10-14T09:22:46.545Z] <5cdeaebed73408ce4fc08df3> Where Kappa metric cames from ? I did not used it ...
[2021-10-18T10:23:08.122Z] <541a528b163965c9bc2053de> @razou sorry I mixed 2 conversations. Ignore the bit on Cohen's Kappa then.
[2021-10-18T10:24:39.939Z] <541a528b163965c9bc2053de> @razou your code snippet works with `clf.fit(X=train_x, Y=train_y)` instead of `clf.fit(X=train_x, Y=train_y_encoded)`.
[2021-10-18T16:47:25.021Z] <5cdeaebed73408ce4fc08df3> Thanks @ogrisel  for answers (y)
[2021-10-20T17:14:20.953Z] <5acfdfffd73408ce4f95738d> how to get precision and recall from function 'precision_recall_curve' for class 0. I posted a question with a code on this topic [here](https://ai.stackexchange.com/questions/32127/how-to-get-precision-and-recall-from-function-precision-recall-curve-for-class)
[2021-10-20T17:34:36.265Z] <55d21ee30fc9f982beadabb8> You should use either
[2021-10-20T17:34:37.398Z] <55d21ee30fc9f982beadabb8> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay.from_estimator
[2021-10-20T17:34:50.784Z] <55d21ee30fc9f982beadabb8> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay.from_predictions
[2021-10-20T17:34:55.594Z] <55d21ee30fc9f982beadabb8> with `pos_label=0`
[2021-10-21T12:43:22.800Z] <5acfdfffd73408ce4f95738d> @glemaitre Solved the problem by turning class 0 into 1.                                                              But it's still not clear what kind of data I get by setting label=0. Updated the code and added two videos with label=0 and label=1. I put the code and videos [here](https://ai.stackexchange.com/questions/32127/how-to-get-precision-and-recall-from-function-precision-recall-curve-for-class/)  It is quite possible that I am difficult to understand, since English is not my native language. There is no opportunity to practice in English.
[2021-10-21T12:47:06.570Z] <5acfdfffd73408ce4f95738d> 
[2021-10-21T13:24:01.629Z] <55d21ee30fc9f982beadabb8> turning class 0 to 1 is equivalent to change `pos_label=0` without changing the label.
[2021-10-21T13:28:22.697Z] <5acfdfffd73408ce4f95738d> Thanks!
[2021-10-30T13:33:10.863Z] <5d7033aad73408ce4fca0665> If we run this command after setup `pytest maint_tools/test_docstrings.py -k sklearn.utils.extmath.cartesian`, we got  platform linux -- Python 3.8.10, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 rootdir: /workspaces/scikit-learn, configfile: setup.cfg plugins: cov-3.0.0 collected 0 items / 2 skipped                                                                                                   =================================================== short test summary info =================================================== SKIPPED [2] maint_tools/test_docstrings.py:12: could not import 'numpydoc.validate': No module named 'numpydoc' ===================================================== 2 skipped in 0.47s ======================================================
[2021-10-30T13:36:28.434Z] <55d21ee30fc9f982beadabb8> you need to install numpydoc via pip or conda
[2021-10-30T13:36:37.083Z] <5d7033aad73408ce4fca0665> Okay
[2021-10-30T13:36:39.141Z] <55d21ee30fc9f982beadabb8> otherwise the test is skipped
[2021-10-30T13:36:51.930Z] <55d21ee30fc9f982beadabb8> we dont impose it because this is an optional dependency
[2021-10-30T13:37:29.103Z] <5d7033aad73408ce4fca0665> Working on #21350 issue 
[2021-10-30T13:43:43.937Z] <5d7033aad73408ce4fca0665> ===================================================== test session starts ===================================================== platform linux -- Python 3.8.10, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 rootdir: /workspaces/scikit-learn, configfile: setup.cfg plugins: cov-3.0.0 collected 2110 items / 2109 deselected / 1 selected                                                                             maint_tools/test_docstrings.py .                                                                                        [100%]  ============================================= 1 passed, 2109 deselected in 0.98s ==============================================
[2021-10-30T13:44:09.854Z] <5d7033aad73408ce4fca0665> now, we got passed, then we make a PR for it ?
[2021-10-30T14:04:00.470Z] <55d21ee30fc9f982beadabb8> yes
[2021-10-30T14:29:39.954Z] <5d7033aad73408ce4fca0665> > yes  Done!
[2021-10-31T13:20:13.189Z] <matrix-zacchiro:matrix.org> hey, i'm unclear on whether this channel is for user- or developer-related questions (or both)? can someone clarify? i don't want to bother others with off-topic questions :-)
[2021-10-31T13:22:01.439Z] <matrix-zacchiro:matrix.org> > hey, i'm unclear on whether this channel is for user- or developer-related questions (or both)? can someone clarify? i don't want to bother others with off-topic questions :-)  oh, i guess the topic answers that (thanks)
[2021-10-31T13:38:43.853Z] <matrix-zacchiro:matrix.org> so, for the actual Q:
[2021-10-31T13:39:11.548Z] <matrix-zacchiro:matrix.org> i'm trying to use sklearn.clustering.DBSCAN on a large document corpus (coming from gensim, converted to numpy sparse matrix)
[2021-10-31T13:39:15.365Z] <matrix-zacchiro:matrix.org> the matrix is this:
[2021-10-31T13:39:17.353Z] <matrix-zacchiro:matrix.org> <6748785x4974743 sparse matrix of type '<class 'numpy.float64'>'         with 677079990 stored elements in Compressed Sparse Column format> 
[2021-10-31T13:40:09.157Z] <matrix-zacchiro:matrix.org> that's ~5M documents with ~7M features (TFIDF-weighted words)
[2021-10-31T13:40:31.032Z] <matrix-zacchiro:matrix.org> i'm trying to cluster this using DBSCAN(n_jobs=64).fit(corpus_csc)
[2021-10-31T13:41:01.770Z] <matrix-zacchiro:matrix.org> how do I know if it will ever terminate? there seems to be no way of having a progress indication
[2021-10-31T13:41:44.670Z] <matrix-zacchiro:matrix.org> (RAM doesn't seem to be an issue for now, it's running on a machine with 1 TiB RAM, but it's sitting at ~70 GiB for now)
[2021-10-31T13:42:14.433Z] <matrix-zacchiro:matrix.org> it's been going on for ~3 days now, any guess on whether it has any chances of terminating in reasonable time?
[2021-10-31T13:43:35.731Z] <matrix-zacchiro:matrix.org> (or how to enable progress logging, if that's possible)
[2021-11-02T19:20:43.140Z] <567f5d7716b6c7089cc043a8> my guess is most of the time is spent on ball_tree or kd_tree in nearestneighbors. If I were to investigate, I'd add a few logging info in those areas to see what's happening, but probably most of them are in cython space. We don't really have logging in those areas, if you want to figure it out, you should add it to your copy of scikit-learn and see where the time is spent.
[2021-11-03T13:38:03.540Z] <matrix-zacchiro:matrix.org> @adrinjalali: thanks for your feedback. Aside from that (which I'm gonna try) any reference number about the performances of sklearn's DBSCAN implementation on large datasets?
[2021-11-03T13:38:23.866Z] <matrix-zacchiro:matrix.org> it'd be very useful to have an idea if I'm "almost there" or, like, only 1e-6 % done
[2021-11-03T14:40:30.771Z] <567f5d7716b6c7089cc043a8> I personally haven't worked with very large datasets and DBSCAN, so I can't really help you there unfortunately.
[2021-11-04T20:34:46.748Z] <5c9a8be3d73408ce4fbbe82f> Does logistic regression support pandas dataframe as input for the X matrix?  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit  Does this then allow us to make use of the new attribute name: `feature_names_in`?
[2021-11-04T20:44:20.996Z] <55d21ee30fc9f982beadabb8> you can pass a daframe
[2021-11-04T20:44:53.306Z] <55d21ee30fc9f982beadabb8> currently `feature_names_in`would be useless in classifier and regressor
[2021-11-04T20:45:06.081Z] <55d21ee30fc9f982beadabb8> because we will convert into a numpy array to make the optimisation
[2021-11-04T20:45:26.381Z] <55d21ee30fc9f982beadabb8> the idea for the moment is to propagate feature names in the preprocessing steps
[2021-11-04T20:45:59.705Z] <55d21ee30fc9f982beadabb8> such that you for instance know the name of the columns of the numpy array that will be passed to the logistic regression (and potentially build the dataframe)
[2021-11-04T20:47:24.579Z] <55d21ee30fc9f982beadabb8> The work that could be done for classifier and regressor is to make that the fitted attribute could use the feature names to decorate themselves
[2021-11-04T20:48:17.870Z] <55d21ee30fc9f982beadabb8> but it can be still be easily done by getting the `feature_names_in` from the last preprocessing stage and create for instance a pandas series using the coefficients
[2021-11-04T20:48:44.176Z] <55d21ee30fc9f982beadabb8> but for the moment we try that we can move the feature names in the preprocessing
[2021-11-05T17:54:29.419Z] <61856d766da037398489e910> Hi folks! I have a very simple fix for https://github.com/scikit-learn/scikit-learn/issues/12052 that only addresses this issue for CalibratedClassifierCV. I know SLEP006 seeks to fix this for the general case, but it appears to still be a WIP. Is it worth me throwing together a PR to simply add the groups parameter to CalibratedClassifierCV with checks to ensure the cv supports it? I've tested this out on my own by subclassing CalibratedClassifierCV and writing a modified fit method. It's essentially a 2 line code change. I'm happy to submit a PR if it seems likely this will be accepted?
[2021-11-06T02:26:09.501Z] <matrix-sumitdatascience:matrix.org> Hi everyone. I was wondering if anyone could get older versions of scikit-learn that are below 1.0.0 installed in a Python 3.9 virtual environment. I think there is no wheel for scikit-learn 0.21.0 or 0.21.1 that works with Python 3.9, so it has to be built from source, which doesn't work very well on a lot of systems. I know installing with Anaconda works, but I was curious if there are some solutions to get it to work with Python 3.9's typical pip install command.
[2021-11-11T06:51:26.877Z] <616083aa6da0373984877911> Hello!
[2021-12-08T20:11:29.723Z] <61a11a356da03739848b5ea2> Hello, Scikit devs and contributors. I have a question regarding one of the examples left in PR #21958. `/examples/linear_model/plot_sparse_logistic_regression_mnist.py`. I guess this one is left because is not as straightforward to accelerate. This example involves a logistic regression using the saga algorithm and l1 penalty. In my attempt to optimize it, I found out that most of the running time is spent fetching the data instead of running the regression itself. The most I could do was 5% faster, which translates to 2 seconds difference. Unfortunately, by reducing `train_samples` the running time is not meaningfully decreased.  Another option I considered was to run LogisticRegression with `tol=0.9` and `n_jobs=2`, and `max_iter=40`. Unfortunately, can't get more than 5%.  One of the tweaks I managed to do was in the plot itself, by running the reshape outside the plot and using a list comprehension itself. Overall it makes the plot faster.  Checking other PRs, it seems that the acceleration obtained in this example is quite low. I am not sure even if this is an example that can be further improved considering the most expensive operation here is `fetch_openml`. For the same reason, not sure submitting a PR with such a low improvement is even a good idea.  I appreciate your thoughts on it. Maybe I'm missing something relevant. Thanks! 
[2021-12-10T19:24:08.533Z] <6186f8e46da037398489fa20> Hi guys, I want to install the scikit-learn package in an environment that previously TensorFlow, NumPy, pandas, scipy, and matplotlib were installed. I installed the scikit-learn package in Windows 7 64-bit. When, in activated enviroment I write: conda install scikit-learn; it shows: ERROR conda.core.link:_execute(699): An error occurred while installing  package 'defaults::scikit-learn-1.0.1-py38hf11a4ad_0'. Rolling back  transaction: done  LinkError: post-link script failed for package  defaults::scikit-learn-1.0.1-py38 hf11a4ad_0 location of failed  script: G:\programfile\anaconda3\envs\tf\Scripts\.scikit-lear n-post-link.bat  ==> script messages <==  <None> ==> script output <==  stdout:  stderr:  return code: 1   ()
[2021-12-10T20:56:45.936Z] <567f5d7716b6c7089cc043a8> @ojeda-e thanks for investigating those ones. Please leave the same comment on the issue, and I'll mark them as "won't change"
[2022-01-25T02:29:51.879Z] <matrix-djmvicente:matrix.org> Hi
[2022-01-26T13:03:48.185Z] <61f03ddb6da03739848f1c1e> hello guys i am getting this error can anybody please tell 
[2022-01-26T13:03:49.907Z] <61f03ddb6da03739848f1c1e> ImportError while loading conftest 'E:\scikit\scikit-learn\sklearn\conftest.py'. sklearn\__init__.py:81: in <module>     from . import __check_build  # noqa: F401 sklearn\__check_build\__init__.py:50: in <module>     raise_build_error(e) sklearn\__check_build\__init__.py:31: in raise_build_error     raise ImportError( E   ImportError: No module named 'sklearn.__check_build._check_build' E   ___________________________________________________________________________ E   Contents of E:\scikit\scikit-learn\sklearn\__check_build: E   setup.py                  _check_build.pyx          __init__.py E   __pycache__ E   ___________________________________________________________________________ E   It seems that scikit-learn has not been built correctly. E E   If you have installed scikit-learn from source, please do not forget E   to build the package before using it: run `python setup.py install` or E   `make` in the source directory. E E   If you have used an installer, please check that it is suited for your E   Python version, your operating system and your platform.
[2022-01-26T13:08:39.702Z] <61f03ddb6da03739848f1c1e> i have tried puthon setup.py install too
[2022-01-26T16:41:11.362Z] <matrix-ogrisel:matrix.org> which error? Please copy the command you used and the error message.
[2022-01-26T19:05:17.049Z] <57b364d540f3a6eec05fce2b> Hello guys, i am having a lot of trouble creating a dummy classifier with scikit-learn. I asked a question with all the details in stackoverflow, can you please check what am i doing wrong? Link: https://www.stackoverflow.com/questions/70866945/assertionerror-not-equal-to-tolerance
[2022-01-27T13:13:55.102Z] <567f5d7716b6c7089cc043a8> @henrique-voni I've answered on SO
[2022-01-29T18:45:16.059Z] <61f5898d6da03739848f5c77> Hello guys while testing  the file my test are getting skipped how to fix it  '''  ==================================================================== test session starts ==================================================================== platform win32 -- Python 3.9.10, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 rootdir: D:\OpenSource\sci-kit\scikit-learn, configfile: setup.cfg plugins: cov-3.0.0 collected 0 items / 2 skipped ''''
[2022-01-29T18:52:47.177Z] <61cc86716da03739848d405f> what is the command you are using ?
[2022-01-29T18:57:11.327Z] <61f5898d6da03739848f5c77> pytest sklearn/tests/test_docstrings.py -k sklearn.datasets._california_housing.fetch_california_housing
[2022-01-29T18:59:59.542Z] <61cc86716da03739848d405f> I think you forgot to install documentation dependencies https://scikit-learn.org/stable/developers/contributing.html#building-the-documentation
[2022-01-29T19:06:50.919Z] <61f5898d6da03739848f5c77> @PurnaChandraMansingh  thanks ,Now its working
[2022-01-30T05:50:49.761Z] <5ee61de0d73408ce4fe6d981> I get an error trying to use a callable for metric with KNN. What is the correct way to use it?  ``` clf = KNeighborsClassifier(metric=dm.get_metric("minkowski")) clf.fit(X,y)  ValueError: Metric '<sklearn.metrics._dist_metrics.EuclideanDistance object at 0x000001ECEC658DD0>' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['brute']) to get valid options. Metric can also be a callable function. ```
[2022-01-30T17:30:54.346Z] <matrix-hansuke:matrix.org> https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
[2022-01-30T18:32:21.159Z] <567f5d7716b6c7089cc043a8> @amy12xx it's always easier for people to give you a meaningful answer if you paste a minimally reproducible code, which can in its entirety be copy/pasted to produce your issue.
[2022-01-30T20:04:22.589Z] <5ee61de0d73408ce4fe6d981> good point :-)
[2022-01-30T20:08:36.027Z] <5ee61de0d73408ce4fe6d981> ``` from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import DistanceMetric as dm from sklearn.datasets import load_iris iris = load_iris() X = iris.data y = iris.target clf = KNeighborsClassifier(metric="euclidean") clf.fit(X,y) clf = KNeighborsClassifier(metric=dm.get_metric("euclidean")) clf.fit(X,y)  Traceback (most recent call last):   File "<stdin>", line 1, in <module>   File "C:\Users\Amanda\Miniconda3\envs\mlenv\lib\site-packages\sklearn\neighbors\_classification.py", line 198, in fit     return self._fit(X, y)   File "C:\Users\Amanda\Miniconda3\envs\mlenv\lib\site-packages\sklearn\neighbors\_base.py", line 437, in _fit     self._check_algorithm_metric()   File "C:\Users\Amanda\Miniconda3\envs\mlenv\lib\site-packages\sklearn\neighbors\_base.py", line 374, in _check_algorithm_metric     raise ValueError( ValueError: Metric '<sklearn.metrics._dist_metrics.EuclideanDistance object at 0x0000018099BB9780>' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['brute']) to get valid options. Metric can also be a callable function.  ``` 
[2022-01-31T15:48:29.928Z] <567f5d7716b6c7089cc043a8> That's indeed curious @amy12xx , I've opened and issue, and you can follow the discussion there: https://github.com/scikit-learn/scikit-learn/issues/22348
[2022-02-11T18:41:51.735Z] <5a0d62aed73408ce4f7ed9b2> Hi, I am using TransformedTargetRegressor with KNeighborsRegressor for precomputed metric, however when I do cross validation with GridSearchCV, an error is raised saying that the dimension of the metric is not correct. The code is like this: ``` from sklearn.preprocessing import MinMaxScaler target_scaler = MinMaxScaler() estimator = Pipeline([         ('scaler', MinMaxScaler()),         ('model', TransformedTargetRegressor(           KNeighborsRegressor(metric='precomputed'),           transformer=target_scaler         ))])  clf = GridSearchCV(estimator, param_grid=grid_params, 					   scoring=scoring, 					   cv=cv, return_train_score=True, refit=True, 					   error_score='raise') clf.fit(D_app, y_app) ... ``` May I ask what may be the problem? In case it is not supported, is there other ways to corrected scale targets in GridSearchCV (as well as HalvingGridSearchCV, etc.). Thank you very much!
[2022-02-13T11:29:46.221Z] <6208ba1a6da037398490413f> I am getting this error-:       Could not find conda environment: sklearn-env. You can list all discoverable environments with `conda info --envs`. 
[2022-02-14T07:29:57.208Z] <6208ba1a6da037398490413f>  E   ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject
[2022-02-14T08:48:16.635Z] <matrix-ogrisel:matrix.org> @Shubham1450: can you please open an issue with this error message and the full output of `conda list`?
[2022-02-19T12:34:48.950Z] <matrix-RebelCoder:matrix.org> Hey smart people. I am trying to figure out/understand the warning. Solution I found just tell you to disable to warning. Maybe someone give a hint why I am seen the following warning is this super simple Multiple Regression example? ``` data_file = pd.read_csv("FuelConsumption.csv")  data_frame = data_file[     [         'ENGINESIZE',         'CYLINDERS',         'FUELCONSUMPTION_CITY',         'FUELCONSUMPTION_HWY',         'FUELCONSUMPTION_COMB',         'CO2EMISSIONS'     ] ]  data_set_x = ['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_COMB'] data_set_y = ['CO2EMISSIONS']  mask = np.random.rand(len(data_frame)) < 0.8 train = data_frame[mask] test = data_frame[~mask]  lr_regression = linear_model.LinearRegression() train_x = np.asanyarray(train[data_set_x]) train_y = np.asanyarray(train[data_set_y]) lr_regression.fit(train_x, train_y)  y_hat = lr_regression.predict(test[data_set_x]) test_x = np.asanyarray(test[data_set_x]) test_y = np.asanyarray(test[data_set_y]) ```  The line 26: ``` y_hat = lr_regression.predict(test[data_set_x]) ```  Produces this warning: ``` sklearn/base.py:443: UserWarning: X has feature names, but LinearRegression was fitted without feature names   warnings.warn( ```
[2022-02-19T13:44:53.182Z] <5c77a43ed73408ce4fb93081> In your example, `lr_regression.fit` was called with an ndarray, while `lr_regression.predict` was called with a DataFrame. To prevent the warning, you can `fit` with the DataFrame directly:  ```python lr_regression.fit(train[data_set_x], train[data_set_y]) ```  without casting to a ndarray.
[2022-02-19T15:11:25.135Z] <matrix-RebelCoder:matrix.org> Interesting! Thanks. I tried that, and it still has a warning though. I think I figured it out. I use the `np array` on all of them now. ``` lr_regression = linear_model.LinearRegression() train_x = np.asanyarray(train[data_set_x]) train_y = np.asanyarray(train[data_set_y]) lr_regression.fit(train_x, train_y)  test_x = np.asanyarray(test[data_set_x]) test_y = np.asanyarray(test[data_set_y]) y_hat = lr_regression.predict(test_x) ```  This works. I am also wondering, (yet to look into it) why `np arrays` are used if just the data frame can be used, as you have suggested?e
[2022-02-21T11:57:23.002Z] <62137b006da037398490b938> I am a question with sklearn.PCA. Whether data needs to be standardized? eg.  the variance may be used before create the pca object?
[2022-02-21T11:58:43.597Z] <62137b006da037398490b938> [![image.png](https://files.gitter.im/541a528c163965c9bc2053e1/rsRh/thumb/image.png)](https://files.gitter.im/541a528c163965c9bc2053e1/rsRh/image.png)
[2022-02-21T12:00:05.825Z] <62137b006da037398490b938> Thank you for answering
[2022-02-22T15:17:42.580Z] <5e7de2b6d73408ce4fde36e6> Hi scikit-learn team! I've got a new computer (MacBookPro, chip: Apple M1 Pro) on which I installed the development version of scikit-learn. When I ran pytest I encountered the following:  ``` (sklearn-dev) <unconvertable>  scikit-learn git:(main) pytest =========================================================================================== test session starts ============================================================================================ platform darwin -- Python 3.9.10, pytest-7.0.1, pluggy-1.0.0 rootdir: /Users/maren/Documents/scikit-learn, configfile: setup.cfg, testpaths: sklearn plugins: xdist-2.5.0, forked-1.4.0, cov-3.0.0 collecting ... [1]    54294 killed     pytest ```` 
[2022-02-22T15:19:34.753Z] <55d21ee30fc9f982beadabb8> this does not look good :)
[2022-02-22T15:19:47.214Z] <5e7de2b6d73408ce4fde36e6> I then tried to check what's going on and found the following. Do you have an idea of what I need to do?  ``` (sklearn-dev) <unconvertable>  scikit-learn git:(main) python -vvv -c "import sklearn" import _frozen_importlib # frozen import _imp # builtin import '_thread' # <class '_frozen_importlib.BuiltinImporter'> import '_warnings' # <class '_frozen_importlib.BuiltinImporter'> import '_weakref' # <class '_frozen_importlib.BuiltinImporter'> import '_io' # <class '_frozen_importlib.BuiltinImporter'> import 'marshal' # <class '_frozen_importlib.BuiltinImporter'> import 'posix' # <class '_frozen_importlib.BuiltinImporter'> import '_frozen_importlib_external' # <class '_frozen_importlib.FrozenImporter'> # installing zipimport hook import 'time' # <class '_frozen_importlib.BuiltinImporter'> import 'zipimport' # <class '_frozen_importlib.FrozenImporter'> # installed zipimport hook # /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__pycache__/__init__.cpython-39.pyc matches /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__init__.py # code object from '/Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__pycache__/__init__.cpython-39.pyc' # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/codecs.cpython-39-darwin.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/codecs.abi3.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/codecs.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/codecs.py # /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/__pycache__/codecs.cpython-39.pyc matches /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/codecs.py # code object from '/Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/__pycache__/codecs.cpython-39.pyc' import '_codecs' # <class '_frozen_importlib.BuiltinImporter'> import 'codecs' # <_frozen_importlib_external.SourceFileLoader object at 0x101613be0> # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/aliases.cpython-39-darwin.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/aliases.abi3.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/aliases.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/aliases.py # /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__pycache__/aliases.cpython-39.pyc matches /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/aliases.py # code object from '/Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__pycache__/aliases.cpython-39.pyc' import 'encodings.aliases' # <_frozen_importlib_external.SourceFileLoader object at 0x101643190> import 'encodings' # <_frozen_importlib_external.SourceFileLoader object at 0x1016139d0> # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/utf_8.cpython-39-darwin.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/utf_8.abi3.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/utf_8.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/utf_8.py # /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__pycache__/utf_8.cpython-39.pyc matches /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/utf_8.py # code object from '/Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__pycache__/utf_8.cpython-39.pyc' import 'encodings.utf_8' # <_frozen_importlib_external.SourceFileLoader object at 0x1016138b0> import '_signal' # <class '_frozen_importlib.BuiltinImporter'> # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/latin_1.cpython-39-darwin.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/latin_1.abi3.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/latin_1.so # trying /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/latin_1.py # /Users/maren/mambaforge/envs/sklearn-dev/lib/python3.9/encodings/__pycache__/latin_1.cpython-39.pyc matches /Users/maren/mambaforg ``` 
[2022-02-22T15:20:26.350Z] <55d21ee30fc9f982beadabb8> which compilers are you using when installing the dev version
[2022-02-22T15:22:30.035Z] <5e7de2b6d73408ce4fde36e6> It looks like I can't post the full error message because it's too long. I followed the installation here: https://scikit-learn.org/stable/developers/advanced_installation.html#macos-compilers-from-conda-forge So I installed `compilers` and `llvm-openmp`.
[2022-02-22T15:24:16.747Z] <5e7de2b6d73408ce4fde36e6> And I used the `Miniforge3-MacOSX-arm64` download from here: https://github.com/conda-forge/miniforge#miniforge
[2022-02-22T15:24:23.163Z] <55d21ee30fc9f982beadabb8> let me try with the last version of comilers on my M1 machine
[2022-02-22T15:26:37.500Z] <55d21ee30fc9f982beadabb8> I assume that you forced installing python 3.9 and not 3.10?
[2022-02-22T15:27:31.427Z] <matrix-ogrisel:matrix.org> you can use https://gist.github.com to post the full error log and give a link here
[2022-02-22T15:30:57.003Z] <5e7de2b6d73408ce4fde36e6> Thank you! Here is the link: https://gist.github.com/marenwestermann/9ffddb7a2f0ef6798d350f3595997ed1
[2022-02-22T15:32:18.794Z] <55d21ee30fc9f982beadabb8> I can reproduce
[2022-02-22T15:35:48.601Z] <55d21ee30fc9f982beadabb8> clang and llvm have been updated 
[2022-02-22T15:39:25.634Z] <55d21ee30fc9f982beadabb8> so temporary I think that installing `compilers=1.3` should fix the problem. I will give it a try.
[2022-02-22T15:39:52.173Z] <55d21ee30fc9f982beadabb8> Then we need to understand why the new compilers are failing. But I can see that clang and llvm have been updated
[2022-02-22T15:42:07.702Z] <55d21ee30fc9f982beadabb8> uhm it is not the compilers :(
[2022-02-22T15:44:11.697Z] <5e7de2b6d73408ce4fde36e6> I just tried using `compilers=1.3` but it didn't solve the problem
[2022-02-22T15:44:35.296Z] <matrix-ogrisel:matrix.org> @marenwestermann: can you please open an issue?
[2022-02-22T15:44:56.388Z] <5e7de2b6d73408ce4fde36e6> Yes, will do
[2022-02-22T15:47:23.030Z] <5e7de2b6d73408ce4fde36e6> I'm about to head off to a PyLadies Berlin open source hack night that I'm hosting, so will do it then. This is actually a good example case that I can show. :) 
[2022-02-22T15:53:03.942Z] <matrix-ogrisel:matrix.org> nice :)
[2022-02-22T15:53:28.118Z] <matrix-ogrisel:matrix.org> hopefully you will be able to find a workaround if it proves too complex to fix
[2022-02-28T09:25:38.945Z] <5e1185ead73408ce4fd5bf77> Hello all. I'm new to contributing here. Can anybody guide me how should I start to contribute in sklearn! 
[2022-03-02T18:31:33.844Z] <614fb4c06da03739848687d4> I am trying to rejuvenate scikit-learn/scikit-learn#14636 which would then close scikit-learn/scikit-learn#8834 and scikit-learn/scikit-learn#8842. That requires merging https://github.com/scipy/scipy/pull/15391 Could someone please help by reviewing? Even though it's SciPy PR, it is a must to merge for sklearn spectral embedding and clustering that relies on SciPy to construct the graph Laplacian.
[2022-03-06T16:11:22.361Z] <5a0d62aed73408ce4f7ed9b2> @adrinjalali Hi, thanks for your advice. Here is my code: ``` import numpy as np from sklearn.pipeline import Pipeline from sklearn.preprocessing import MinMaxScaler from sklearn.compose import TransformedTargetRegressor from sklearn.neighbors import KNeighborsRegressor from sklearn.model_selection import GridSearchCV  target_scaler = MinMaxScaler() estimator = Pipeline([         ('scaler', MinMaxScaler()),         ('model', TransformedTargetRegressor(           KNeighborsRegressor(metric='precomputed'),           transformer=target_scaler         ))])  grid_params = {'model__regressor__n_neighbors': [3, 5, 7]} scoring = 'accuracy' clf = GridSearchCV(estimator, param_grid=grid_params,                        scoring=scoring,                        cv=5, return_train_score=True, refit=True,                        error_score='raise')  D_app = np.random.rand(10, 10) y_app = np.random.rand(10) clf.fit(D_app, y_app) ``` The following error is raised: ``` File "/media/ljia/DATA/research-repo/projects/202110 Redox/codes/Redox/issues/target_scaling.py", line 34, in <module>     clf.fit(D_app, y_app)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py", line 891, in fit     self._run_search(evaluate_candidates)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py", line 1392, in _run_search     evaluate_candidates(ParameterGrid(self.param_grid))    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py", line 838, in evaluate_candidates     out = parallel(    File "/home/ljia/.local/lib/python3.8/site-packages/joblib/parallel.py", line 1043, in __call__     if self.dispatch_one_batch(iterator):    File "/home/ljia/.local/lib/python3.8/site-packages/joblib/parallel.py", line 861, in dispatch_one_batch     self._dispatch(tasks)    File "/home/ljia/.local/lib/python3.8/site-packages/joblib/parallel.py", line 779, in _dispatch     job = self._backend.apply_async(batch, callback=cb)    File "/home/ljia/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 208, in apply_async     result = ImmediateResult(func)    File "/home/ljia/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py", line 572, in __init__     self.results = batch()    File "/home/ljia/.local/lib/python3.8/site-packages/joblib/parallel.py", line 262, in __call__     return [func(*args, **kwargs)    File "/home/ljia/.local/lib/python3.8/site-packages/joblib/parallel.py", line 262, in <listcomp>     return [func(*args, **kwargs)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py", line 211, in __call__     return self.function(*args, **kwargs)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 681, in _fit_and_score     estimator.fit(X_train, y_train, **fit_params)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/pipeline.py", line 394, in fit     self._final_estimator.fit(Xt, y, **fit_params_last_step)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/compose/_target.py", line 246, in fit     self.regressor_.fit(X, y_trans, **fit_params)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/neighbors/_regression.py", line 213, in fit     return self._fit(X, y)    File "/home/ljia/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py", line 489, in _fit     raise ValueError(  ValueError: Precomputed matrix must be square. Input is a 8x10 matrix. ``` May I ask what may be the problem? In case it is not supported, are there other ways to correctly scale targets in GridSearchCV (as well as HalvingGridSearchCV, etc.)? Thank you very much!
[2022-03-14T17:36:21.367Z] <5f31510fd73408ce4febd603> Hello! I hope everyone is well. Just wondering, when is the next sklearn release happening, `1.0.3`?
[2022-03-15T11:24:10.783Z] <592e4901d73408ce4f638303> Hello Everyone, I have a very specific use case designed around scikit-learn and wanted to see if it was possible to code it up. The overall idea is to train a 1D embedding using a pretrained GLM. For this, I take a pretrained Poisson Regressor model trained using scikit-learn(this is GIVEN and persay has been trained on 50 features), I want to add a new feature to it i.e a random variable X ~ N(0, 1) and retrain the model to get a 51 parameter model. Once this is done, I treat the input X as a parameter, freeze the model and get optimal value for X_i using gradient based approaches. Finally, upon having the optimal set of X_i, I want to retrain end to end using all 51 features. This is the gist of the algorithm that is designed. Any leads towards APIs or whether this is achievable or not would be really helpful. Thanks!
[2022-03-23T19:53:00.097Z] <564789be16b6c7089cbab8b7> in sklearn.inspection.permutation_importance(estimator, X, y, *, scoring=None, n_repeats=5, n_jobs=None, random_state=None, sample_weight=None, max_samples=1.0 what is the default for scoring? 
[2022-03-23T19:53:56.501Z] <564789be16b6c7089cbab8b7> A " baseline metric, defined by scoring, is evaluated on a (potentially different) dataset defined by the x" so it has to be something
[2022-03-24T17:33:37.338Z] <matrix-ogrisel:matrix.org> I think it's using `estimator.score(X_test, y_test)` by default.
[2022-03-24T17:33:49.140Z] <matrix-ogrisel:matrix.org> So accuracy for classifier and R2 for regressors.
[2022-03-25T14:11:58.164Z] <564789be16b6c7089cbab8b7> @ogrisel:matrix.org  thank you
[2022-03-25T14:12:32.495Z] <564789be16b6c7089cbab8b7> I am really confused though...
[2022-03-25T14:12:48.461Z] <564789be16b6c7089cbab8b7> model = xgbr.fit(X_train, y_train) print(model.score(X_test, y_test)) r = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=0) for i in r.importances_mean.argsort()[::-1]:     print(f"{r.importances_mean[i]:.3f}" f" +/- {r.importances_std[i]:.3f}") 
[2022-03-25T14:13:34.734Z] <564789be16b6c7089cbab8b7> that simple code that give feature importance gives me a value over 1.20 for the top one. But how can you have a permutation feature importance higher than 1?
[2022-03-27T05:45:09.186Z] <564789be16b6c7089cbab8b7> At least a partial answer is that r2 can be arbitrarily negative 
[2022-04-29T10:38:56.241Z] <5e7de2b6d73408ce4fde36e6> Hi! I promoted the scikit-learn office hours on PyLadies slack and WiMLDS slack because many people don't seem to be aware of them. I also did a tweet via PyLadies Berlin (https://twitter.com/PyLadiesBer/status/1519981569343164417). I think that the biweekly office hours is a great initiative that is especially helpful for folks belonging to groups which are underrepresented in tech and open source. I hope that the office hours and also spreading the word about them in these communities will help with contributor retention. 
[2022-04-29T11:57:27.960Z] <55d21ee30fc9f982beadabb8> Thanks Maren. Indeed, I assume that it could be motivating to have a closer follow-up on some PR.
[2022-05-16T18:31:07.100Z] <62828ace6da0373984968dd7> Hi everyone, i'm new in this community and i want to apologize in advance for any errors i might make in asking the following question. So, i have to implement a classification task using scikit-multiflow for a big dataset (84 feature x 2,5 milion of exemples), processed like a stream. After many and many attempts my code finally run without warnings or errors but there is a problem: i am using the class Evaluate Prequential and its methods for the classification and, by setting adquate metrics to evaluate the goodness of this classification, i obtain very high values for each metric used. This is "strange" considering the dataset i am working on, reason why i want to generate the confusion matrix in order to understand on wich classes my classification algorithm works better and on wich classes it makes more misclassification. Generating confusion matrix is very easy using scikit-learn, but this method needs to have as input parameter true labels and predicted labels and here is the problem: i cannot isolate from Evaluate Prequential, in particular from the method "evaluate", predicted labels, consequently i have no way to generate the confusion matrix because i have not predicted labels to make a comparison with true labels. For sure there is trick to get around this problem but all of my attempts since two days failed and i have no more ideas on how i could do it. Please, do you have an idea on how to solve this problem? Thank you a lot.
[2022-05-27T22:53:44.890Z] <matrix-auw9da:matrix.org> ok I have a set of market returns. But I want to explain the returns using a set of features, then find the hierarchy and find an equal weighted portfolio that minimizes variance. How can this be done?
[2022-05-27T22:53:51.312Z] <matrix-auw9da:matrix.org> ``ok I have a set of market returns. But I want to explain the returns using a set of features, then find the hierarchy``
[2022-05-27T22:54:00.921Z] <matrix-auw9da:matrix.org> this much Idk how to do, I can figure out the rest.
[2022-06-01T14:06:06.958Z] <579618a040f3a6eec05c5e42> Hey folks, I have maybe a silly question. But is there any fundamental difference between `model_selection.cross_validate` and doing it manually?  For instance, take a look at the example below, I can't figure out why the roc scores in red are different while the logloss scores in green are the same?  I expect that the roc scores should match, unless I'm doing sth stupid and haven't noticed yet?
[2022-06-01T14:06:25.160Z] <579618a040f3a6eec05c5e42> [![image.png](https://files.gitter.im/541a528c163965c9bc2053e1/s4Ci/thumb/image.png)](https://files.gitter.im/541a528c163965c9bc2053e1/s4Ci/image.png)
[2022-06-01T15:08:48.698Z] <579618a040f3a6eec05c5e42> I seems that `cross_validate` uses silently a different splitting mechanism depending on label `y`. For int/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, Fold is used.  If that's true then this is an undesired behaviour for me as a user. I want things to be explicit and not implicit like this spending hours searching to find what's going on?  On an additional note I don't understand the phrase `In all other cases, Fold is used.`, so in the case of my example instead of using `StratifiedGroupKFold` is `cross_validate` implicitly using just `Fold`?
[2022-06-02T08:42:33.233Z] <55d21ee30fc9f982beadabb8> > If that's true then this is an undesired behaviour for me as a user. I want things to be explicit and not implicit like this spending hours searching to find what's going on?  Stratification will always be the best but this is not possible with regression. So we stated in the `cv` argument doc and the user guide as well:  > When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin.  One should improve the documentation to make it explicit for the default `None` and add `cross_validate` together with `cross_val_score`.
[2022-06-02T08:49:01.715Z] <55d21ee30fc9f982beadabb8> > On an additional note I don't understand the phrase In all other cases, Fold is used., so in the case of my example instead of using StratifiedGroupKFold is cross_validate implicitly using just Fold?  Oh actually this is already documented properly. `Fold` is a typo, it should be replace with `KFold` and link to the cv splitter.
[2022-06-05T04:41:38.548Z] <56805cf416b6c7089cc051b2> Any suggestions on how to get my PR reviewed? 
[2022-06-05T06:11:27.466Z] <628dfd066da03739849737d8> If your PR is ready, you can add [MRG] to the title of PR. You can check the PR checklist: https://scikit-learn.org/dev/developers/contributing.html#pull-request-checklist. And I found the wiki have some reviewers you can ping: https://github.com/scikit-learn/scikit-learn/wiki/Available-reviewers.
[2022-06-05T06:15:35.361Z] <56805cf416b6c7089cc051b2> Thanks! I didn't know about that checklist
[2022-06-09T14:20:51.646Z] <5f31510fd73408ce4febd603> Hello, I see `ElasticNet` does not have an `n_jobs` parameter. Does that mean it uses all available resources on the machine to train? https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html
