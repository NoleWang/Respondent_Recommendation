{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7684e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb1c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fd264",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94776a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training files\n",
    "df_etd_training = pd.read_csv(\"../Data/chat_pattern/training/etd_pattern_training.csv\")\n",
    "df_ps_training = pd.read_csv(\"../Data/chat_pattern/training/ps_pattern_training.csv\")\n",
    "df_ngram_training = pd.read_csv(\"../Data/chat_pattern/training/ngram_training.csv\")\n",
    "df_pos_training = pd.read_csv(\"../Data/chat_pattern/training/pos_training.csv\")\n",
    "\n",
    "#testing files\n",
    "df_etd_testing = pd.read_csv(\"../Data/chat_pattern/testing/etd_pattern_testing.csv\")\n",
    "df_ps_testing = pd.read_csv(\"../Data/chat_pattern/testing/ps_pattern_testing.csv\")\n",
    "df_ngram_testing = pd.read_csv(\"../Data/chat_pattern/testing/ngram_testing.csv\")\n",
    "df_pos_testing = pd.read_csv(\"../Data/chat_pattern/testing/pos_testing.csv\")\n",
    "\n",
    "#label\n",
    "df_label_training = pd.read_csv(\"../Data/chat_pattern/chat_annotation_1000_pos.csv\")\n",
    "df_label_testing = pd.read_csv(\"../Data/chat_pattern/chat_testing_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etd_train = df_etd_training.values\n",
    "X_ps_train = df_ps_training.values\n",
    "X_ngram_train = df_ngram_training.values\n",
    "X_pos_train = df_pos_training.values\n",
    "\n",
    "X_etd_ngram_train = np.hstack((X_etd_train, X_ngram_train))\n",
    "X_ps_ngram_train = np.hstack((X_ps_train, X_ngram_train))\n",
    "X_etd_pos_train = np.hstack((X_etd_train, X_pos_train))\n",
    "X_ps_pos_train = np.hstack((X_ps_train, X_pos_train))\n",
    "X_ngram_pos_train = np.hstack((X_ngram_train, X_pos_train))\n",
    "\n",
    "X_all_etd_train = np.hstack((X_etd_ngram_train, X_pos_train))\n",
    "X_all_ps_train = np.hstack((X_ps_ngram_train, X_pos_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59eb6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etd_test = df_etd_testing.values\n",
    "X_ps_test = df_ps_testing.values\n",
    "X_ngram_test = df_ngram_testing.values\n",
    "X_pos_test = df_pos_testing.values\n",
    "\n",
    "\n",
    "X_etd_ngram_test = np.hstack((X_etd_test, X_ngram_test))\n",
    "X_etd_pos_test = np.hstack((X_etd_test, X_pos_test))\n",
    "X_ngram_pos_test = np.hstack((X_ngram_test, X_pos_test))\n",
    "X_ps_ngram_test = np.hstack((X_ps_test, X_ngram_test))\n",
    "X_ps_pos_test = np.hstack((X_ps_test, X_pos_test))\n",
    "\n",
    "X_all_etd_test = np.hstack((X_etd_ngram_test, X_pos_test))\n",
    "X_all_ps_test = np.hstack((X_ngram_pos_test, X_pos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1400154",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_etd_train = df_label_training[\"y_ETD\"].values\n",
    "y_ps_train = df_label_training[\"y_PS\"].values\n",
    "y_etd_test = df_label_testing[\"y_ETD\"].values\n",
    "y_ps_test = df_label_testing[\"y_PS\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437fe43",
   "metadata": {},
   "source": [
    "## Train Test Split (10-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319b6b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>issue</th>\n",
       "      <th>PS_sent</th>\n",
       "      <th>predicted_PS</th>\n",
       "      <th>ETD_sent</th>\n",
       "      <th>predicted_ETD</th>\n",
       "      <th>y_PS</th>\n",
       "      <th>y'_PS</th>\n",
       "      <th>Acc_PS</th>\n",
       "      <th>y_ETD</th>\n",
       "      <th>y'_ETD</th>\n",
       "      <th>Acc_ETD</th>\n",
       "      <th>openAI_PS</th>\n",
       "      <th>Inferred_PS_pattern</th>\n",
       "      <th>y''_PS</th>\n",
       "      <th>ACC_AI_PS</th>\n",
       "      <th>openAI_ETD</th>\n",
       "      <th>Inferred_ETD_pattern</th>\n",
       "      <th>y''_ETD</th>\n",
       "      <th>ACC_AI_ETD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angular</td>\n",
       "      <td>Hi, when I am trying to apply class dynamicall...</td>\n",
       "      <td>T2: it is messing up my material css i.e I am ...</td>\n",
       "      <td>PS_NEG_VERB,PS_NEG_AUX_ADV_ADJ,PS_NEG_AUX_VERB,</td>\n",
       "      <td>T1: when I am trying to apply class dynamicall...</td>\n",
       "      <td>ETD_TRYING_TO,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The sentence \"\"\" it is messing up my material ...</td>\n",
       "      <td>PS_NEG_VERB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"\"\" when I am trying to apply cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angular</td>\n",
       "      <td>is it possible to get a RouteConfig matched ag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T1: I'm trying to create a Breadcrumb componen...</td>\n",
       "      <td>ETD_BE_POSSIBLE_TO,ETD_TRYING_TO,ETD_WOULD_LIKE,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No patterns found. The answer is NO.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"\"\" I'm trying to create a Breadc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I have angular running from a .Net Core server...</td>\n",
       "      <td>T1: The server won't even load the app (by des...</td>\n",
       "      <td>PS_NEG_AUX_VERB,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No patterns found. The answer is NO.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The sentence \"\"\" What's the best way for the a...</td>\n",
       "      <td>new</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angular</td>\n",
       "      <td>Hello everyone, I want to do sub menu with sea...</td>\n",
       "      <td>T2: but  i have problem in sub menu</td>\n",
       "      <td>PS_PROBLEM,</td>\n",
       "      <td>T1: I want to do sub menu with searh like in g...</td>\n",
       "      <td>ETD_WANT_TO,ETD_CAN_QUESTION,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The sentence \"\"\" i have problem in sub menu wi...</td>\n",
       "      <td>\"problem\" is the [error-term]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"i have problem in sub menu with ...</td>\n",
       "      <td>new</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angular</td>\n",
       "      <td>I'm struggling with getting this logic\\n      ...</td>\n",
       "      <td>T1: I'm struggling with getting this logic</td>\n",
       "      <td>PS_STRUGGLING,PS_VERB_NO,</td>\n",
       "      <td>T2: I wanted to set a default value to the dro...</td>\n",
       "      <td>ETD_WANT_TO,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The sentence \"I'm struggling with getting this...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"\"\"I wanted to set a default valu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                              issue  \\\n",
       "0  angular  Hi, when I am trying to apply class dynamicall...   \n",
       "1  angular  is it possible to get a RouteConfig matched ag...   \n",
       "2      NaN  I have angular running from a .Net Core server...   \n",
       "3  angular  Hello everyone, I want to do sub menu with sea...   \n",
       "4  angular  I'm struggling with getting this logic\\n      ...   \n",
       "\n",
       "                                             PS_sent  \\\n",
       "0  T2: it is messing up my material css i.e I am ...   \n",
       "1                                                NaN   \n",
       "2  T1: The server won't even load the app (by des...   \n",
       "3                T2: but  i have problem in sub menu   \n",
       "4         T1: I'm struggling with getting this logic   \n",
       "\n",
       "                                      predicted_PS  \\\n",
       "0  PS_NEG_VERB,PS_NEG_AUX_ADV_ADJ,PS_NEG_AUX_VERB,   \n",
       "1                                              NaN   \n",
       "2                                 PS_NEG_AUX_VERB,   \n",
       "3                                      PS_PROBLEM,   \n",
       "4                        PS_STRUGGLING,PS_VERB_NO,   \n",
       "\n",
       "                                            ETD_sent  \\\n",
       "0  T1: when I am trying to apply class dynamicall...   \n",
       "1  T1: I'm trying to create a Breadcrumb componen...   \n",
       "2                                                NaN   \n",
       "3  T1: I want to do sub menu with searh like in g...   \n",
       "4  T2: I wanted to set a default value to the dro...   \n",
       "\n",
       "                                      predicted_ETD  y_PS  y'_PS  Acc_PS  \\\n",
       "0                                    ETD_TRYING_TO,     1      1       1   \n",
       "1  ETD_BE_POSSIBLE_TO,ETD_TRYING_TO,ETD_WOULD_LIKE,     0      0       1   \n",
       "2                                               NaN     1      1       1   \n",
       "3                     ETD_WANT_TO,ETD_CAN_QUESTION,     1      1       1   \n",
       "4                                      ETD_WANT_TO,     1      1       1   \n",
       "\n",
       "   y_ETD  y'_ETD  Acc_ETD                                          openAI_PS  \\\n",
       "0      1       1        1  The sentence \"\"\" it is messing up my material ...   \n",
       "1      1       1        1               No patterns found. The answer is NO.   \n",
       "2      0       0        1               No patterns found. The answer is NO.   \n",
       "3      1       1        1  The sentence \"\"\" i have problem in sub menu wi...   \n",
       "4      1       1        1  The sentence \"I'm struggling with getting this...   \n",
       "\n",
       "             Inferred_PS_pattern  y''_PS  ACC_AI_PS  \\\n",
       "0                    PS_NEG_VERB     1.0        1.0   \n",
       "1                            NaN     0.0        1.0   \n",
       "2                            NaN     0.0        0.0   \n",
       "3  \"problem\" is the [error-term]     1.0        1.0   \n",
       "4                            NaN     1.0        1.0   \n",
       "\n",
       "                                          openAI_ETD Inferred_ETD_pattern  \\\n",
       "0  The sentence \"\"\" when I am trying to apply cla...                  NaN   \n",
       "1  The sentence \"\"\" I'm trying to create a Breadc...                  NaN   \n",
       "2  The sentence \"\"\" What's the best way for the a...                  new   \n",
       "3  The sentence \"i have problem in sub menu with ...                  new   \n",
       "4  The sentence \"\"\"I wanted to set a default valu...                  NaN   \n",
       "\n",
       "   y''_ETD  ACC_AI_ETD  \n",
       "0      1.0         1.0  \n",
       "1      1.0         1.0  \n",
       "2      1.0         0.0  \n",
       "3      1.0         1.0  \n",
       "4      1.0         1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"../Data/chat_pattern/chat_test_1000.csv\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e14d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random = df_all.sample(n=len(df_all),ignore_index=True)\n",
    "df_split = np.array_split(df_random, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7d9a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"../Data/chat_pattern/cross_validate/\"\n",
    "for i in range(len(df_split)):\n",
    "    df_split = np.array_split(df_random, 10)\n",
    "    df_test = df_split[i]\n",
    "    df_val = df_split[len(df_split)-i-1]\n",
    "    frame_train = [df_split[index] for index in range(len(df_split)) if index != i and index != (len(df_split)-i-1)]\n",
    "    df_train = pd.concat(frame_train)\n",
    "    \n",
    "    if not os.path.exists(train_path+str(i)+\"/\"):\n",
    "        os.makedirs(train_path+str(i)+\"/\")\n",
    "        \n",
    "    df_train.to_csv(train_path+str(i)+\"/\"+\"train_800.csv\",index = None)\n",
    "    df_val.to_csv(train_path+str(i)+\"/\"+\"val_100.csv\",index = None)\n",
    "    df_test.to_csv(train_path+str(i)+\"/\"+\"test_100.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dac4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etd_train_list = []\n",
    "X_ps_train_list = []\n",
    "X_ngram_train_list = []\n",
    "X_pos_train_list = []\n",
    "X_etd_ngram_train_list = []\n",
    "X_ps_ngram_train_list = []\n",
    "X_etd_pos_train_list = []\n",
    "X_ps_pos_train_list = []\n",
    "X_ngram_pos_train_list = []\n",
    "X_all_etd_train_list = []\n",
    "X_all_ps_train_list = []\n",
    "\n",
    "X_etd_test_list = []\n",
    "X_ps_test_list = []\n",
    "X_ngram_test_list = []\n",
    "X_pos_test_list = []\n",
    "X_etd_ngram_test_list = []\n",
    "X_ps_ngram_test_list = []\n",
    "X_etd_pos_test_list = []\n",
    "X_ps_pos_test_list = []\n",
    "X_ngram_pos_test_list = []\n",
    "X_all_etd_test_list = []\n",
    "X_all_ps_test_list = []\n",
    "\n",
    "X_etd_val_list = []\n",
    "X_ps_val_list = []\n",
    "X_ngram_val_list = []\n",
    "X_pos_val_list = []\n",
    "X_etd_ngram_val_list = []\n",
    "X_ps_ngram_val_list = []\n",
    "X_etd_pos_val_list = []\n",
    "X_ps_pos_val_list = []\n",
    "X_ngram_pos_val_list = []\n",
    "X_all_etd_val_list = []\n",
    "X_all_ps_val_list = []\n",
    "\n",
    "y_etd_train_list = []\n",
    "y_ps_train_list = []\n",
    "y_etd_test_list = []\n",
    "y_ps_test_list = []\n",
    "y_etd_val_list = []\n",
    "y_ps_val_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc271f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_10fold_data(path):\n",
    "    dir_list = os.listdir(path)\n",
    "    for folder in dir_list:\n",
    "        #training files\n",
    "        df_etd_train = pd.read_csv(path+folder+\"/train/etd_pattern_train.csv\")\n",
    "        df_ps_train = pd.read_csv(path+folder+\"/train/ps_pattern_train.csv\")\n",
    "        df_ngram_train = pd.read_csv(path+folder+\"/train/ngram_train.csv\")\n",
    "        df_pos_train = pd.read_csv(path+folder+\"/train/pos_train.csv\")\n",
    "\n",
    "        #test files\n",
    "        df_etd_test = pd.read_csv(path+folder+\"/test/etd_pattern_test.csv\")\n",
    "        df_ps_test = pd.read_csv(path+folder+\"/test/ps_pattern_test.csv\")\n",
    "        df_ngram_test = pd.read_csv(path+folder+\"/test/ngram_test.csv\")\n",
    "        df_pos_test = pd.read_csv(path+folder+\"/test/pos_test.csv\")\n",
    "        \n",
    "        #validation files\n",
    "        df_etd_val = pd.read_csv(path+folder+\"/val/etd_pattern_val.csv\")\n",
    "        df_ps_val = pd.read_csv(path+folder+\"/val/ps_pattern_val.csv\")\n",
    "        df_ngram_val = pd.read_csv(path+folder+\"/val/ngram_val.csv\")\n",
    "        df_pos_val = pd.read_csv(path+folder+\"/val/pos_val.csv\")\n",
    "\n",
    "        #label\n",
    "        df_label_train = pd.read_csv(path+folder+\"/train_800.csv\")\n",
    "        df_label_test = pd.read_csv(path+folder+\"/test_100.csv\")\n",
    "        df_label_val = pd.read_csv(path+folder+\"/val_100.csv\")\n",
    "        \n",
    "        #train\n",
    "        X_etd_train = df_etd_train.values\n",
    "        X_ps_train = df_ps_train.values\n",
    "        X_ngram_train = df_ngram_train.values\n",
    "        X_pos_train = df_pos_train.values\n",
    "\n",
    "        X_etd_ngram_train = np.hstack((X_etd_train, X_ngram_train))\n",
    "        X_ps_ngram_train = np.hstack((X_ps_train, X_ngram_train))\n",
    "        X_etd_pos_train = np.hstack((X_etd_train, X_pos_train))\n",
    "        X_ps_pos_train = np.hstack((X_ps_train, X_pos_train))\n",
    "        X_ngram_pos_train = np.hstack((X_ngram_train, X_pos_train))\n",
    "\n",
    "        X_all_etd_train = np.hstack((X_etd_ngram_train, X_pos_train))\n",
    "        X_all_ps_train = np.hstack((X_ps_ngram_train, X_pos_train))\n",
    "        \n",
    "        #test\n",
    "        X_etd_test = df_etd_test.values\n",
    "        X_ps_test = df_ps_test.values\n",
    "        X_ngram_test = df_ngram_test.values\n",
    "        X_pos_test = df_pos_test.values\n",
    "\n",
    "        X_etd_ngram_test = np.hstack((X_etd_test, X_ngram_test))\n",
    "        X_etd_pos_test = np.hstack((X_etd_test, X_pos_test))\n",
    "        X_ngram_pos_test = np.hstack((X_ngram_test, X_pos_test))\n",
    "        X_ps_ngram_test = np.hstack((X_ps_test, X_ngram_test))\n",
    "        X_ps_pos_test = np.hstack((X_ps_test, X_pos_test))\n",
    "\n",
    "        X_all_etd_test = np.hstack((X_etd_ngram_test, X_pos_test))\n",
    "        X_all_ps_test = np.hstack((X_ps_ngram_test, X_pos_test))\n",
    "        \n",
    "        #val\n",
    "        X_etd_val = df_etd_val.values\n",
    "        X_ps_val = df_ps_val.values\n",
    "        X_ngram_val = df_ngram_val.values\n",
    "        X_pos_val = df_pos_val.values\n",
    "\n",
    "        X_etd_ngram_val = np.hstack((X_etd_val, X_ngram_val))\n",
    "        X_etd_pos_val = np.hstack((X_etd_val, X_pos_val))\n",
    "        X_ngram_pos_val = np.hstack((X_ngram_val, X_pos_val))\n",
    "        X_ps_ngram_val = np.hstack((X_ps_val, X_ngram_val))\n",
    "        X_ps_pos_val = np.hstack((X_ps_val, X_pos_val))\n",
    "\n",
    "        X_all_etd_val = np.hstack((X_etd_ngram_val, X_pos_val))\n",
    "        X_all_ps_val = np.hstack((X_ps_ngram_val, X_pos_val))\n",
    "        \n",
    "        y_etd_train = df_label_train[\"y_ETD\"].values\n",
    "        y_ps_train = df_label_train[\"y_PS\"].values\n",
    "        y_etd_test = df_label_test[\"y_ETD\"].values\n",
    "        y_ps_test = df_label_test[\"y_PS\"].values\n",
    "        y_etd_val = df_label_val[\"y_ETD\"].values\n",
    "        y_ps_val = df_label_val[\"y_PS\"].values\n",
    "        \n",
    "        X_etd_train_list.append(X_etd_train)\n",
    "        X_ps_train_list.append(X_ps_train)\n",
    "        X_ngram_train_list.append(X_ngram_train)\n",
    "        X_pos_train_list.append(X_pos_train)\n",
    "        X_etd_ngram_train_list.append(X_etd_ngram_train)\n",
    "        X_ps_ngram_train_list.append(X_ps_ngram_train)\n",
    "        X_etd_pos_train_list.append(X_etd_pos_train)\n",
    "        X_ps_pos_train_list.append(X_ps_pos_train)\n",
    "        X_ngram_pos_train_list.append(X_ngram_pos_train)\n",
    "        X_all_etd_train_list.append(X_all_etd_train)\n",
    "        X_all_ps_train_list.append(X_all_ps_train)\n",
    "        \n",
    "        X_etd_test_list.append(X_etd_test)\n",
    "        X_ps_test_list.append(X_ps_test)\n",
    "        X_ngram_test_list.append(X_ngram_test)\n",
    "        X_pos_test_list.append(X_pos_test)\n",
    "        X_etd_ngram_test_list.append(X_etd_ngram_test)\n",
    "        X_ps_ngram_test_list.append(X_ps_ngram_test)\n",
    "        X_etd_pos_test_list.append(X_etd_pos_test)\n",
    "        X_ps_pos_test_list.append(X_ps_pos_test)\n",
    "        X_ngram_pos_test_list.append(X_ngram_pos_test)\n",
    "        X_all_etd_test_list.append(X_all_etd_test)\n",
    "        X_all_ps_test_list.append(X_all_ps_test)\n",
    "        \n",
    "        X_etd_val_list.append(X_etd_val)\n",
    "        X_ps_val_list.append(X_ps_val)\n",
    "        X_ngram_val_list.append(X_ngram_val)\n",
    "        X_pos_val_list.append(X_pos_val)\n",
    "        X_etd_ngram_val_list.append(X_etd_ngram_val)\n",
    "        X_ps_ngram_val_list.append(X_ps_ngram_val)\n",
    "        X_etd_pos_val_list.append(X_etd_pos_val)\n",
    "        X_ps_pos_val_list.append(X_ps_pos_val)\n",
    "        X_ngram_pos_val_list.append(X_ngram_pos_val)\n",
    "        X_all_etd_val_list.append(X_all_etd_val)\n",
    "        X_all_ps_val_list.append(X_all_ps_val)\n",
    "        \n",
    "        y_etd_train_list.append(y_etd_train)\n",
    "        y_ps_train_list.append(y_ps_train)\n",
    "        y_etd_test_list.append(y_etd_test)\n",
    "        y_ps_test_list.append(y_ps_test)\n",
    "        y_etd_val_list.append(y_etd_val)\n",
    "        y_ps_val_list.append(y_ps_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6d0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_10fold_data(\"../Data/chat_pattern/cross_validate/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b9ee8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4427a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(X_train, y_train, X_test, y_test):\n",
    "    y_test_model = []\n",
    "    yhat_model = []\n",
    "    param_grid = {'C': np.linspace(0.001, 100, 20)}\n",
    "    \n",
    "    svc = SVC()\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print('CV Train score: {:.2f}'.format(grid_search.best_score_))\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    \n",
    "    predictions = grid_search.predict(X_test)\n",
    "    precison = mt.precision_score(y_test, predictions)\n",
    "    recall = mt.recall_score(y_test, predictions)\n",
    "    score = mt.f1_score(y_test, predictions)\n",
    "    \n",
    "    print(\"precision:\",round(precison,3),\"recall:\",round(recall,3),\"F1:\",round(score,3))\n",
    "    \n",
    "    for val in zip(y_test, predictions):\n",
    "        yhat_model.append(val[1])\n",
    "        y_test_model.append(val[0])\n",
    "    \n",
    "    return precison,recall,score, y_test_model, yhat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_2(X_train, y_train, X_test, y_test):\n",
    "    y_test_model = []\n",
    "    yhat_model = []\n",
    "    param_grid = {'C': np.linspace(0.001, 100, 20)}\n",
    "    \n",
    "    svc = SVC()\n",
    "    scoring = {'Precision': 'precision', 'Recall':'recall', 'F1': 'f1'}\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=10, scoring = scoring, refit = \"F1\")\n",
    "    \n",
    "    #X_train = np.vstack((X_train, X_test))\n",
    "    #y_train = np.concatenate((y_train, y_test))\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    #print('CV Train score: {:.2f}'.format(grid_search.best_score_))\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    \n",
    "    results = grid_search.cv_results_\n",
    "    \n",
    "    precison = np.average(results[\"mean_test_Precision\"])\n",
    "    recall = np.average(results[\"mean_test_Recall\"])\n",
    "    score = np.average(results[\"mean_test_F1\"])\n",
    "    \n",
    "    print(\"precision:\",round(precison,3),\"recall:\",round(recall,3),\"F1:\",round(score,3))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86e2f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X_train_list, y_train_list, X_test_list, y_test_list, X_val_list, y_val_list):\n",
    "    \n",
    "    param_grid = {'C': np.linspace(0.001, 100, 20)}\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for X_train,y_train,X_test,y_test,X_val,y_val in zip(X_train_list, y_train_list, X_test_list, y_test_list, X_val_list, y_val_list):\n",
    "        svc = SVC()\n",
    "        grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
    "        grid_search.fit(X_val, y_val)\n",
    "    \n",
    "        #print('CV Train score: {:.2f}'.format(grid_search.best_score_))\n",
    "        #print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "        \n",
    "        clf = SVC(**grid_search.best_params_)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        precison = mt.precision_score(y_test, predictions)\n",
    "        recall = mt.recall_score(y_test, predictions)\n",
    "        score = mt.f1_score(y_test, predictions)\n",
    "        \n",
    "        precision_list.append(precison)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(score)\n",
    "    \n",
    "    print(\"precision:\",round(np.average(precision_list),3),\"recall:\",round(np.average(recall_list),3),\"F1:\",round(np.average(f1_list),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771d227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate1(X_train_list, y_train_list, X_test_list, y_test_list, X_val_list, y_val_list):\n",
    "    \n",
    "    param_grid = {'C': np.linspace(0.001, 100, 20)}\n",
    "    \n",
    "    for X_train,y_train,X_test,y_test,X_val,y_val in zip(X_train_list, y_train_list, X_test_list, y_test_list, X_val_list, y_val_list):\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        \n",
    "        svc = SVC()\n",
    "        grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
    "        grid_search.fit(X_val, y_val)\n",
    "    \n",
    "        #print('CV Train score: {:.2f}'.format(grid_search.best_score_))\n",
    "        #print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "        \n",
    "        clf = SVC(**grid_search.best_params_)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        precison = mt.precision_score(y_test, predictions)\n",
    "        recall = mt.recall_score(y_test, predictions)\n",
    "        score = mt.f1_score(y_test, predictions)\n",
    "        \n",
    "        precision_list.append(precison)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(score)\n",
    "    \n",
    "    print(\"precision:\",round(np.average(precision_list),3),\"recall:\",round(np.average(recall_list),3),\"F1:\",round(np.average(f1_list),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c8cac",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248835a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.877 recall: 0.778 F1: 0.824\n"
     ]
    }
   ],
   "source": [
    "# 1. ETD: pattern\n",
    "cross_validate(X_etd_train_list, y_etd_train_list, X_etd_test_list, y_etd_test_list, X_etd_val_list, y_etd_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9322a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.692 recall: 0.793 F1: 0.733\n"
     ]
    }
   ],
   "source": [
    "# 2. ETD: pos\n",
    "cross_validate(X_pos_train_list, y_etd_train_list, X_pos_test_list, y_etd_test_list, X_pos_val_list, y_etd_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40818a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.875 recall: 0.656 F1: 0.75\n"
     ]
    }
   ],
   "source": [
    "# 3. ETD: n-gram\n",
    "cross_validate(X_ngram_train_list, y_etd_train_list, X_ngram_test_list, y_etd_test_list,X_ngram_val_list, y_etd_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11631728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.73 recall: 0.844 F1: 0.783\n"
     ]
    }
   ],
   "source": [
    "# 4. ETD: pattern + pos\n",
    "cross_validate(X_etd_pos_train_list, y_etd_train_list, X_etd_pos_test_list, y_etd_test_list,X_etd_pos_val_list, y_etd_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7afc0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.895 recall: 0.797 F1: 0.843\n"
     ]
    }
   ],
   "source": [
    "# 5. ETD: pattern + n-gram\n",
    "cross_validate(X_etd_ngram_train_list, y_etd_train_list, X_etd_ngram_test_list, y_etd_test_list, X_etd_ngram_val_list, y_etd_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aea2784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.806 recall: 0.781 F1: 0.794\n"
     ]
    }
   ],
   "source": [
    "# 6. ETD: n-gram + pos\n",
    "cross_validate(X_ngram_pos_train_list, y_etd_train_list, X_ngram_pos_test_list, y_etd_test_list,X_ngram_pos_val_list, y_etd_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22a52f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.836 recall: 0.797 F1: 0.816\n"
     ]
    }
   ],
   "source": [
    "# 7. ETD: pattern + n-gram + pos\n",
    "cross_validate(X_all_etd_train_list, y_etd_train_list, X_all_etd_test_list, y_etd_test_list,X_all_etd_val_list, y_etd_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe1564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.872 recall: 0.889 F1: 0.88\n"
     ]
    }
   ],
   "source": [
    "# 8. PS: pattern\n",
    "cross_validate(X_ps_train_list, y_ps_train_list, X_ps_test_list, y_ps_test_list, X_ps_val_list, y_ps_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41f0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.752 recall: 0.907 F1: 0.815\n"
     ]
    }
   ],
   "source": [
    "# 9. PS: pos\n",
    "cross_validate(X_pos_train_list, y_ps_train_list, X_pos_test_list, y_ps_test_list,X_pos_val_list, y_ps_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef3ca512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.959 recall: 0.635 F1: 0.764\n"
     ]
    }
   ],
   "source": [
    "# 10. PS: n-gram\n",
    "cross_validate(X_ngram_train_list, y_ps_train_list, X_ngram_test_list, y_ps_test_list,X_ngram_val_list, y_ps_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f13fcf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.836 recall: 0.824 F1: 0.83\n"
     ]
    }
   ],
   "source": [
    "# 11. PS: pattern + pos\n",
    "cross_validate(X_ps_pos_train_list, y_ps_train_list, X_ps_pos_test_list, y_ps_test_list,X_ps_pos_val_list, y_ps_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bec803b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.93 recall: 0.716 F1: 0.809\n"
     ]
    }
   ],
   "source": [
    "# 12. PS: pattern + n-gram\n",
    "cross_validate(X_ps_ngram_train_list, y_ps_train_list, X_ps_ngram_test_list, y_ps_test_list,X_ps_ngram_val_list, y_ps_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8e839a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.845 recall: 0.811 F1: 0.828\n"
     ]
    }
   ],
   "source": [
    "# 13. PS: n-gram + pos\n",
    "cross_validate(X_ngram_pos_train_list, y_ps_train_list, X_ngram_pos_test_list, y_ps_test_list,X_ngram_pos_val_list, y_ps_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d92d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.861 recall: 0.838 F1: 0.849\n"
     ]
    }
   ],
   "source": [
    "# 14. PS: pattern + n-gram + pos\n",
    "cross_validate(X_all_ps_train_list, y_ps_train_list, X_all_ps_test_list, y_ps_test_list,X_all_ps_val_list, y_ps_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2eb844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
