{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e7684e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adb1c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fd264",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94776a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training files\n",
    "df_etd_training = pd.read_csv(\"../Data/chat_pattern/training/etd_pattern_training.csv\")\n",
    "df_ps_training = pd.read_csv(\"../Data/chat_pattern/training/ps_pattern_training.csv\")\n",
    "df_ngram_training = pd.read_csv(\"../Data/chat_pattern/training/ngram_training.csv\")\n",
    "df_pos_training = pd.read_csv(\"../Data/chat_pattern/training/pos_training.csv\")\n",
    "\n",
    "#testing files\n",
    "df_etd_testing = pd.read_csv(\"../Data/chat_pattern/testing/etd_pattern_testing.csv\")\n",
    "df_ps_testing = pd.read_csv(\"../Data/chat_pattern/testing/ps_pattern_testing.csv\")\n",
    "df_ngram_testing = pd.read_csv(\"../Data/chat_pattern/testing/ngram_testing.csv\")\n",
    "df_pos_testing = pd.read_csv(\"../Data/chat_pattern/testing/pos_testing.csv\")\n",
    "\n",
    "#label\n",
    "df_label_training = pd.read_csv(\"../Data/chat_pattern/chat_annotation_1000_pos.csv\")\n",
    "df_label_testing = pd.read_csv(\"../Data/chat_pattern/chat_testing_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etd_train = df_etd_training.values\n",
    "X_ps_train = df_ps_training.values\n",
    "X_ngram_train = df_ngram_training.values\n",
    "X_pos_train = df_pos_training.values\n",
    "\n",
    "X_etd_ngram_train = np.hstack((X_etd_train, X_ngram_train))\n",
    "X_ps_ngram_train = np.hstack((X_ps_train, X_ngram_train))\n",
    "X_etd_pos_train = np.hstack((X_etd_train, X_pos_train))\n",
    "X_ps_pos_train = np.hstack((X_ps_train, X_pos_train))\n",
    "X_ngram_pos_train = np.hstack((X_ngram_train, X_pos_train))\n",
    "\n",
    "X_all_etd_train = np.hstack((X_etd_ngram_train, X_pos_train))\n",
    "X_all_ps_train = np.hstack((X_ps_ngram_train, X_pos_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59eb6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etd_test = df_etd_testing.values\n",
    "X_ps_test = df_ps_testing.values\n",
    "X_ngram_test = df_ngram_testing.values\n",
    "X_pos_test = df_pos_testing.values\n",
    "\n",
    "\n",
    "X_etd_ngram_test = np.hstack((X_etd_test, X_ngram_test))\n",
    "X_etd_pos_test = np.hstack((X_etd_test, X_pos_test))\n",
    "X_ngram_pos_test = np.hstack((X_ngram_test, X_pos_test))\n",
    "X_ps_ngram_test = np.hstack((X_ps_test, X_ngram_test))\n",
    "X_ps_pos_test = np.hstack((X_ps_test, X_pos_test))\n",
    "\n",
    "X_all_etd_test = np.hstack((X_etd_ngram_test, X_pos_test))\n",
    "X_all_ps_test = np.hstack((X_ngram_pos_test, X_pos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1400154",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_etd_train = df_label_training[\"y_ETD\"].values\n",
    "y_ps_train = df_label_training[\"y_PS\"].values\n",
    "y_etd_test = df_label_testing[\"y_ETD\"].values\n",
    "y_ps_test = df_label_testing[\"y_PS\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437fe43",
   "metadata": {},
   "source": [
    "## Train Test Split (10-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319b6b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>issue</th>\n",
       "      <th>PS_sent</th>\n",
       "      <th>predicted_PS</th>\n",
       "      <th>ETD_sent</th>\n",
       "      <th>predicted_ETD</th>\n",
       "      <th>y_PS</th>\n",
       "      <th>y'_PS</th>\n",
       "      <th>Acc_PS</th>\n",
       "      <th>y_ETD</th>\n",
       "      <th>y'_ETD</th>\n",
       "      <th>Acc_ETD</th>\n",
       "      <th>openAI_PS</th>\n",
       "      <th>Inferred_PS_pattern</th>\n",
       "      <th>y''_PS</th>\n",
       "      <th>ACC_AI_PS</th>\n",
       "      <th>openAI_ETD</th>\n",
       "      <th>Inferred_ETD_pattern</th>\n",
       "      <th>y''_ETD</th>\n",
       "      <th>ACC_AI_ETD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angular</td>\n",
       "      <td>Hi, when I am trying to apply class dynamicall...</td>\n",
       "      <td>T2: it is messing up my material css i.e I am ...</td>\n",
       "      <td>PS_NEG_VERB,PS_NEG_AUX_ADV_ADJ,PS_NEG_AUX_VERB,</td>\n",
       "      <td>T1: when I am trying to apply class dynamicall...</td>\n",
       "      <td>ETD_TRYING_TO,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The sentence \"\"\" it is messing up my material ...</td>\n",
       "      <td>PS_NEG_VERB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"\"\" when I am trying to apply cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angular</td>\n",
       "      <td>is it possible to get a RouteConfig matched ag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T1: I'm trying to create a Breadcrumb componen...</td>\n",
       "      <td>ETD_BE_POSSIBLE_TO,ETD_TRYING_TO,ETD_WOULD_LIKE,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No patterns found. The answer is NO.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"\"\" I'm trying to create a Breadc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I have angular running from a .Net Core server...</td>\n",
       "      <td>T1: The server won't even load the app (by des...</td>\n",
       "      <td>PS_NEG_AUX_VERB,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No patterns found. The answer is NO.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The sentence \"\"\" What's the best way for the a...</td>\n",
       "      <td>new</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angular</td>\n",
       "      <td>Hello everyone, I want to do sub menu with sea...</td>\n",
       "      <td>T2: but  i have problem in sub menu</td>\n",
       "      <td>PS_PROBLEM,</td>\n",
       "      <td>T1: I want to do sub menu with searh like in g...</td>\n",
       "      <td>ETD_WANT_TO,ETD_CAN_QUESTION,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The sentence \"\"\" i have problem in sub menu wi...</td>\n",
       "      <td>\"problem\" is the [error-term]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"i have problem in sub menu with ...</td>\n",
       "      <td>new</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angular</td>\n",
       "      <td>I'm struggling with getting this logic\\n      ...</td>\n",
       "      <td>T1: I'm struggling with getting this logic</td>\n",
       "      <td>PS_STRUGGLING,PS_VERB_NO,</td>\n",
       "      <td>T2: I wanted to set a default value to the dro...</td>\n",
       "      <td>ETD_WANT_TO,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The sentence \"I'm struggling with getting this...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The sentence \"\"\"I wanted to set a default valu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                              issue  \\\n",
       "0  angular  Hi, when I am trying to apply class dynamicall...   \n",
       "1  angular  is it possible to get a RouteConfig matched ag...   \n",
       "2      NaN  I have angular running from a .Net Core server...   \n",
       "3  angular  Hello everyone, I want to do sub menu with sea...   \n",
       "4  angular  I'm struggling with getting this logic\\n      ...   \n",
       "\n",
       "                                             PS_sent  \\\n",
       "0  T2: it is messing up my material css i.e I am ...   \n",
       "1                                                NaN   \n",
       "2  T1: The server won't even load the app (by des...   \n",
       "3                T2: but  i have problem in sub menu   \n",
       "4         T1: I'm struggling with getting this logic   \n",
       "\n",
       "                                      predicted_PS  \\\n",
       "0  PS_NEG_VERB,PS_NEG_AUX_ADV_ADJ,PS_NEG_AUX_VERB,   \n",
       "1                                              NaN   \n",
       "2                                 PS_NEG_AUX_VERB,   \n",
       "3                                      PS_PROBLEM,   \n",
       "4                        PS_STRUGGLING,PS_VERB_NO,   \n",
       "\n",
       "                                            ETD_sent  \\\n",
       "0  T1: when I am trying to apply class dynamicall...   \n",
       "1  T1: I'm trying to create a Breadcrumb componen...   \n",
       "2                                                NaN   \n",
       "3  T1: I want to do sub menu with searh like in g...   \n",
       "4  T2: I wanted to set a default value to the dro...   \n",
       "\n",
       "                                      predicted_ETD  y_PS  y'_PS  Acc_PS  \\\n",
       "0                                    ETD_TRYING_TO,     1      1       1   \n",
       "1  ETD_BE_POSSIBLE_TO,ETD_TRYING_TO,ETD_WOULD_LIKE,     0      0       1   \n",
       "2                                               NaN     1      1       1   \n",
       "3                     ETD_WANT_TO,ETD_CAN_QUESTION,     1      1       1   \n",
       "4                                      ETD_WANT_TO,     1      1       1   \n",
       "\n",
       "   y_ETD  y'_ETD  Acc_ETD                                          openAI_PS  \\\n",
       "0      1       1        1  The sentence \"\"\" it is messing up my material ...   \n",
       "1      1       1        1               No patterns found. The answer is NO.   \n",
       "2      0       0        1               No patterns found. The answer is NO.   \n",
       "3      1       1        1  The sentence \"\"\" i have problem in sub menu wi...   \n",
       "4      1       1        1  The sentence \"I'm struggling with getting this...   \n",
       "\n",
       "             Inferred_PS_pattern  y''_PS  ACC_AI_PS  \\\n",
       "0                    PS_NEG_VERB     1.0        1.0   \n",
       "1                            NaN     0.0        1.0   \n",
       "2                            NaN     0.0        0.0   \n",
       "3  \"problem\" is the [error-term]     1.0        1.0   \n",
       "4                            NaN     1.0        1.0   \n",
       "\n",
       "                                          openAI_ETD Inferred_ETD_pattern  \\\n",
       "0  The sentence \"\"\" when I am trying to apply cla...                  NaN   \n",
       "1  The sentence \"\"\" I'm trying to create a Breadc...                  NaN   \n",
       "2  The sentence \"\"\" What's the best way for the a...                  new   \n",
       "3  The sentence \"i have problem in sub menu with ...                  new   \n",
       "4  The sentence \"\"\"I wanted to set a default valu...                  NaN   \n",
       "\n",
       "   y''_ETD  ACC_AI_ETD  \n",
       "0      1.0         1.0  \n",
       "1      1.0         1.0  \n",
       "2      1.0         0.0  \n",
       "3      1.0         1.0  \n",
       "4      1.0         1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"../Data/chat_pattern/chat_test_1000.csv\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e14d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random = df_all.sample(n=len(df_all),ignore_index=True)\n",
    "df_split = np.array_split(df_random, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7d9a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"../Data/chat_pattern/cross_validate/\"\n",
    "for i in range(len(df_split)):\n",
    "    df_split = np.array_split(df_random, 10)\n",
    "    df_test = df_split[i]\n",
    "    df_val = df_split[len(df_split)-i-1]\n",
    "    frame_train = [df_split[index] for index in range(len(df_split)) if index != i and index != (len(df_split)-i-1)]\n",
    "    df_train = pd.concat(frame_train)\n",
    "    \n",
    "    if not os.path.exists(train_path+str(i)+\"/\"):\n",
    "        os.makedirs(train_path+str(i)+\"/\")\n",
    "        \n",
    "    df_train.to_csv(train_path+str(i)+\"/\"+\"train_800.csv\",index = None)\n",
    "    df_val.to_csv(train_path+str(i)+\"/\"+\"val_100.csv\",index = None)\n",
    "    df_test.to_csv(train_path+str(i)+\"/\"+\"test_100.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dac4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etd_train_list = []\n",
    "X_ps_train_list = []\n",
    "X_ngram_train_list = []\n",
    "X_pos_train_list = []\n",
    "X_etd_ngram_train_list = []\n",
    "X_ps_ngram_train_list = []\n",
    "X_etd_pos_train_list = []\n",
    "X_ps_pos_train_list = []\n",
    "X_ngram_pos_train_list = []\n",
    "X_all_etd_train_list = []\n",
    "X_all_ps_train_list = []\n",
    "\n",
    "X_etd_test_list = []\n",
    "X_ps_test_list = []\n",
    "X_ngram_test_list = []\n",
    "X_pos_test_list = []\n",
    "X_etd_ngram_test_list = []\n",
    "X_ps_ngram_test_list = []\n",
    "X_etd_pos_test_list = []\n",
    "X_ps_pos_test_list = []\n",
    "X_ngram_pos_test_list = []\n",
    "X_all_etd_test_list = []\n",
    "X_all_ps_test_list = []\n",
    "\n",
    "X_etd_val_list = []\n",
    "X_ps_val_list = []\n",
    "X_ngram_val_list = []\n",
    "X_pos_val_list = []\n",
    "X_etd_ngram_val_list = []\n",
    "X_ps_ngram_val_list = []\n",
    "X_etd_pos_val_list = []\n",
    "X_ps_pos_val_list = []\n",
    "X_ngram_pos_val_list = []\n",
    "X_all_etd_val_list = []\n",
    "X_all_ps_val_list = []\n",
    "\n",
    "y_etd_train_list = []\n",
    "y_ps_train_list = []\n",
    "y_etd_test_list = []\n",
    "y_ps_test_list = []\n",
    "y_etd_val_list = []\n",
    "y_ps_val_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc271f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_10fold_data(path):\n",
    "    dir_list = os.listdir(path)\n",
    "    for folder in dir_list:\n",
    "        #training files\n",
    "        df_etd_train = pd.read_csv(path+folder+\"/train/etd_pattern_train.csv\")\n",
    "        df_ps_train = pd.read_csv(path+folder+\"/train/ps_pattern_train.csv\")\n",
    "        df_ngram_train = pd.read_csv(path+folder+\"/train/ngram_train.csv\")\n",
    "        df_pos_train = pd.read_csv(path+folder+\"/train/pos_train.csv\")\n",
    "\n",
    "        #test files\n",
    "        df_etd_test = pd.read_csv(path+folder+\"/test/etd_pattern_test.csv\")\n",
    "        df_ps_test = pd.read_csv(path+folder+\"/test/ps_pattern_test.csv\")\n",
    "        df_ngram_test = pd.read_csv(path+folder+\"/test/ngram_test.csv\")\n",
    "        df_pos_test = pd.read_csv(path+folder+\"/test/pos_test.csv\")\n",
    "        \n",
    "        #validation files\n",
    "        df_etd_val = pd.read_csv(path+folder+\"/val/etd_pattern_val.csv\")\n",
    "        df_ps_val = pd.read_csv(path+folder+\"/val/ps_pattern_val.csv\")\n",
    "        df_ngram_val = pd.read_csv(path+folder+\"/val/ngram_val.csv\")\n",
    "        df_pos_val = pd.read_csv(path+folder+\"/val/pos_val.csv\")\n",
    "\n",
    "        #label\n",
    "        df_label_train = pd.read_csv(path+folder+\"/train_800.csv\")\n",
    "        df_label_test = pd.read_csv(path+folder+\"/test_100.csv\")\n",
    "        df_label_val = pd.read_csv(path+folder+\"/val_100.csv\")\n",
    "        \n",
    "        #train\n",
    "        X_etd_train = df_etd_train.values\n",
    "        X_ps_train = df_ps_train.values\n",
    "        X_ngram_train = df_ngram_train.values\n",
    "        X_pos_train = df_pos_train.values\n",
    "\n",
    "        X_etd_ngram_train = np.hstack((X_etd_train, X_ngram_train))\n",
    "        X_ps_ngram_train = np.hstack((X_ps_train, X_ngram_train))\n",
    "        X_etd_pos_train = np.hstack((X_etd_train, X_pos_train))\n",
    "        X_ps_pos_train = np.hstack((X_ps_train, X_pos_train))\n",
    "        X_ngram_pos_train = np.hstack((X_ngram_train, X_pos_train))\n",
    "\n",
    "        X_all_etd_train = np.hstack((X_etd_ngram_train, X_pos_train))\n",
    "        X_all_ps_train = np.hstack((X_ps_ngram_train, X_pos_train))\n",
    "        \n",
    "        #test\n",
    "        X_etd_test = df_etd_test.values\n",
    "        X_ps_test = df_ps_test.values\n",
    "        X_ngram_test = df_ngram_test.values\n",
    "        X_pos_test = df_pos_test.values\n",
    "\n",
    "        X_etd_ngram_test = np.hstack((X_etd_test, X_ngram_test))\n",
    "        X_etd_pos_test = np.hstack((X_etd_test, X_pos_test))\n",
    "        X_ngram_pos_test = np.hstack((X_ngram_test, X_pos_test))\n",
    "        X_ps_ngram_test = np.hstack((X_ps_test, X_ngram_test))\n",
    "        X_ps_pos_test = np.hstack((X_ps_test, X_pos_test))\n",
    "\n",
    "        X_all_etd_test = np.hstack((X_etd_ngram_test, X_pos_test))\n",
    "        X_all_ps_test = np.hstack((X_ngram_pos_test, X_pos_test))\n",
    "        \n",
    "        #val\n",
    "        X_etd_val = df_etd_val.values\n",
    "        X_ps_val = df_ps_val.values\n",
    "        X_ngram_val = df_ngram_val.values\n",
    "        X_pos_val = df_pos_val.values\n",
    "\n",
    "        X_etd_ngram_val = np.hstack((X_etd_val, X_ngram_val))\n",
    "        X_etd_pos_val = np.hstack((X_etd_val, X_pos_val))\n",
    "        X_ngram_pos_val = np.hstack((X_ngram_val, X_pos_val))\n",
    "        X_ps_ngram_val = np.hstack((X_ps_val, X_ngram_val))\n",
    "        X_ps_pos_val = np.hstack((X_ps_val, X_pos_val))\n",
    "\n",
    "        X_all_etd_val = np.hstack((X_etd_ngram_val, X_pos_val))\n",
    "        X_all_ps_val = np.hstack((X_ngram_pos_val, X_pos_val))\n",
    "        \n",
    "        y_etd_train = df_label_train[\"y_ETD\"].values\n",
    "        y_ps_train = df_label_train[\"y_PS\"].values\n",
    "        y_etd_test = df_label_test[\"y_ETD\"].values\n",
    "        y_ps_test = df_label_test[\"y_PS\"].values\n",
    "        y_etd_val = df_label_val[\"y_ETD\"].values\n",
    "        y_ps_val = df_label_val[\"y_PS\"].values\n",
    "        \n",
    "        X_etd_train_list.append(X_etd_train)\n",
    "        X_ps_train_list.append(X_ps_train)\n",
    "        X_ngram_train_list.append(X_ngram_train)\n",
    "        X_pos_train_list.append(X_pos_train)\n",
    "        X_etd_ngram_train_list.append(X_etd_ngram_train)\n",
    "        X_ps_ngram_train_list.append(X_ps_ngram_train)\n",
    "        X_etd_pos_train_list.append(X_etd_pos_train)\n",
    "        X_ps_pos_train_list.append(X_ps_pos_train)\n",
    "        X_ngram_pos_train_list.append(X_ngram_pos_train)\n",
    "        X_all_etd_train_list.append(X_all_etd_train)\n",
    "        X_all_ps_train_list.append(X_all_ps_train)\n",
    "        \n",
    "        X_etd_test_list.append(X_etd_test)\n",
    "        X_ps_test_list.append(X_ps_test)\n",
    "        X_ngram_test_list.append(X_ngram_test)\n",
    "        X_pos_test_list.append(X_pos_test)\n",
    "        X_etd_ngram_test_list.append(X_etd_ngram_test)\n",
    "        X_ps_ngram_test_list.append(X_ps_ngram_test)\n",
    "        X_etd_pos_test_list.append(X_etd_pos_test)\n",
    "        X_ps_pos_test_list.append(X_ps_pos_test)\n",
    "        X_ngram_pos_test_list.append(X_ngram_pos_test)\n",
    "        X_all_etd_test_list.append(X_all_etd_test)\n",
    "        X_all_ps_test_list.append(X_all_ps_test)\n",
    "        \n",
    "        X_etd_val_list.append(X_etd_val)\n",
    "        X_ps_val_list.append(X_ps_val)\n",
    "        X_ngram_val_list.append(X_ngram_val)\n",
    "        X_pos_val_list.append(X_pos_val)\n",
    "        X_etd_ngram_val_list.append(X_etd_ngram_val)\n",
    "        X_ps_ngram_val_list.append(X_ps_ngram_val)\n",
    "        X_etd_pos_val_list.append(X_etd_pos_val)\n",
    "        X_ps_pos_val_list.append(X_ps_pos_val)\n",
    "        X_ngram_pos_val_list.append(X_ngram_pos_val)\n",
    "        X_all_etd_val_list.append(X_all_etd_val)\n",
    "        X_all_ps_val_list.append(X_all_ps_val)\n",
    "        \n",
    "        y_etd_train_list.append(y_etd_train)\n",
    "        y_ps_train_list.append(y_ps_train)\n",
    "        y_etd_test_list.append(y_etd_test)\n",
    "        y_ps_test_list.append(y_ps_test)\n",
    "        y_etd_val_list.append(y_etd_val)\n",
    "        y_ps_val_list.append(y_ps_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a6d0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_10fold_data(\"../Data/chat_pattern/cross_validate/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b9ee8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4427a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(X_train, y_train, X_test, y_test):\n",
    "    y_test_model = []\n",
    "    yhat_model = []\n",
    "    param_grid = {'C': np.linspace(0.001, 100, 20)}\n",
    "    \n",
    "    svc = SVC()\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print('CV Train score: {:.2f}'.format(grid_search.best_score_))\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    \n",
    "    predictions = grid_search.predict(X_test)\n",
    "    precison = mt.precision_score(y_test, predictions)\n",
    "    recall = mt.recall_score(y_test, predictions)\n",
    "    score = mt.f1_score(y_test, predictions)\n",
    "    \n",
    "    print(\"precision:\",round(precison,3),\"recall:\",round(recall,3),\"F1:\",round(score,3))\n",
    "    \n",
    "    for val in zip(y_test, predictions):\n",
    "        yhat_model.append(val[1])\n",
    "        y_test_model.append(val[0])\n",
    "    \n",
    "    return precison,recall,score, y_test_model, yhat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "771d227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X_train_list, y_train_list, X_test_list, y_test_list, X_val_list, y_val_list):\n",
    "    \n",
    "    param_grid = {'C': np.linspace(0.001, 100, 20)}\n",
    "    \n",
    "    for X_train,y_train,X_test,y_test,X_val,y_val in zip(X_train_list, y_train_list, X_test_list, y_test_list, X_val_list, y_val_list):\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        \n",
    "        svc = SVC()\n",
    "        grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
    "        grid_search.fit(X_val, y_val)\n",
    "    \n",
    "        #print('CV Train score: {:.2f}'.format(grid_search.best_score_))\n",
    "        #print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "        \n",
    "        clf = SVC(**grid_search.best_params_)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        precison = mt.precision_score(y_test, predictions)\n",
    "        recall = mt.recall_score(y_test, predictions)\n",
    "        score = mt.f1_score(y_test, predictions)\n",
    "        \n",
    "        precision_list.append(precison)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(score)\n",
    "    \n",
    "    print(\"precision:\",round(np.average(precision_list),3),\"recall:\",round(np.average(recall_list),3),\"F1:\",round(np.average(f1_list),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c8cac",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "248835a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.875 recall: 0.86 F1: 0.867\n"
     ]
    }
   ],
   "source": [
    "# 1. ETD: pattern\n",
    "cross_validate(X_etd_train_list, y_etd_train_list, X_etd_test_list, y_etd_test_list, X_etd_val_list, y_etd_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9322a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train score: 0.69\n",
      "Best parameters: {'C': 21.053421052631577}\n",
      "precision: 0.782 recall: 0.735 F1: 0.758\n"
     ]
    }
   ],
   "source": [
    "# 2. ETD: pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_pos_train, y_etd_train, X_pos_test, y_etd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "40818a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train score: 0.71\n",
      "Best parameters: {'C': 5.264105263157894}\n",
      "precision: 0.769 recall: 0.909 F1: 0.833\n"
     ]
    }
   ],
   "source": [
    "# 3. ETD: n-gram\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_ngram_train, y_etd_train, X_ngram_test, y_etd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "11631728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train score: 0.78\n",
      "Best parameters: {'C': 10.527210526315788}\n",
      "precision: 0.855 recall: 0.848 F1: 0.852\n"
     ]
    }
   ],
   "source": [
    "# 4. ETD: pattern + pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_etd_pos_train, y_etd_train, X_etd_pos_test, y_etd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f7afc0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train score: 0.77\n",
      "Best parameters: {'C': 5.264105263157894}\n",
      "precision: 0.812 recall: 0.917 F1: 0.861\n"
     ]
    }
   ],
   "source": [
    "# 5. ETD: pattern + n-gram\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_etd_ngram_train, y_etd_train, X_etd_ngram_test, y_etd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3aea2784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train score: 0.73\n",
      "Best parameters: {'C': 5.264105263157894}\n",
      "precision: 0.787 recall: 0.841 F1: 0.813\n"
     ]
    }
   ],
   "source": [
    "# 6. ETD: n-gram + pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_ngram_pos_train, y_etd_train, X_ngram_pos_test, y_etd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "22a52f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train score: 0.76\n",
      "Best parameters: {'C': 5.264105263157894}\n",
      "precision: 0.823 recall: 0.879 F1: 0.85\n"
     ]
    }
   ],
   "source": [
    "# 7. ETD: pattern + n-gram + pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_all_etd_train, y_etd_train, X_all_etd_test, y_etd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bbe1564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.838 recall: 0.925 F1: 0.879\n"
     ]
    }
   ],
   "source": [
    "# 8. PS: pattern\n",
    "cross_validate(X_ps_train_list, y_ps_train_list, X_ps_test_list, y_ps_test_list, X_ps_val_list, y_ps_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. PS: pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_pos_train, y_ps_train, X_pos_test, y_ps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ca512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. PS: n-gram\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_ngram_train, y_ps_train, X_ngram_test, y_ps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fcf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. PS: pattern + pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_ps_pos_train, y_ps_train, X_ps_pos_test, y_ps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec803b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. PS: pattern + n-gram\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_ps_ngram_train, y_ps_train, X_ps_ngram_test, y_ps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e839a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. PS: n-gram + pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_ngram_pos_train, y_ps_train, X_ngram_pos_test, y_ps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. PS: pattern + n-gram + pos\n",
    "prec,recall,f1_scores, y_test_model, yhat_model = train_evaluate(X_all_ps_train, y_ps_train, X_all_ps_test, y_ps_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
