{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d4316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 14:24:48.254777: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-11 14:24:52.778044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simin/miniconda3/envs/tf-rank/lib/:/home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/simin/miniconda3/envs/tf-rank/lib/:/home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-04-11 14:24:52.778476: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simin/miniconda3/envs/tf-rank/lib/:/home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/simin/miniconda3/envs/tf-rank/lib/:/home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-04-11 14:24:52.778731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90a528bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = '../StackExchange/Stackoverflow/train.tfrecords'\n",
    "_TEST_DATA_PATH = '../StackExchange/Stackoverflow/test.tfrecords'\n",
    "\n",
    "# Store the vocabulary path for query and document tokens.\n",
    "_VOCAB_PATH = '../StackExchange/Stackoverflow/vocab.txt'\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = 100\n",
    "\n",
    "# The document relevance label.\n",
    "_LABEL_FEATURE = \"relevance\"\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_HIDDEN_LAYER_DIMS = [\"64\", \"32\", \"16\"]\n",
    "_DROPOUT_RATE = 0.8\n",
    "_GROUP_SIZE = 1  # Pointwise scoring.\n",
    "\n",
    "# Location of model directory and number of training steps.\n",
    "_MODEL_DIR = \"/tmp/ranking_model_dir\"\n",
    "_NUM_TRAIN_STEPS = 60 * 1000\n",
    "_EMBEDDING_DIMENSION = 20\n",
    "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\",\"c++\",\"c#\",\"f#\",\"node.js\",\"nodejs\",\".json\",\".js\",\".net\",\"objective-c\",\n",
    "                                  \"asp.net\",\"ruby-on-rails\",\"angular.js\",\"angular-js\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21c2e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_feature_columns():\n",
    "    \"\"\"Returns context feature names to column definitions.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        key=\"query_tokens\",\n",
    "        vocabulary_file=_VOCAB_PATH)\n",
    "    query_embedding_column = tf.feature_column.embedding_column(\n",
    "        sparse_column, _EMBEDDING_DIMENSION)\n",
    "    return {\"query_tokens\": query_embedding_column}\n",
    "\n",
    "\n",
    "def example_feature_columns():\n",
    "    \"\"\"Returns the example feature columns.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        key=\"document_tokens\",\n",
    "        vocabulary_file=_VOCAB_PATH)\n",
    "    document_embedding_column = tf.feature_column.embedding_column(\n",
    "        sparse_column, _EMBEDDING_DIMENSION)\n",
    "    return {\"document_tokens\": document_embedding_column}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2991ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(path, num_epochs=None):\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values())\n",
    "    label_column = tf.feature_column.numeric_column(\n",
    "        _LABEL_FEATURE, dtype=tf.int64, default_value=_PADDING_LABEL)\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()) + [label_column])\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern=path,\n",
    "        data_format=tfr.data.ELWC,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        list_size=_LIST_SIZE,\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=False,\n",
    "        num_epochs=num_epochs)\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    label = tf.squeeze(features.pop(_LABEL_FEATURE), axis=2)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89fb6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform_fn():\n",
    "    def _transform_fn(features, mode):\n",
    "        \"\"\"Defines transform_fn.\"\"\"\n",
    "        context_features, example_features = tfr.feature.encode_listwise_features(\n",
    "            features=features,\n",
    "            context_feature_columns=context_feature_columns(),\n",
    "            example_feature_columns=example_feature_columns(),\n",
    "            mode=mode,\n",
    "            scope=\"transform_layer\")\n",
    "\n",
    "        return context_features, example_features\n",
    "    return _transform_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebf844aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        \"\"\"Defines the network to score a group of documents.\"\"\"\n",
    "        with tf.compat.v1.name_scope(\"input_layer\"):\n",
    "            context_input = [\n",
    "                tf.compat.v1.layers.flatten(context_features[name])\n",
    "                for name in sorted(context_feature_columns())\n",
    "            ]\n",
    "            group_input = [\n",
    "                tf.compat.v1.layers.flatten(group_features[name])\n",
    "                for name in sorted(example_feature_columns())\n",
    "            ]\n",
    "            input_layer = tf.concat(context_input + group_input, 1)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        cur_layer = input_layer\n",
    "        cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "            cur_layer,\n",
    "            training=is_training,\n",
    "            momentum=0.99)\n",
    "\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
    "            cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "                cur_layer,\n",
    "                training=is_training,\n",
    "                momentum=0.99)\n",
    "            cur_layer = tf.nn.relu(cur_layer)\n",
    "            cur_layer = tf.compat.v1.layers.dropout(\n",
    "                inputs=cur_layer, rate=_DROPOUT_RATE, training=is_training)\n",
    "        logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n",
    "        return logits\n",
    "\n",
    "    return _score_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06fccce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric_fns():\n",
    "    \"\"\"Returns a dict from name to metric functions.\n",
    "\n",
    "    This can be customized as follows. Care must be taken when handling padded\n",
    "    lists.\n",
    "\n",
    "    def _auc(labels, predictions, features):\n",
    "        is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
    "        clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
    "        clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
    "        return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
    "    metric_fns[\"auc\"] = _auc\n",
    "\n",
    "    Returns:\n",
    "        A dict mapping from metric name to a metric function with above signature.\n",
    "    \"\"\"\n",
    "    metric_fns = {}\n",
    "   \n",
    "    metric_fns.update({\n",
    "        f\"metric/ndcg@{topn}\": tfr.metrics.make_ranking_metric_fn(\n",
    "            tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "        for topn in [10,15,20,25,30]\n",
    "    })\n",
    "    \"\"\"\n",
    "    metric_fns.update({\n",
    "        f\"metric/map@{topn}\": tfr.metrics.make_ranking_metric_fn(\n",
    "            tfr.metrics.RankingMetricKey.MAP, topn=topn)\n",
    "        for topn in [15, 20]\n",
    "    })\n",
    "    \"\"\"\n",
    "    \n",
    "    return metric_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11998803",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072917a",
   "metadata": {},
   "source": [
    "### Create vocab.txt using bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d75323b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import shutil\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1ee42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../StackExchange/Stackoverflow/train/\"\n",
    "df_train = pd.read_csv(\"../StackExchange/Stackoverflow/cluster_4d.csv\")\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 16\n",
    "seed = 42\n",
    "class_list = sorted([str(folder) for folder in set(df_train[\"label\"])])\n",
    "num_class = len(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7602cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(sentence):\n",
    "    return ''.join(char for char in sentence if ord(char) < 128)\n",
    "\n",
    "'''\n",
    "def html_Filter(sentence):\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text\n",
    "    #print(\"after html_Filter\",sentence)\n",
    "    \n",
    "    return sentence\n",
    "'''\n",
    "\n",
    "def html_Filter(sentence):\n",
    "    soup = BeautifulSoup(sentence, \"html.parser\")\n",
    "    for data in soup(['style', 'script']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    "    \n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "\n",
    "\n",
    "def keywords_transform(sentence):\n",
    "    delimiter = [char for char in string.punctuation]\n",
    "    punc_reserved = ['#','+','-',\"'\"]\n",
    "    delimiter_filter = list(set(delimiter) - set(punc_reserved))\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    for char in delimiter_filter:\n",
    "        sentence = sentence.replace(char,' '+char+' ')\n",
    "\n",
    "    sentence = sentence.replace(\"node js\",\"node.js\")\n",
    "    sentence = sentence.replace(\"node . js\",\"node.js\")\n",
    "    sentence = sentence.replace(\" . js\",\".js\")\n",
    "    sentence = sentence.replace(\" . net\",\".net\")\n",
    "    sentence = sentence.replace(\"asp . net\",\"asp.net\")\n",
    "    sentence = sentence.replace(\" . json\",\".json\")\n",
    "    sentence = sentence.replace(\"objective c\",\"objective-c\")\n",
    "    sentence = sentence.replace(\"ruby on rails\",\"ruby-on-rails\")\n",
    "    sentence = sentence.replace(\"angular js\",\"angular-js\")\n",
    "    sentence = sentence.replace(\"angular . js\",\"angular.js\")\n",
    "    \n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dd165d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vocab_file(filepath, vocab):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for token in vocab:\n",
    "            print(token, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1224fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform dataset if needed\n",
    "for name in class_list:\n",
    "    newpath = train_path+name+'/' \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "for i, sentence, label in zip(df_train[\"Id\"],df_train[\"sentence\"],df_train[\"label\"]):\n",
    "    sentence = html_Filter(sentence)\n",
    "    sentence = remove_non_ascii(sentence)\n",
    "    sentence = keywords_transform(sentence)\n",
    "    \n",
    "    #vlabel_list.append(label)\n",
    "    \n",
    "    with open(train_path+str(label)+'/'+str(i)+\".txt\",\"w\",encoding=\"UTF-8\") as f:\n",
    "        f.write(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a6c3c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2194 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#fetech dataset\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels=None,\n",
    "    label_mode = None,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e02cd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_params=dict(lower_case=True)\n",
    "\n",
    "bert_vocab_args = dict(\n",
    "    # The target vocabulary size\n",
    "    vocab_size = 8000,\n",
    "    # Reserved tokens that must be included in the vocabulary\n",
    "    reserved_tokens=reserved_tokens,\n",
    "    # Arguments for `text.BertTokenizer`\n",
    "    bert_tokenizer_params=bert_tokenizer_params,\n",
    "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
    "    learn_params={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4b5a631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = bert_vocab.bert_vocab_from_dataset(\n",
    "    train_ds.cache().prefetch(buffer_size=AUTOTUNE),\n",
    "    **bert_vocab_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "520ce477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838\n"
     ]
    }
   ],
   "source": [
    "print(len(en_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "00a076f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', '[UNK]', '[START]', '[END]', 'c++', 'c#', 'f#', 'node.js', 'nodejs', '.json', '.js', '.net', 'objective-c', 'asp.net', 'ruby-on-rails', 'angular.js', 'angular-js', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', 'the', 'to', 'is', 'in', 'this', 'and', 'java', 'of', 'it', 'at', 'if', '##s', 'for', 'string', 'new', 'that', 'error', 'class', 'public', 'my', 'int', 'not', 'but', 'function', 'with', 'have', 'from', 'return', 'id', 'code', 'na', 'on', 'android', 'name', 'as', 'get', 'value', 'an', 'void', 'can', 'data', 'file', 'how', 'when', 'am', 'be', 'com', 'using', 'what', 'org', 'do', 'null', 'main', 'import', 'so', '##1', '##2', 'out', 'add', 'use', 'or', 'php', 'private', 'here', 'type', 'var', 'app', 'object', '##ing', 'why', 'array', 'text', 'method', 'list', 'are', 'like', 'system', 'by', 'line', 'apache', '10', 'result', 'you', 'no', '##ed', 'which', '##d', 'does', 'http', 'all', 'user', 'true', 'me', 'there', 'self', 'any', 'view', 'set', 'include', 'print', 'run', 'log', 'trying', '##l', 'div', 'else', 'console', 'following', 'input', '##3', 'one', 'some', 'std', 'char', 'exception']\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fef85fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vocab_file(_VOCAB_PATH, en_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ad5fe",
   "metadata": {},
   "source": [
    "### Create elwc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "610c1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    \n",
    "    \n",
    "    tokens = value.split()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[token.encode() for token in tokens]))\n",
    "'''\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    \n",
    "    \n",
    "    value = html_Filter(value)\n",
    "    value = remove_non_ascii(value)\n",
    "    value = keywords_transform(value)\n",
    "    whitespace_tokenizer = tf_text.WhitespaceTokenizer()\n",
    "    words = whitespace_tokenizer.tokenize(value).numpy().tolist()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=words))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79af183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfexample(feature0, feature1):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "        'document_tokens': _bytes_feature(feature0),\n",
    "        'relevance': _int64_feature(feature1), \n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81e8fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfquery(feature0):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "        'query_tokens': _bytes_feature(feature0),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07d73699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_elwc(elwc,num_example):\n",
    "    return tfr.data.parse_from_example_list(\n",
    "        [elwc],\n",
    "        list_size=num_example,\n",
    "        context_feature_spec={\"query_tokens\": tf.io.RaggedFeature(dtype=tf.string)},\n",
    "        example_feature_spec={\n",
    "            \"document_tokens\":\n",
    "                tf.io.RaggedFeature(dtype=tf.string),\n",
    "            \"relevance\":\n",
    "                tf.io.FixedLenFeature(shape=[], dtype=tf.int64, default_value=0)\n",
    "        },\n",
    "        size_feature_name=\"_list_size_\",\n",
    "        mask_feature_name=\"_mask_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1f20f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_serialized_elwc(tf_query, tf_examples):\n",
    "    ELWC = input_pb2.ExampleListWithContext()\n",
    "    ELWC.context.CopyFrom(tf_query)\n",
    "\n",
    "    for example in tf_examples:\n",
    "        example_features = ELWC.examples.add()\n",
    "        example_features.CopyFrom(example)\n",
    "    \n",
    "    return ELWC.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8b66e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset):\n",
    "    ELWC_list = []\n",
    "    \n",
    "    for data in dataset:\n",
    "        tf_query = create_tfquery(data[\"query\"])\n",
    "        \n",
    "        EXAMPLES = []\n",
    "        for doc in data[\"documents\"]:\n",
    "            tf_example = create_tfexample(doc[\"doc\"],doc[\"relevance\"])\n",
    "            EXAMPLES.append(tf_example)\n",
    "        \n",
    "        ELWC_list.append(create_serialized_elwc(tf_query, EXAMPLES))\n",
    "    \n",
    "    return ELWC_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228dbf7",
   "metadata": {},
   "source": [
    "#### stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "18b07e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5badc733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14191212</td>\n",
       "      <td>Alternative Function for EREGI in PHP &lt;p&gt;I was...</td>\n",
       "      <td>&lt;php&gt;&lt;regex&gt;&lt;preg-match&gt;&lt;eregi&gt;</td>\n",
       "      <td>2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14198874</td>\n",
       "      <td>JasperReports: Unsupported major.minor version...</td>\n",
       "      <td>&lt;java&gt;&lt;version&gt;&lt;unsupported-class-version&gt;</td>\n",
       "      <td>29595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1335851</td>\n",
       "      <td>What does \"use strict\" do in JavaScript, and w...</td>\n",
       "      <td>&lt;javascript&gt;&lt;syntax&gt;&lt;jslint&gt;&lt;use-strict&gt;</td>\n",
       "      <td>29590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1335886</td>\n",
       "      <td>mySQL Operand should contain 1 column error &lt;p...</td>\n",
       "      <td>&lt;mysql&gt;&lt;sql&gt;&lt;mysql-error-1241&gt;</td>\n",
       "      <td>123659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1352885</td>\n",
       "      <td>Remove elements as you traverse a list in Pyth...</td>\n",
       "      <td>&lt;python&gt;&lt;list&gt;&lt;loops&gt;&lt;iterator&gt;&lt;python-datamodel&gt;</td>\n",
       "      <td>15259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>14113884</td>\n",
       "      <td>Protect C++ program against decompiling &lt;block...</td>\n",
       "      <td>&lt;c++&gt;&lt;windows&gt;&lt;obfuscation&gt;&lt;decompiling&gt;&lt;sourc...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>14115904</td>\n",
       "      <td>$_POST not working. \"Notice: Undefined index: ...</td>\n",
       "      <td>&lt;php&gt;&lt;http-post&gt;&lt;undefined-index&gt;</td>\n",
       "      <td>8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>14121385</td>\n",
       "      <td>Select Distinct Rows from MySQL database throu...</td>\n",
       "      <td>&lt;php&gt;&lt;mysql&gt;&lt;pdo&gt;&lt;haversine&gt;</td>\n",
       "      <td>2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>14123290</td>\n",
       "      <td>Pull data from PHP object received from twitte...</td>\n",
       "      <td>&lt;php&gt;&lt;twitter&gt;&lt;twitter-streaming-api&gt;</td>\n",
       "      <td>219989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>14132789</td>\n",
       "      <td>Relative imports for the billionth time &lt;p&gt;I'v...</td>\n",
       "      <td>&lt;python&gt;&lt;import&gt;&lt;relative-path&gt;&lt;python-packagi...</td>\n",
       "      <td>147029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2194 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                           sentence  \\\n",
       "0     14191212  Alternative Function for EREGI in PHP <p>I was...   \n",
       "1     14198874  JasperReports: Unsupported major.minor version...   \n",
       "2      1335851  What does \"use strict\" do in JavaScript, and w...   \n",
       "3      1335886  mySQL Operand should contain 1 column error <p...   \n",
       "4      1352885  Remove elements as you traverse a list in Pyth...   \n",
       "...        ...                                                ...   \n",
       "2189  14113884  Protect C++ program against decompiling <block...   \n",
       "2190  14115904  $_POST not working. \"Notice: Undefined index: ...   \n",
       "2191  14121385  Select Distinct Rows from MySQL database throu...   \n",
       "2192  14123290  Pull data from PHP object received from twitte...   \n",
       "2193  14132789  Relative imports for the billionth time <p>I'v...   \n",
       "\n",
       "                                                    tag   label  \n",
       "0                       <php><regex><preg-match><eregi>    2867  \n",
       "1            <java><version><unsupported-class-version>   29595  \n",
       "2              <javascript><syntax><jslint><use-strict>   29590  \n",
       "3                        <mysql><sql><mysql-error-1241>  123659  \n",
       "4     <python><list><loops><iterator><python-datamodel>   15259  \n",
       "...                                                 ...     ...  \n",
       "2189  <c++><windows><obfuscation><decompiling><sourc...      29  \n",
       "2190                  <php><http-post><undefined-index>    8549  \n",
       "2191                       <php><mysql><pdo><haversine>    2802  \n",
       "2192              <php><twitter><twitter-streaming-api>  219989  \n",
       "2193  <python><import><relative-path><python-packagi...  147029  \n",
       "\n",
       "[2194 rows x 4 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../StackExchange/Stackoverflow/cluster_4d.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e08e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6fd714c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "234a8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for label in label_set:\n",
    "    df_relevant = df[df[\"label\"] == label]    \n",
    "    df_irrelevant = df[df[\"label\"] != label]\n",
    "    \n",
    "    for index in list(df_relevant.index.values):\n",
    "        data = {}\n",
    "        data[\"qid\"] = df_relevant.loc[index][\"Id\"]\n",
    "        data[\"query\"] = df_relevant.loc[index][\"sentence\"]\n",
    "        data[\"label\"] = df_relevant.loc[index][\"label\"]\n",
    "        \n",
    "        docs = []\n",
    "        df_doc = df_relevant[df_relevant[\"Id\"] != df_relevant.loc[index][\"Id\"]]\n",
    "        for index_d in list(df_doc.index.values):\n",
    "            doc = {}\n",
    "            doc[\"doc_id\"] = df_doc.loc[index_d][\"Id\"]\n",
    "            doc[\"doc\"] = df_doc.loc[index_d][\"sentence\"]\n",
    "            doc[\"relevance\"] = 1\n",
    "            \n",
    "            docs.append(doc)\n",
    "        \n",
    "        \n",
    "        if len(docs) < _LIST_SIZE:\n",
    "            num_irrelevant = _LIST_SIZE - len(docs)\n",
    "            df_irdoc = df_irrelevant.sample(num_irrelevant)\n",
    "            for index_d in list(df_irdoc.index.values):\n",
    "                doc = {}\n",
    "                doc[\"doc_id\"] = df_irdoc.loc[index_d][\"Id\"]\n",
    "                doc[\"doc\"] = df_irdoc.loc[index_d][\"sentence\"]\n",
    "                doc[\"relevance\"] = 0\n",
    "            \n",
    "                docs.append(doc)\n",
    "        \n",
    "        data[\"documents\"] = docs\n",
    "        \n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "08f0345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "train = []\n",
    "test = []\n",
    "has_label = set()\n",
    "\n",
    "for data in dataset:\n",
    "    if data[\"label\"] in has_label:\n",
    "        train.append(data)\n",
    "    else:\n",
    "        test.append(data)\n",
    "        has_label.add(data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c5376276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1971\n",
      "test: 223\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\",len(train))\n",
    "print(\"test:\",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "43e28360",
   "metadata": {},
   "outputs": [],
   "source": [
    "elwc_train = create_dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eee79229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elwc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "edabfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(_TRAIN_DATA_PATH) as writer:\n",
    "    for objs in elwc_train:\n",
    "        writer.write(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "abe113f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "elwc_test = create_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d08c78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(_TEST_DATA_PATH) as writer:\n",
    "    for objs in elwc_test:\n",
    "        writer.write(objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c39ac",
   "metadata": {},
   "source": [
    "## Losses, Metrics and Ranking Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad9fc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function. To find a complete list of available\n",
    "# loss functions or to learn how to add your own custom function\n",
    "# please refer to the tensorflow_ranking.losses module.\n",
    "\n",
    "_LOSS = tfr.losses.RankingLossKey.APPROX_NDCG_LOSS\n",
    "loss_fn = tfr.losses.make_loss_fn(_LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba31dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "    learning_rate=_LEARNING_RATE)\n",
    "\n",
    "\n",
    "def _train_op_fn(loss):\n",
    "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "    minimize_op = optimizer.minimize(\n",
    "        loss=loss, global_step=tf.compat.v1.train.get_global_step())\n",
    "    train_op = tf.group([update_ops, minimize_op])\n",
    "    return train_op\n",
    "\n",
    "\n",
    "ranking_head = tfr.head.create_ranking_head(\n",
    "      loss_fn=loss_fn,\n",
    "      eval_metric_fns=eval_metric_fns(),\n",
    "      train_op_fn=_train_op_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab13156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building groupwise ranking model.\n"
     ]
    }
   ],
   "source": [
    "model_fn = tfr.model.make_groupwise_ranking_fn(\n",
    "          group_score_fn=make_score_fn(),\n",
    "          transform_fn=make_transform_fn(),\n",
    "          group_size=_GROUP_SIZE,\n",
    "          ranking_head=ranking_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803568ce",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d7a0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_fn():\n",
    "    \"\"\"Train and eval function used by `tf.estimator.train_and_evaluate`.\"\"\"\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        save_checkpoints_steps=5000)\n",
    "    ranker = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=_MODEL_DIR,\n",
    "        config=run_config)\n",
    "\n",
    "    train_input_fn = lambda: input_fn(_TRAIN_DATA_PATH)\n",
    "    eval_input_fn = lambda: input_fn(_TEST_DATA_PATH, num_epochs=1)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=train_input_fn, max_steps=_NUM_TRAIN_STEPS)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        name=\"eval\",\n",
    "        input_fn=eval_input_fn,\n",
    "        throttle_secs=15)\n",
    "    return (ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89935a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/ranking_model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x7f64255445e0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "ranker, train_spec, eval_spec = train_and_eval_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f003e8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/simin/miniconda3/envs/tf-rank/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 5000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8601/2110212537.py:8: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(context_features[name])\n",
      "/tmp/ipykernel_8601/2110212537.py:12: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(group_features[name])\n",
      "/tmp/ipykernel_8601/2110212537.py:19: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_8601/2110212537.py:25: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
      "/tmp/ipykernel_8601/2110212537.py:26: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_8601/2110212537.py:31: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dropout(\n",
      "/tmp/ipykernel_8601/2110212537.py:33: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/training/adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 14:46:25.196942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:46:25.197569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:46:25.198130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:46:25.198930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:46:25.198965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 14:46:25.199419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:46:25.199473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = -0.38075534, step = 0\n",
      "INFO:tensorflow:global_step/sec: 19.9146\n",
      "INFO:tensorflow:loss = -0.35086948, step = 100 (5.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3391\n",
      "INFO:tensorflow:loss = -0.7109562, step = 200 (6.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3679\n",
      "INFO:tensorflow:loss = -0.9846302, step = 300 (6.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0204\n",
      "INFO:tensorflow:loss = -0.654637, step = 400 (6.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0191\n",
      "INFO:tensorflow:loss = -0.514652, step = 500 (6.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.28\n",
      "INFO:tensorflow:loss = -0.8163458, step = 600 (4.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5749\n",
      "INFO:tensorflow:loss = -0.68553746, step = 700 (5.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5435\n",
      "INFO:tensorflow:loss = -0.5118628, step = 800 (4.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4395\n",
      "INFO:tensorflow:loss = -0.44080466, step = 900 (4.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3225\n",
      "INFO:tensorflow:loss = -0.8362761, step = 1000 (4.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6701\n",
      "INFO:tensorflow:loss = -0.72609454, step = 1100 (4.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3597\n",
      "INFO:tensorflow:loss = -0.42856467, step = 1200 (4.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1329\n",
      "INFO:tensorflow:loss = -0.42926896, step = 1300 (4.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6788\n",
      "INFO:tensorflow:loss = -0.57095647, step = 1400 (4.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8474\n",
      "INFO:tensorflow:loss = -0.8333069, step = 1500 (4.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9318\n",
      "INFO:tensorflow:loss = -0.48581904, step = 1600 (4.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0573\n",
      "INFO:tensorflow:loss = -0.39572257, step = 1700 (4.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.919\n",
      "INFO:tensorflow:loss = -0.68664813, step = 1800 (4.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9266\n",
      "INFO:tensorflow:loss = -0.38325635, step = 1900 (4.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4276\n",
      "INFO:tensorflow:loss = -0.44232476, step = 2000 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8543\n",
      "INFO:tensorflow:loss = -0.40025496, step = 2100 (4.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0428\n",
      "INFO:tensorflow:loss = -0.4227321, step = 2200 (4.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2505\n",
      "INFO:tensorflow:loss = -0.6597482, step = 2300 (4.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4069\n",
      "INFO:tensorflow:loss = -0.41246614, step = 2400 (4.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9817\n",
      "INFO:tensorflow:loss = -0.7317729, step = 2500 (4.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8979\n",
      "INFO:tensorflow:loss = -0.38626692, step = 2600 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6909\n",
      "INFO:tensorflow:loss = -0.41122133, step = 2700 (4.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9672\n",
      "INFO:tensorflow:loss = -0.56836367, step = 2800 (4.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0416\n",
      "INFO:tensorflow:loss = -0.4296516, step = 2900 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5881\n",
      "INFO:tensorflow:loss = -0.4714448, step = 3000 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5881\n",
      "INFO:tensorflow:loss = -0.38733906, step = 3100 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5819\n",
      "INFO:tensorflow:loss = -0.44904903, step = 3200 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2457\n",
      "INFO:tensorflow:loss = -0.90193874, step = 3300 (4.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5157\n",
      "INFO:tensorflow:loss = -0.43659374, step = 3400 (5.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0918\n",
      "INFO:tensorflow:loss = -0.39319688, step = 3500 (4.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2215\n",
      "INFO:tensorflow:loss = -0.47869733, step = 3600 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8287\n",
      "INFO:tensorflow:loss = -0.43125027, step = 3700 (4.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2025\n",
      "INFO:tensorflow:loss = -0.45043674, step = 3800 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5274\n",
      "INFO:tensorflow:loss = -0.39184552, step = 3900 (4.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6543\n",
      "INFO:tensorflow:loss = -0.4297483, step = 4000 (4.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3483\n",
      "INFO:tensorflow:loss = -0.9038993, step = 4100 (4.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8161\n",
      "INFO:tensorflow:loss = -0.4802529, step = 4200 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1444\n",
      "INFO:tensorflow:loss = -0.3779212, step = 4300 (4.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2773\n",
      "INFO:tensorflow:loss = -0.50805104, step = 4400 (4.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7719\n",
      "INFO:tensorflow:loss = -0.4168166, step = 4500 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8487\n",
      "INFO:tensorflow:loss = -0.43514538, step = 4600 (4.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9778\n",
      "INFO:tensorflow:loss = -0.3744226, step = 4700 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2094\n",
      "INFO:tensorflow:loss = -0.39657354, step = 4800 (4.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9371\n",
      "INFO:tensorflow:loss = -0.77991045, step = 4900 (4.360 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T14:50:22\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 14:50:22.483520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:50:22.484457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:50:22.484934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:50:22.486472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:50:22.486548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 14:50:22.487100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:50:22.487211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.17568s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-14:50:23\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, labels_mean = 0.08838565, logits_mean = 0.8993795, loss = -0.4083168, metric/ndcg@10 = 0.1197257, metric/ndcg@15 = 0.14293662, metric/ndcg@20 = 0.17245288, metric/ndcg@25 = 0.19667988, metric/ndcg@30 = 0.21285532\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/ranking_model_dir/model.ckpt-5000\n",
      "INFO:tensorflow:global_step/sec: 13.7991\n",
      "INFO:tensorflow:loss = -0.36056203, step = 5000 (7.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7456\n",
      "INFO:tensorflow:loss = -0.4671197, step = 5100 (4.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3671\n",
      "INFO:tensorflow:loss = -0.4997003, step = 5200 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8864\n",
      "INFO:tensorflow:loss = -0.4383783, step = 5300 (4.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.993\n",
      "INFO:tensorflow:loss = -0.50231695, step = 5400 (4.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.935\n",
      "INFO:tensorflow:loss = -0.36450684, step = 5500 (4.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8963\n",
      "INFO:tensorflow:loss = -0.35741913, step = 5600 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0669\n",
      "INFO:tensorflow:loss = -0.6499762, step = 5700 (4.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8118\n",
      "INFO:tensorflow:loss = -0.5758939, step = 5800 (4.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6491\n",
      "INFO:tensorflow:loss = -0.502625, step = 5900 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2329\n",
      "INFO:tensorflow:loss = -0.4703844, step = 6000 (4.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6634\n",
      "INFO:tensorflow:loss = -0.43908328, step = 6100 (4.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5927\n",
      "INFO:tensorflow:loss = -0.4631601, step = 6200 (4.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5145\n",
      "INFO:tensorflow:loss = -0.495032, step = 6300 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8308\n",
      "INFO:tensorflow:loss = -0.6671881, step = 6400 (4.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.914\n",
      "INFO:tensorflow:loss = -0.43073824, step = 6500 (4.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8795\n",
      "INFO:tensorflow:loss = -0.51312315, step = 6600 (4.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4546\n",
      "INFO:tensorflow:loss = -0.53942525, step = 6700 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9335\n",
      "INFO:tensorflow:loss = -0.6575854, step = 6800 (4.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4458\n",
      "INFO:tensorflow:loss = -0.53356016, step = 6900 (4.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7062\n",
      "INFO:tensorflow:loss = -0.43575594, step = 7000 (4.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2608\n",
      "INFO:tensorflow:loss = -0.458234, step = 7100 (4.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7274\n",
      "INFO:tensorflow:loss = -0.9802892, step = 7200 (4.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8401\n",
      "INFO:tensorflow:loss = -0.47727197, step = 7300 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1902\n",
      "INFO:tensorflow:loss = -0.45781448, step = 7400 (4.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1575\n",
      "INFO:tensorflow:loss = -0.40095058, step = 7500 (4.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9795\n",
      "INFO:tensorflow:loss = -0.80922914, step = 7600 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0466\n",
      "INFO:tensorflow:loss = -0.35411736, step = 7700 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5736\n",
      "INFO:tensorflow:loss = -0.4234672, step = 7800 (4.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0294\n",
      "INFO:tensorflow:loss = -0.39390117, step = 7900 (4.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1495\n",
      "INFO:tensorflow:loss = -0.9846171, step = 8000 (4.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7399\n",
      "INFO:tensorflow:loss = -0.6899719, step = 8100 (4.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7692\n",
      "INFO:tensorflow:loss = -0.4602715, step = 8200 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3647\n",
      "INFO:tensorflow:loss = -0.67185766, step = 8300 (4.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4137\n",
      "INFO:tensorflow:loss = -0.6017413, step = 8400 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7976\n",
      "INFO:tensorflow:loss = -0.39786094, step = 8500 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1034\n",
      "INFO:tensorflow:loss = -0.35226756, step = 8600 (4.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8134\n",
      "INFO:tensorflow:loss = -0.6911874, step = 8700 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8326\n",
      "INFO:tensorflow:loss = -0.97718287, step = 8800 (4.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.637\n",
      "INFO:tensorflow:loss = -0.67765075, step = 8900 (4.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0117\n",
      "INFO:tensorflow:loss = -0.52073336, step = 9000 (4.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2023\n",
      "INFO:tensorflow:loss = -0.81388366, step = 9100 (4.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3789\n",
      "INFO:tensorflow:loss = -0.65318465, step = 9200 (4.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1817\n",
      "INFO:tensorflow:loss = -0.5472014, step = 9300 (4.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8264\n",
      "INFO:tensorflow:loss = -0.47532642, step = 9400 (4.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.071\n",
      "INFO:tensorflow:loss = -0.8441806, step = 9500 (4.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3924\n",
      "INFO:tensorflow:loss = -0.7545514, step = 9600 (4.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9768\n",
      "INFO:tensorflow:loss = -0.47335353, step = 9700 (4.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0212\n",
      "INFO:tensorflow:loss = -0.4630584, step = 9800 (4.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9813\n",
      "INFO:tensorflow:loss = -0.5874895, step = 9900 (4.351 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T14:54:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 14:54:09.236007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:54:09.236544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:54:09.237032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:54:09.237785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:54:09.237820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 14:54:09.238233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:54:09.238282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.07801s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-14:54:10\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, labels_mean = 0.08838565, logits_mean = 0.86041874, loss = -0.4434934, metric/ndcg@10 = 0.16266018, metric/ndcg@15 = 0.19525483, metric/ndcg@20 = 0.22220892, metric/ndcg@25 = 0.24966007, metric/ndcg@30 = 0.27261785\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/ranking_model_dir/model.ckpt-10000\n",
      "INFO:tensorflow:global_step/sec: 14.0575\n",
      "INFO:tensorflow:loss = -0.8424092, step = 10000 (7.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6743\n",
      "INFO:tensorflow:loss = -0.5371222, step = 10100 (4.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6056\n",
      "INFO:tensorflow:loss = -0.42915648, step = 10200 (4.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0935\n",
      "INFO:tensorflow:loss = -0.7420404, step = 10300 (4.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3207\n",
      "INFO:tensorflow:loss = -0.36404577, step = 10400 (4.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2793\n",
      "INFO:tensorflow:loss = -0.4695629, step = 10500 (4.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9775\n",
      "INFO:tensorflow:loss = -0.3881853, step = 10600 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0437\n",
      "INFO:tensorflow:loss = -0.43025622, step = 10700 (4.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4671\n",
      "INFO:tensorflow:loss = -0.6921282, step = 10800 (4.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.127\n",
      "INFO:tensorflow:loss = -0.42374638, step = 10900 (4.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0426\n",
      "INFO:tensorflow:loss = -0.69804883, step = 11000 (4.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1556\n",
      "INFO:tensorflow:loss = -0.41137618, step = 11100 (4.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8721\n",
      "INFO:tensorflow:loss = -0.3949133, step = 11200 (4.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4407\n",
      "INFO:tensorflow:loss = -0.59782064, step = 11300 (4.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1473\n",
      "INFO:tensorflow:loss = -0.42362982, step = 11400 (4.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9059\n",
      "INFO:tensorflow:loss = -0.43463248, step = 11500 (4.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1661\n",
      "INFO:tensorflow:loss = -0.36048985, step = 11600 (4.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7812\n",
      "INFO:tensorflow:loss = -0.48886353, step = 11700 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1335\n",
      "INFO:tensorflow:loss = -0.8990948, step = 11800 (4.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6249\n",
      "INFO:tensorflow:loss = -0.4421189, step = 11900 (4.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9934\n",
      "INFO:tensorflow:loss = -0.40925056, step = 12000 (4.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5232\n",
      "INFO:tensorflow:loss = -0.510496, step = 12100 (4.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2663\n",
      "INFO:tensorflow:loss = -0.40162894, step = 12200 (4.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5288\n",
      "INFO:tensorflow:loss = -0.44185954, step = 12300 (4.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0491\n",
      "INFO:tensorflow:loss = -0.39354956, step = 12400 (4.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3681\n",
      "INFO:tensorflow:loss = -0.44148237, step = 12500 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5203\n",
      "INFO:tensorflow:loss = -0.8980904, step = 12600 (4.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1177\n",
      "INFO:tensorflow:loss = -0.49126023, step = 12700 (4.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1745\n",
      "INFO:tensorflow:loss = -0.39750463, step = 12800 (4.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4481\n",
      "INFO:tensorflow:loss = -0.5392932, step = 12900 (4.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9099\n",
      "INFO:tensorflow:loss = -0.40250343, step = 13000 (4.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8705\n",
      "INFO:tensorflow:loss = -0.46019942, step = 13100 (4.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8864\n",
      "INFO:tensorflow:loss = -0.41612977, step = 13200 (4.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.781\n",
      "INFO:tensorflow:loss = -0.41775906, step = 13300 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0118\n",
      "INFO:tensorflow:loss = -0.8132884, step = 13400 (4.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8259\n",
      "INFO:tensorflow:loss = -0.37252915, step = 13500 (4.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2311\n",
      "INFO:tensorflow:loss = -0.44435534, step = 13600 (4.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1345\n",
      "INFO:tensorflow:loss = -0.5491737, step = 13700 (4.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3833\n",
      "INFO:tensorflow:loss = -0.47521693, step = 13800 (4.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.666\n",
      "INFO:tensorflow:loss = -0.5163851, step = 13900 (4.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5443\n",
      "INFO:tensorflow:loss = -0.3972509, step = 14000 (4.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7846\n",
      "INFO:tensorflow:loss = -0.37313145, step = 14100 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1904\n",
      "INFO:tensorflow:loss = -0.68295515, step = 14200 (4.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7603\n",
      "INFO:tensorflow:loss = -0.57871854, step = 14300 (4.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8808\n",
      "INFO:tensorflow:loss = -0.5161722, step = 14400 (4.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9002\n",
      "INFO:tensorflow:loss = -0.5293098, step = 14500 (4.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9612\n",
      "INFO:tensorflow:loss = -0.44681054, step = 14600 (4.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0825\n",
      "INFO:tensorflow:loss = -0.48707885, step = 14700 (4.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0054\n",
      "INFO:tensorflow:loss = -0.50574875, step = 14800 (4.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5847\n",
      "INFO:tensorflow:loss = -0.6255733, step = 14900 (4.633 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 15000...\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 15000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T14:57:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 14:57:55.353133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:57:55.353873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:57:55.354393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:57:55.355177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:57:55.355215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 14:57:55.355639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 14:57:55.355692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.13080s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-14:57:56\n",
      "INFO:tensorflow:Saving dict for global step 15000: global_step = 15000, labels_mean = 0.08838565, logits_mean = 0.98679966, loss = -0.47014794, metric/ndcg@10 = 0.19579116, metric/ndcg@15 = 0.23251401, metric/ndcg@20 = 0.2635419, metric/ndcg@25 = 0.29133874, metric/ndcg@30 = 0.31479242\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /tmp/ranking_model_dir/model.ckpt-15000\n",
      "INFO:tensorflow:global_step/sec: 15.1478\n",
      "INFO:tensorflow:loss = -0.46711487, step = 15000 (6.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6687\n",
      "INFO:tensorflow:loss = -0.5389099, step = 15100 (4.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6223\n",
      "INFO:tensorflow:loss = -0.57804394, step = 15200 (4.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2492\n",
      "INFO:tensorflow:loss = -0.6592938, step = 15300 (4.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8336\n",
      "INFO:tensorflow:loss = -0.53193283, step = 15400 (4.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9227\n",
      "INFO:tensorflow:loss = -0.4615956, step = 15500 (4.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2792\n",
      "INFO:tensorflow:loss = -0.50165117, step = 15600 (4.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6414\n",
      "INFO:tensorflow:loss = -0.9845449, step = 15700 (4.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8639\n",
      "INFO:tensorflow:loss = -0.5056643, step = 15800 (4.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1779\n",
      "INFO:tensorflow:loss = -0.4213727, step = 15900 (4.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.204\n",
      "INFO:tensorflow:loss = -0.46749684, step = 16000 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0832\n",
      "INFO:tensorflow:loss = -0.8150004, step = 16100 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6582\n",
      "INFO:tensorflow:loss = -0.38618428, step = 16200 (4.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4521\n",
      "INFO:tensorflow:loss = -0.4632804, step = 16300 (4.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7492\n",
      "INFO:tensorflow:loss = -0.41566432, step = 16400 (4.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0847\n",
      "INFO:tensorflow:loss = -0.98044, step = 16500 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9143\n",
      "INFO:tensorflow:loss = -0.6895665, step = 16600 (4.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1705\n",
      "INFO:tensorflow:loss = -0.43635237, step = 16700 (4.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4822\n",
      "INFO:tensorflow:loss = -0.6454989, step = 16800 (4.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3515\n",
      "INFO:tensorflow:loss = -0.636715, step = 16900 (4.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.849\n",
      "INFO:tensorflow:loss = -0.4223857, step = 17000 (4.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9309\n",
      "INFO:tensorflow:loss = -0.3757121, step = 17100 (4.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5714\n",
      "INFO:tensorflow:loss = -0.6787423, step = 17200 (5.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9657\n",
      "INFO:tensorflow:loss = -0.981372, step = 17300 (7.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2415\n",
      "INFO:tensorflow:loss = -0.7165935, step = 17400 (4.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2891\n",
      "INFO:tensorflow:loss = -0.55281174, step = 17500 (4.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8455\n",
      "INFO:tensorflow:loss = -0.80460393, step = 17600 (4.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8936\n",
      "INFO:tensorflow:loss = -0.6572715, step = 17700 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3811\n",
      "INFO:tensorflow:loss = -0.5149156, step = 17800 (4.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5113\n",
      "INFO:tensorflow:loss = -0.4845449, step = 17900 (4.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.065\n",
      "INFO:tensorflow:loss = -0.84579545, step = 18000 (4.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3502\n",
      "INFO:tensorflow:loss = -0.8015988, step = 18100 (4.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1057\n",
      "INFO:tensorflow:loss = -0.5107578, step = 18200 (4.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9709\n",
      "INFO:tensorflow:loss = -0.4907984, step = 18300 (4.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5225\n",
      "INFO:tensorflow:loss = -0.63409364, step = 18400 (4.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9027\n",
      "INFO:tensorflow:loss = -0.85568535, step = 18500 (4.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8351\n",
      "INFO:tensorflow:loss = -0.56208366, step = 18600 (4.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4295\n",
      "INFO:tensorflow:loss = -0.43457583, step = 18700 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.441\n",
      "INFO:tensorflow:loss = -0.7571954, step = 18800 (4.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4005\n",
      "INFO:tensorflow:loss = -0.36003062, step = 18900 (4.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0451\n",
      "INFO:tensorflow:loss = -0.4948005, step = 19000 (4.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1374\n",
      "INFO:tensorflow:loss = -0.41337445, step = 19100 (4.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5392\n",
      "INFO:tensorflow:loss = -0.45998806, step = 19200 (4.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.287\n",
      "INFO:tensorflow:loss = -0.73996305, step = 19300 (4.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9953\n",
      "INFO:tensorflow:loss = -0.45784813, step = 19400 (4.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0826\n",
      "INFO:tensorflow:loss = -0.6738585, step = 19500 (4.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9137\n",
      "INFO:tensorflow:loss = -0.42406923, step = 19600 (4.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9673\n",
      "INFO:tensorflow:loss = -0.42775154, step = 19700 (4.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2056\n",
      "INFO:tensorflow:loss = -0.59627855, step = 19800 (4.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5078\n",
      "INFO:tensorflow:loss = -0.4916994, step = 19900 (4.649 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20000...\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:01:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:01:46.136043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:01:46.136739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:01:46.137225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:01:46.138352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:01:46.138391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:01:46.138851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:01:46.138899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.58613s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:01:47\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, labels_mean = 0.08838565, logits_mean = 1.2440097, loss = -0.48699382, metric/ndcg@10 = 0.21795587, metric/ndcg@15 = 0.25422582, metric/ndcg@20 = 0.2862176, metric/ndcg@25 = 0.3169025, metric/ndcg@30 = 0.34565696\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/ranking_model_dir/model.ckpt-20000\n",
      "INFO:tensorflow:global_step/sec: 14.0287\n",
      "INFO:tensorflow:loss = -0.50678754, step = 20000 (7.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2271\n",
      "INFO:tensorflow:loss = -0.40635073, step = 20100 (4.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0918\n",
      "INFO:tensorflow:loss = -0.5135975, step = 20200 (4.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5992\n",
      "INFO:tensorflow:loss = -0.88580847, step = 20300 (4.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1518\n",
      "INFO:tensorflow:loss = -0.46304008, step = 20400 (4.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0351\n",
      "INFO:tensorflow:loss = -0.41294956, step = 20500 (4.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3341\n",
      "INFO:tensorflow:loss = -0.5400671, step = 20600 (4.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7898\n",
      "INFO:tensorflow:loss = -0.4493994, step = 20700 (4.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4855\n",
      "INFO:tensorflow:loss = -0.48226672, step = 20800 (4.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0029\n",
      "INFO:tensorflow:loss = -0.4197253, step = 20900 (4.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7929\n",
      "INFO:tensorflow:loss = -0.47202513, step = 21000 (4.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5798\n",
      "INFO:tensorflow:loss = -0.88903767, step = 21100 (4.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8202\n",
      "INFO:tensorflow:loss = -0.50844157, step = 21200 (4.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1229\n",
      "INFO:tensorflow:loss = -0.3761967, step = 21300 (4.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.747\n",
      "INFO:tensorflow:loss = -0.50027716, step = 21400 (4.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0563\n",
      "INFO:tensorflow:loss = -0.4203828, step = 21500 (4.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4802\n",
      "INFO:tensorflow:loss = -0.4773201, step = 21600 (4.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7937\n",
      "INFO:tensorflow:loss = -0.49223834, step = 21700 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.771\n",
      "INFO:tensorflow:loss = -0.41192496, step = 21800 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2632\n",
      "INFO:tensorflow:loss = -0.827152, step = 21900 (4.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8275\n",
      "INFO:tensorflow:loss = -0.41553083, step = 22000 (4.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4238\n",
      "INFO:tensorflow:loss = -0.46110564, step = 22100 (4.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.17\n",
      "INFO:tensorflow:loss = -0.52759385, step = 22200 (4.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0424\n",
      "INFO:tensorflow:loss = -0.5008662, step = 22300 (4.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4867\n",
      "INFO:tensorflow:loss = -0.5580214, step = 22400 (4.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3715\n",
      "INFO:tensorflow:loss = -0.43913996, step = 22500 (4.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9347\n",
      "INFO:tensorflow:loss = -0.38333082, step = 22600 (4.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9407\n",
      "INFO:tensorflow:loss = -0.6820502, step = 22700 (4.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4648\n",
      "INFO:tensorflow:loss = -0.5785246, step = 22800 (4.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.35\n",
      "INFO:tensorflow:loss = -0.56401825, step = 22900 (4.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0085\n",
      "INFO:tensorflow:loss = -0.5456028, step = 23000 (4.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8424\n",
      "INFO:tensorflow:loss = -0.46359587, step = 23100 (4.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1026\n",
      "INFO:tensorflow:loss = -0.5670191, step = 23200 (4.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.889\n",
      "INFO:tensorflow:loss = -0.5623124, step = 23300 (4.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6007\n",
      "INFO:tensorflow:loss = -0.6091671, step = 23400 (4.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1767\n",
      "INFO:tensorflow:loss = -0.5245894, step = 23500 (4.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6778\n",
      "INFO:tensorflow:loss = -0.62746066, step = 23600 (4.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0383\n",
      "INFO:tensorflow:loss = -0.6073533, step = 23700 (4.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6736\n",
      "INFO:tensorflow:loss = -0.6617274, step = 23800 (4.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9299\n",
      "INFO:tensorflow:loss = -0.53712964, step = 23900 (4.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8934\n",
      "INFO:tensorflow:loss = -0.4615144, step = 24000 (4.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.167\n",
      "INFO:tensorflow:loss = -0.54063874, step = 24100 (4.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1103\n",
      "INFO:tensorflow:loss = -0.98534393, step = 24200 (4.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1801\n",
      "INFO:tensorflow:loss = -0.4913405, step = 24300 (4.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9821\n",
      "INFO:tensorflow:loss = -0.45858347, step = 24400 (4.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6506\n",
      "INFO:tensorflow:loss = -0.472153, step = 24500 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5755\n",
      "INFO:tensorflow:loss = -0.812978, step = 24600 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.981\n",
      "INFO:tensorflow:loss = -0.38234097, step = 24700 (4.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5805\n",
      "INFO:tensorflow:loss = -0.51030755, step = 24800 (4.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6813\n",
      "INFO:tensorflow:loss = -0.4438021, step = 24900 (4.835 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 25000...\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "WARNING:tensorflow:From /home/simin/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1064: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 25000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:05:35\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:05:35.835501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:05:35.836130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:05:35.836712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:05:35.837590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:05:35.837636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:05:35.838106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:05:35.838170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.17872s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:05:36\n",
      "INFO:tensorflow:Saving dict for global step 25000: global_step = 25000, labels_mean = 0.08838565, logits_mean = 1.5292815, loss = -0.5017298, metric/ndcg@10 = 0.23447442, metric/ndcg@15 = 0.27849397, metric/ndcg@20 = 0.31474906, metric/ndcg@25 = 0.34347373, metric/ndcg@30 = 0.37195364\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25000: /tmp/ranking_model_dir/model.ckpt-25000\n",
      "INFO:tensorflow:global_step/sec: 13.8668\n",
      "INFO:tensorflow:loss = -0.9805316, step = 25000 (7.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5834\n",
      "INFO:tensorflow:loss = -0.69098747, step = 25100 (5.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3757\n",
      "INFO:tensorflow:loss = -0.4842991, step = 25200 (8.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5217\n",
      "INFO:tensorflow:loss = -0.63288, step = 25300 (6.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7943\n",
      "INFO:tensorflow:loss = -0.6603592, step = 25400 (5.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1102\n",
      "INFO:tensorflow:loss = -0.46255568, step = 25500 (5.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3361\n",
      "INFO:tensorflow:loss = -0.4247609, step = 25600 (5.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3235\n",
      "INFO:tensorflow:loss = -0.62014437, step = 25700 (5.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5693\n",
      "INFO:tensorflow:loss = -0.98601806, step = 25800 (5.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4473\n",
      "INFO:tensorflow:loss = -0.7423228, step = 25900 (5.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8201\n",
      "INFO:tensorflow:loss = -0.5751811, step = 26000 (5.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4036\n",
      "INFO:tensorflow:loss = -0.8269159, step = 26100 (5.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8798\n",
      "INFO:tensorflow:loss = -0.6824137, step = 26200 (5.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9335\n",
      "INFO:tensorflow:loss = -0.5506444, step = 26300 (5.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2368\n",
      "INFO:tensorflow:loss = -0.4796595, step = 26400 (5.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7635\n",
      "INFO:tensorflow:loss = -0.84517133, step = 26500 (5.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8592\n",
      "INFO:tensorflow:loss = -0.83742166, step = 26600 (5.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.151\n",
      "INFO:tensorflow:loss = -0.57137877, step = 26700 (5.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7543\n",
      "INFO:tensorflow:loss = -0.5446125, step = 26800 (5.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7436\n",
      "INFO:tensorflow:loss = -0.65606904, step = 26900 (5.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1734\n",
      "INFO:tensorflow:loss = -0.84575665, step = 27000 (5.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7672\n",
      "INFO:tensorflow:loss = -0.6086985, step = 27100 (5.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6785\n",
      "INFO:tensorflow:loss = -0.5105529, step = 27200 (5.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2358\n",
      "INFO:tensorflow:loss = -0.80142486, step = 27300 (5.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.492\n",
      "INFO:tensorflow:loss = -0.38468295, step = 27400 (5.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4876\n",
      "INFO:tensorflow:loss = -0.51255447, step = 27500 (5.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6944\n",
      "INFO:tensorflow:loss = -0.44169784, step = 27600 (5.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4181\n",
      "INFO:tensorflow:loss = -0.4635332, step = 27700 (5.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1449\n",
      "INFO:tensorflow:loss = -0.75251335, step = 27800 (4.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3477\n",
      "INFO:tensorflow:loss = -0.42356235, step = 27900 (4.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4407\n",
      "INFO:tensorflow:loss = -0.66851556, step = 28000 (4.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6203\n",
      "INFO:tensorflow:loss = -0.5286087, step = 28100 (4.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3075\n",
      "INFO:tensorflow:loss = -0.43828005, step = 28200 (4.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8991\n",
      "INFO:tensorflow:loss = -0.6333643, step = 28300 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3295\n",
      "INFO:tensorflow:loss = -0.50580114, step = 28400 (4.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8984\n",
      "INFO:tensorflow:loss = -0.5450928, step = 28500 (4.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.065\n",
      "INFO:tensorflow:loss = -0.45498276, step = 28600 (4.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3617\n",
      "INFO:tensorflow:loss = -0.5229382, step = 28700 (4.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4093\n",
      "INFO:tensorflow:loss = -0.90649426, step = 28800 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6471\n",
      "INFO:tensorflow:loss = -0.4932372, step = 28900 (4.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3272\n",
      "INFO:tensorflow:loss = -0.46595782, step = 29000 (4.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3147\n",
      "INFO:tensorflow:loss = -0.5827337, step = 29100 (4.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4516\n",
      "INFO:tensorflow:loss = -0.45863366, step = 29200 (4.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7984\n",
      "INFO:tensorflow:loss = -0.51411957, step = 29300 (4.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.516\n",
      "INFO:tensorflow:loss = -0.39198858, step = 29400 (4.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3691\n",
      "INFO:tensorflow:loss = -0.49610478, step = 29500 (4.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6926\n",
      "INFO:tensorflow:loss = -0.89673454, step = 29600 (4.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6026\n",
      "INFO:tensorflow:loss = -0.51566184, step = 29700 (4.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6484\n",
      "INFO:tensorflow:loss = -0.4330749, step = 29800 (4.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8986\n",
      "INFO:tensorflow:loss = -0.53435755, step = 29900 (4.567 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 30000...\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 30000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:09:56\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:09:56.236675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:09:56.237379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:09:56.237998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:09:56.238863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:09:56.238899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:09:56.239349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:09:56.239402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.09800s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:09:57\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, labels_mean = 0.08838565, logits_mean = 1.6764073, loss = -0.5251919, metric/ndcg@10 = 0.27335295, metric/ndcg@15 = 0.31706825, metric/ndcg@20 = 0.35039258, metric/ndcg@25 = 0.37968302, metric/ndcg@30 = 0.4043568\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: /tmp/ranking_model_dir/model.ckpt-30000\n",
      "INFO:tensorflow:global_step/sec: 13.9474\n",
      "INFO:tensorflow:loss = -0.4210811, step = 30000 (7.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.52\n",
      "INFO:tensorflow:loss = -0.5186105, step = 30100 (4.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6815\n",
      "INFO:tensorflow:loss = -0.4580031, step = 30200 (4.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5281\n",
      "INFO:tensorflow:loss = -0.42691135, step = 30300 (4.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9374\n",
      "INFO:tensorflow:loss = -0.86023855, step = 30400 (4.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.475\n",
      "INFO:tensorflow:loss = -0.43519837, step = 30500 (4.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3949\n",
      "INFO:tensorflow:loss = -0.42779803, step = 30600 (4.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1134\n",
      "INFO:tensorflow:loss = -0.55375546, step = 30700 (4.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5012\n",
      "INFO:tensorflow:loss = -0.5528445, step = 30800 (4.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0548\n",
      "INFO:tensorflow:loss = -0.54700696, step = 30900 (4.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8097\n",
      "INFO:tensorflow:loss = -0.4667162, step = 31000 (4.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9137\n",
      "INFO:tensorflow:loss = -0.4530763, step = 31100 (4.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4273\n",
      "INFO:tensorflow:loss = -0.6952933, step = 31200 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6184\n",
      "INFO:tensorflow:loss = -0.58145154, step = 31300 (4.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9046\n",
      "INFO:tensorflow:loss = -0.5834763, step = 31400 (4.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8427\n",
      "INFO:tensorflow:loss = -0.5769348, step = 31500 (5.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6438\n",
      "INFO:tensorflow:loss = -0.510646, step = 31600 (4.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.335\n",
      "INFO:tensorflow:loss = -0.61075234, step = 31700 (4.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.646\n",
      "INFO:tensorflow:loss = -0.5585742, step = 31800 (4.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5813\n",
      "INFO:tensorflow:loss = -0.58948743, step = 31900 (4.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7445\n",
      "INFO:tensorflow:loss = -0.55541956, step = 32000 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3014\n",
      "INFO:tensorflow:loss = -0.64854175, step = 32100 (4.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2208\n",
      "INFO:tensorflow:loss = -0.62520677, step = 32200 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1478\n",
      "INFO:tensorflow:loss = -0.64382625, step = 32300 (4.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6493\n",
      "INFO:tensorflow:loss = -0.5300286, step = 32400 (4.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.862\n",
      "INFO:tensorflow:loss = -0.49161363, step = 32500 (4.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8888\n",
      "INFO:tensorflow:loss = -0.5571132, step = 32600 (4.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6041\n",
      "INFO:tensorflow:loss = -0.9735524, step = 32700 (5.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8117\n",
      "INFO:tensorflow:loss = -0.5153293, step = 32800 (4.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4639\n",
      "INFO:tensorflow:loss = -0.45293713, step = 32900 (4.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4576\n",
      "INFO:tensorflow:loss = -0.53111136, step = 33000 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7143\n",
      "INFO:tensorflow:loss = -0.8053297, step = 33100 (4.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5434\n",
      "INFO:tensorflow:loss = -0.44297442, step = 33200 (4.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4143\n",
      "INFO:tensorflow:loss = -0.5409825, step = 33300 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8933\n",
      "INFO:tensorflow:loss = -0.47515684, step = 33400 (5.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4114\n",
      "INFO:tensorflow:loss = -0.98056287, step = 33500 (4.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5297\n",
      "INFO:tensorflow:loss = -0.6882341, step = 33600 (4.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0167\n",
      "INFO:tensorflow:loss = -0.5062445, step = 33700 (4.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5885\n",
      "INFO:tensorflow:loss = -0.6160798, step = 33800 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7679\n",
      "INFO:tensorflow:loss = -0.6841367, step = 33900 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1398\n",
      "INFO:tensorflow:loss = -0.44180694, step = 34000 (5.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4295\n",
      "INFO:tensorflow:loss = -0.42272162, step = 34100 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4007\n",
      "INFO:tensorflow:loss = -0.5855547, step = 34200 (4.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2628\n",
      "INFO:tensorflow:loss = -0.98186517, step = 34300 (4.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0908\n",
      "INFO:tensorflow:loss = -0.73340607, step = 34400 (4.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8212\n",
      "INFO:tensorflow:loss = -0.5767259, step = 34500 (4.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5537\n",
      "INFO:tensorflow:loss = -0.8162647, step = 34600 (4.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0283\n",
      "INFO:tensorflow:loss = -0.6888142, step = 34700 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4925\n",
      "INFO:tensorflow:loss = -0.55058706, step = 34800 (5.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4286\n",
      "INFO:tensorflow:loss = -0.47466645, step = 34900 (4.459 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 35000...\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 35000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:13:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-35000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:13:49.573855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:13:49.574493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:13:49.575014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:13:49.575788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:13:49.575823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:13:49.576413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:13:49.576512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.14203s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:13:50\n",
      "INFO:tensorflow:Saving dict for global step 35000: global_step = 35000, labels_mean = 0.08838565, logits_mean = 1.6955129, loss = -0.5507948, metric/ndcg@10 = 0.31633064, metric/ndcg@15 = 0.36181834, metric/ndcg@20 = 0.3994694, metric/ndcg@25 = 0.42425323, metric/ndcg@30 = 0.44946435\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: /tmp/ranking_model_dir/model.ckpt-35000\n",
      "INFO:tensorflow:global_step/sec: 14.3581\n",
      "INFO:tensorflow:loss = -0.8539937, step = 35000 (6.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8126\n",
      "INFO:tensorflow:loss = -0.8890754, step = 35100 (4.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1783\n",
      "INFO:tensorflow:loss = -0.60581416, step = 35200 (4.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7608\n",
      "INFO:tensorflow:loss = -0.5617964, step = 35300 (4.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5894\n",
      "INFO:tensorflow:loss = -0.7040431, step = 35400 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3965\n",
      "INFO:tensorflow:loss = -0.855242, step = 35500 (4.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4967\n",
      "INFO:tensorflow:loss = -0.6531165, step = 35600 (4.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6479\n",
      "INFO:tensorflow:loss = -0.52819854, step = 35700 (4.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5808\n",
      "INFO:tensorflow:loss = -0.8390305, step = 35800 (4.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3416\n",
      "INFO:tensorflow:loss = -0.44725752, step = 35900 (4.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7203\n",
      "INFO:tensorflow:loss = -0.5379035, step = 36000 (4.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.096\n",
      "INFO:tensorflow:loss = -0.5028509, step = 36100 (4.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6268\n",
      "INFO:tensorflow:loss = -0.5013317, step = 36200 (4.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4431\n",
      "INFO:tensorflow:loss = -0.8143471, step = 36300 (4.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8267\n",
      "INFO:tensorflow:loss = -0.45400852, step = 36400 (4.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2241\n",
      "INFO:tensorflow:loss = -0.64980626, step = 36500 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7872\n",
      "INFO:tensorflow:loss = -0.55948997, step = 36600 (4.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5744\n",
      "INFO:tensorflow:loss = -0.47686595, step = 36700 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3824\n",
      "INFO:tensorflow:loss = -0.67266643, step = 36800 (4.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8954\n",
      "INFO:tensorflow:loss = -0.528267, step = 36900 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3635\n",
      "INFO:tensorflow:loss = -0.55291975, step = 37000 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4295\n",
      "INFO:tensorflow:loss = -0.5120155, step = 37100 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5421\n",
      "INFO:tensorflow:loss = -0.5666827, step = 37200 (4.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6941\n",
      "INFO:tensorflow:loss = -0.90478325, step = 37300 (4.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0189\n",
      "INFO:tensorflow:loss = -0.49820113, step = 37400 (4.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3589\n",
      "INFO:tensorflow:loss = -0.48206216, step = 37500 (4.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7696\n",
      "INFO:tensorflow:loss = -0.63717, step = 37600 (4.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6738\n",
      "INFO:tensorflow:loss = -0.4984648, step = 37700 (4.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4416\n",
      "INFO:tensorflow:loss = -0.5141231, step = 37800 (4.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3675\n",
      "INFO:tensorflow:loss = -0.41364056, step = 37900 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9321\n",
      "INFO:tensorflow:loss = -0.5372137, step = 38000 (4.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7779\n",
      "INFO:tensorflow:loss = -0.91456676, step = 38100 (4.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4026\n",
      "INFO:tensorflow:loss = -0.54027015, step = 38200 (4.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7998\n",
      "INFO:tensorflow:loss = -0.45670018, step = 38300 (4.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7627\n",
      "INFO:tensorflow:loss = -0.5458265, step = 38400 (4.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5957\n",
      "INFO:tensorflow:loss = -0.43571413, step = 38500 (4.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4815\n",
      "INFO:tensorflow:loss = -0.50393784, step = 38600 (4.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6631\n",
      "INFO:tensorflow:loss = -0.48189098, step = 38700 (4.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7657\n",
      "INFO:tensorflow:loss = -0.45083398, step = 38800 (4.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.319\n",
      "INFO:tensorflow:loss = -0.8801261, step = 38900 (4.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5409\n",
      "INFO:tensorflow:loss = -0.46757913, step = 39000 (4.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.453\n",
      "INFO:tensorflow:loss = -0.44481516, step = 39100 (4.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.895\n",
      "INFO:tensorflow:loss = -0.5717715, step = 39200 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9611\n",
      "INFO:tensorflow:loss = -0.5674393, step = 39300 (4.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0379\n",
      "INFO:tensorflow:loss = -0.57949364, step = 39400 (4.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6081\n",
      "INFO:tensorflow:loss = -0.48869437, step = 39500 (4.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.604\n",
      "INFO:tensorflow:loss = -0.43243593, step = 39600 (4.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3899\n",
      "INFO:tensorflow:loss = -0.7119254, step = 39700 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8666\n",
      "INFO:tensorflow:loss = -0.591258, step = 39800 (4.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6966\n",
      "INFO:tensorflow:loss = -0.58609164, step = 39900 (4.406 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 40000...\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 40000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:17:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:17:39.089514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:17:39.090131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:17:39.090619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:17:39.091299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:17:39.091334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:17:39.091781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:17:39.091834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.26237s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:17:40\n",
      "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, labels_mean = 0.08838565, logits_mean = 1.7644172, loss = -0.5666943, metric/ndcg@10 = 0.33684915, metric/ndcg@15 = 0.388036, metric/ndcg@20 = 0.4228215, metric/ndcg@25 = 0.4532632, metric/ndcg@30 = 0.47411236\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: /tmp/ranking_model_dir/model.ckpt-40000\n",
      "INFO:tensorflow:global_step/sec: 14.4954\n",
      "INFO:tensorflow:loss = -0.53512454, step = 40000 (6.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2089\n",
      "INFO:tensorflow:loss = -0.50846887, step = 40100 (4.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.75\n",
      "INFO:tensorflow:loss = -0.6183058, step = 40200 (4.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1574\n",
      "INFO:tensorflow:loss = -0.5647731, step = 40300 (4.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.529\n",
      "INFO:tensorflow:loss = -0.59768236, step = 40400 (4.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.566\n",
      "INFO:tensorflow:loss = -0.603964, step = 40500 (4.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3721\n",
      "INFO:tensorflow:loss = -0.71361625, step = 40600 (5.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4317\n",
      "INFO:tensorflow:loss = -0.6537972, step = 40700 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9678\n",
      "INFO:tensorflow:loss = -0.6525431, step = 40800 (4.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8522\n",
      "INFO:tensorflow:loss = -0.6155405, step = 40900 (4.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.859\n",
      "INFO:tensorflow:loss = -0.51668143, step = 41000 (4.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2205\n",
      "INFO:tensorflow:loss = -0.6172554, step = 41100 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4308\n",
      "INFO:tensorflow:loss = -0.94656086, step = 41200 (5.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8591\n",
      "INFO:tensorflow:loss = -0.503361, step = 41300 (4.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7344\n",
      "INFO:tensorflow:loss = -0.46776074, step = 41400 (4.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6967\n",
      "INFO:tensorflow:loss = -0.5822386, step = 41500 (4.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2975\n",
      "INFO:tensorflow:loss = -0.8097807, step = 41600 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8335\n",
      "INFO:tensorflow:loss = -0.5091151, step = 41700 (4.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5914\n",
      "INFO:tensorflow:loss = -0.5546151, step = 41800 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3975\n",
      "INFO:tensorflow:loss = -0.5105197, step = 41900 (5.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7774\n",
      "INFO:tensorflow:loss = -0.98548234, step = 42000 (5.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3084\n",
      "INFO:tensorflow:loss = -0.7155107, step = 42100 (4.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.598\n",
      "INFO:tensorflow:loss = -0.5144764, step = 42200 (4.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4104\n",
      "INFO:tensorflow:loss = -0.62610143, step = 42300 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0343\n",
      "INFO:tensorflow:loss = -0.70526403, step = 42400 (4.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3315\n",
      "INFO:tensorflow:loss = -0.48782548, step = 42500 (4.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0132\n",
      "INFO:tensorflow:loss = -0.43897733, step = 42600 (4.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3014\n",
      "INFO:tensorflow:loss = -0.5834826, step = 42700 (4.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8591\n",
      "INFO:tensorflow:loss = -0.9803421, step = 42800 (4.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5337\n",
      "INFO:tensorflow:loss = -0.756534, step = 42900 (4.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5179\n",
      "INFO:tensorflow:loss = -0.595776, step = 43000 (4.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5883\n",
      "INFO:tensorflow:loss = -0.8118545, step = 43100 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.437\n",
      "INFO:tensorflow:loss = -0.6741115, step = 43200 (4.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6532\n",
      "INFO:tensorflow:loss = -0.5649857, step = 43300 (4.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2026\n",
      "INFO:tensorflow:loss = -0.54318035, step = 43400 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2526\n",
      "INFO:tensorflow:loss = -0.875515, step = 43500 (4.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0897\n",
      "INFO:tensorflow:loss = -0.92984325, step = 43600 (4.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1967\n",
      "INFO:tensorflow:loss = -0.6520035, step = 43700 (4.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3629\n",
      "INFO:tensorflow:loss = -0.5826138, step = 43800 (4.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8373\n",
      "INFO:tensorflow:loss = -0.72719884, step = 43900 (5.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0515\n",
      "INFO:tensorflow:loss = -0.870682, step = 44000 (4.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2522\n",
      "INFO:tensorflow:loss = -0.6730304, step = 44100 (4.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.738\n",
      "INFO:tensorflow:loss = -0.5498942, step = 44200 (4.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.484\n",
      "INFO:tensorflow:loss = -0.8631649, step = 44300 (4.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2321\n",
      "INFO:tensorflow:loss = -0.5392223, step = 44400 (4.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0363\n",
      "INFO:tensorflow:loss = -0.56512815, step = 44500 (4.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1721\n",
      "INFO:tensorflow:loss = -0.5256899, step = 44600 (4.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4381\n",
      "INFO:tensorflow:loss = -0.5103892, step = 44700 (4.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5021\n",
      "INFO:tensorflow:loss = -0.8427198, step = 44800 (4.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6983\n",
      "INFO:tensorflow:loss = -0.47339487, step = 44900 (4.609 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 45000...\n",
      "INFO:tensorflow:Saving checkpoints for 45000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 45000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:21:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-45000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:21:32.433349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:21:32.433985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:21:32.434496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:21:32.435280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:21:32.435316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:21:32.435754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:21:32.435809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.20030s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:21:33\n",
      "INFO:tensorflow:Saving dict for global step 45000: global_step = 45000, labels_mean = 0.08838565, logits_mean = 1.7489473, loss = -0.5784596, metric/ndcg@10 = 0.35853735, metric/ndcg@15 = 0.40664095, metric/ndcg@20 = 0.44366926, metric/ndcg@25 = 0.46662536, metric/ndcg@30 = 0.48934668\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 45000: /tmp/ranking_model_dir/model.ckpt-45000\n",
      "INFO:tensorflow:global_step/sec: 15.085\n",
      "INFO:tensorflow:loss = -0.6764736, step = 45000 (6.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9517\n",
      "INFO:tensorflow:loss = -0.57739127, step = 45100 (5.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3901\n",
      "INFO:tensorflow:loss = -0.5077199, step = 45200 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0884\n",
      "INFO:tensorflow:loss = -0.68786496, step = 45300 (4.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4554\n",
      "INFO:tensorflow:loss = -0.5329362, step = 45400 (4.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5124\n",
      "INFO:tensorflow:loss = -0.5722069, step = 45500 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9412\n",
      "INFO:tensorflow:loss = -0.55064255, step = 45600 (4.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8992\n",
      "INFO:tensorflow:loss = -0.55975366, step = 45700 (4.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7834\n",
      "INFO:tensorflow:loss = -0.9160774, step = 45800 (4.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0876\n",
      "INFO:tensorflow:loss = -0.5518655, step = 45900 (4.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6304\n",
      "INFO:tensorflow:loss = -0.5138511, step = 46000 (4.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2001\n",
      "INFO:tensorflow:loss = -0.63087624, step = 46100 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1179\n",
      "INFO:tensorflow:loss = -0.6141859, step = 46200 (4.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4269\n",
      "INFO:tensorflow:loss = -0.510412, step = 46300 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.612\n",
      "INFO:tensorflow:loss = -0.46476993, step = 46400 (4.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5376\n",
      "INFO:tensorflow:loss = -0.56231344, step = 46500 (5.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4596\n",
      "INFO:tensorflow:loss = -0.9190542, step = 46600 (4.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7967\n",
      "INFO:tensorflow:loss = -0.55171764, step = 46700 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.881\n",
      "INFO:tensorflow:loss = -0.43449855, step = 46800 (4.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.766\n",
      "INFO:tensorflow:loss = -0.54086894, step = 46900 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9174\n",
      "INFO:tensorflow:loss = -0.46070164, step = 47000 (4.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.158\n",
      "INFO:tensorflow:loss = -0.5454685, step = 47100 (5.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8483\n",
      "INFO:tensorflow:loss = -0.4952834, step = 47200 (4.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6504\n",
      "INFO:tensorflow:loss = -0.48207808, step = 47300 (4.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1613\n",
      "INFO:tensorflow:loss = -0.8893577, step = 47400 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9377\n",
      "INFO:tensorflow:loss = -0.51627004, step = 47500 (4.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4097\n",
      "INFO:tensorflow:loss = -0.4835127, step = 47600 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5662\n",
      "INFO:tensorflow:loss = -0.652174, step = 47700 (4.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.913\n",
      "INFO:tensorflow:loss = -0.59677184, step = 47800 (5.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3104\n",
      "INFO:tensorflow:loss = -0.57449067, step = 47900 (4.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8839\n",
      "INFO:tensorflow:loss = -0.52310735, step = 48000 (4.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.721\n",
      "INFO:tensorflow:loss = -0.50489986, step = 48100 (4.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8678\n",
      "INFO:tensorflow:loss = -0.73712707, step = 48200 (4.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5879\n",
      "INFO:tensorflow:loss = -0.6007566, step = 48300 (4.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5294\n",
      "INFO:tensorflow:loss = -0.5833851, step = 48400 (4.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7218\n",
      "INFO:tensorflow:loss = -0.57883143, step = 48500 (4.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6111\n",
      "INFO:tensorflow:loss = -0.505493, step = 48600 (4.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7591\n",
      "INFO:tensorflow:loss = -0.67283046, step = 48700 (4.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9468\n",
      "INFO:tensorflow:loss = -0.54856455, step = 48800 (4.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8107\n",
      "INFO:tensorflow:loss = -0.5813508, step = 48900 (4.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5905\n",
      "INFO:tensorflow:loss = -0.64762884, step = 49000 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8095\n",
      "INFO:tensorflow:loss = -0.7411349, step = 49100 (5.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6893\n",
      "INFO:tensorflow:loss = -0.67113006, step = 49200 (4.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2939\n",
      "INFO:tensorflow:loss = -0.6612142, step = 49300 (4.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8343\n",
      "INFO:tensorflow:loss = -0.6149467, step = 49400 (4.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0776\n",
      "INFO:tensorflow:loss = -0.48873648, step = 49500 (4.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6233\n",
      "INFO:tensorflow:loss = -0.6479927, step = 49600 (4.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0847\n",
      "INFO:tensorflow:loss = -0.92184514, step = 49700 (5.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7609\n",
      "INFO:tensorflow:loss = -0.5252799, step = 49800 (4.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4829\n",
      "INFO:tensorflow:loss = -0.5165341, step = 49900 (4.655 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 50000...\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 50000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:25:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-50000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:25:25.612818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:25:25.613499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:25:25.614003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:25:25.614714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:25:25.614750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:25:25.615288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:25:25.615343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.06909s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:25:26\n",
      "INFO:tensorflow:Saving dict for global step 50000: global_step = 50000, labels_mean = 0.08838565, logits_mean = 1.6296537, loss = -0.5781513, metric/ndcg@10 = 0.35897928, metric/ndcg@15 = 0.40614673, metric/ndcg@20 = 0.44131997, metric/ndcg@25 = 0.4731859, metric/ndcg@30 = 0.4938804\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50000: /tmp/ranking_model_dir/model.ckpt-50000\n",
      "INFO:tensorflow:global_step/sec: 14.5723\n",
      "INFO:tensorflow:loss = -0.60863185, step = 50000 (6.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0122\n",
      "INFO:tensorflow:loss = -0.82943386, step = 50100 (4.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1011\n",
      "INFO:tensorflow:loss = -0.5212095, step = 50200 (4.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8912\n",
      "INFO:tensorflow:loss = -0.60497034, step = 50300 (4.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5824\n",
      "INFO:tensorflow:loss = -0.5321726, step = 50400 (4.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5152\n",
      "INFO:tensorflow:loss = -0.9809497, step = 50500 (4.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.07\n",
      "INFO:tensorflow:loss = -0.69704956, step = 50600 (4.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9057\n",
      "INFO:tensorflow:loss = -0.552295, step = 50700 (4.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6524\n",
      "INFO:tensorflow:loss = -0.61906934, step = 50800 (4.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0469\n",
      "INFO:tensorflow:loss = -0.7153172, step = 50900 (4.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6711\n",
      "INFO:tensorflow:loss = -0.49196804, step = 51000 (4.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4256\n",
      "INFO:tensorflow:loss = -0.49772185, step = 51100 (4.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7766\n",
      "INFO:tensorflow:loss = -0.5856713, step = 51200 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.174\n",
      "INFO:tensorflow:loss = -0.98221266, step = 51300 (4.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0248\n",
      "INFO:tensorflow:loss = -0.7695843, step = 51400 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1341\n",
      "INFO:tensorflow:loss = -0.6258539, step = 51500 (4.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1618\n",
      "INFO:tensorflow:loss = -0.8156266, step = 51600 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3477\n",
      "INFO:tensorflow:loss = -0.6456263, step = 51700 (4.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3918\n",
      "INFO:tensorflow:loss = -0.5759983, step = 51800 (4.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8257\n",
      "INFO:tensorflow:loss = -0.5496372, step = 51900 (4.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8132\n",
      "INFO:tensorflow:loss = -0.87477136, step = 52000 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3745\n",
      "INFO:tensorflow:loss = -0.96108514, step = 52100 (4.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2902\n",
      "INFO:tensorflow:loss = -0.7045649, step = 52200 (4.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5366\n",
      "INFO:tensorflow:loss = -0.58399004, step = 52300 (5.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1461\n",
      "INFO:tensorflow:loss = -0.74190384, step = 52400 (4.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8121\n",
      "INFO:tensorflow:loss = -0.8589126, step = 52500 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8553\n",
      "INFO:tensorflow:loss = -0.6676667, step = 52600 (4.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4629\n",
      "INFO:tensorflow:loss = -0.56917024, step = 52700 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8173\n",
      "INFO:tensorflow:loss = -0.8773797, step = 52800 (4.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5288\n",
      "INFO:tensorflow:loss = -0.5715827, step = 52900 (4.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3749\n",
      "INFO:tensorflow:loss = -0.5299187, step = 53000 (4.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.686\n",
      "INFO:tensorflow:loss = -0.56481767, step = 53100 (4.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4136\n",
      "INFO:tensorflow:loss = -0.55814123, step = 53200 (4.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2478\n",
      "INFO:tensorflow:loss = -0.86003447, step = 53300 (4.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9465\n",
      "INFO:tensorflow:loss = -0.5362207, step = 53400 (4.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4139\n",
      "INFO:tensorflow:loss = -0.6899173, step = 53500 (4.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5987\n",
      "INFO:tensorflow:loss = -0.6139719, step = 53600 (4.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.996\n",
      "INFO:tensorflow:loss = -0.54188555, step = 53700 (4.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9066\n",
      "INFO:tensorflow:loss = -0.691097, step = 53800 (4.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5743\n",
      "INFO:tensorflow:loss = -0.5813209, step = 53900 (4.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9653\n",
      "INFO:tensorflow:loss = -0.5684687, step = 54000 (4.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5791\n",
      "INFO:tensorflow:loss = -0.601106, step = 54100 (4.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2164\n",
      "INFO:tensorflow:loss = -0.5788001, step = 54200 (4.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2293\n",
      "INFO:tensorflow:loss = -0.9255508, step = 54300 (4.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5013\n",
      "INFO:tensorflow:loss = -0.5416099, step = 54400 (4.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5859\n",
      "INFO:tensorflow:loss = -0.5311292, step = 54500 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7965\n",
      "INFO:tensorflow:loss = -0.6560281, step = 54600 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5782\n",
      "INFO:tensorflow:loss = -0.58272743, step = 54700 (4.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6517\n",
      "INFO:tensorflow:loss = -0.5585009, step = 54800 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8625\n",
      "INFO:tensorflow:loss = -0.45845383, step = 54900 (4.794 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 55000...\n",
      "INFO:tensorflow:Saving checkpoints for 55000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 55000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:29:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-55000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:29:16.823620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:29:16.824281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:29:16.824800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:29:16.825672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:29:16.825713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:29:16.826266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:29:16.826322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.10972s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:29:17\n",
      "INFO:tensorflow:Saving dict for global step 55000: global_step = 55000, labels_mean = 0.08838565, logits_mean = 1.4384208, loss = -0.5876592, metric/ndcg@10 = 0.3726686, metric/ndcg@15 = 0.41982424, metric/ndcg@20 = 0.45841688, metric/ndcg@25 = 0.4835013, metric/ndcg@30 = 0.5071552\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 55000: /tmp/ranking_model_dir/model.ckpt-55000\n",
      "INFO:tensorflow:global_step/sec: 14.347\n",
      "INFO:tensorflow:loss = -0.53344995, step = 55000 (6.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6512\n",
      "INFO:tensorflow:loss = -0.9250084, step = 55100 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7336\n",
      "INFO:tensorflow:loss = -0.6042637, step = 55200 (4.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5739\n",
      "INFO:tensorflow:loss = -0.5003617, step = 55300 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0846\n",
      "INFO:tensorflow:loss = -0.5839727, step = 55400 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.965\n",
      "INFO:tensorflow:loss = -0.5046692, step = 55500 (4.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8345\n",
      "INFO:tensorflow:loss = -0.5576881, step = 55600 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9295\n",
      "INFO:tensorflow:loss = -0.53405416, step = 55700 (4.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5495\n",
      "INFO:tensorflow:loss = -0.52143073, step = 55800 (4.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8541\n",
      "INFO:tensorflow:loss = -0.913886, step = 55900 (4.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1927\n",
      "INFO:tensorflow:loss = -0.53684247, step = 56000 (4.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5271\n",
      "INFO:tensorflow:loss = -0.47307757, step = 56100 (4.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.23\n",
      "INFO:tensorflow:loss = -0.6642741, step = 56200 (4.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.795\n",
      "INFO:tensorflow:loss = -0.61852086, step = 56300 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8963\n",
      "INFO:tensorflow:loss = -0.6067613, step = 56400 (4.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8176\n",
      "INFO:tensorflow:loss = -0.5516144, step = 56500 (4.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6178\n",
      "INFO:tensorflow:loss = -0.48906392, step = 56600 (4.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8863\n",
      "INFO:tensorflow:loss = -0.7652416, step = 56700 (4.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9925\n",
      "INFO:tensorflow:loss = -0.61590475, step = 56800 (4.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4631\n",
      "INFO:tensorflow:loss = -0.6456541, step = 56900 (4.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6623\n",
      "INFO:tensorflow:loss = -0.6093023, step = 57000 (4.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3624\n",
      "INFO:tensorflow:loss = -0.55487055, step = 57100 (4.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.738\n",
      "INFO:tensorflow:loss = -0.6714548, step = 57200 (4.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0968\n",
      "INFO:tensorflow:loss = -0.5695648, step = 57300 (4.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9521\n",
      "INFO:tensorflow:loss = -0.55425346, step = 57400 (4.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7447\n",
      "INFO:tensorflow:loss = -0.69480383, step = 57500 (4.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0832\n",
      "INFO:tensorflow:loss = -0.76392716, step = 57600 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6566\n",
      "INFO:tensorflow:loss = -0.702265, step = 57700 (4.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0456\n",
      "INFO:tensorflow:loss = -0.66377723, step = 57800 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2944\n",
      "INFO:tensorflow:loss = -0.6650864, step = 57900 (4.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6202\n",
      "INFO:tensorflow:loss = -0.49516612, step = 58000 (4.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7307\n",
      "INFO:tensorflow:loss = -0.69963807, step = 58100 (4.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4406\n",
      "INFO:tensorflow:loss = -0.91529924, step = 58200 (4.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7442\n",
      "INFO:tensorflow:loss = -0.5576631, step = 58300 (4.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1865\n",
      "INFO:tensorflow:loss = -0.588514, step = 58400 (4.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.999\n",
      "INFO:tensorflow:loss = -0.609378, step = 58500 (4.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8265\n",
      "INFO:tensorflow:loss = -0.81609124, step = 58600 (4.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0891\n",
      "INFO:tensorflow:loss = -0.5559742, step = 58700 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4498\n",
      "INFO:tensorflow:loss = -0.615533, step = 58800 (4.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4821\n",
      "INFO:tensorflow:loss = -0.56900847, step = 58900 (4.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1331\n",
      "INFO:tensorflow:loss = -0.98609805, step = 59000 (4.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0659\n",
      "INFO:tensorflow:loss = -0.72003895, step = 59100 (4.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4242\n",
      "INFO:tensorflow:loss = -0.5949888, step = 59200 (4.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9085\n",
      "INFO:tensorflow:loss = -0.61927986, step = 59300 (4.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9491\n",
      "INFO:tensorflow:loss = -0.7367391, step = 59400 (4.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0751\n",
      "INFO:tensorflow:loss = -0.5540762, step = 59500 (4.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9356\n",
      "INFO:tensorflow:loss = -0.5491912, step = 59600 (4.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1278\n",
      "INFO:tensorflow:loss = -0.5776166, step = 59700 (4.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8187\n",
      "INFO:tensorflow:loss = -0.98541176, step = 59800 (4.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2673\n",
      "INFO:tensorflow:loss = -0.78586686, step = 59900 (4.491 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 60000...\n",
      "INFO:tensorflow:Saving checkpoints for 60000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 60000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:33:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-60000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:33:04.143657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:33:04.144297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:33:04.144775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:33:04.145446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:33:04.145480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:33:04.145909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:33:04.145959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.08082s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:33:05\n",
      "INFO:tensorflow:Saving dict for global step 60000: global_step = 60000, labels_mean = 0.08838565, logits_mean = 1.1170325, loss = -0.5914071, metric/ndcg@10 = 0.37330833, metric/ndcg@15 = 0.42361632, metric/ndcg@20 = 0.45931676, metric/ndcg@25 = 0.48714957, metric/ndcg@30 = 0.5108478\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 60000: /tmp/ranking_model_dir/model.ckpt-60000\n",
      "INFO:tensorflow:global_step/sec: 14.7396\n",
      "INFO:tensorflow:loss = -0.6311711, step = 60000 (6.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3419\n",
      "INFO:tensorflow:loss = -0.8191486, step = 60100 (4.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8218\n",
      "INFO:tensorflow:loss = -0.6770883, step = 60200 (4.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5222\n",
      "INFO:tensorflow:loss = -0.5978298, step = 60300 (4.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4339\n",
      "INFO:tensorflow:loss = -0.47526684, step = 60400 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5551\n",
      "INFO:tensorflow:loss = -0.87891376, step = 60500 (4.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3133\n",
      "INFO:tensorflow:loss = -0.9849553, step = 60600 (4.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.188\n",
      "INFO:tensorflow:loss = -0.6883724, step = 60700 (4.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7792\n",
      "INFO:tensorflow:loss = -0.6275881, step = 60800 (4.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8267\n",
      "INFO:tensorflow:loss = -0.78898203, step = 60900 (4.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6162\n",
      "INFO:tensorflow:loss = -0.8521416, step = 61000 (4.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1437\n",
      "INFO:tensorflow:loss = -0.66648626, step = 61100 (4.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9368\n",
      "INFO:tensorflow:loss = -0.548867, step = 61200 (4.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6145\n",
      "INFO:tensorflow:loss = -0.8826277, step = 61300 (4.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9856\n",
      "INFO:tensorflow:loss = -0.6266533, step = 61400 (4.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4138\n",
      "INFO:tensorflow:loss = -0.5755858, step = 61500 (4.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2745\n",
      "INFO:tensorflow:loss = -0.6020802, step = 61600 (4.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3687\n",
      "INFO:tensorflow:loss = -0.5660271, step = 61700 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0116\n",
      "INFO:tensorflow:loss = -0.8640479, step = 61800 (4.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0727\n",
      "INFO:tensorflow:loss = -0.5572076, step = 61900 (4.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6375\n",
      "INFO:tensorflow:loss = -0.657323, step = 62000 (4.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.315\n",
      "INFO:tensorflow:loss = -0.6524558, step = 62100 (4.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6115\n",
      "INFO:tensorflow:loss = -0.54259735, step = 62200 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5578\n",
      "INFO:tensorflow:loss = -0.685351, step = 62300 (4.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2703\n",
      "INFO:tensorflow:loss = -0.58600533, step = 62400 (4.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7062\n",
      "INFO:tensorflow:loss = -0.5778714, step = 62500 (4.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9703\n",
      "INFO:tensorflow:loss = -0.6276329, step = 62600 (4.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8419\n",
      "INFO:tensorflow:loss = -0.59581023, step = 62700 (4.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4537\n",
      "INFO:tensorflow:loss = -0.9102897, step = 62800 (4.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4937\n",
      "INFO:tensorflow:loss = -0.6118169, step = 62900 (4.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5936\n",
      "INFO:tensorflow:loss = -0.5786847, step = 63000 (4.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7803\n",
      "INFO:tensorflow:loss = -0.67467296, step = 63100 (4.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0963\n",
      "INFO:tensorflow:loss = -0.6608079, step = 63200 (4.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0587\n",
      "INFO:tensorflow:loss = -0.55343795, step = 63300 (4.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2847\n",
      "INFO:tensorflow:loss = -0.48654836, step = 63400 (4.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7331\n",
      "INFO:tensorflow:loss = -0.57455015, step = 63500 (4.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0201\n",
      "INFO:tensorflow:loss = -0.92595506, step = 63600 (4.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7073\n",
      "INFO:tensorflow:loss = -0.63999397, step = 63700 (4.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.778\n",
      "INFO:tensorflow:loss = -0.53628397, step = 63800 (4.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.029\n",
      "INFO:tensorflow:loss = -0.57389593, step = 63900 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1054\n",
      "INFO:tensorflow:loss = -0.5249306, step = 64000 (4.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1633\n",
      "INFO:tensorflow:loss = -0.5190953, step = 64100 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1925\n",
      "INFO:tensorflow:loss = -0.634936, step = 64200 (4.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9\n",
      "INFO:tensorflow:loss = -0.5293076, step = 64300 (4.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8097\n",
      "INFO:tensorflow:loss = -0.9220889, step = 64400 (4.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3348\n",
      "INFO:tensorflow:loss = -0.5789381, step = 64500 (4.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0122\n",
      "INFO:tensorflow:loss = -0.5341306, step = 64600 (4.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4711\n",
      "INFO:tensorflow:loss = -0.6781633, step = 64700 (4.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4841\n",
      "INFO:tensorflow:loss = -0.64888465, step = 64800 (4.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6825\n",
      "INFO:tensorflow:loss = -0.6443504, step = 64900 (4.409 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 65000...\n",
      "INFO:tensorflow:Saving checkpoints for 65000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 65000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:36:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-65000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:36:52.886881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:36:52.887387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:36:52.887961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:36:52.888648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:36:52.888683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:36:52.889114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:36:52.889163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.06793s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:36:53\n",
      "INFO:tensorflow:Saving dict for global step 65000: global_step = 65000, labels_mean = 0.08838565, logits_mean = 0.7674456, loss = -0.5945333, metric/ndcg@10 = 0.37852833, metric/ndcg@15 = 0.42711303, metric/ndcg@20 = 0.46248403, metric/ndcg@25 = 0.49220678, metric/ndcg@30 = 0.5135247\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 65000: /tmp/ranking_model_dir/model.ckpt-65000\n",
      "INFO:tensorflow:global_step/sec: 14.8454\n",
      "INFO:tensorflow:loss = -0.5875709, step = 65000 (6.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2068\n",
      "INFO:tensorflow:loss = -0.5247451, step = 65100 (4.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8349\n",
      "INFO:tensorflow:loss = -0.7668113, step = 65200 (4.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9857\n",
      "INFO:tensorflow:loss = -0.5959098, step = 65300 (4.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5162\n",
      "INFO:tensorflow:loss = -0.6468133, step = 65400 (4.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7317\n",
      "INFO:tensorflow:loss = -0.6486845, step = 65500 (4.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2642\n",
      "INFO:tensorflow:loss = -0.5783274, step = 65600 (4.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8178\n",
      "INFO:tensorflow:loss = -0.6964878, step = 65700 (4.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2609\n",
      "INFO:tensorflow:loss = -0.5544851, step = 65800 (4.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7541\n",
      "INFO:tensorflow:loss = -0.5832185, step = 65900 (4.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9721\n",
      "INFO:tensorflow:loss = -0.70698035, step = 66000 (4.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3503\n",
      "INFO:tensorflow:loss = -0.76145107, step = 66100 (4.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8219\n",
      "INFO:tensorflow:loss = -0.7118248, step = 66200 (4.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6251\n",
      "INFO:tensorflow:loss = -0.6759952, step = 66300 (4.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2813\n",
      "INFO:tensorflow:loss = -0.63724685, step = 66400 (4.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5952\n",
      "INFO:tensorflow:loss = -0.533858, step = 66500 (4.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9655\n",
      "INFO:tensorflow:loss = -0.69792175, step = 66600 (4.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4233\n",
      "INFO:tensorflow:loss = -0.9170016, step = 66700 (4.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8624\n",
      "INFO:tensorflow:loss = -0.53117603, step = 66800 (4.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9126\n",
      "INFO:tensorflow:loss = -0.59723186, step = 66900 (4.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3546\n",
      "INFO:tensorflow:loss = -0.6400237, step = 67000 (4.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3056\n",
      "INFO:tensorflow:loss = -0.81472087, step = 67100 (4.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5291\n",
      "INFO:tensorflow:loss = -0.59443766, step = 67200 (4.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2654\n",
      "INFO:tensorflow:loss = -0.6556258, step = 67300 (4.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7195\n",
      "INFO:tensorflow:loss = -0.59482414, step = 67400 (4.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7651\n",
      "INFO:tensorflow:loss = -0.98331225, step = 67500 (4.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3583\n",
      "INFO:tensorflow:loss = -0.69784296, step = 67600 (4.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9034\n",
      "INFO:tensorflow:loss = -0.5787144, step = 67700 (4.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3325\n",
      "INFO:tensorflow:loss = -0.60944355, step = 67800 (4.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6707\n",
      "INFO:tensorflow:loss = -0.7843095, step = 67900 (4.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8452\n",
      "INFO:tensorflow:loss = -0.54477066, step = 68000 (4.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3429\n",
      "INFO:tensorflow:loss = -0.6028762, step = 68100 (4.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6253\n",
      "INFO:tensorflow:loss = -0.6007557, step = 68200 (4.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0836\n",
      "INFO:tensorflow:loss = -0.98431796, step = 68300 (4.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0884\n",
      "INFO:tensorflow:loss = -0.796865, step = 68400 (5.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6404\n",
      "INFO:tensorflow:loss = -0.6586335, step = 68500 (5.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2794\n",
      "INFO:tensorflow:loss = -0.809155, step = 68600 (5.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8653\n",
      "INFO:tensorflow:loss = -0.6525161, step = 68700 (5.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7322\n",
      "INFO:tensorflow:loss = -0.5944065, step = 68800 (5.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2655\n",
      "INFO:tensorflow:loss = -0.5436553, step = 68900 (5.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3782\n",
      "INFO:tensorflow:loss = -0.8544086, step = 69000 (5.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1581\n",
      "INFO:tensorflow:loss = -0.9806657, step = 69100 (5.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9063\n",
      "INFO:tensorflow:loss = -0.7194481, step = 69200 (5.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5152\n",
      "INFO:tensorflow:loss = -0.60838175, step = 69300 (5.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4801\n",
      "INFO:tensorflow:loss = -0.8052256, step = 69400 (5.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2424\n",
      "INFO:tensorflow:loss = -0.86047566, step = 69500 (5.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5318\n",
      "INFO:tensorflow:loss = -0.6642746, step = 69600 (5.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6184\n",
      "INFO:tensorflow:loss = -0.6217476, step = 69700 (4.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5667\n",
      "INFO:tensorflow:loss = -0.8745432, step = 69800 (4.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.998\n",
      "INFO:tensorflow:loss = -0.7011059, step = 69900 (4.348 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 70000...\n",
      "INFO:tensorflow:Saving checkpoints for 70000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 70000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:40:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-70000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:40:53.268912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:40:53.269706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:40:53.270165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:40:53.271064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:40:53.271099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:40:53.271566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:40:53.271614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.06423s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:40:54\n",
      "INFO:tensorflow:Saving dict for global step 70000: global_step = 70000, labels_mean = 0.08838565, logits_mean = 0.59134495, loss = -0.59616953, metric/ndcg@10 = 0.37931663, metric/ndcg@15 = 0.42870677, metric/ndcg@20 = 0.46868944, metric/ndcg@25 = 0.4966133, metric/ndcg@30 = 0.51457775\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 70000: /tmp/ranking_model_dir/model.ckpt-70000\n",
      "INFO:tensorflow:global_step/sec: 14.6681\n",
      "INFO:tensorflow:loss = -0.63788664, step = 70000 (6.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2563\n",
      "INFO:tensorflow:loss = -0.60045993, step = 70100 (4.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9602\n",
      "INFO:tensorflow:loss = -0.5857808, step = 70200 (4.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.085\n",
      "INFO:tensorflow:loss = -0.86096686, step = 70300 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7935\n",
      "INFO:tensorflow:loss = -0.60776085, step = 70400 (4.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3061\n",
      "INFO:tensorflow:loss = -0.642943, step = 70500 (4.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5347\n",
      "INFO:tensorflow:loss = -0.6896396, step = 70600 (4.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4527\n",
      "INFO:tensorflow:loss = -0.5620862, step = 70700 (4.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9302\n",
      "INFO:tensorflow:loss = -0.7155014, step = 70800 (4.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0851\n",
      "INFO:tensorflow:loss = -0.595796, step = 70900 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.362\n",
      "INFO:tensorflow:loss = -0.58387196, step = 71000 (4.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2128\n",
      "INFO:tensorflow:loss = -0.69356906, step = 71100 (4.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.549\n",
      "INFO:tensorflow:loss = -0.65539014, step = 71200 (4.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5723\n",
      "INFO:tensorflow:loss = -0.910422, step = 71300 (4.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.871\n",
      "INFO:tensorflow:loss = -0.53725326, step = 71400 (4.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9366\n",
      "INFO:tensorflow:loss = -0.59515697, step = 71500 (4.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5761\n",
      "INFO:tensorflow:loss = -0.69203454, step = 71600 (4.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4761\n",
      "INFO:tensorflow:loss = -0.6609151, step = 71700 (4.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.183\n",
      "INFO:tensorflow:loss = -0.5614175, step = 71800 (4.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9554\n",
      "INFO:tensorflow:loss = -0.48092884, step = 71900 (4.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2486\n",
      "INFO:tensorflow:loss = -0.60619843, step = 72000 (4.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.726\n",
      "INFO:tensorflow:loss = -0.9306842, step = 72100 (4.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6933\n",
      "INFO:tensorflow:loss = -0.6391851, step = 72200 (4.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4332\n",
      "INFO:tensorflow:loss = -0.54745257, step = 72300 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5121\n",
      "INFO:tensorflow:loss = -0.6000025, step = 72400 (4.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6624\n",
      "INFO:tensorflow:loss = -0.5707705, step = 72500 (4.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7539\n",
      "INFO:tensorflow:loss = -0.5787735, step = 72600 (4.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5468\n",
      "INFO:tensorflow:loss = -0.5806545, step = 72700 (4.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6149\n",
      "INFO:tensorflow:loss = -0.543814, step = 72800 (4.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9273\n",
      "INFO:tensorflow:loss = -0.91988826, step = 72900 (4.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8312\n",
      "INFO:tensorflow:loss = -0.59823006, step = 73000 (4.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4621\n",
      "INFO:tensorflow:loss = -0.5367403, step = 73100 (4.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6728\n",
      "INFO:tensorflow:loss = -0.75292975, step = 73200 (4.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1646\n",
      "INFO:tensorflow:loss = -0.62159824, step = 73300 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5272\n",
      "INFO:tensorflow:loss = -0.61076427, step = 73400 (4.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.197\n",
      "INFO:tensorflow:loss = -0.57315254, step = 73500 (4.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8026\n",
      "INFO:tensorflow:loss = -0.57988316, step = 73600 (4.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7292\n",
      "INFO:tensorflow:loss = -0.79804444, step = 73700 (4.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0427\n",
      "INFO:tensorflow:loss = -0.5797764, step = 73800 (4.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4884\n",
      "INFO:tensorflow:loss = -0.6521309, step = 73900 (4.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8149\n",
      "INFO:tensorflow:loss = -0.63399744, step = 74000 (4.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7728\n",
      "INFO:tensorflow:loss = -0.59708893, step = 74100 (4.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.868\n",
      "INFO:tensorflow:loss = -0.69301593, step = 74200 (4.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1148\n",
      "INFO:tensorflow:loss = -0.584794, step = 74300 (4.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6082\n",
      "INFO:tensorflow:loss = -0.5833799, step = 74400 (4.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2313\n",
      "INFO:tensorflow:loss = -0.71162313, step = 74500 (4.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1943\n",
      "INFO:tensorflow:loss = -0.71180207, step = 74600 (4.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9036\n",
      "INFO:tensorflow:loss = -0.73593736, step = 74700 (4.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8596\n",
      "INFO:tensorflow:loss = -0.6745305, step = 74800 (4.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1833\n",
      "INFO:tensorflow:loss = -0.66788626, step = 74900 (4.508 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 75000...\n",
      "INFO:tensorflow:Saving checkpoints for 75000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 75000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:44:41\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-75000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:44:41.951109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:44:41.951742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:44:41.952221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:44:41.952967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:44:41.953003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:44:41.953436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:44:41.953485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.06061s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:44:42\n",
      "INFO:tensorflow:Saving dict for global step 75000: global_step = 75000, labels_mean = 0.08838565, logits_mean = 0.35713255, loss = -0.6023326, metric/ndcg@10 = 0.39290434, metric/ndcg@15 = 0.43621662, metric/ndcg@20 = 0.4698158, metric/ndcg@25 = 0.49867985, metric/ndcg@30 = 0.5207999\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 75000: /tmp/ranking_model_dir/model.ckpt-75000\n",
      "INFO:tensorflow:global_step/sec: 15.1444\n",
      "INFO:tensorflow:loss = -0.53566325, step = 75000 (6.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7764\n",
      "INFO:tensorflow:loss = -0.72479, step = 75100 (4.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5825\n",
      "INFO:tensorflow:loss = -0.89399654, step = 75200 (4.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3281\n",
      "INFO:tensorflow:loss = -0.5749023, step = 75300 (4.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.933\n",
      "INFO:tensorflow:loss = -0.6345297, step = 75400 (4.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0307\n",
      "INFO:tensorflow:loss = -0.6825876, step = 75500 (4.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.184\n",
      "INFO:tensorflow:loss = -0.8318888, step = 75600 (4.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.867\n",
      "INFO:tensorflow:loss = -0.60734, step = 75700 (4.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3675\n",
      "INFO:tensorflow:loss = -0.6686394, step = 75800 (4.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6865\n",
      "INFO:tensorflow:loss = -0.6254095, step = 75900 (4.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2988\n",
      "INFO:tensorflow:loss = -0.9840588, step = 76000 (4.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5872\n",
      "INFO:tensorflow:loss = -0.6861255, step = 76100 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2006\n",
      "INFO:tensorflow:loss = -0.6153991, step = 76200 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.557\n",
      "INFO:tensorflow:loss = -0.56445944, step = 76300 (4.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.019\n",
      "INFO:tensorflow:loss = -0.799875, step = 76400 (4.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.036\n",
      "INFO:tensorflow:loss = -0.49693054, step = 76500 (4.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5215\n",
      "INFO:tensorflow:loss = -0.6044773, step = 76600 (4.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0746\n",
      "INFO:tensorflow:loss = -0.58387476, step = 76700 (4.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0085\n",
      "INFO:tensorflow:loss = -0.9847951, step = 76800 (4.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6615\n",
      "INFO:tensorflow:loss = -0.7882999, step = 76900 (4.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6046\n",
      "INFO:tensorflow:loss = -0.6744355, step = 77000 (4.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8829\n",
      "INFO:tensorflow:loss = -0.7991454, step = 77100 (4.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2961\n",
      "INFO:tensorflow:loss = -0.69848657, step = 77200 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8791\n",
      "INFO:tensorflow:loss = -0.619167, step = 77300 (4.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3553\n",
      "INFO:tensorflow:loss = -0.5046889, step = 77400 (4.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5563\n",
      "INFO:tensorflow:loss = -0.84334654, step = 77500 (4.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.012\n",
      "INFO:tensorflow:loss = -0.9822888, step = 77600 (4.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8438\n",
      "INFO:tensorflow:loss = -0.7522315, step = 77700 (4.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1085\n",
      "INFO:tensorflow:loss = -0.6549386, step = 77800 (4.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9349\n",
      "INFO:tensorflow:loss = -0.82742965, step = 77900 (4.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.909\n",
      "INFO:tensorflow:loss = -0.8561002, step = 78000 (4.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7188\n",
      "INFO:tensorflow:loss = -0.68926764, step = 78100 (4.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7328\n",
      "INFO:tensorflow:loss = -0.6408509, step = 78200 (4.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3058\n",
      "INFO:tensorflow:loss = -0.88006854, step = 78300 (4.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3092\n",
      "INFO:tensorflow:loss = -0.70696616, step = 78400 (4.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6798\n",
      "INFO:tensorflow:loss = -0.568648, step = 78500 (4.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2949\n",
      "INFO:tensorflow:loss = -0.64598656, step = 78600 (4.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5049\n",
      "INFO:tensorflow:loss = -0.6392592, step = 78700 (4.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8461\n",
      "INFO:tensorflow:loss = -0.8816736, step = 78800 (4.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9181\n",
      "INFO:tensorflow:loss = -0.6436954, step = 78900 (4.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.408\n",
      "INFO:tensorflow:loss = -0.622445, step = 79000 (4.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8428\n",
      "INFO:tensorflow:loss = -0.7132071, step = 79100 (4.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0236\n",
      "INFO:tensorflow:loss = -0.6238347, step = 79200 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4251\n",
      "INFO:tensorflow:loss = -0.6690736, step = 79300 (4.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.603\n",
      "INFO:tensorflow:loss = -0.5542418, step = 79400 (4.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3449\n",
      "INFO:tensorflow:loss = -0.59476066, step = 79500 (4.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9212\n",
      "INFO:tensorflow:loss = -0.7145814, step = 79600 (4.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8431\n",
      "INFO:tensorflow:loss = -0.67965114, step = 79700 (4.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2822\n",
      "INFO:tensorflow:loss = -0.8864012, step = 79800 (4.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9708\n",
      "INFO:tensorflow:loss = -0.6781324, step = 79900 (4.552 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 80000...\n",
      "INFO:tensorflow:Saving checkpoints for 80000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 80000...\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-11T15:48:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 15:48:29.900497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:48:29.901108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:48:29.901584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:48:29.902260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:48:29.902295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 15:48:29.902746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 15:48:29.902796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.11199s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-11-15:48:30\n",
      "INFO:tensorflow:Saving dict for global step 80000: global_step = 80000, labels_mean = 0.08838565, logits_mean = 0.24251305, loss = -0.59881335, metric/ndcg@10 = 0.38847926, metric/ndcg@15 = 0.431609, metric/ndcg@20 = 0.4638764, metric/ndcg@25 = 0.49133143, metric/ndcg@30 = 0.51015365\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 80000: /tmp/ranking_model_dir/model.ckpt-80000\n",
      "INFO:tensorflow:Loss for final step: -0.53266895.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'labels_mean': 0.08838565,\n",
       "  'logits_mean': 0.24251305,\n",
       "  'loss': -0.59881335,\n",
       "  'metric/ndcg@10': 0.38847926,\n",
       "  'metric/ndcg@15': 0.431609,\n",
       "  'metric/ndcg@20': 0.4638764,\n",
       "  'metric/ndcg@25': 0.49133143,\n",
       "  'metric/ndcg@30': 0.51015365,\n",
       "  'global_step': 80000},\n",
       " [])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! rm -rf \"/tmp/ranking_model_dir\"  # Clean up the model directory.\n",
    "#ranker, train_spec, eval_spec = train_and_eval_fn()\n",
    "tf.estimator.train_and_evaluate(ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801f806",
   "metadata": {},
   "source": [
    "## Inference and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4004d70",
   "metadata": {},
   "source": [
    "We show how to generate predictions over the features of a dataset. We assume that the label is not present and needs to be inferred using the ranking model.\n",
    "\n",
    "Similar to the `input_fn` used for training and evaluation,  `predict_input_fn` reads in data in ELWC format and stored as TFRecords to generate features. We set number of epochs to be 1, so that the generator stops iterating when it reaches the end of the dataset. Also the datapoints are not shuffled while reading, so that the behavior of the `predict()` function is deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31819ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_fn(path):\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values())\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()))\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern=path,\n",
    "        data_format=tfr.data.ELWC,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        list_size=_LIST_SIZE,\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=False,\n",
    "        num_epochs=1)\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73ef17",
   "metadata": {},
   "source": [
    "We generate predictions on the test dataset, where we only consider context and example features and predict the labels. The `predict_input_fn` generates predictions on a batch of datapoints. Batching allows us to iterate over large datasets which cannot be loaded in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e90d1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = ranker.predict(input_fn=lambda: predict_input_fn(_TEST_DATA_PATH), checkpoint_path = ranker.latest_checkpoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11c5f773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7f633870bf40>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "26ac3161",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert elements of <generator object Estimator.predict at 0x7f633870bf40> to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m min_score \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_min\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-rank/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py:545\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    543\u001b[0m   str_values \u001b[38;5;241m=\u001b[39m [compat\u001b[38;5;241m.\u001b[39mas_bytes(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values]\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert elements of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to Tensor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider casting elements to a supported type. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/api_docs/python/tf/dtypes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor supported TF dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    549\u001b[0m tensor_proto\u001b[38;5;241m.\u001b[39mstring_val\u001b[38;5;241m.\u001b[39mextend(str_values)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_proto\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert elements of <generator object Estimator.predict at 0x7f633870bf40> to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes."
     ]
    }
   ],
   "source": [
    "min_score = tf.reduce_min(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10b12ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = ranker.predict(input_fn=lambda: predict_input_fn(_TEST_DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ecc424",
   "metadata": {},
   "source": [
    "`ranker.predict` returns a generator, which we can iterate over to create predictions, till the generator is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dd316b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8601/2110212537.py:8: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(context_features[name])\n",
      "/tmp/ipykernel_8601/2110212537.py:12: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(group_features[name])\n",
      "/tmp/ipykernel_8601/2110212537.py:19: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_8601/2110212537.py:25: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
      "/tmp/ipykernel_8601/2110212537.py:26: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_8601/2110212537.py:31: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dropout(\n",
      "/tmp/ipykernel_8601/2110212537.py:33: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 17:46:03.703960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:46:03.704692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:46:03.705222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:46:03.706469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:46:03.706506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 17:46:03.706934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:46:03.706990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "x = next(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee3b6f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.4237769 ,  0.8294823 ,  1.7756721 ,  0.66004986, -1.9319623 ,\n",
       "       -3.280347  ,  0.79950994,  0.5583087 , -4.1684847 ,  0.0209748 ,\n",
       "       -2.6044571 , -2.3729713 , -4.5766644 , -8.008365  , -1.8633786 ,\n",
       "        0.66209227,  0.7212383 ,  0.66492724, -0.9772345 , -2.5914204 ,\n",
       "       -0.12898526, -1.0828134 , -3.251166  , -0.50223786, -1.0883168 ,\n",
       "       -3.8000958 ,  0.72496104, -1.9635459 ,  0.28606403, -1.6808677 ,\n",
       "        0.7683895 , -1.6272818 , -0.11683585,  2.0080442 ,  0.6251223 ,\n",
       "        0.22300681,  0.5173819 , -0.6149293 , -0.9635947 , -0.9104118 ,\n",
       "        1.2739093 ,  0.5615401 ,  0.53147465,  0.9736903 ,  0.66492724,\n",
       "       -1.3775594 ,  0.16696864,  0.7729212 ,  0.1807997 , -0.88749516,\n",
       "        0.44319364,  0.5651194 ,  0.0608917 ,  0.66492724, -2.2440448 ,\n",
       "        0.01946455,  0.09867238,  0.45462605, -2.6637235 , -2.306296  ,\n",
       "        0.8817905 , -1.4189719 ,  0.5037826 ,  0.5383252 ,  0.324545  ,\n",
       "       -0.55213475,  0.7378726 ,  2.7565176 , -1.605391  ,  1.1548172 ,\n",
       "       -1.8877691 , -2.0947452 , -0.418494  ,  0.4815307 , -4.3869057 ,\n",
       "       -1.1592677 ,  0.81059134,  0.711643  ,  1.7813827 , -1.4681355 ,\n",
       "        0.7228329 , -0.18137565, -0.25542772, -1.940169  , -1.7551028 ,\n",
       "       -1.0798404 ,  0.6284044 , -4.0820446 ,  0.54317385,  0.42284516,\n",
       "       -1.7150079 , -4.6782184 ,  2.89063   ,  0.5778314 , -1.5219647 ,\n",
       "        3.2134633 , -1.5261405 ,  0.71142495, -0.76385736,  0.02980817],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a8b2f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in query_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 5838 in document_tokens is inferred from the number of elements in the vocabulary_file ../StackExchange/Stackoverflow/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8601/2110212537.py:8: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(context_features[name])\n",
      "/tmp/ipykernel_8601/2110212537.py:12: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(group_features[name])\n",
      "/tmp/ipykernel_8601/2110212537.py:19: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_8601/2110212537.py:25: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
      "/tmp/ipykernel_8601/2110212537.py:26: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/tmp/ipykernel_8601/2110212537.py:31: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dropout(\n",
      "/tmp/ipykernel_8601/2110212537.py:33: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 17:49:25.239986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:49:25.240728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:49:25.241376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:49:25.242087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:49:25.242122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-11 17:49:25.242564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-11 17:49:25.242616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "x2 = next(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0416d438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.4237769 ,  0.8294823 ,  1.7756721 ,  0.66004986, -1.9319623 ,\n",
       "       -3.280347  ,  0.79950994,  0.5583087 , -4.1684847 ,  0.0209748 ,\n",
       "       -2.6044571 , -2.3729713 , -4.5766644 , -8.008365  , -1.8633786 ,\n",
       "        0.66209227,  0.7212383 ,  0.66492724, -0.9772345 , -2.5914204 ,\n",
       "       -0.12898526, -1.0828134 , -3.251166  , -0.50223786, -1.0883168 ,\n",
       "       -3.8000958 ,  0.72496104, -1.9635459 ,  0.28606403, -1.6808677 ,\n",
       "        0.7683895 , -1.6272818 , -0.11683585,  2.0080442 ,  0.6251223 ,\n",
       "        0.22300681,  0.5173819 , -0.6149293 , -0.9635947 , -0.9104118 ,\n",
       "        1.2739093 ,  0.5615401 ,  0.53147465,  0.9736903 ,  0.66492724,\n",
       "       -1.3775594 ,  0.16696864,  0.7729212 ,  0.1807997 , -0.88749516,\n",
       "        0.44319364,  0.5651194 ,  0.0608917 ,  0.66492724, -2.2440448 ,\n",
       "        0.01946455,  0.09867238,  0.45462605, -2.6637235 , -2.306296  ,\n",
       "        0.8817905 , -1.4189719 ,  0.5037826 ,  0.5383252 ,  0.324545  ,\n",
       "       -0.55213475,  0.7378726 ,  2.7565176 , -1.605391  ,  1.1548172 ,\n",
       "       -1.8877691 , -2.0947452 , -0.418494  ,  0.4815307 , -4.3869057 ,\n",
       "       -1.1592677 ,  0.81059134,  0.711643  ,  1.7813827 , -1.4681355 ,\n",
       "        0.7228329 , -0.18137565, -0.25542772, -1.940169  , -1.7551028 ,\n",
       "       -1.0798404 ,  0.6284044 , -4.0820446 ,  0.54317385,  0.42284516,\n",
       "       -1.7150079 , -4.6782184 ,  2.89063   ,  0.5778314 , -1.5219647 ,\n",
       "        3.2134633 , -1.5261405 ,  0.71142495, -0.76385736,  0.02980817],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "419f85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e471ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.8983476 , -2.6677127 ,  3.4520075 ,  0.21621923,  4.6609907 ,\n",
       "       -3.2321227 , -6.6224174 ,  2.70285   , -2.7546382 ,  4.6620975 ,\n",
       "        1.0986121 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,\n",
       "        4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,\n",
       "        4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,\n",
       "        4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,\n",
       "        4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,\n",
       "        4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,\n",
       "        4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,\n",
       "        4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ,  4.1087656 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47690d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-rank",
   "language": "python",
   "name": "tf-rank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
