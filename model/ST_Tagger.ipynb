{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\Documents\\GitFiles\\Respondent_Recommendation\\Model\\.env\\seq2seq\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.inp_lang_tokenizer = None\n",
    "        self.targ_lang_tokenizer = None\n",
    "    \n",
    "    def create_dataset(self, path, num_examples):\n",
    "        # path : path to spa-eng.txt file\n",
    "        # num_examples : Limit the total number of training example for faster training (set num_examples = len(lines) to use full data)\n",
    "        lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "        word_pairs = [[w for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "        print(word_pairs[:5])\n",
    "\n",
    "        return zip(*word_pairs)\n",
    "\n",
    "    # Step 3 and Step 4\n",
    "    def tokenize(self, lang):\n",
    "        # lang = list of sentences in a language\n",
    "        \n",
    "        # print(len(lang), \"example sentence: {}\".format(lang[0]))\n",
    "        lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>')\n",
    "        lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "        ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \n",
    "        ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\n",
    "        tensor = lang_tokenizer.texts_to_sequences(lang) \n",
    "\n",
    "        ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences \n",
    "        ## and pads the sequences to match the longest sequences in the given input\n",
    "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "        return tensor, lang_tokenizer\n",
    "\n",
    "    def load_dataset(self, path, num_examples=None):\n",
    "        # creating cleaned input, output pairs\n",
    "        inp_lang, targ_lang = self.create_dataset(path, num_examples)\n",
    "\n",
    "        input_tensor, inp_lang_tokenizer = self.tokenize(inp_lang)\n",
    "        target_tensor, targ_lang_tokenizer = self.tokenize(targ_lang)\n",
    "\n",
    "        return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
    "\n",
    "    def call(self, num_examples, BUFFER_SIZE, BATCH_SIZE):\n",
    "        file_path = \"../Data/StackExchange/final_data/training/pairs_1224.txt\"\n",
    "        \n",
    "        input_tensor, target_tensor, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(file_path, num_examples)\n",
    "        \n",
    "        input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
    "        train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
    "        val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "        return train_dataset, val_dataset, self.inp_lang_tokenizer, self.targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<start> differ intel ppc hardwar softwar differ intel ppc mac <end>', '<start> hardware mac powerpc macos <end>'], ['<start> turn back mac script command line vpn softwar us work ipsecurita requir turn mac start connect turn mac order us vpn connect program forget turn wa run script command turn <end>', '<start> macos mobileme terminal back-to-my-mac script <end>'], ['<start> microsoft offic 2008 support rtl languag microsoft offic 2008 macbook pro offic support languag farsi arab offic 2010 window problem think lack support busi competit reason <end>', '<start> software microsoft-office <end>'], ['<start> repair start disk option power failur reboot notic drive need repair util run leopard cd start order perform fix option run repair util startup disk <end>', '<start> macos snow-leopard <end>'], ['<start> disabl get startup sound mac make turn macbook make start nois annoi volum abil turn want sound plai disabl startup sound <end>', '<start> mac audio startup <end>']]\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 600000\n",
    "BATCH_SIZE = 64\n",
    "# Let's limit the #training examples for faster training\n",
    "num_examples = 600000\n",
    "\n",
    "dataset_creator = Dataset()\n",
    "train_dataset, val_dataset, inp_lang, targ_lang = dataset_creator.call(num_examples, BUFFER_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 4389]), TensorShape([64, 8]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "max_length_input = example_input_batch.shape[1]\n",
    "max_length_output = example_target_batch.shape[1]\n",
    "\n",
    "embedding_dim = 64\n",
    "units = 256\n",
    "steps_per_epoch = num_examples//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length_text, max_length_tag, vocab_size_text, vocab_size_tag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4389, 8, 991131, 42250)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"max_length_text, max_length_tag, vocab_size_text, vocab_size_tag\")\n",
    "max_length_input, max_length_output, vocab_inp_size, vocab_tar_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        ##-------- LSTM layer in Encoder ------- ##\n",
    "        self.lstm_layer = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                   dropout=0.2, \n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, h, c = self.lstm_layer(x, initial_state = hidden)\n",
    "        return output, h, c\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 4389, 256)\n",
      "Encoder h vecotr shape: (batch size, units) (64, 256)\n",
      "Encoder c vector shape: (batch size, units) (64, 256)\n"
     ]
    }
   ],
   "source": [
    "## Test Encoder Stack\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
    "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_type='luong'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.attention_type = attention_type\n",
    "    \n",
    "        # Embedding Layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    \n",
    "        #Final Dense layer on which softmax will be applied\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # Define the fundamental cell for decoder recurrent structure\n",
    "        self.decoder_rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
    "   \n",
    "\n",
    "\n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention_mechanism = self.build_attention_mechanism(self.dec_units, \n",
    "                                                              None, self.batch_sz*[max_length_input], self.attention_type)\n",
    "\n",
    "        # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
    "        self.rnn_cell = self.build_rnn_cell(batch_sz)\n",
    "\n",
    "        # Define the decoder with respect to fundamental rnn cell\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
    "\n",
    "    \n",
    "    def build_rnn_cell(self, batch_sz):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \n",
    "                                  self.attention_mechanism, attention_layer_size=self.dec_units)\n",
    "        return rnn_cell\n",
    "\n",
    "    def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
    "        # ------------- #\n",
    "        # typ: Which sort of attention (Bahdanau, Luong)\n",
    "        # dec_units: final dimension of attention outputs \n",
    "        # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n",
    "        # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n",
    "\n",
    "        if(attention_type=='bahdanau'):\n",
    "            return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
    "        else:\n",
    "            return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
    "\n",
    "    def build_initial_state(self, batch_sz, encoder_state, Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
    "        return decoder_initial_state\n",
    "\n",
    "    def call(self, inputs, initial_state):\n",
    "        x = self.embedding(inputs)\n",
    "        outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_sz*[max_length_output-1])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Outputs Shape:  (64, 7, 42250)\n"
     ]
    }
   ],
   "source": [
    "# Test decoder stack\n",
    "\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 'luong')\n",
    "sample_x = tf.random.uniform((BATCH_SIZE, max_length_output))\n",
    "decoder.attention_mechanism.setup_memory(sample_output)\n",
    "initial_state = decoder.build_initial_state(BATCH_SIZE, [sample_h, sample_c], tf.float32)\n",
    "\n",
    "\n",
    "sample_decoder_outputs = decoder(sample_x, initial_state)\n",
    "\n",
    "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  \n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './tagger_checkpoints_1224'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "\n",
    "        dec_input = targ[ : , :-1 ] # Ignore <end> token\n",
    "        real = targ[ : , 1: ]         # ignore <start> token\n",
    "\n",
    "        # Set the AttentionMechanism object with encoder_outputs\n",
    "        decoder.attention_mechanism.setup_memory(enc_output)\n",
    "\n",
    "        # Create AttentionWrapperState as initial_state for decoder\n",
    "        decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "        pred = decoder(dec_input, decoder_initial_state)\n",
    "        logits = pred.rnn_output\n",
    "        loss = loss_function(real, logits)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 6.8001\n",
      "Epoch 1 Batch 1000 Loss 4.5542\n",
      "Epoch 1 Batch 2000 Loss 4.4538\n",
      "Epoch 1 Batch 3000 Loss 3.7502\n",
      "Epoch 1 Batch 4000 Loss 3.5969\n",
      "Epoch 1 Batch 5000 Loss 3.2878\n",
      "Epoch 1 Batch 6000 Loss 2.8406\n",
      "Epoch 1 Batch 7000 Loss 2.7855\n",
      "Epoch 1 Loss 2.8838\n",
      "Time taken for 1 epoch 7220.683002710342 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.8231\n",
      "Epoch 2 Batch 1000 Loss 2.3916\n",
      "Epoch 2 Batch 2000 Loss 2.3214\n",
      "Epoch 2 Batch 3000 Loss 2.4207\n",
      "Epoch 2 Batch 4000 Loss 2.2033\n",
      "Epoch 2 Batch 5000 Loss 2.2678\n",
      "Epoch 2 Batch 6000 Loss 2.3097\n",
      "Epoch 2 Batch 7000 Loss 2.2167\n",
      "Epoch 2 Loss 1.8635\n",
      "Time taken for 1 epoch 6271.654099225998 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.6491\n",
      "Epoch 3 Batch 1000 Loss 2.0079\n",
      "Epoch 3 Batch 2000 Loss 1.7905\n",
      "Epoch 3 Batch 3000 Loss 1.9712\n",
      "Epoch 3 Batch 4000 Loss 1.9349\n",
      "Epoch 3 Batch 5000 Loss 1.8225\n",
      "Epoch 3 Batch 6000 Loss 2.0212\n",
      "Epoch 3 Batch 7000 Loss 1.6320\n",
      "Epoch 3 Loss 1.4836\n",
      "Time taken for 1 epoch 6096.306877851486 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.5848\n",
      "Epoch 4 Batch 1000 Loss 1.5949\n",
      "Epoch 4 Batch 2000 Loss 1.8591\n",
      "Epoch 4 Batch 3000 Loss 1.5479\n",
      "Epoch 4 Batch 4000 Loss 1.4969\n",
      "Epoch 4 Batch 5000 Loss 1.6264\n",
      "Epoch 4 Batch 6000 Loss 1.6938\n",
      "Epoch 4 Batch 7000 Loss 1.5348\n",
      "Epoch 4 Loss 1.2310\n",
      "Time taken for 1 epoch 6113.566295385361 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0988\n",
      "Epoch 5 Batch 1000 Loss 1.2077\n",
      "Epoch 5 Batch 2000 Loss 1.2701\n",
      "Epoch 5 Batch 3000 Loss 1.1905\n",
      "Epoch 5 Batch 4000 Loss 1.3212\n",
      "Epoch 5 Batch 5000 Loss 1.4148\n",
      "Epoch 5 Batch 6000 Loss 1.3352\n",
      "Epoch 5 Batch 7000 Loss 1.4403\n",
      "Epoch 5 Loss 1.0116\n",
      "Time taken for 1 epoch 6095.971710443497 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.9190\n",
      "Epoch 6 Batch 1000 Loss 0.8897\n",
      "Epoch 6 Batch 2000 Loss 1.1609\n",
      "Epoch 6 Batch 3000 Loss 1.1751\n",
      "Epoch 6 Batch 4000 Loss 1.1908\n",
      "Epoch 6 Batch 5000 Loss 1.0554\n",
      "Epoch 6 Batch 6000 Loss 1.1000\n",
      "Epoch 6 Batch 7000 Loss 0.9516\n",
      "Epoch 6 Loss 0.8378\n",
      "Time taken for 1 epoch 6171.348222732544 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.7778\n",
      "Epoch 7 Batch 1000 Loss 0.8211\n",
      "Epoch 7 Batch 2000 Loss 0.8812\n",
      "Epoch 7 Batch 3000 Loss 0.9118\n",
      "Epoch 7 Batch 4000 Loss 0.9807\n",
      "Epoch 7 Batch 5000 Loss 0.9442\n",
      "Epoch 7 Batch 6000 Loss 0.8264\n",
      "Epoch 7 Batch 7000 Loss 0.9904\n",
      "Epoch 7 Loss 0.7059\n",
      "Time taken for 1 epoch 6097.251889228821 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.5660\n",
      "Epoch 8 Batch 1000 Loss 0.6561\n",
      "Epoch 8 Batch 2000 Loss 0.8321\n",
      "Epoch 8 Batch 3000 Loss 0.7307\n",
      "Epoch 8 Batch 4000 Loss 0.8350\n",
      "Epoch 8 Batch 5000 Loss 0.9005\n",
      "Epoch 8 Batch 6000 Loss 0.9495\n",
      "Epoch 8 Batch 7000 Loss 0.8531\n",
      "Epoch 8 Loss 0.6044\n",
      "Time taken for 1 epoch 6076.142371177673 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.5810\n",
      "Epoch 9 Batch 1000 Loss 0.5387\n",
      "Epoch 9 Batch 2000 Loss 0.6607\n",
      "Epoch 9 Batch 3000 Loss 0.7792\n",
      "Epoch 9 Batch 4000 Loss 0.7429\n",
      "Epoch 9 Batch 5000 Loss 0.7625\n",
      "Epoch 9 Batch 6000 Loss 0.7745\n",
      "Epoch 9 Batch 7000 Loss 0.7516\n",
      "Epoch 9 Loss 0.5233\n",
      "Time taken for 1 epoch 6303.293406963348 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.5302\n",
      "Epoch 10 Batch 1000 Loss 0.5426\n",
      "Epoch 10 Batch 2000 Loss 0.4551\n",
      "Epoch 10 Batch 3000 Loss 0.6070\n",
      "Epoch 10 Batch 4000 Loss 0.5300\n",
      "Epoch 10 Batch 5000 Loss 0.4336\n",
      "Epoch 10 Batch 6000 Loss 0.6496\n",
      "Epoch 10 Batch 7000 Loss 0.5428\n",
      "Epoch 10 Loss 0.4581\n",
      "Time taken for 1 epoch 6870.270652770996 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.5032\n",
      "Epoch 11 Batch 1000 Loss 0.5653\n",
      "Epoch 11 Batch 2000 Loss 0.4162\n",
      "Epoch 11 Batch 3000 Loss 0.5208\n",
      "Epoch 11 Batch 4000 Loss 0.5891\n",
      "Epoch 11 Batch 5000 Loss 0.5207\n",
      "Epoch 11 Batch 6000 Loss 0.5832\n",
      "Epoch 11 Batch 7000 Loss 0.6509\n",
      "Epoch 11 Loss 0.4052\n",
      "Time taken for 1 epoch 6802.6807680130005 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.3795\n",
      "Epoch 12 Batch 1000 Loss 0.3775\n",
      "Epoch 12 Batch 2000 Loss 0.4422\n",
      "Epoch 12 Batch 3000 Loss 0.3846\n",
      "Epoch 12 Batch 4000 Loss 0.3898\n",
      "Epoch 12 Batch 5000 Loss 0.6430\n",
      "Epoch 12 Batch 6000 Loss 0.5956\n",
      "Epoch 12 Batch 7000 Loss 0.5550\n",
      "Epoch 12 Loss 0.3610\n",
      "Time taken for 1 epoch 6602.348735332489 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.3050\n",
      "Epoch 13 Batch 1000 Loss 0.4525\n",
      "Epoch 13 Batch 2000 Loss 0.5088\n",
      "Epoch 13 Batch 3000 Loss 0.4729\n",
      "Epoch 13 Batch 4000 Loss 0.4464\n",
      "Epoch 13 Batch 5000 Loss 0.5105\n",
      "Epoch 13 Batch 6000 Loss 0.3863\n",
      "Epoch 13 Batch 7000 Loss 0.4370\n",
      "Epoch 13 Loss 0.3279\n",
      "Time taken for 1 epoch 6591.248243093491 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.2307\n",
      "Epoch 14 Batch 1000 Loss 0.3233\n",
      "Epoch 14 Batch 2000 Loss 0.3931\n",
      "Epoch 14 Batch 3000 Loss 0.2849\n",
      "Epoch 14 Batch 4000 Loss 0.3023\n",
      "Epoch 14 Batch 5000 Loss 0.3930\n",
      "Epoch 14 Batch 6000 Loss 0.3294\n",
      "Epoch 14 Batch 7000 Loss 0.5054\n",
      "Epoch 14 Loss 0.2896\n",
      "Time taken for 1 epoch 6899.703430891037 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.3646\n",
      "Epoch 15 Batch 1000 Loss 0.2925\n",
      "Epoch 15 Batch 2000 Loss 0.3021\n",
      "Epoch 15 Batch 3000 Loss 0.3773\n",
      "Epoch 15 Batch 4000 Loss 0.4090\n",
      "Epoch 15 Batch 5000 Loss 0.4334\n",
      "Epoch 15 Batch 6000 Loss 0.2588\n",
      "Epoch 15 Batch 7000 Loss 0.2839\n",
      "Epoch 15 Loss 0.2697\n",
      "Time taken for 1 epoch 7049.597634315491 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.2664\n",
      "Epoch 16 Batch 1000 Loss 0.2847\n",
      "Epoch 16 Batch 2000 Loss 0.2952\n",
      "Epoch 16 Batch 3000 Loss 0.3583\n",
      "Epoch 16 Batch 4000 Loss 0.4296\n",
      "Epoch 16 Batch 5000 Loss 0.3505\n",
      "Epoch 16 Batch 6000 Loss 0.3482\n",
      "Epoch 16 Batch 7000 Loss 0.3974\n",
      "Epoch 16 Loss 0.2490\n",
      "Time taken for 1 epoch 7199.557156562805 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.3635\n",
      "Epoch 17 Batch 1000 Loss 0.2590\n",
      "Epoch 17 Batch 2000 Loss 0.2795\n",
      "Epoch 17 Batch 3000 Loss 0.2526\n",
      "Epoch 17 Batch 4000 Loss 0.3130\n",
      "Epoch 17 Batch 5000 Loss 0.2493\n",
      "Epoch 17 Batch 6000 Loss 0.3035\n",
      "Epoch 17 Batch 7000 Loss 0.3052\n",
      "Epoch 17 Loss 0.2299\n",
      "Time taken for 1 epoch 6104.866336107254 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.2284\n",
      "Epoch 18 Batch 1000 Loss 0.2056\n",
      "Epoch 18 Batch 2000 Loss 0.2612\n",
      "Epoch 18 Batch 3000 Loss 0.2294\n",
      "Epoch 18 Batch 4000 Loss 0.1734\n",
      "Epoch 18 Batch 5000 Loss 0.3072\n",
      "Epoch 18 Batch 6000 Loss 0.3464\n",
      "Epoch 18 Batch 7000 Loss 0.4677\n",
      "Epoch 18 Loss 0.2137\n",
      "Time taken for 1 epoch 6095.697131872177 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1856\n",
      "Epoch 19 Batch 1000 Loss 0.2323\n",
      "Epoch 19 Batch 2000 Loss 0.2869\n",
      "Epoch 19 Batch 3000 Loss 0.3003\n",
      "Epoch 19 Batch 4000 Loss 0.2252\n",
      "Epoch 19 Batch 5000 Loss 0.2689\n",
      "Epoch 19 Batch 6000 Loss 0.1911\n",
      "Epoch 19 Batch 7000 Loss 0.3311\n",
      "Epoch 19 Loss 0.1995\n",
      "Time taken for 1 epoch 6164.388142585754 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.2253\n",
      "Epoch 20 Batch 1000 Loss 0.2558\n",
      "Epoch 20 Batch 2000 Loss 0.1670\n",
      "Epoch 20 Batch 3000 Loss 0.3467\n",
      "Epoch 20 Batch 4000 Loss 0.2569\n",
      "Epoch 20 Batch 5000 Loss 0.2200\n",
      "Epoch 20 Batch 6000 Loss 0.2336\n",
      "Epoch 20 Batch 7000 Loss 0.3320\n",
      "Epoch 20 Loss 0.1866\n",
      "Time taken for 1 epoch 6106.516610622406 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.1364\n",
      "Epoch 21 Batch 1000 Loss 0.2454\n",
      "Epoch 21 Batch 2000 Loss 0.1253\n",
      "Epoch 21 Batch 3000 Loss 0.2314\n",
      "Epoch 21 Batch 4000 Loss 0.2407\n",
      "Epoch 21 Batch 5000 Loss 0.2296\n",
      "Epoch 21 Batch 6000 Loss 0.2148\n",
      "Epoch 21 Batch 7000 Loss 0.3440\n",
      "Epoch 21 Loss 0.1753\n",
      "Time taken for 1 epoch 6087.417578458786 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.1448\n",
      "Epoch 22 Batch 1000 Loss 0.1540\n",
      "Epoch 22 Batch 2000 Loss 0.1859\n",
      "Epoch 22 Batch 3000 Loss 0.2210\n",
      "Epoch 22 Batch 4000 Loss 0.2512\n",
      "Epoch 22 Batch 5000 Loss 0.1351\n",
      "Epoch 22 Batch 6000 Loss 0.1974\n",
      "Epoch 22 Batch 7000 Loss 0.2383\n",
      "Epoch 22 Loss 0.1656\n",
      "Time taken for 1 epoch 6538.277243375778 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.1483\n",
      "Epoch 23 Batch 1000 Loss 0.1378\n",
      "Epoch 23 Batch 2000 Loss 0.1447\n",
      "Epoch 23 Batch 3000 Loss 0.2186\n",
      "Epoch 23 Batch 4000 Loss 0.1492\n",
      "Epoch 23 Batch 5000 Loss 0.1705\n",
      "Epoch 23 Batch 6000 Loss 0.3591\n",
      "Epoch 23 Batch 7000 Loss 0.1306\n",
      "Epoch 23 Loss 0.1561\n",
      "Time taken for 1 epoch 6904.451799869537 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.1598\n",
      "Epoch 24 Batch 1000 Loss 0.1264\n",
      "Epoch 24 Batch 2000 Loss 0.1236\n",
      "Epoch 24 Batch 3000 Loss 0.1542\n",
      "Epoch 24 Batch 4000 Loss 0.2535\n",
      "Epoch 24 Batch 5000 Loss 0.2404\n",
      "Epoch 24 Batch 6000 Loss 0.2201\n",
      "Epoch 24 Batch 7000 Loss 0.1977\n",
      "Epoch 24 Loss 0.1484\n",
      "Time taken for 1 epoch 7236.232722520828 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.1454\n",
      "Epoch 25 Batch 1000 Loss 0.1353\n",
      "Epoch 25 Batch 2000 Loss 0.1453\n",
      "Epoch 25 Batch 3000 Loss 0.1458\n",
      "Epoch 25 Batch 4000 Loss 0.1741\n",
      "Epoch 25 Batch 5000 Loss 0.1860\n",
      "Epoch 25 Batch 6000 Loss 0.2205\n",
      "Epoch 25 Batch 7000 Loss 0.1348\n",
      "Epoch 25 Loss 0.1417\n",
      "Time taken for 1 epoch 6952.058066368103 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.1536\n",
      "Epoch 26 Batch 1000 Loss 0.1289\n",
      "Epoch 26 Batch 2000 Loss 0.1187\n",
      "Epoch 26 Batch 3000 Loss 0.2249\n",
      "Epoch 26 Batch 4000 Loss 0.1844\n",
      "Epoch 26 Batch 5000 Loss 0.2114\n",
      "Epoch 26 Batch 6000 Loss 0.2153\n",
      "Epoch 26 Batch 7000 Loss 0.1789\n",
      "Epoch 26 Loss 0.1343\n",
      "Time taken for 1 epoch 6925.4617619514465 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 0 Loss 0.1564\n",
      "Epoch 27 Batch 1000 Loss 0.1616\n",
      "Epoch 27 Batch 2000 Loss 0.1502\n",
      "Epoch 27 Batch 3000 Loss 0.1632\n",
      "Epoch 27 Batch 4000 Loss 0.1597\n",
      "Epoch 27 Batch 5000 Loss 0.1417\n",
      "Epoch 27 Batch 6000 Loss 0.1111\n",
      "Epoch 27 Batch 7000 Loss 0.2005\n",
      "Epoch 27 Loss 0.1284\n",
      "Time taken for 1 epoch 7037.08930683136 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.1136\n",
      "Epoch 28 Batch 1000 Loss 0.1124\n",
      "Epoch 28 Batch 2000 Loss 0.1484\n",
      "Epoch 28 Batch 3000 Loss 0.1756\n",
      "Epoch 28 Batch 4000 Loss 0.1787\n",
      "Epoch 28 Batch 5000 Loss 0.2485\n",
      "Epoch 28 Batch 6000 Loss 0.1946\n",
      "Epoch 28 Batch 7000 Loss 0.1085\n",
      "Epoch 28 Loss 0.1228\n",
      "Time taken for 1 epoch 6933.612475633621 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.1214\n",
      "Epoch 29 Batch 1000 Loss 0.0966\n",
      "Epoch 29 Batch 2000 Loss 0.1255\n",
      "Epoch 29 Batch 3000 Loss 0.1342\n",
      "Epoch 29 Batch 4000 Loss 0.1359\n",
      "Epoch 29 Batch 5000 Loss 0.1484\n",
      "Epoch 29 Batch 6000 Loss 0.1522\n",
      "Epoch 29 Batch 7000 Loss 0.1378\n",
      "Epoch 29 Loss 0.1180\n",
      "Time taken for 1 epoch 6797.934002161026 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.1721\n",
      "Epoch 30 Batch 1000 Loss 0.1489\n",
      "Epoch 30 Batch 2000 Loss 0.1457\n",
      "Epoch 30 Batch 3000 Loss 0.0956\n",
      "Epoch 30 Batch 4000 Loss 0.1255\n",
      "Epoch 30 Batch 5000 Loss 0.1722\n",
      "Epoch 30 Batch 6000 Loss 0.1610\n",
      "Epoch 30 Batch 7000 Loss 0.1101\n",
      "Epoch 30 Loss 0.1133\n",
      "Time taken for 1 epoch 6968.337641716003 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.1437\n",
      "Epoch 31 Batch 1000 Loss 0.1572\n",
      "Epoch 31 Batch 2000 Loss 0.1090\n",
      "Epoch 31 Batch 3000 Loss 0.1143\n",
      "Epoch 31 Batch 4000 Loss 0.1137\n",
      "Epoch 31 Batch 5000 Loss 0.1428\n",
      "Epoch 31 Batch 6000 Loss 0.1408\n",
      "Epoch 31 Batch 7000 Loss 0.1425\n",
      "Epoch 31 Loss 0.1089\n",
      "Time taken for 1 epoch 6745.46085190773 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.1306\n",
      "Epoch 32 Batch 1000 Loss 0.1456\n",
      "Epoch 32 Batch 2000 Loss 0.0890\n",
      "Epoch 32 Batch 3000 Loss 0.1633\n",
      "Epoch 32 Batch 4000 Loss 0.1165\n",
      "Epoch 32 Batch 5000 Loss 0.1164\n",
      "Epoch 32 Batch 6000 Loss 0.0953\n",
      "Epoch 32 Batch 7000 Loss 0.1146\n",
      "Epoch 32 Loss 0.1047\n",
      "Time taken for 1 epoch 6855.4392375946045 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.1049\n",
      "Epoch 33 Batch 1000 Loss 0.0737\n",
      "Epoch 33 Batch 2000 Loss 0.1209\n",
      "Epoch 33 Batch 3000 Loss 0.0997\n",
      "Epoch 33 Batch 4000 Loss 0.1448\n",
      "Epoch 33 Batch 5000 Loss 0.1001\n",
      "Epoch 33 Batch 6000 Loss 0.1562\n",
      "Epoch 33 Batch 7000 Loss 0.1382\n",
      "Epoch 33 Loss 0.1011\n",
      "Time taken for 1 epoch 6798.503108501434 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0728\n",
      "Epoch 34 Batch 1000 Loss 0.0581\n",
      "Epoch 34 Batch 2000 Loss 0.1358\n",
      "Epoch 34 Batch 3000 Loss 0.1263\n",
      "Epoch 34 Batch 4000 Loss 0.0943\n",
      "Epoch 34 Batch 5000 Loss 0.1135\n",
      "Epoch 34 Batch 6000 Loss 0.1609\n",
      "Epoch 34 Batch 7000 Loss 0.2074\n",
      "Epoch 34 Loss 0.0981\n",
      "Time taken for 1 epoch 6764.068381071091 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0830\n",
      "Epoch 35 Batch 1000 Loss 0.0744\n",
      "Epoch 35 Batch 2000 Loss 0.1538\n",
      "Epoch 35 Batch 3000 Loss 0.1022\n",
      "Epoch 35 Batch 4000 Loss 0.2017\n",
      "Epoch 35 Batch 5000 Loss 0.1285\n",
      "Epoch 35 Batch 6000 Loss 0.1272\n",
      "Epoch 35 Batch 7000 Loss 0.1929\n",
      "Epoch 35 Loss 0.0946\n",
      "Time taken for 1 epoch 6899.6000390052795 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0540\n",
      "Epoch 36 Batch 1000 Loss 0.1249\n",
      "Epoch 36 Batch 2000 Loss 0.1546\n",
      "Epoch 36 Batch 3000 Loss 0.0823\n",
      "Epoch 36 Batch 4000 Loss 0.1161\n",
      "Epoch 36 Batch 5000 Loss 0.0965\n",
      "Epoch 36 Batch 6000 Loss 0.1329\n",
      "Epoch 36 Batch 7000 Loss 0.1088\n",
      "Epoch 36 Loss 0.0918\n",
      "Time taken for 1 epoch 7362.670222997665 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.1210\n",
      "Epoch 37 Batch 1000 Loss 0.1017\n",
      "Epoch 37 Batch 2000 Loss 0.0705\n",
      "Epoch 37 Batch 3000 Loss 0.1941\n",
      "Epoch 37 Batch 4000 Loss 0.0737\n",
      "Epoch 37 Batch 5000 Loss 0.1516\n",
      "Epoch 37 Batch 6000 Loss 0.0609\n",
      "Epoch 37 Batch 7000 Loss 0.1604\n",
      "Epoch 37 Loss 0.0887\n",
      "Time taken for 1 epoch 7028.905903577805 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.1042\n",
      "Epoch 38 Batch 1000 Loss 0.0844\n",
      "Epoch 38 Batch 2000 Loss 0.0394\n",
      "Epoch 38 Batch 3000 Loss 0.1309\n",
      "Epoch 38 Batch 4000 Loss 0.0765\n",
      "Epoch 38 Batch 5000 Loss 0.0988\n",
      "Epoch 38 Batch 6000 Loss 0.1106\n",
      "Epoch 38 Batch 7000 Loss 0.1101\n",
      "Epoch 38 Loss 0.0859\n",
      "Time taken for 1 epoch 7007.719696044922 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.1234\n",
      "Epoch 39 Batch 1000 Loss 0.0503\n",
      "Epoch 39 Batch 2000 Loss 0.0916\n",
      "Epoch 39 Batch 3000 Loss 0.1332\n",
      "Epoch 39 Batch 4000 Loss 0.1458\n",
      "Epoch 39 Batch 5000 Loss 0.1493\n",
      "Epoch 39 Batch 6000 Loss 0.1500\n",
      "Epoch 39 Batch 7000 Loss 0.1779\n",
      "Epoch 39 Loss 0.0835\n",
      "Time taken for 1 epoch 6965.017096281052 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0797\n",
      "Epoch 40 Batch 1000 Loss 0.1210\n",
      "Epoch 40 Batch 2000 Loss 0.0898\n",
      "Epoch 40 Batch 3000 Loss 0.0986\n",
      "Epoch 40 Batch 4000 Loss 0.1376\n",
      "Epoch 40 Batch 5000 Loss 0.1822\n",
      "Epoch 40 Batch 6000 Loss 0.1783\n",
      "Epoch 40 Batch 7000 Loss 0.1183\n",
      "Epoch 40 Loss 0.0813\n",
      "Time taken for 1 epoch 7011.3406665325165 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0638\n",
      "Epoch 41 Batch 1000 Loss 0.0508\n",
      "Epoch 41 Batch 2000 Loss 0.0750\n",
      "Epoch 41 Batch 3000 Loss 0.1218\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# print(enc_hidden[0].shape, enc_hidden[1].shape)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, targ)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset\u001b[38;5;241m.\u001b[39mtake(steps_per_epoch)):\n\u001b[0;32m     11\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m train_step(inp, targ, enc_hidden)\n\u001b[0;32m     12\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n",
      "File \u001b[1;32m~\\Documents\\GitFiles\\Respondent_Recommendation\\Model\\.env\\seq2seq\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitFiles\\Respondent_Recommendation\\Model\\.env\\seq2seq\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitFiles\\Respondent_Recommendation\\Model\\.env\\seq2seq\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3010\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3011\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3012\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3013\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentence(sentence):\n",
    "    #sentence = dataset_creator.preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ') if i in inp_lang.word_index.keys()]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                          maxlen=max_length_input,\n",
    "                                                          padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    inference_batch_size = inputs.shape[0]\n",
    "    result = ''\n",
    "\n",
    "    enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
    "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
    "\n",
    "    dec_h = enc_h\n",
    "    dec_c = enc_c\n",
    "\n",
    "    start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<start>'])\n",
    "    end_token = targ_lang.word_index['<end>']\n",
    "\n",
    "    greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "\n",
    "    # Instantiate BasicDecoder object\n",
    "    decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc)\n",
    "    # Setup Memory in decoder stack\n",
    "    decoder.attention_mechanism.setup_memory(enc_out)\n",
    "    # set decoder_initial_state\n",
    "    decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n",
    "\n",
    "\n",
    "    ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n",
    "    ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n",
    "    ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n",
    "    decoder_embedding_matrix = decoder.embedding.variables[0]\n",
    "  \n",
    "    outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\n",
    "    return outputs.sample_id.numpy()\n",
    "\n",
    "\n",
    "def translate(sentence):\n",
    "    result = evaluate_sentence(sentence)\n",
    "    print(result)\n",
    "    result = targ_lang.sequences_to_texts(result)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "def translate_batch(sentence):\n",
    "    result = []\n",
    "    try:\n",
    "        result = evaluate_sentence(sentence)\n",
    "        #print(result)\n",
    "        result = targ_lang.sequences_to_texts(result)\n",
    "        #print('Input: %s' % (sentence))\n",
    "        #print('Predicted translation: {}'.format(result))\n",
    "    except:\n",
    "        result.append(\"Failed!!!!!!\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_calc(pred_tag, true_tag):\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    precision_avg = 0\n",
    "    recall_avg = 0\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    for ptag, ttag in zip(pred_tag, true_tag):\n",
    "        pred_set = set(ptag)\n",
    "        true_set = set(ttag)\n",
    "    \n",
    "        TP = len(pred_set.intersection(true_set))\n",
    "        FP = len(pred_set.difference(true_set))\n",
    "        FN = len(true_set.difference(pred_set))\n",
    "    \n",
    "        precision_avg += TP / (TP + FP)\n",
    "        recall_avg += TP / (TP + FN)\n",
    "        precision.append(TP / (TP + FP))\n",
    "        recall.append(TP / (TP + FN))\n",
    "        \n",
    "    precision_final = precision_avg / len(true_tag)\n",
    "    recall_final = recall_avg / len(true_tag)\n",
    "    \n",
    "    F1 = 2 * (precision_final * recall_final) / (precision_final + recall_final)\n",
    "    \n",
    "    print(\"precision:\",precision_final,\"recall:\",recall_final,\"f1:\",F1)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2452020e1c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 109  438 4337    3]]\n",
      "Input: rxj subject someon background doc subject href htt github com reactiv extens rxj blob master doc subject rel nofollow doc lanat background someon conc com someth\n",
      "Predicted translation: ['webpack rxjs flutter-animation <end>']\n"
     ]
    }
   ],
   "source": [
    "translate(u'rxj subject someon background doc subject href htt github com reactiv extens rxj blob master doc subject rel nofollow doc lanat background someon conc com someth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  34  443  126   34 3529    3]]\n",
      "Input: angular js directiv control code in case\n",
      "Predicted translation: ['angularjs gruntjs internet-explorer angularjs zone.js <end>']\n"
     ]
    }
   ],
   "source": [
    "translate(u'angular js directiv control code in case')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = \"evaluation/posdata_preprocessed/\"\n",
    "#file_list = os.listdir(path)\n",
    "file_list = [int(filename) for filename in os.listdir(path)]\n",
    "file_list = sorted(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issue_preprocessed = []\n",
    "\n",
    "for filename in file_list:\n",
    "    with open(path+str(filename), 'r') as f:\n",
    "        issue_preprocessed.append(f.readline())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tags_predicted = [translate_batch(u''+issue) for issue in issue_preprocessed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"evaluation/validation_stack.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_predicted = [translate_batch(u''+issue) for issue in list(df[\"processed_new\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tags_new\"] = tags_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"evaluation/validation_stack_result.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108489"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag = [tags_predicted[i][0][:-5].strip().split(' ') for i in range(len(tags_predicted))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['iphone', 'email', 'exchange-activesync', 'xpc', 'javascript-debugger'],\n",
       " ['macbook-pro', 'time-machine', 'macos'],\n",
       " ['iphone', 'passwords', 'encryption', 'pc'],\n",
       " ['macos', 'software-recommendation', 'software-rec', 'client-relations'],\n",
       " ['macbook-pro', 'encryption', '3rd-party'],\n",
       " ['iphone', 'software-recommendation', 'applications', 'layer', 'display'],\n",
       " ['macbook-pro', 'video', 'television', 'video-adapter'],\n",
       " ['macos', 'cocoa', 'lock-screen', 'unauthorizedaccessexcepti'],\n",
       " ['macos', 'snow-leopard', 'crash', 'hang'],\n",
       " ['macbook-pro', 'power']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tag[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tag = [item.strip().split(' ') for item in list(df[\"Tag_True\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['iphone', 'software-recommendation'],\n",
       " ['macbook-pro'],\n",
       " ['iphone', 'software-recommendation'],\n",
       " ['macos', 'software-recommendation', 'snow-leopard'],\n",
       " ['macbook-pro']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_tag[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108489"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.36040735312646655 recall: 0.3820356595292487 f1: 0.3709064763323706\n"
     ]
    }
   ],
   "source": [
    "prec,recall = f1_calc(pred_tag,true_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2,\n",
       " 0.3333333333333333,\n",
       " 0.25,\n",
       " 0.5,\n",
       " 0.3333333333333333,\n",
       " 0.6,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.5]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"precision\"] = prec\n",
    "df[\"recall\"] = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Tag_True</th>\n",
       "      <th>processed_new</th>\n",
       "      <th>Tags_new</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone App for Displaying Email on a Locked Sc...</td>\n",
       "      <td>iphone software-recommendation</td>\n",
       "      <td>iphon app displai email screen exchang support...</td>\n",
       "      <td>[iphone email exchange-activesync xpc javascri...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I tell when it's a good time to buy a ...</td>\n",
       "      <td>macbook-pro</td>\n",
       "      <td>tell time bui macbook want date instanc date g...</td>\n",
       "      <td>[macbook-pro time-machine macos &lt;end&gt;]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Password keeper for iPhone, Mac and Windows? &lt;...</td>\n",
       "      <td>iphone software-recommendation</td>\n",
       "      <td>password keeper iphon mac window solut sync ac...</td>\n",
       "      <td>[iphone passwords encryption pc &lt;end&gt;]</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good Newsgroup Client for OS X &lt;p&gt;I've just sw...</td>\n",
       "      <td>macos software-recommendation snow-leopard</td>\n",
       "      <td>newsgroup client x ve switch os x struggl find...</td>\n",
       "      <td>[macos software-recommendation software-rec cl...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there a slipcase for 17\" MacBook Pros which...</td>\n",
       "      <td>macbook-pro</td>\n",
       "      <td>slipcas macbook pro open side carri mbp pannie...</td>\n",
       "      <td>[macbook-pro encryption 3rd-party &lt;end&gt;]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input  \\\n",
       "0  iPhone App for Displaying Email on a Locked Sc...   \n",
       "1  How can I tell when it's a good time to buy a ...   \n",
       "2  Password keeper for iPhone, Mac and Windows? <...   \n",
       "3  Good Newsgroup Client for OS X <p>I've just sw...   \n",
       "4  is there a slipcase for 17\" MacBook Pros which...   \n",
       "\n",
       "                                     Tag_True  \\\n",
       "0              iphone software-recommendation   \n",
       "1                                 macbook-pro   \n",
       "2              iphone software-recommendation   \n",
       "3  macos software-recommendation snow-leopard   \n",
       "4                                 macbook-pro   \n",
       "\n",
       "                                       processed_new  \\\n",
       "0  iphon app displai email screen exchang support...   \n",
       "1  tell time bui macbook want date instanc date g...   \n",
       "2  password keeper iphon mac window solut sync ac...   \n",
       "3  newsgroup client x ve switch os x struggl find...   \n",
       "4  slipcas macbook pro open side carri mbp pannie...   \n",
       "\n",
       "                                            Tags_new  precision    recall  \n",
       "0  [iphone email exchange-activesync xpc javascri...   0.200000  0.500000  \n",
       "1             [macbook-pro time-machine macos <end>]   0.333333  1.000000  \n",
       "2             [iphone passwords encryption pc <end>]   0.250000  0.500000  \n",
       "3  [macos software-recommendation software-rec cl...   0.500000  0.666667  \n",
       "4           [macbook-pro encryption 3rd-party <end>]   0.333333  1.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"evaluation/validation_stack_result.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_evaluate_sentence(sentence, beam_width=3):\n",
    "  #sentence = dataset_creator.preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                          maxlen=max_length_input,\n",
    "                                                          padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "  inference_batch_size = inputs.shape[0]\n",
    "  result = ''\n",
    "\n",
    "  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
    "  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
    "\n",
    "  dec_h = enc_h\n",
    "  dec_c = enc_c\n",
    "\n",
    "  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<start>'])\n",
    "  end_token = targ_lang.word_index['<end>']\n",
    "\n",
    "  # From official documentation\n",
    "  # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
    "  # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
    "  # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
    "  # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
    "\n",
    "  enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\n",
    "  decoder.attention_mechanism.setup_memory(enc_out)\n",
    "  print(\"beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] :\", enc_out.shape)\n",
    "\n",
    "  # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
    "  hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)\n",
    "  decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)\n",
    "  decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\n",
    "\n",
    "  # Instantiate BeamSearchDecoder\n",
    "  decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoder.rnn_cell,beam_width=beam_width, output_layer=decoder.fc)\n",
    "  decoder_embedding_matrix = decoder.embedding.variables[0]\n",
    "\n",
    "  # The BeamSearchDecoder object's call() function takes care of everything.\n",
    "  outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, start_tokens=start_tokens, end_token=end_token, initial_state=decoder_initial_state)\n",
    "  # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
    "  # The final beam predictions are stored in outputs.predicted_id\n",
    "  # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
    "  # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
    "  # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
    "\n",
    "  \n",
    "  # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
    "  # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
    "  # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
    "  final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
    "  beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
    "  \n",
    "  return final_outputs.numpy(), beam_scores.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_translate(sentence):\n",
    "  result, beam_scores = beam_evaluate_sentence(sentence)\n",
    "  print(result.shape, beam_scores.shape)\n",
    "  for beam, score in zip(result, beam_scores):\n",
    "    print(beam.shape, score.shape)\n",
    "    output = targ_lang.sequences_to_texts(beam)\n",
    "    output = [a[:a.index('<end>')] for a in output]\n",
    "    beam_score = [a.sum() for a in score]\n",
    "    print('Input: %s' % (sentence))\n",
    "    for i in range(len(output)):\n",
    "      print('{} Predicted translation: {}  {}'.format(i+1, output[i], beam_score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'directiv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbeam_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mangular js directiv control code in case\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 2\u001b[0m, in \u001b[0;36mbeam_translate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbeam_translate\u001b[39m(sentence):\n\u001b[1;32m----> 2\u001b[0m   result, beam_scores \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_evaluate_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mshape, beam_scores\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m beam, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, beam_scores):\n",
      "Cell \u001b[1;32mIn[77], line 4\u001b[0m, in \u001b[0;36mbeam_evaluate_sentence\u001b[1;34m(sentence, beam_width)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbeam_evaluate_sentence\u001b[39m(sentence, beam_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m#sentence = dataset_creator.preprocess_sentence(sentence)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [inp_lang\u001b[38;5;241m.\u001b[39mword_index[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      5\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msequence\u001b[38;5;241m.\u001b[39mpad_sequences([inputs],\n\u001b[0;32m      6\u001b[0m                                                           maxlen\u001b[38;5;241m=\u001b[39mmax_length_input,\n\u001b[0;32m      7\u001b[0m                                                           padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(inputs)\n",
      "Cell \u001b[1;32mIn[77], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbeam_evaluate_sentence\u001b[39m(sentence, beam_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m#sentence = dataset_creator.preprocess_sentence(sentence)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\u001b[43minp_lang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      5\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msequence\u001b[38;5;241m.\u001b[39mpad_sequences([inputs],\n\u001b[0;32m      6\u001b[0m                                                           maxlen\u001b[38;5;241m=\u001b[39mmax_length_input,\n\u001b[0;32m      7\u001b[0m                                                           padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(inputs)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'directiv'"
     ]
    }
   ],
   "source": [
    "beam_translate(u'angular js directiv control code in case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "seq2seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
